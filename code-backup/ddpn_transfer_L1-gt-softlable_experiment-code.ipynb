{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make full use of the screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dongwenjian-ThinkPad-E460'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.uname()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongwenjian-ThinkPad-E460\n"
     ]
    }
   ],
   "source": [
    "computer_name = os.uname()[1]\n",
    "if computer_name == \"wenjian-desktop\":\n",
    "    fr_dataset_volume = \"3k\"\n",
    "    img_dir = \"/home/wenjian/Internship/data/flickr30kentities/flickr30k-images/\"  # For visualization\n",
    "    \n",
    "    features_dir = \"/home/wenjian/Internship/data/flickr30kentities/flickr30k-feats-otani/bottom-up-feats/\"\n",
    "    #features_dir = \"/home/wenjian/Internship/GitHubCloned/DDPN/data/flickr30k/features/bottom-up-feats-resnet101/\"\n",
    "\n",
    "    #train_image_list_filepath = \"/home/wenjian/Internship/data/flickr30kentities/Multi30k/task1/image_splits/train.txt\"\n",
    "    #train_triple_filepath = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries_fr_1000-images.csv\"\n",
    "    train_triple_filepath = f\"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries_fr_{fr_dataset_volume}-images.csv\"\n",
    "    train_triple_filepath_en = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries.csv\"\n",
    "\n",
    "    val_triple_filepath = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/val_queries_fr.csv\"\n",
    "    test_triple_filepath = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/test_2016_flickr_queries_fr.csv\"\n",
    "    \n",
    "    xml_dirpath = \"/home/wenjian/Internship/data/flickr30kentities/annotations/Annotations/\"\n",
    "\n",
    "    project_root = \"/home/wenjian/Internship/DDPN_transfer/\"\n",
    "    \n",
    "    english_pretrained_model_path = \"/home/wenjian/Internship/DDPN_transfer/pretrained-models/2019-08-17_19-26-48_L1-gt-softlabel_drop0.5_checkpoint_4_69.30.tar\"\n",
    "    specific_dictionary_file = \"/home/wenjian/Internship/data/word_allignment/lex.e2f\"  # The file name is e2f, but in fact it is f2e\n",
    "    general_dictionary_file = f\"/home/wenjian/Internship/DDPN_transfer/dictionary/Fr-En-GoogleTrans_dictionary{fr_dataset_volume}.txt\"\n",
    "    \n",
    "elif computer_name == \"apas\":\n",
    "    img_dir = \"/home/wenjian/data/flickr30kentities/flickr30k-images/\"  # For visualization\n",
    "    \n",
    "    features_dir = \"/home/wenjian/data/flickr30kentities/bottom-up-feats/\"\n",
    "    \n",
    "    #train_image_list_filepath = \"/home/wenjian/data/flickr30kentities/Multi30k/task1/image_splits/train.txt\"\n",
    "    #train_triple_filepath = \"/home/wenjian/data/flickr30kentities/queries_extracted/train_queries_fr_auto_3000.csv\"\n",
    "    train_triple_filepath = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries_fr_1000-images.csv\"\n",
    "    train_triple_filepath_en = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries.csv\"\n",
    "\n",
    "    val_triple_filepath = \"/home/wenjian/data/flickr30kentities/queries_extracted/val_queries_fr.csv\"\n",
    "\n",
    "    xml_dirpath = \"/home/wenjian/data/flickr30kentities/annotations/Annotations/\"\n",
    "\n",
    "    project_root = None\n",
    "    \n",
    "    english_pretrained_model_path = None\n",
    "    dictionary_file = None\n",
    "    general_dictionary_file = None\n",
    "    \n",
    "elif computer_name == \"dongwenjian-ThinkPad-E460\":\n",
    "    fr_dataset_volume = \"5k\"\n",
    "    img_dir = \"/media/dongwenjian/SSDBACKUP/Internship/data/flickr30kentities/flickr30k-images/\"  # For visualization\n",
    "    \n",
    "    features_dir = \"/media/dongwenjian/SSDBACKUP/Internship/data/flickr30kentities/flickr30k-feats-otani/bottom-up-feats/\"\n",
    "    #features_dir = \"/home/wenjian/Internship/GitHubCloned/DDPN/data/flickr30k/features/bottom-up-feats-resnet101/\"\n",
    "\n",
    "    #train_image_list_filepath = \"/home/wenjian/Internship/data/flickr30kentities/Multi30k/task1/image_splits/train.txt\"\n",
    "    #train_triple_filepath = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries_fr_1000-images.csv\"\n",
    "    train_triple_filepath = f\"/media/dongwenjian/SSDBACKUP/newly_added/data/flickr30kentities/queries_extracted/train_queries_fr_{fr_dataset_volume}-images.csv\"\n",
    "    train_triple_filepath_en = \"/media/dongwenjian/SSDBACKUP/newly_added/data/flickr30kentities/queries_extracted/train_queries.csv\"\n",
    "\n",
    "    val_triple_filepath = \"/media/dongwenjian/SSDBACKUP/newly_added/data/flickr30kentities/queries_extracted/val_queries_fr.csv\"\n",
    "    test_triple_filepath = \"/media/dongwenjian/SSDBACKUP/newly_added/data/flickr30kentities/queries_extracted/test_2016_flickr_queries_fr.csv\"\n",
    "    \n",
    "    xml_dirpath = \"/media/dongwenjian/SSDBACKUP/Internship/data/flickr30kentities/annotations/Annotations/\"\n",
    "\n",
    "    project_root = \"/media/dongwenjian/SSDBACKUP/newly_added/new_experiments/\"\n",
    "    \n",
    "    english_pretrained_model_path = \"/media/dongwenjian/SSDBACKUP/Internship/DDPN_transfer/pretrained-models/2019-08-17_19-26-48_L1-gt-softlabel_drop0.5_checkpoint_4_69.30.tar\"\n",
    "    specific_dictionary_file = \"/media/dongwenjian/SSDBACKUP/Internship/data/word_allignment/lex.e2f\"  # The file name is e2f, but in fact it is f2e\n",
    "    general_dictionary_file = f\"/media/dongwenjian/SSDBACKUP/newly_added/new_experiments/dictionary/Fr-En-GoogleTrans_dictionary{fr_dataset_volume}.txt\"\n",
    "    \n",
    "else:\n",
    "    raise Exception(\"Failed to initialize paths: computer not recognized\")\n",
    "print(computer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self):\n",
    "        # cfg_path for future use\n",
    "        self.xml_dirpath = xml_dirpath\n",
    "        self.triple_filepaths = {'train': train_triple_filepath,\n",
    "                                 'val': val_triple_filepath,\n",
    "                                 'test': test_triple_filepath\n",
    "                                }\n",
    "        self.RPN_TOPN = 100\n",
    "        \n",
    "        # Configure for network\n",
    "        self.WORD_EMB_SIZE = 300\n",
    "        self.RNN_DIM = 1024\n",
    "        self.VISUAL_FEATURES = 2048  # For resnet\n",
    "        self.SPATIAL_FEATURES = 5\n",
    "        self.SOFTLABEL_THRESHOLD = 0.5 # 0.5 in paper\n",
    "        self.GAMMA = 1\n",
    "        self.DELTA = 1\n",
    "        self.STEMMING = False\n",
    "        self.epsilon = 1e-7\n",
    "        self.dropout_rate = 0.5\n",
    "        self.lr_decay_rate = 0.7\n",
    "        self.initial_lr = 0.001\n",
    "        self.use_pretrained_word_embedding = None  # candidate: None, \"GloVe\"\n",
    "        #self.use_pretrained_model = False\n",
    "        self.regression_loss = False\n",
    "        self.transfer_learning = True\n",
    "        \n",
    "         \n",
    "        # At the beginning those paths are not wrapped and they exist as global variables. \n",
    "        # Then in order to wrap the training, validation and test process into functions, we need to avoid global variables. \n",
    "        # Thus we begin to wrap more things into CFG.\n",
    "        # It should be noticed that, the part before training are not adapted yet, thus for the following variables they may still use the original global variables\n",
    "        \n",
    "        # The paths \n",
    "        self.fr_dataset_volume = fr_dataset_volume\n",
    "        self.img_dir = img_dir\n",
    "        self.features_dir = features_dir\n",
    "\n",
    "        self.train_triple_filepath_en = train_triple_filepath_en\n",
    "        \n",
    "        self.project_root = project_root \n",
    "        \n",
    "        self.english_pretrained_model_path = english_pretrained_model_path\n",
    "        self.general_dictionary_file = general_dictionary_file\n",
    "        self.specific_dictionary_file = specific_dictionary_file\n",
    "        \n",
    "        # The file names to store the training process\n",
    "        self.pth_filename = None\n",
    "        self.checkpoint_filename_base = None\n",
    "        self.process_filename = None\n",
    "        self.pytorch_model_save_path = None\n",
    "        self.pytorch_result_save_path = None\n",
    "        self.pytorch_checkpoint_save_path = None\n",
    "        self.output_root = None\n",
    "        self.output_dir_name = None\n",
    "        self.output_dir = None\n",
    "        self.log_dir = None\n",
    "        # Here we create them as None just as a reminder that those variables will be involved later. \n",
    "        \n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_imageID_list = []\n",
    "# with open(train_image_list_filepath, 'r') as f:\n",
    "#     l = f.readline()\n",
    "#     while l :\n",
    "#         train_imageID_list.append(l.split('.')[0])\n",
    "#         l = f.readline()\n",
    "# print(len(train_imageID_list))\n",
    "# print(train_imageID_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish vocabulary dictionary from training set: French   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_triple_filepath)\n",
    "#stemmer = SnowballStemmer(\"english\")\n",
    "corpus_list = train_df[\"entity_content\"].values.tolist()\n",
    "corpus_list = ['EMPTYWORDTOKEN', 'UNKNOWNWORD'] + corpus_list  # 'EMPTYWORDTOKEN' is the token for empty word. It is needed because the input data for word embedding layer require padding. \n",
    "\n",
    "if cfg.STEMMING:\n",
    "    corpus = [[stemmer.stem(w) for w in word_tokenize(q, language=\"french\")] for q in corpus_list]\n",
    "else: \n",
    "    corpus = [[w.lower() for w in word_tokenize(q, language=\"french\")] for q in corpus_list]\n",
    "# corpus is a list of list of string\n",
    "\n",
    "training_corpus_dct = gensim.corpora.Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMPTYWORDTOKEN',\n",
       " 'UNKNOWNWORD',\n",
       " 'deux jeunes hommes blancs',\n",
       " 'de buissons',\n",
       " 'plusieurs hommes',\n",
       " 'casque',\n",
       " 'un système de poulies géant',\n",
       " 'une petite fille',\n",
       " 'une maisonnette en bois',\n",
       " 'un homme',\n",
       " 'une chemise bleue',\n",
       " 'une échelle',\n",
       " 'une fenêtre',\n",
       " 'deux hommes',\n",
       " 'fourneaux',\n",
       " 'un homme',\n",
       " 'vert',\n",
       " 'une guitare',\n",
       " 'un autre homme',\n",
       " 'sa chemise',\n",
       " 'un homme',\n",
       " 'un ours en peluche',\n",
       " 'une fille branchée',\n",
       " 'son portable',\n",
       " 'la rue',\n",
       " 'une femme',\n",
       " 'un gros sac',\n",
       " 'une porte',\n",
       " 'des garçons',\n",
       " 'des barres',\n",
       " 'une classe de ballet , composée de cinq filles',\n",
       " 'quatre gars',\n",
       " 'des chapeaux',\n",
       " \"haut d' un escalier\",\n",
       " 'un chien noir',\n",
       " 'un chien à tâches',\n",
       " 'un homme',\n",
       " 'uniforme orange',\n",
       " 'un tracteur vert',\n",
       " 'plusieurs femmes',\n",
       " 'une femme',\n",
       " 'un haut noir',\n",
       " 'des lunettes',\n",
       " 'sucre',\n",
       " 'un bundt cake',\n",
       " 'une petite fille',\n",
       " 'un grand arc-en-ciel peint',\n",
       " 'un homme',\n",
       " 'un banc [',\n",
       " 'un chien blanc',\n",
       " 'cinq personnes',\n",
       " 'cercle',\n",
       " 'leurs instruments',\n",
       " 'un groupe de femmes âgées',\n",
       " 'la clarinette [',\n",
       " 'leur partition',\n",
       " 'une grande structure',\n",
       " 'la chaussée',\n",
       " 'une importante foule de gens',\n",
       " 'un homme',\n",
       " 'son dos',\n",
       " 'deux enfants',\n",
       " 'un petit manège à bascule',\n",
       " 'le sable',\n",
       " 'un homme',\n",
       " 'un gilet réfléchissant',\n",
       " 'un casque',\n",
       " 'un drapeau',\n",
       " 'la route',\n",
       " 'une personne',\n",
       " 'un manteau bleu',\n",
       " 'un trottoir encombré',\n",
       " 'une peinture représentant une scène de rue',\n",
       " 'un homme',\n",
       " 'un pantalon vert',\n",
       " 'la route',\n",
       " 'le petit enfant',\n",
       " 'rouge',\n",
       " 'un jeune homme',\n",
       " 'une veste noire et jaune',\n",
       " 'un homme',\n",
       " 'un urinoir',\n",
       " 'une tasse de café',\n",
       " 'cinq personnes',\n",
       " 'un vieil homme',\n",
       " 'une bière',\n",
       " 'un chien policier dressé',\n",
       " 'son maître',\n",
       " 'un fourgon de police',\n",
       " 'une personne',\n",
       " 'vélo',\n",
       " 'une route enneigée',\n",
       " 'cinq hommes',\n",
       " 'chemise blanche',\n",
       " 'une cravate',\n",
       " 'un pantalon noir',\n",
       " \"l' arrière d' un fourgon ouvert\",\n",
       " 'un homme',\n",
       " 'un chapeau',\n",
       " 'des machines',\n",
       " 'une femme noire',\n",
       " 'un homme blanc',\n",
       " 'de bougies [',\n",
       " 'des cartons',\n",
       " 'un asiatique',\n",
       " 'le trottoir',\n",
       " 'un homme',\n",
       " 'une voiture',\n",
       " 'conducteur',\n",
       " 'deux jeunes bambins',\n",
       " 'des gens',\n",
       " 'une personne',\n",
       " 'un étrange véhicule',\n",
       " 'un homme',\n",
       " 'un véhicule argenté',\n",
       " 'une belle mariée',\n",
       " 'le trottoir',\n",
       " 'son nouveau mari',\n",
       " 'un petit garçon',\n",
       " 'la gamecube',\n",
       " 'un mcdonald',\n",
       " 'un chien blanc',\n",
       " 'le bord de la plage',\n",
       " 'une balle orange',\n",
       " 'un groupe de gens',\n",
       " 'un homme',\n",
       " 'lunettes de soleil',\n",
       " \"d' une femme\",\n",
       " 'chemisier blanc',\n",
       " 'des gens',\n",
       " 'un homme',\n",
       " 'un chapeau en ballons',\n",
       " 'des tables de picnic',\n",
       " 'un garçon',\n",
       " 'trois enfants',\n",
       " 'du bois',\n",
       " 'un garçon',\n",
       " 'une veste rouge',\n",
       " \"l' eau\",\n",
       " 'un homme',\n",
       " 'chemise blanche',\n",
       " 'un homme',\n",
       " 'une veste rouge',\n",
       " 'un morceau de papier',\n",
       " 'des hommes',\n",
       " 'la rue',\n",
       " 'des enfants',\n",
       " 'un petit garçon',\n",
       " 'la rue',\n",
       " 'un homme',\n",
       " 'salopette',\n",
       " 'un mur de pierre',\n",
       " 'un chien noir',\n",
       " 'une bûche',\n",
       " 'un homme',\n",
       " 'costume',\n",
       " 'deux autres messieurs',\n",
       " 'un costume',\n",
       " 'un homme',\n",
       " 'une chemise rouge',\n",
       " 'vélo',\n",
       " \"l' eau\",\n",
       " 'un homme , pieds nus',\n",
       " 'un fort vert olive',\n",
       " 'des hotdogs',\n",
       " 'un petit réchaud',\n",
       " 'une tasse de plastique bleu',\n",
       " 'un chien',\n",
       " 'la neige',\n",
       " 'une foule',\n",
       " \"l' homme\",\n",
       " 'skis',\n",
       " 'les illustrations',\n",
       " 'la neige',\n",
       " 'sept alpinistes',\n",
       " \"d' un rocher\",\n",
       " 'un autre homme',\n",
       " 'une corde',\n",
       " \"la corps souple d' une jeune gymnaste\",\n",
       " \"la poutre d' équilibre\",\n",
       " 'un jeune garçon',\n",
       " 'un jouet atv',\n",
       " \"d' une piscine en caoutchouc\",\n",
       " 'une femme',\n",
       " 'coupe-vent rouge',\n",
       " 'un homme',\n",
       " 'un objet rouge [',\n",
       " 'un avion',\n",
       " 'un chien',\n",
       " 'un tuyau',\n",
       " 'un homme',\n",
       " 'une petite fille',\n",
       " 'leur chariot',\n",
       " 'un chien blanc',\n",
       " 'un jouet pour chiens jaune',\n",
       " 'un type',\n",
       " 'chemise verte',\n",
       " 'la main',\n",
       " 'une partie de son visage',\n",
       " 'un restaurant',\n",
       " 'un chien noir et blanc',\n",
       " 'un jouet jaune',\n",
       " 'deux randonneurs',\n",
       " 'un morceau de neige',\n",
       " 'un homme',\n",
       " 'sa nouvelle création en bois',\n",
       " 'un père âgé',\n",
       " 'son fils adulte',\n",
       " 'un voyageur barbu',\n",
       " 'une chemise rouge',\n",
       " 'une carte',\n",
       " 'un jeune garçon',\n",
       " 'un canard',\n",
       " \"d' eau\",\n",
       " 'un parc vert',\n",
       " 'un couple',\n",
       " \"l' herbe\",\n",
       " 'un bébé',\n",
       " 'une poussette',\n",
       " 'quelques hommes',\n",
       " 'un immeuble',\n",
       " 'une voiture en stationnement',\n",
       " 'le chien noir',\n",
       " \"l' eau\",\n",
       " 'un homme',\n",
       " \"la glace d' un étang gelé\",\n",
       " 'deux chiens beiges imposants',\n",
       " 'une plage de sable',\n",
       " 'une personne',\n",
       " 'bleu et rouge',\n",
       " 'deux pics à glace',\n",
       " 'trois personnes',\n",
       " 'un chemin',\n",
       " 'un homme',\n",
       " 'costume noir fait des pelletées de neige',\n",
       " 'la rue',\n",
       " 'un couple',\n",
       " 'leur gâteau de mariage',\n",
       " 'un chien noir mouillé',\n",
       " 'un jouet vert',\n",
       " \"l' herbe\",\n",
       " 'des villageois',\n",
       " 'leur récolte',\n",
       " 'un homme',\n",
       " 'blanc',\n",
       " 'du chanteur [',\n",
       " 'un t-shirt jaune',\n",
       " 'un garçon',\n",
       " 'son skateboard',\n",
       " 'une foule',\n",
       " \"l' eau\",\n",
       " 'un homme',\n",
       " 'un bébé',\n",
       " 'un kayak jaune',\n",
       " 'deux personnes',\n",
       " 'un banc',\n",
       " 'une femme',\n",
       " 'un chantier de construction',\n",
       " 'la rue',\n",
       " 'trois hommes',\n",
       " 'deux hommes',\n",
       " 'un banc',\n",
       " 'un panneau publicitaire',\n",
       " 'des lunettes',\n",
       " 'un groupe de jeunes',\n",
       " 'la rue',\n",
       " 'des drapeaux',\n",
       " 'trois hommes',\n",
       " 'un autre',\n",
       " 'le poisson',\n",
       " 'une femme',\n",
       " 'un débardeur blanc',\n",
       " 'une jupe [',\n",
       " 'deux hommes',\n",
       " 'deux femmes',\n",
       " 'des marches en extérieur',\n",
       " 'un jouet',\n",
       " 'sa bouche',\n",
       " 'un gardien de but de hockey',\n",
       " 'veste rouge',\n",
       " \"l' objectif\",\n",
       " 'le bâton',\n",
       " \"l' homme\",\n",
       " 'le sac à dos',\n",
       " 'une cour de bâtiment',\n",
       " \"une sculpture d' art.\",\n",
       " 'un tout petit',\n",
       " 'un chapeau rouge',\n",
       " 'un garde-corps',\n",
       " 'trois chiens',\n",
       " 'un champ herbeux',\n",
       " 'une personne',\n",
       " 'un homme',\n",
       " 'un gratte-ciel',\n",
       " 'une femme',\n",
       " 'son bébé',\n",
       " 'une poussette',\n",
       " 'un homme',\n",
       " 'une chemise rouge',\n",
       " 'des fruits',\n",
       " 'un jeune garçon blond',\n",
       " 'une fille aux cheveux noirs',\n",
       " 'une table pour les enfants',\n",
       " 'le garçon',\n",
       " 'sa nourriture',\n",
       " 'la table',\n",
       " 'un homme',\n",
       " 'noir',\n",
       " 'une guitare électrique',\n",
       " 'une fille',\n",
       " 'la balle',\n",
       " 'un homme',\n",
       " 'chemise noire',\n",
       " 'une guitare de couleur noire',\n",
       " 'un homme',\n",
       " 'une chemise noire',\n",
       " 'le béton',\n",
       " 'une femme',\n",
       " 'chemise blanche',\n",
       " 'une table',\n",
       " 'une femme',\n",
       " 'une couverture rouge',\n",
       " 'un homme solitaire',\n",
       " 'un pont',\n",
       " 'un enfant',\n",
       " 'un homme',\n",
       " 'son chien',\n",
       " 'les haricots verts',\n",
       " 'un barbecue',\n",
       " 'trois personnes',\n",
       " 'un rebord',\n",
       " 'une montagne',\n",
       " 'plusieurs personnes',\n",
       " 'une passerelle très grande',\n",
       " 'un jeune garçon',\n",
       " 'deux petites filles',\n",
       " 'un vieil homme [',\n",
       " 'homme asiatique',\n",
       " 'une femme blonde',\n",
       " \"la main à l' extérieur\",\n",
       " \"l' homme\",\n",
       " 'un homme âgé',\n",
       " 'cheveux gris',\n",
       " 'une chaise',\n",
       " 'un grand instrument',\n",
       " 'bambou',\n",
       " 'un homme',\n",
       " 'chemise blanche',\n",
       " 'un vélo',\n",
       " 'une rue très fréquentée',\n",
       " 'un homme',\n",
       " 'une échelle peinture',\n",
       " 'un homme de plus de 30 ans',\n",
       " 'deux femmes',\n",
       " 'un groupe de gens',\n",
       " 'des nouilles',\n",
       " 'une femme',\n",
       " 'un bol',\n",
       " 'de fruits',\n",
       " 'la tête [',\n",
       " 'un gars',\n",
       " 'bleu',\n",
       " 'un trou',\n",
       " 'quatre enfants',\n",
       " 'un vélo [',\n",
       " 'deux individus',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'une baignoire',\n",
       " 'un bébé dort',\n",
       " 'un costume rose rayé',\n",
       " \"un membre d' une tribu africaine\",\n",
       " 'robe tribale',\n",
       " 'un guerrier samouraï',\n",
       " 'robe noire',\n",
       " 'son épée',\n",
       " 'fourreau',\n",
       " \"un tapis d' entraînement à l' extérieur\",\n",
       " 'plusieurs jeunes',\n",
       " 'un rail',\n",
       " 'cinq randonneurs',\n",
       " 'un',\n",
       " 'les autres',\n",
       " 'une rivière rocheuse',\n",
       " 'un agent de sécurité',\n",
       " 'une sculpture [',\n",
       " 'deux femmes',\n",
       " 'une',\n",
       " 'vert',\n",
       " \"l' autre\",\n",
       " 'pourpre',\n",
       " 'un trottoir',\n",
       " 'deux filles',\n",
       " 'de quelques buissons',\n",
       " 'téléphone',\n",
       " 'une jeune fille',\n",
       " 'en multicolore',\n",
       " 'une boule orange',\n",
       " 'sa main droite',\n",
       " 'un herbe vert',\n",
       " 'une maison',\n",
       " 'un enfant',\n",
       " 'un jouet',\n",
       " 'le sol',\n",
       " 'un jeune planchiste',\n",
       " 'sa planche',\n",
       " 'un autre',\n",
       " 'deux enfants',\n",
       " \"l' herbe\",\n",
       " 'une jeune femme',\n",
       " 'une bouteille',\n",
       " 'un banc',\n",
       " \"la main d' un homme\",\n",
       " 'un pilote',\n",
       " 'son talkie-walkie',\n",
       " 'une fille',\n",
       " 'une grande rivière',\n",
       " 'une',\n",
       " 'des nattes',\n",
       " \"l' eau\",\n",
       " 'un couple',\n",
       " 'des pulls blancs',\n",
       " 'une table de restaurant',\n",
       " 'un repas',\n",
       " 'une table',\n",
       " 'deux ouvriers du bâtiment [',\n",
       " 'une poutre en acier',\n",
       " 'un enfant',\n",
       " 'un bol',\n",
       " 'deux enfants',\n",
       " 'un ballon',\n",
       " 'la boue',\n",
       " 'une petite fille',\n",
       " 'une brochure',\n",
       " 'deux femmes',\n",
       " 'des gens',\n",
       " \"le trottoir d' un parc\",\n",
       " 'un petit enfant',\n",
       " 'un grand plongeoir',\n",
       " 'la piscine',\n",
       " 'un chien de couleur claire',\n",
       " 'la plage',\n",
       " 'un homme',\n",
       " \"une bassine d' eau en bois\",\n",
       " 'un fruit',\n",
       " 'un homme',\n",
       " 'un banc',\n",
       " 'un arrêt de bus',\n",
       " 'une petite fille',\n",
       " 'chemise rouge',\n",
       " 'jean',\n",
       " 'un petit arbre',\n",
       " 'un autre petite fille',\n",
       " 'un homme',\n",
       " 'une voiture [',\n",
       " 'une femme',\n",
       " 'un t-shirt rouge',\n",
       " 'une couverture',\n",
       " 'un homme',\n",
       " 'une crêpe',\n",
       " 'plusieurs pompiers',\n",
       " 'plusieurs pompiers',\n",
       " 'un bâtiment',\n",
       " 'leurs camions',\n",
       " 'une plage',\n",
       " 'des gens',\n",
       " 'le rivage',\n",
       " 'des hommes',\n",
       " 'des casques',\n",
       " 'des gilets de sécurité',\n",
       " 'un vendeur de magazines',\n",
       " 'un collage très coloré de magazines',\n",
       " 'un homme',\n",
       " 'un casque',\n",
       " 'un t-shirt bleu',\n",
       " 'une salopette en jean bleue',\n",
       " 'la boulangerie',\n",
       " 'son apprenti',\n",
       " \"un groupe d' hommes torse nu\",\n",
       " \"l' ombre\",\n",
       " 'une plage tropicale',\n",
       " 'un garçon',\n",
       " 'son short de bain bleu',\n",
       " 'un skieur',\n",
       " 'une montagne enneigée',\n",
       " 'un garçon',\n",
       " 'une chemise rouge',\n",
       " 'vélo juste',\n",
       " 'un monticule de terre',\n",
       " 'des coureurs',\n",
       " 'trois garçons',\n",
       " 'un tas de sable',\n",
       " 'milieu',\n",
       " 'un homme âgé',\n",
       " 'une canne',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'un médecin',\n",
       " 'des infirmières',\n",
       " 'blouses bleues',\n",
       " 'un chien noir et blanc',\n",
       " 'un jouet jaune',\n",
       " 'un chien laineux',\n",
       " 'un doberman',\n",
       " 'un homme',\n",
       " 'une boule de bowling',\n",
       " 'une piste',\n",
       " 'un vieil homme ridé , barbu',\n",
       " 'noir',\n",
       " 'un magnifique âne blanc',\n",
       " 'des rochers blancs',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'un canapé bleu',\n",
       " 'un homme',\n",
       " 'un maillot jaune',\n",
       " 'un javelot',\n",
       " 'une piste',\n",
       " 'une foule',\n",
       " 'des montgolfières',\n",
       " 'une femme',\n",
       " 'un magazine',\n",
       " \"l' épaule d' une autre femme\",\n",
       " 'deux hommes',\n",
       " 'allumer des bougies',\n",
       " 'un jeune homme',\n",
       " 'un centre commercial',\n",
       " 'le petit garçon',\n",
       " 'vélo',\n",
       " 'un groupe de gens',\n",
       " 'une table',\n",
       " 'une pièce sombre',\n",
       " 'un homme',\n",
       " 'deux chiens',\n",
       " 'une plage',\n",
       " 'un garçon',\n",
       " 'de mousse',\n",
       " 'le visage',\n",
       " 'des dizaines de personnes',\n",
       " 'une jeune femme',\n",
       " 'un bikini de couleur claire',\n",
       " 'un homme',\n",
       " 'un chapeau de cowboy en paille',\n",
       " 'un garçon',\n",
       " 'un toboggan',\n",
       " 'une piscine',\n",
       " 'des tubes colorés',\n",
       " 'un homme',\n",
       " 'une combinaison de plongée',\n",
       " 'un tout-petit',\n",
       " 'un groupe de personnes',\n",
       " \"l' arrière d' un camion\",\n",
       " 'la route',\n",
       " 'une zone rurale',\n",
       " 'deux chefs',\n",
       " 'des hamburgers',\n",
       " \"la cuisine d' un restaurant\",\n",
       " 'deux jeunes garçons',\n",
       " 'des grimaces',\n",
       " 'une personne',\n",
       " 'un pantalon brun',\n",
       " 'étincelles',\n",
       " 'une femme',\n",
       " 'une colline',\n",
       " 'une croix blanche',\n",
       " 'une plage',\n",
       " 'quatre filles',\n",
       " \"l' herbe\",\n",
       " 'plusieurs hommes',\n",
       " 'des hommes [',\n",
       " 'chemin de fer',\n",
       " 'un homme',\n",
       " 'une fille',\n",
       " 'deux chevaux',\n",
       " 'un feu contenu',\n",
       " 'des travailleurs',\n",
       " 'des gilets réfléchissants',\n",
       " 'un wagon',\n",
       " 'un vieil homme',\n",
       " 'une classique , rustique , volkswagen beetle',\n",
       " 'une femme',\n",
       " 'une armature en métal blanc',\n",
       " 'le trottoir',\n",
       " 'trois chiens',\n",
       " 'une balle',\n",
       " 'un homme sans t-shirt',\n",
       " 'une femme',\n",
       " 'un ponton',\n",
       " 'des hommes',\n",
       " 'gilets de sécurité',\n",
       " 'une piste',\n",
       " 'un homme',\n",
       " 'son matériel',\n",
       " 'une femme',\n",
       " 'cheveux rouge',\n",
       " 'mascara',\n",
       " 'ces cils',\n",
       " 'un chien blanc',\n",
       " 'sa tête',\n",
       " 'une femme',\n",
       " 'short bleu',\n",
       " 't-shirt blanc',\n",
       " \"un rocher d' intérieur\",\n",
       " 'beaucoup de scooters',\n",
       " \"l' hélicoptère de la police du parc régional\",\n",
       " 'un homme',\n",
       " 'un gilet réfléchissant [',\n",
       " 'un échaffaudage',\n",
       " 'un groupe de quatorze personnes',\n",
       " 'une pièce',\n",
       " 'des tables pour diner',\n",
       " 'une scène',\n",
       " 'un adolescent',\n",
       " 'un toboggan gonflable',\n",
       " 'une famille',\n",
       " 'un tracteur',\n",
       " 'une vieille femme',\n",
       " 'des aliments',\n",
       " 'une cuisine',\n",
       " 'deux jeunes gens',\n",
       " 'une flamboyante jeune femme',\n",
       " 'un bikini rouge',\n",
       " 'une coiffe à plume rouge',\n",
       " 'deux skieurs',\n",
       " 'des skieurs',\n",
       " \"sommet d' une colline couverte de neige\",\n",
       " 'un chien brun',\n",
       " \"l' herbe\",\n",
       " 'une femme',\n",
       " 't-shirt vert',\n",
       " 'jean',\n",
       " 'un rebord',\n",
       " 'du café',\n",
       " 'la main',\n",
       " 'son sac',\n",
       " 'une grande porte',\n",
       " 'un document',\n",
       " 'des personnes',\n",
       " 'une femme',\n",
       " 'violet clair',\n",
       " 'un corsage',\n",
       " 'ses mains',\n",
       " 'ses genoux',\n",
       " 'une mère',\n",
       " 'ses enfants',\n",
       " 'une promenade [',\n",
       " 'six hommes',\n",
       " 'le sable',\n",
       " 'des palettes en bois',\n",
       " 'une femme',\n",
       " 'débardeur vert',\n",
       " 'trois enfants',\n",
       " 'un homme',\n",
       " 't-shirt noir',\n",
       " 'pantalon noir',\n",
       " \"le moteur d' une vieille automobile vert antique\",\n",
       " 'un jerrican jaune',\n",
       " \"l' herbe\",\n",
       " 'une femme',\n",
       " 'veste bleue',\n",
       " 'un poney brun',\n",
       " \"l' eau\",\n",
       " 'deux chevaux',\n",
       " 'une charette',\n",
       " 'une femme',\n",
       " 'une personne',\n",
       " 'une falaise',\n",
       " 'une corde',\n",
       " 'le groupe de randonneurs',\n",
       " 'une montagne',\n",
       " 'une femme',\n",
       " 'la craie',\n",
       " 'trois jeunes adultes',\n",
       " 'la fille',\n",
       " 'frapper un des garçons',\n",
       " 'le visage',\n",
       " 'le garçon',\n",
       " \"un groupe d' enfants\",\n",
       " 'les mains',\n",
       " 'un homme',\n",
       " 'un maillot',\n",
       " 'une plateforme de béton',\n",
       " \"une vaste étendue d' eau\",\n",
       " 'une femme',\n",
       " 'une machine à coudre',\n",
       " 'une femme',\n",
       " 'un t-shirt bland',\n",
       " 'une personne',\n",
       " 'une fille',\n",
       " 'un marché vendant',\n",
       " 'poivrons',\n",
       " 'une femme agée',\n",
       " 'une chaine',\n",
       " 'une canne',\n",
       " 'la main',\n",
       " 'un garçon',\n",
       " '4 bulles',\n",
       " 'un pré',\n",
       " 'un petit garçon',\n",
       " \"l' eau\",\n",
       " 'un chien',\n",
       " 'un tunnel',\n",
       " 'un chien jaune',\n",
       " 'un chien noir et blanc',\n",
       " 'la poussière',\n",
       " 'deux hommes',\n",
       " 'la plage',\n",
       " 'une petite fille',\n",
       " 'maillot de bain imprimé fleuri',\n",
       " 'une petite fille',\n",
       " 'maillot de bain',\n",
       " 'une poutre',\n",
       " 'la plage',\n",
       " 'un jeune garçon asiatique',\n",
       " 'une barrière',\n",
       " 'une rangée de casquettes colorées',\n",
       " 'un chien noir et blanc',\n",
       " 'une piscine',\n",
       " 'les garçons',\n",
       " 'deux personnes [',\n",
       " 'plusieurs personnes',\n",
       " 'une sortie en moto-neige',\n",
       " 'deux personnes',\n",
       " 'la neige',\n",
       " 'un jeune homme',\n",
       " 'un t-shirt noir',\n",
       " 'une chaise pliante',\n",
       " 'une grande pile',\n",
       " 'une femme',\n",
       " 'une rue en ville',\n",
       " 'une petite fille',\n",
       " 'des cheveux bruns',\n",
       " 'les pétales',\n",
       " 'une fleur',\n",
       " 'trois personnes',\n",
       " \"un quad à l' extérieur\",\n",
       " 'un homme',\n",
       " 'un quad',\n",
       " 'un homme',\n",
       " 'un quad',\n",
       " 'un petit bâtiment',\n",
       " 'une femme',\n",
       " 'cheveux foncés',\n",
       " 'un bikini',\n",
       " 'la plage',\n",
       " 'deux mains',\n",
       " 'de nourriture',\n",
       " 'une poêle en fer',\n",
       " 'une spatule',\n",
       " 'deux femmes',\n",
       " \"un champs entouré d' une barrière\",\n",
       " 'une vache',\n",
       " 'un gros bateau',\n",
       " 'la jetée',\n",
       " 'deux hommes',\n",
       " 'un homme',\n",
       " 'des sandales',\n",
       " 'un cardigan blanc',\n",
       " 'un banc vert',\n",
       " 'son téléphone portable',\n",
       " 'un homme',\n",
       " 'scène',\n",
       " 'un micro',\n",
       " 'three mecs',\n",
       " 'un éléphant',\n",
       " 'une structure en forme de maison',\n",
       " 'des arbres',\n",
       " 'un homme mexicain',\n",
       " 'le capot de son camion',\n",
       " 'un garçon',\n",
       " 'des lunettes jaunes',\n",
       " 'une fille rousse',\n",
       " 'un groupe de gens',\n",
       " 'différents types de drapeaux',\n",
       " 'un petit garçon blanc',\n",
       " 'un jouet renversé',\n",
       " 'petit garçon',\n",
       " 'un ballon de foot',\n",
       " 'un terrain',\n",
       " 'une femme',\n",
       " 'un mec',\n",
       " 'un congélateur',\n",
       " 'un groupe de gens',\n",
       " 'des tabourets',\n",
       " 'des gens',\n",
       " 'un drapeau américain [',\n",
       " 'une jeune fille',\n",
       " 'la peinture',\n",
       " 'un cycliste',\n",
       " 'vélo',\n",
       " 'une route en virage',\n",
       " 'une coline',\n",
       " 'une petite fille',\n",
       " 'en jeans',\n",
       " 'un champs',\n",
       " 'homme',\n",
       " 'une chemise bleu',\n",
       " 'un pantalon noir',\n",
       " 'un de ses pouces',\n",
       " 'des lunettes',\n",
       " 'son autre main',\n",
       " 'un couple',\n",
       " 'un escalator',\n",
       " 'un joueur de football',\n",
       " 'maillot vert',\n",
       " 'un ballon',\n",
       " 'les mains',\n",
       " 'quelques uns de ses coéquipiers',\n",
       " 'un joueur adverse',\n",
       " 'rouge',\n",
       " 'le ballon',\n",
       " 'des hommes',\n",
       " 'un mur',\n",
       " 'le désert',\n",
       " 'un groupe de jeunes amies',\n",
       " 'de maquillage',\n",
       " 'de bandeaux',\n",
       " 'un banc',\n",
       " 'la dame',\n",
       " 'un sac noir en bandoulière',\n",
       " 'un homme',\n",
       " 'un blouson noir',\n",
       " 'un groupe de gens',\n",
       " 'un chien noir',\n",
       " 'un jouet en corde',\n",
       " 'une jeune fille',\n",
       " 'une vieille caméra',\n",
       " 'fille',\n",
       " 'des vêtements bizarres',\n",
       " 'une brochure',\n",
       " 'un porche en bois',\n",
       " 'un homme',\n",
       " 'des habits funky',\n",
       " 'la guitare',\n",
       " 'un gardien de hockey',\n",
       " \"l' équipe opposée\",\n",
       " 'un adulte',\n",
       " 'un enfant',\n",
       " 'la plage',\n",
       " 'un homme',\n",
       " 'un tablier',\n",
       " 'le bord du trottoir',\n",
       " 'un chien marron et blanc',\n",
       " 'un frisbee',\n",
       " 'le public',\n",
       " 'deux joueurs de tennis',\n",
       " 'un court de tennis',\n",
       " 'deux jongleurs',\n",
       " 'torches enflammées',\n",
       " 'une foule de gens [',\n",
       " 'des marches',\n",
       " 'deux enfants',\n",
       " 'sans chaussures',\n",
       " 'un bébé',\n",
       " 'des galets',\n",
       " 'un garçon',\n",
       " 'une casquette gap',\n",
       " 'une grimace',\n",
       " 'cinq hommes',\n",
       " 'un',\n",
       " 'une chemise blanche',\n",
       " \"une photo d' un enfant\",\n",
       " 'une personne',\n",
       " 'un chapeau',\n",
       " 'un garçon',\n",
       " 'une fille',\n",
       " 'un haut vert speedo',\n",
       " 'des lunettes bleues',\n",
       " 'des garçons',\n",
       " 'un scooter',\n",
       " 'deux femmes',\n",
       " 'un homme',\n",
       " 'un jeu de cartes',\n",
       " 'la bière',\n",
       " 'des gens',\n",
       " 'du pabst blue ribbon',\n",
       " 'du coca light',\n",
       " 'un homme',\n",
       " 'des chaussures rouges',\n",
       " 'un t-shirt blanc',\n",
       " 'un pantalon gris',\n",
       " 'un alpiniste',\n",
       " 'une petite fille',\n",
       " \"l' eau\",\n",
       " 'une sculpture de grenouille',\n",
       " 'un chien',\n",
       " 'la plage',\n",
       " 'des gens',\n",
       " 'un',\n",
       " 'le journal',\n",
       " 'une fille',\n",
       " 'un short rouge',\n",
       " 'une chemise blanche',\n",
       " 'un trou',\n",
       " 'un oiseau noir',\n",
       " 'blanc',\n",
       " \"la main d' une personne\",\n",
       " 'des graines de tournesol',\n",
       " 'une femme',\n",
       " 'une chemise blanche',\n",
       " 'une jupe rose',\n",
       " 'une balle de tennis',\n",
       " 'un chien',\n",
       " 'le sable',\n",
       " 'un toit',\n",
       " 'un homme',\n",
       " 'un grand appareil en forme de caméra',\n",
       " 'un champ',\n",
       " 'un campeur',\n",
       " 'quelques véhicules garés',\n",
       " 'un petit garçon',\n",
       " 'les vagues',\n",
       " 'une femme',\n",
       " 'tenue musulmane',\n",
       " 'un jeune garçon',\n",
       " 'la rue',\n",
       " 'le petit chien',\n",
       " 'une femme',\n",
       " 'un trottoir',\n",
       " \"une plate-forme d' herbe surélevée\",\n",
       " 'un homme',\n",
       " 'pantalon rouge',\n",
       " 'une table de parc',\n",
       " 'un chien',\n",
       " 'sa gueule ouverte',\n",
       " 'un champ',\n",
       " 'une petite fille souriante',\n",
       " 'une piscine extérieure',\n",
       " 'un vélo',\n",
       " 'une rue',\n",
       " 'une corde',\n",
       " 'un gars',\n",
       " 'la corde',\n",
       " 'un homme',\n",
       " 'son enfant',\n",
       " 'un navire',\n",
       " 'un petit enfant',\n",
       " 'un lit',\n",
       " 'les hommes',\n",
       " 'une veste de sécurité orange',\n",
       " \"les réparations d' une rue\",\n",
       " 'un homme',\n",
       " 'un gilet de sécurité',\n",
       " 'les briques',\n",
       " 'un ouvrier',\n",
       " 'une rue',\n",
       " 'un homme',\n",
       " 'du sable blanc',\n",
       " 'un snowboard',\n",
       " 'un homme',\n",
       " 'un gilet orange',\n",
       " 'un immeuble',\n",
       " 'un mec',\n",
       " 'une chemise jaune',\n",
       " 'un pantalon brun clair',\n",
       " 'la foule',\n",
       " 'une jeune fille',\n",
       " 'une tenue de karaté',\n",
       " 'un grand trophée',\n",
       " 'un gamin',\n",
       " 'des flotteurs',\n",
       " 'un lac',\n",
       " 'une femme',\n",
       " 'rose',\n",
       " 'un hamburger',\n",
       " 'une spatule',\n",
       " 'un garçon',\n",
       " 'un t-shirt sale',\n",
       " \"l' eau de mer à hauteur de genoux\",\n",
       " 'un homme',\n",
       " \"l' arrière d' une statue de nu\",\n",
       " 'un petit bambin',\n",
       " 'blanc',\n",
       " 'une dame [',\n",
       " 'un drapeau',\n",
       " 'une personne',\n",
       " 'une structure',\n",
       " 'le lac',\n",
       " 'un jeune homme',\n",
       " 'une veste grise',\n",
       " \"le comptoir d' un magasin de bijoux\",\n",
       " 'des gens',\n",
       " 'les escaliers',\n",
       " 'une église',\n",
       " \"un certain nombre d' enfants\",\n",
       " \"la côte d' une ville\",\n",
       " 'une femme',\n",
       " 'deux hommes',\n",
       " 'un projet de menuiserie',\n",
       " 'des outils manuels',\n",
       " 'une femme',\n",
       " 'deux filles',\n",
       " 'rose',\n",
       " 'un homme',\n",
       " 'un costume noir',\n",
       " 'une mallette',\n",
       " 'une femme brune',\n",
       " 'la rue',\n",
       " 'une tasse',\n",
       " 'un petit garçon chauve',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13836"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emptywordtoken']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknownword']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token2id': {'emptywordtoken': 0,\n",
       "  'unknownword': 1,\n",
       "  'blancs': 2,\n",
       "  'deux': 3,\n",
       "  'hommes': 4,\n",
       "  'jeunes': 5,\n",
       "  'buissons': 6,\n",
       "  'de': 7,\n",
       "  'plusieurs': 8,\n",
       "  'casque': 9,\n",
       "  'géant': 10,\n",
       "  'poulies': 11,\n",
       "  'système': 12,\n",
       "  'un': 13,\n",
       "  'fille': 14,\n",
       "  'petite': 15,\n",
       "  'une': 16,\n",
       "  'bois': 17,\n",
       "  'en': 18,\n",
       "  'maisonnette': 19,\n",
       "  'homme': 20,\n",
       "  'bleue': 21,\n",
       "  'chemise': 22,\n",
       "  'échelle': 23,\n",
       "  'fenêtre': 24,\n",
       "  'fourneaux': 25,\n",
       "  'vert': 26,\n",
       "  'guitare': 27,\n",
       "  'autre': 28,\n",
       "  'sa': 29,\n",
       "  'ours': 30,\n",
       "  'peluche': 31,\n",
       "  'branchée': 32,\n",
       "  'portable': 33,\n",
       "  'son': 34,\n",
       "  'la': 35,\n",
       "  'rue': 36,\n",
       "  'femme': 37,\n",
       "  'gros': 38,\n",
       "  'sac': 39,\n",
       "  'porte': 40,\n",
       "  'des': 41,\n",
       "  'garçons': 42,\n",
       "  'barres': 43,\n",
       "  ',': 44,\n",
       "  'ballet': 45,\n",
       "  'cinq': 46,\n",
       "  'classe': 47,\n",
       "  'composée': 48,\n",
       "  'filles': 49,\n",
       "  'gars': 50,\n",
       "  'quatre': 51,\n",
       "  'chapeaux': 52,\n",
       "  \"'\": 53,\n",
       "  'd': 54,\n",
       "  'escalier': 55,\n",
       "  'haut': 56,\n",
       "  'chien': 57,\n",
       "  'noir': 58,\n",
       "  'tâches': 59,\n",
       "  'à': 60,\n",
       "  'orange': 61,\n",
       "  'uniforme': 62,\n",
       "  'tracteur': 63,\n",
       "  'femmes': 64,\n",
       "  'lunettes': 65,\n",
       "  'sucre': 66,\n",
       "  'bundt': 67,\n",
       "  'cake': 68,\n",
       "  'arc-en-ciel': 69,\n",
       "  'grand': 70,\n",
       "  'peint': 71,\n",
       "  '[': 72,\n",
       "  'banc': 73,\n",
       "  'blanc': 74,\n",
       "  'personnes': 75,\n",
       "  'cercle': 76,\n",
       "  'instruments': 77,\n",
       "  'leurs': 78,\n",
       "  'groupe': 79,\n",
       "  'âgées': 80,\n",
       "  'clarinette': 81,\n",
       "  'leur': 82,\n",
       "  'partition': 83,\n",
       "  'grande': 84,\n",
       "  'structure': 85,\n",
       "  'chaussée': 86,\n",
       "  'foule': 87,\n",
       "  'gens': 88,\n",
       "  'importante': 89,\n",
       "  'dos': 90,\n",
       "  'enfants': 91,\n",
       "  'bascule': 92,\n",
       "  'manège': 93,\n",
       "  'petit': 94,\n",
       "  'le': 95,\n",
       "  'sable': 96,\n",
       "  'gilet': 97,\n",
       "  'réfléchissant': 98,\n",
       "  'drapeau': 99,\n",
       "  'route': 100,\n",
       "  'personne': 101,\n",
       "  'bleu': 102,\n",
       "  'manteau': 103,\n",
       "  'encombré': 104,\n",
       "  'trottoir': 105,\n",
       "  'peinture': 106,\n",
       "  'représentant': 107,\n",
       "  'scène': 108,\n",
       "  'pantalon': 109,\n",
       "  'enfant': 110,\n",
       "  'rouge': 111,\n",
       "  'jeune': 112,\n",
       "  'et': 113,\n",
       "  'jaune': 114,\n",
       "  'noire': 115,\n",
       "  'veste': 116,\n",
       "  'urinoir': 117,\n",
       "  'café': 118,\n",
       "  'tasse': 119,\n",
       "  'vieil': 120,\n",
       "  'bière': 121,\n",
       "  'dressé': 122,\n",
       "  'policier': 123,\n",
       "  'maître': 124,\n",
       "  'fourgon': 125,\n",
       "  'police': 126,\n",
       "  'vélo': 127,\n",
       "  'enneigée': 128,\n",
       "  'blanche': 129,\n",
       "  'cravate': 130,\n",
       "  'arrière': 131,\n",
       "  'l': 132,\n",
       "  'ouvert': 133,\n",
       "  'chapeau': 134,\n",
       "  'machines': 135,\n",
       "  'bougies': 136,\n",
       "  'cartons': 137,\n",
       "  'asiatique': 138,\n",
       "  'voiture': 139,\n",
       "  'conducteur': 140,\n",
       "  'bambins': 141,\n",
       "  'véhicule': 142,\n",
       "  'étrange': 143,\n",
       "  'argenté': 144,\n",
       "  'belle': 145,\n",
       "  'mariée': 146,\n",
       "  'mari': 147,\n",
       "  'nouveau': 148,\n",
       "  'garçon': 149,\n",
       "  'gamecube': 150,\n",
       "  'mcdonald': 151,\n",
       "  'bord': 152,\n",
       "  'plage': 153,\n",
       "  'balle': 154,\n",
       "  'soleil': 155,\n",
       "  'chemisier': 156,\n",
       "  'ballons': 157,\n",
       "  'picnic': 158,\n",
       "  'tables': 159,\n",
       "  'trois': 160,\n",
       "  'du': 161,\n",
       "  'eau': 162,\n",
       "  'morceau': 163,\n",
       "  'papier': 164,\n",
       "  'salopette': 165,\n",
       "  'mur': 166,\n",
       "  'pierre': 167,\n",
       "  'bûche': 168,\n",
       "  'costume': 169,\n",
       "  'autres': 170,\n",
       "  'messieurs': 171,\n",
       "  'nus': 172,\n",
       "  'pieds': 173,\n",
       "  'fort': 174,\n",
       "  'olive': 175,\n",
       "  'hotdogs': 176,\n",
       "  'réchaud': 177,\n",
       "  'plastique': 178,\n",
       "  'neige': 179,\n",
       "  'skis': 180,\n",
       "  'illustrations': 181,\n",
       "  'les': 182,\n",
       "  'alpinistes': 183,\n",
       "  'sept': 184,\n",
       "  'rocher': 185,\n",
       "  'corde': 186,\n",
       "  'corps': 187,\n",
       "  'gymnaste': 188,\n",
       "  'souple': 189,\n",
       "  'poutre': 190,\n",
       "  'équilibre': 191,\n",
       "  'atv': 192,\n",
       "  'jouet': 193,\n",
       "  'caoutchouc': 194,\n",
       "  'piscine': 195,\n",
       "  'coupe-vent': 196,\n",
       "  'objet': 197,\n",
       "  'avion': 198,\n",
       "  'tuyau': 199,\n",
       "  'chariot': 200,\n",
       "  'chiens': 201,\n",
       "  'pour': 202,\n",
       "  'type': 203,\n",
       "  'verte': 204,\n",
       "  'main': 205,\n",
       "  'partie': 206,\n",
       "  'visage': 207,\n",
       "  'restaurant': 208,\n",
       "  'randonneurs': 209,\n",
       "  'création': 210,\n",
       "  'nouvelle': 211,\n",
       "  'père': 212,\n",
       "  'âgé': 213,\n",
       "  'adulte': 214,\n",
       "  'fils': 215,\n",
       "  'barbu': 216,\n",
       "  'voyageur': 217,\n",
       "  'carte': 218,\n",
       "  'canard': 219,\n",
       "  'parc': 220,\n",
       "  'couple': 221,\n",
       "  'herbe': 222,\n",
       "  'bébé': 223,\n",
       "  'poussette': 224,\n",
       "  'quelques': 225,\n",
       "  'immeuble': 226,\n",
       "  'stationnement': 227,\n",
       "  'gelé': 228,\n",
       "  'glace': 229,\n",
       "  'étang': 230,\n",
       "  'beiges': 231,\n",
       "  'imposants': 232,\n",
       "  'pics': 233,\n",
       "  'chemin': 234,\n",
       "  'fait': 235,\n",
       "  'pelletées': 236,\n",
       "  'gâteau': 237,\n",
       "  'mariage': 238,\n",
       "  'mouillé': 239,\n",
       "  'villageois': 240,\n",
       "  'récolte': 241,\n",
       "  'chanteur': 242,\n",
       "  't-shirt': 243,\n",
       "  'skateboard': 244,\n",
       "  'kayak': 245,\n",
       "  'chantier': 246,\n",
       "  'construction': 247,\n",
       "  'panneau': 248,\n",
       "  'publicitaire': 249,\n",
       "  'drapeaux': 250,\n",
       "  'poisson': 251,\n",
       "  'débardeur': 252,\n",
       "  'jupe': 253,\n",
       "  'extérieur': 254,\n",
       "  'marches': 255,\n",
       "  'bouche': 256,\n",
       "  'but': 257,\n",
       "  'gardien': 258,\n",
       "  'hockey': 259,\n",
       "  'objectif': 260,\n",
       "  'bâton': 261,\n",
       "  'bâtiment': 262,\n",
       "  'cour': 263,\n",
       "  '.': 264,\n",
       "  'art': 265,\n",
       "  'sculpture': 266,\n",
       "  'tout': 267,\n",
       "  'garde-corps': 268,\n",
       "  'champ': 269,\n",
       "  'herbeux': 270,\n",
       "  'gratte-ciel': 271,\n",
       "  'fruits': 272,\n",
       "  'blond': 273,\n",
       "  'aux': 274,\n",
       "  'cheveux': 275,\n",
       "  'noirs': 276,\n",
       "  'table': 277,\n",
       "  'nourriture': 278,\n",
       "  'électrique': 279,\n",
       "  'couleur': 280,\n",
       "  'béton': 281,\n",
       "  'couverture': 282,\n",
       "  'solitaire': 283,\n",
       "  'pont': 284,\n",
       "  'haricots': 285,\n",
       "  'verts': 286,\n",
       "  'barbecue': 287,\n",
       "  'rebord': 288,\n",
       "  'montagne': 289,\n",
       "  'passerelle': 290,\n",
       "  'très': 291,\n",
       "  'petites': 292,\n",
       "  'blonde': 293,\n",
       "  'gris': 294,\n",
       "  'chaise': 295,\n",
       "  'instrument': 296,\n",
       "  'bambou': 297,\n",
       "  'fréquentée': 298,\n",
       "  '30': 299,\n",
       "  'ans': 300,\n",
       "  'plus': 301,\n",
       "  'nouilles': 302,\n",
       "  'bol': 303,\n",
       "  'tête': 304,\n",
       "  'trou': 305,\n",
       "  'individus': 306,\n",
       "  'baignoire': 307,\n",
       "  'dort': 308,\n",
       "  'rayé': 309,\n",
       "  'rose': 310,\n",
       "  'africaine': 311,\n",
       "  'membre': 312,\n",
       "  'tribu': 313,\n",
       "  'robe': 314,\n",
       "  'tribale': 315,\n",
       "  'guerrier': 316,\n",
       "  'samouraï': 317,\n",
       "  'épée': 318,\n",
       "  'fourreau': 319,\n",
       "  'entraînement': 320,\n",
       "  'tapis': 321,\n",
       "  'rail': 322,\n",
       "  'rivière': 323,\n",
       "  'rocheuse': 324,\n",
       "  'agent': 325,\n",
       "  'sécurité': 326,\n",
       "  'pourpre': 327,\n",
       "  'téléphone': 328,\n",
       "  'multicolore': 329,\n",
       "  'boule': 330,\n",
       "  'droite': 331,\n",
       "  'maison': 332,\n",
       "  'sol': 333,\n",
       "  'planchiste': 334,\n",
       "  'planche': 335,\n",
       "  'bouteille': 336,\n",
       "  'pilote': 337,\n",
       "  'talkie-walkie': 338,\n",
       "  'nattes': 339,\n",
       "  'pulls': 340,\n",
       "  'repas': 341,\n",
       "  'ouvriers': 342,\n",
       "  'acier': 343,\n",
       "  'ballon': 344,\n",
       "  'boue': 345,\n",
       "  'brochure': 346,\n",
       "  'plongeoir': 347,\n",
       "  'claire': 348,\n",
       "  'bassine': 349,\n",
       "  'fruit': 350,\n",
       "  'arrêt': 351,\n",
       "  'bus': 352,\n",
       "  'jean': 353,\n",
       "  'arbre': 354,\n",
       "  'crêpe': 355,\n",
       "  'pompiers': 356,\n",
       "  'camions': 357,\n",
       "  'rivage': 358,\n",
       "  'casques': 359,\n",
       "  'gilets': 360,\n",
       "  'magazines': 361,\n",
       "  'vendeur': 362,\n",
       "  'collage': 363,\n",
       "  'coloré': 364,\n",
       "  'boulangerie': 365,\n",
       "  'apprenti': 366,\n",
       "  'nu': 367,\n",
       "  'torse': 368,\n",
       "  'ombre': 369,\n",
       "  'tropicale': 370,\n",
       "  'bain': 371,\n",
       "  'short': 372,\n",
       "  'skieur': 373,\n",
       "  'juste': 374,\n",
       "  'monticule': 375,\n",
       "  'terre': 376,\n",
       "  'coureurs': 377,\n",
       "  'tas': 378,\n",
       "  'milieu': 379,\n",
       "  'canne': 380,\n",
       "  'médecin': 381,\n",
       "  'infirmières': 382,\n",
       "  'bleues': 383,\n",
       "  'blouses': 384,\n",
       "  'laineux': 385,\n",
       "  'doberman': 386,\n",
       "  'bowling': 387,\n",
       "  'piste': 388,\n",
       "  'ridé': 389,\n",
       "  'magnifique': 390,\n",
       "  'âne': 391,\n",
       "  'rochers': 392,\n",
       "  'canapé': 393,\n",
       "  'maillot': 394,\n",
       "  'javelot': 395,\n",
       "  'montgolfières': 396,\n",
       "  'magazine': 397,\n",
       "  'épaule': 398,\n",
       "  'allumer': 399,\n",
       "  'centre': 400,\n",
       "  'commercial': 401,\n",
       "  'pièce': 402,\n",
       "  'sombre': 403,\n",
       "  'mousse': 404,\n",
       "  'dizaines': 405,\n",
       "  'bikini': 406,\n",
       "  'cowboy': 407,\n",
       "  'paille': 408,\n",
       "  'toboggan': 409,\n",
       "  'colorés': 410,\n",
       "  'tubes': 411,\n",
       "  'combinaison': 412,\n",
       "  'plongée': 413,\n",
       "  'tout-petit': 414,\n",
       "  'camion': 415,\n",
       "  'rurale': 416,\n",
       "  'zone': 417,\n",
       "  'chefs': 418,\n",
       "  'hamburgers': 419,\n",
       "  'cuisine': 420,\n",
       "  'grimaces': 421,\n",
       "  'brun': 422,\n",
       "  'étincelles': 423,\n",
       "  'colline': 424,\n",
       "  'croix': 425,\n",
       "  'fer': 426,\n",
       "  'chevaux': 427,\n",
       "  'contenu': 428,\n",
       "  'feu': 429,\n",
       "  'travailleurs': 430,\n",
       "  'réfléchissants': 431,\n",
       "  'wagon': 432,\n",
       "  'beetle': 433,\n",
       "  'classique': 434,\n",
       "  'rustique': 435,\n",
       "  'volkswagen': 436,\n",
       "  'armature': 437,\n",
       "  'métal': 438,\n",
       "  'sans': 439,\n",
       "  'ponton': 440,\n",
       "  'matériel': 441,\n",
       "  'mascara': 442,\n",
       "  'ces': 443,\n",
       "  'cils': 444,\n",
       "  'intérieur': 445,\n",
       "  'beaucoup': 446,\n",
       "  'scooters': 447,\n",
       "  'hélicoptère': 448,\n",
       "  'régional': 449,\n",
       "  'échaffaudage': 450,\n",
       "  'quatorze': 451,\n",
       "  'diner': 452,\n",
       "  'adolescent': 453,\n",
       "  'gonflable': 454,\n",
       "  'famille': 455,\n",
       "  'vieille': 456,\n",
       "  'aliments': 457,\n",
       "  'flamboyante': 458,\n",
       "  'coiffe': 459,\n",
       "  'plume': 460,\n",
       "  'skieurs': 461,\n",
       "  'couverte': 462,\n",
       "  'sommet': 463,\n",
       "  'document': 464,\n",
       "  'clair': 465,\n",
       "  'violet': 466,\n",
       "  'corsage': 467,\n",
       "  'mains': 468,\n",
       "  'ses': 469,\n",
       "  'genoux': 470,\n",
       "  'mère': 471,\n",
       "  'promenade': 472,\n",
       "  'six': 473,\n",
       "  'palettes': 474,\n",
       "  'antique': 475,\n",
       "  'automobile': 476,\n",
       "  'moteur': 477,\n",
       "  'jerrican': 478,\n",
       "  'poney': 479,\n",
       "  'charette': 480,\n",
       "  'falaise': 481,\n",
       "  'craie': 482,\n",
       "  'adultes': 483,\n",
       "  'frapper': 484,\n",
       "  'plateforme': 485,\n",
       "  'vaste': 486,\n",
       "  'étendue': 487,\n",
       "  'coudre': 488,\n",
       "  'machine': 489,\n",
       "  'bland': 490,\n",
       "  'marché': 491,\n",
       "  'vendant': 492,\n",
       "  'poivrons': 493,\n",
       "  'agée': 494,\n",
       "  'chaine': 495,\n",
       "  '4': 496,\n",
       "  'bulles': 497,\n",
       "  'pré': 498,\n",
       "  'tunnel': 499,\n",
       "  'poussière': 500,\n",
       "  'fleuri': 501,\n",
       "  'imprimé': 502,\n",
       "  'barrière': 503,\n",
       "  'casquettes': 504,\n",
       "  'colorées': 505,\n",
       "  'rangée': 506,\n",
       "  'moto-neige': 507,\n",
       "  'sortie': 508,\n",
       "  'pliante': 509,\n",
       "  'pile': 510,\n",
       "  'ville': 511,\n",
       "  'bruns': 512,\n",
       "  'pétales': 513,\n",
       "  'fleur': 514,\n",
       "  'quad': 515,\n",
       "  'foncés': 516,\n",
       "  'poêle': 517,\n",
       "  'spatule': 518,\n",
       "  'champs': 519,\n",
       "  'entouré': 520,\n",
       "  'vache': 521,\n",
       "  'bateau': 522,\n",
       "  'jetée': 523,\n",
       "  'sandales': 524,\n",
       "  'cardigan': 525,\n",
       "  'micro': 526,\n",
       "  'mecs': 527,\n",
       "  'three': 528,\n",
       "  'éléphant': 529,\n",
       "  'forme': 530,\n",
       "  'arbres': 531,\n",
       "  'mexicain': 532,\n",
       "  'capot': 533,\n",
       "  'jaunes': 534,\n",
       "  'rousse': 535,\n",
       "  'différents': 536,\n",
       "  'types': 537,\n",
       "  'renversé': 538,\n",
       "  'foot': 539,\n",
       "  'terrain': 540,\n",
       "  'mec': 541,\n",
       "  'congélateur': 542,\n",
       "  'tabourets': 543,\n",
       "  'américain': 544,\n",
       "  'cycliste': 545,\n",
       "  'virage': 546,\n",
       "  'coline': 547,\n",
       "  'jeans': 548,\n",
       "  'pouces': 549,\n",
       "  'escalator': 550,\n",
       "  'football': 551,\n",
       "  'joueur': 552,\n",
       "  'coéquipiers': 553,\n",
       "  'uns': 554,\n",
       "  'adverse': 555,\n",
       "  'désert': 556,\n",
       "  'amies': 557,\n",
       "  'maquillage': 558,\n",
       "  'bandeaux': 559,\n",
       "  'dame': 560,\n",
       "  'bandoulière': 561,\n",
       "  'blouson': 562,\n",
       "  'caméra': 563,\n",
       "  'bizarres': 564,\n",
       "  'vêtements': 565,\n",
       "  'porche': 566,\n",
       "  'funky': 567,\n",
       "  'habits': 568,\n",
       "  'opposée': 569,\n",
       "  'équipe': 570,\n",
       "  'tablier': 571,\n",
       "  'marron': 572,\n",
       "  'frisbee': 573,\n",
       "  'public': 574,\n",
       "  'joueurs': 575,\n",
       "  'tennis': 576,\n",
       "  'court': 577,\n",
       "  'jongleurs': 578,\n",
       "  'enflammées': 579,\n",
       "  'torches': 580,\n",
       "  'chaussures': 581,\n",
       "  'galets': 582,\n",
       "  'casquette': 583,\n",
       "  'gap': 584,\n",
       "  'grimace': 585,\n",
       "  'photo': 586,\n",
       "  'speedo': 587,\n",
       "  'scooter': 588,\n",
       "  'cartes': 589,\n",
       "  'jeu': 590,\n",
       "  'blue': 591,\n",
       "  'pabst': 592,\n",
       "  'ribbon': 593,\n",
       "  'coca': 594,\n",
       "  'light': 595,\n",
       "  'rouges': 596,\n",
       "  'alpiniste': 597,\n",
       "  'grenouille': 598,\n",
       "  'journal': 599,\n",
       "  'oiseau': 600,\n",
       "  'graines': 601,\n",
       "  'tournesol': 602,\n",
       "  'toit': 603,\n",
       "  'appareil': 604,\n",
       "  'campeur': 605,\n",
       "  'garés': 606,\n",
       "  'véhicules': 607,\n",
       "  'vagues': 608,\n",
       "  'musulmane': 609,\n",
       "  'tenue': 610,\n",
       "  'plate-forme': 611,\n",
       "  'surélevée': 612,\n",
       "  'gueule': 613,\n",
       "  'ouverte': 614,\n",
       "  'souriante': 615,\n",
       "  'extérieure': 616,\n",
       "  'navire': 617,\n",
       "  'lit': 618,\n",
       "  'réparations': 619,\n",
       "  'briques': 620,\n",
       "  'ouvrier': 621,\n",
       "  'snowboard': 622,\n",
       "  'karaté': 623,\n",
       "  'trophée': 624,\n",
       "  'gamin': 625,\n",
       "  'flotteurs': 626,\n",
       "  'lac': 627,\n",
       "  'hamburger': 628,\n",
       "  'sale': 629,\n",
       "  'hauteur': 630,\n",
       "  'mer': 631,\n",
       "  'statue': 632,\n",
       "  'bambin': 633,\n",
       "  'grise': 634,\n",
       "  'bijoux': 635,\n",
       "  'comptoir': 636,\n",
       "  'magasin': 637,\n",
       "  'escaliers': 638,\n",
       "  'église': 639,\n",
       "  'certain': 640,\n",
       "  'nombre': 641,\n",
       "  'côte': 642,\n",
       "  'menuiserie': 643,\n",
       "  'projet': 644,\n",
       "  'manuels': 645,\n",
       "  'outils': 646,\n",
       "  'mallette': 647,\n",
       "  'brune': 648,\n",
       "  'chauve': 649,\n",
       "  'poulet': 650,\n",
       "  'plan': 651,\n",
       "  'bouches': 652,\n",
       "  'écharpe': 653,\n",
       "  'tricoté': 654,\n",
       "  'algues': 655,\n",
       "  'sauteuse': 656,\n",
       "  'scie': 657,\n",
       "  'derby': 658,\n",
       "  'feminine': 659,\n",
       "  'roller': 660,\n",
       "  'entre': 661,\n",
       "  'lits': 662,\n",
       "  'tronçonneuse': 663,\n",
       "  'énorme': 664,\n",
       "  'moto': 665,\n",
       "  'affiche': 666,\n",
       "  'manuscrite': 667,\n",
       "  'bienvenue': 668,\n",
       "  'motards': 669,\n",
       "  'chose': 670,\n",
       "  'quelque': 671,\n",
       "  'ligne': 672,\n",
       "  'assis': 673,\n",
       "  'certains': 674,\n",
       "  'debout': 675,\n",
       "  'pistes': 676,\n",
       "  'décorations': 677,\n",
       "  'plafond': 678,\n",
       "  'forgeron': 679,\n",
       "  'cheval': 680,\n",
       "  'dreadlocks': 681,\n",
       "  'kilt': 682,\n",
       "  'joue': 683,\n",
       "  'passagers': 684,\n",
       "  'porcs': 685,\n",
       "  'parking': 686,\n",
       "  'flaque': 687,\n",
       "  'marchandises': 688,\n",
       "  'signe': 689,\n",
       "  'canyon': 690,\n",
       "  'clôture': 691,\n",
       "  'seau': 692,\n",
       "  'sweat-shirt': 693,\n",
       "  'velours': 694,\n",
       "  'pinceau': 695,\n",
       "  'chiffons': 696,\n",
       "  'vieillard': 697,\n",
       "  'épaules': 698,\n",
       "  'brosse': 699,\n",
       "  'grosse': 700,\n",
       "  'marteau': 701,\n",
       "  'quarte': 702,\n",
       "  'blanches': 703,\n",
       "  'chemises': 704,\n",
       "  'coupée': 705,\n",
       "  'livres': 706,\n",
       "  'poubelle': 707,\n",
       "  'ferrée': 708,\n",
       "  'voie': 709,\n",
       "  'jumelles': 710,\n",
       "  'hutte': 711,\n",
       "  'vélos': 712,\n",
       "  'échafaudage': 713,\n",
       "  'bavoir': 714,\n",
       "  'filet': 715,\n",
       "  'au': 716,\n",
       "  'baseball': 717,\n",
       "  'couvercle': 718,\n",
       "  'grill': 719,\n",
       "  'kebab': 720,\n",
       "  'shish': 721,\n",
       "  'protection': 722,\n",
       "  'chirurgicale': 723,\n",
       "  'pelle': 724,\n",
       "  'petits': 725,\n",
       "  'buisson': 726,\n",
       "  'pantalons': 727,\n",
       "  'fourche': 728,\n",
       "  'branches': 729,\n",
       "  'appartements': 730,\n",
       "  'complexe': 731,\n",
       "  'surface': 732,\n",
       "  'bâtons': 733,\n",
       "  'brettelles': 734,\n",
       "  'amis': 735,\n",
       "  'chargement': 736,\n",
       "  'rampe': 737,\n",
       "  'livre': 738,\n",
       "  'dinosaures': 739,\n",
       "  'verre': 740,\n",
       "  'traîneau': 741,\n",
       "  'pain': 742,\n",
       "  'paniers': 743,\n",
       "  'bagages': 744,\n",
       "  'propriété': 745,\n",
       "  'nageuse': 746,\n",
       "  'bonnet': 747,\n",
       "  'pince-nez': 748,\n",
       "  'ordinateurs': 749,\n",
       "  'portables': 750,\n",
       "  'fosse': 751,\n",
       "  'lumières': 752,\n",
       "  'noël': 753,\n",
       "  'poupée': 754,\n",
       "  'princesse': 755,\n",
       "  'dehors': 756,\n",
       "  'moyenne': 757,\n",
       "  'taille': 758,\n",
       "  'récipient': 759,\n",
       "  'ami': 760,\n",
       "  'laisse': 761,\n",
       "  'bassin': 762,\n",
       "  'toison': 763,\n",
       "  'manger': 764,\n",
       "  'maman': 765,\n",
       "  'grue': 766,\n",
       "  'tonnelle': 767,\n",
       "  'monde': 768,\n",
       "  'articles': 769,\n",
       "  'berge': 770,\n",
       "  'cocotte': 771,\n",
       "  'tongs': 772,\n",
       "  'transport': 773,\n",
       "  'bout': 774,\n",
       "  'client': 775,\n",
       "  'fleurs': 776,\n",
       "  'tubercules': 777,\n",
       "  'capuche': 778,\n",
       "  'tente': 779,\n",
       "  'gazon': 780,\n",
       "  'jouets': 781,\n",
       "  '5': 782,\n",
       "  'athlètes': 783,\n",
       "  'hauts': 784,\n",
       "  'bas': 785,\n",
       "  'câbles': 786,\n",
       "  'joyeux': 787,\n",
       "  'elmo': 788,\n",
       "  'nourrisson': 789,\n",
       "  'désordonnée': 790,\n",
       "  'anneau': 791,\n",
       "  'nez': 792,\n",
       "  'cet': 793,\n",
       "  'fontaine': 794,\n",
       "  'foncé': 795,\n",
       "  'château': 796,\n",
       "  'seule': 797,\n",
       "  'amc': 798,\n",
       "  'bulle': 799,\n",
       "  'a': 800,\n",
       "  'beige': 801,\n",
       "  'auvent': 802,\n",
       "  'roses': 803,\n",
       "  'employés': 804,\n",
       "  'parents': 805,\n",
       "  'chariots': 806,\n",
       "  'voitures': 807,\n",
       "  'arrosage': 808,\n",
       "  'bâches': 809,\n",
       "  'florida': 810,\n",
       "  'marlins': 811,\n",
       "  'courses': 812,\n",
       "  'monsieur': 813,\n",
       "  'sentier': 814,\n",
       "  'cette': 815,\n",
       "  'image': 816,\n",
       "  'cantonniers': 817,\n",
       "  'vestes': 818,\n",
       "  'oranges': 819,\n",
       "  'brouette': 820,\n",
       "  'pilotis': 821,\n",
       "  'batteurs': 822,\n",
       "  'terrier': 823,\n",
       "  'gazonné': 824,\n",
       "  'carreaux': 825,\n",
       "  'carnaval': 826,\n",
       "  'tour': 827,\n",
       "  'clown': 828,\n",
       "  'faux': 829,\n",
       "  'blonds': 830,\n",
       "  'sales': 831,\n",
       "  'age': 832,\n",
       "  'moyen': 833,\n",
       "  'couettes': 834,\n",
       "  'ordinateur': 835,\n",
       "  'écran': 836,\n",
       "  'chers': 837,\n",
       "  'vitrine': 838,\n",
       "  'boutiques': 839,\n",
       "  'peut-être': 840,\n",
       "  'publicité': 841,\n",
       "  'rétro-éclairé': 842,\n",
       "  'agens': 843,\n",
       "  'murale': 844,\n",
       "  'grosses': 845,\n",
       "  'manches': 846,\n",
       "  'barbe': 847,\n",
       "  'argent': 848,\n",
       "  'monocycle': 849,\n",
       "  'trottinette': 850,\n",
       "  'ski': 851,\n",
       "  'crabe': 852,\n",
       "  'bétonné': 853,\n",
       "  'pull': 854,\n",
       "  'dragon': 855,\n",
       "  'marionnette': 856,\n",
       "  'jardin': 857,\n",
       "  'bâtiments': 858,\n",
       "  'murs': 859,\n",
       "  'vertes': 860,\n",
       "  'jour': 861,\n",
       "  'brillante': 862,\n",
       "  'violette': 863,\n",
       "  'clients': 864,\n",
       "  'guichet': 865,\n",
       "  'bonnets': 866,\n",
       "  'sur': 867,\n",
       "  'navetteurs': 868,\n",
       "  'haute': 869,\n",
       "  'pratiquants': 870,\n",
       "  'clavier': 871,\n",
       "  'spectateurs': 872,\n",
       "  'visière': 873,\n",
       "  'ceintures': 874,\n",
       "  'noires': 875,\n",
       "  'martiaux': 876,\n",
       "  'étudiante': 877,\n",
       "  'arme': 878,\n",
       "  'arts': 879,\n",
       "  'stand': 880,\n",
       "  'papa': 881,\n",
       "  '8': 882,\n",
       "  'pierres': 883,\n",
       "  'tuiles': 884,\n",
       "  'clairs': 885,\n",
       "  'sandwich': 886,\n",
       "  'blocs': 887,\n",
       "  'rectangulaires': 888,\n",
       "  'roue': 889,\n",
       "  'balles': 890,\n",
       "  'multicolores': 891,\n",
       "  'quilles': 892,\n",
       "  'gravillonnée': 893,\n",
       "  'afro-américains': 894,\n",
       "  'trompette': 895,\n",
       "  'badauds': 896,\n",
       "  'officiers': 897,\n",
       "  'brunes': 898,\n",
       "  'tenues': 899,\n",
       "  'boussole': 900,\n",
       "  'coté': 901,\n",
       "  'péniche': 902,\n",
       "  'balancelle': 903,\n",
       "  'gant': 904,\n",
       "  'abondante': 905,\n",
       "  'fluo': 906,\n",
       "  'agents': 907,\n",
       "  'voirie': 908,\n",
       "  'toile': 909,\n",
       "  'balançoire': 910,\n",
       "  'avec': 911,\n",
       "  'pêchent': 912,\n",
       "  'cuillère': 913,\n",
       "  'pêcheur': 914,\n",
       "  'baume': 915,\n",
       "  'lèvres': 916,\n",
       "  'boutons': 917,\n",
       "  'mixage': 918,\n",
       "  'rayures': 919,\n",
       "  'stands': 920,\n",
       "  'plaine': 921,\n",
       "  'adolescentes': 922,\n",
       "  'tétine': 923,\n",
       "  'fauteuil': 924,\n",
       "  'rickshaw': 925,\n",
       "  'élégant': 926,\n",
       "  'navigable': 927,\n",
       "  'surveillance': 928,\n",
       "  'rembourré': 929,\n",
       "  'fermier': 930,\n",
       "  'bar': 931,\n",
       "  'canettes': 932,\n",
       "  'soda': 933,\n",
       "  'autour': 934,\n",
       "  'grills': 935,\n",
       "  'viande': 936,\n",
       "  'grands': 937,\n",
       "  'bancs': 938,\n",
       "  'secouristes': 939,\n",
       "  'argile': 940,\n",
       "  'potier': 941,\n",
       "  'artiste': 942,\n",
       "  'dessin': 943,\n",
       "  'section': 944,\n",
       "  'élaboré': 945,\n",
       "  'imposante': 946,\n",
       "  'batterie': 947,\n",
       "  'onze': 948,\n",
       "  'tabouret': 949,\n",
       "  'cages': 950,\n",
       "  'lot': 951,\n",
       "  'inhabituelle': 952,\n",
       "  'manière': 953,\n",
       "  'vêtu': 954,\n",
       "  'crème': 955,\n",
       "  'glacée': 956,\n",
       "  'réfrigérateur': 957,\n",
       "  'tiare': 958,\n",
       "  'error': 959,\n",
       "  'bouclé': 960,\n",
       "  'reflet': 961,\n",
       "  'marbre': 962,\n",
       "  'poli': 963,\n",
       "  'hanches': 964,\n",
       "  'cigarette': 965,\n",
       "  'important': 966,\n",
       "  'cuisinier': 967,\n",
       "  'vin': 968,\n",
       "  'poils': 969,\n",
       "  'steak': 970,\n",
       "  'plateau': 971,\n",
       "  'paix': 972,\n",
       "  'masques': 973,\n",
       "  'costumes': 974,\n",
       "  'statues': 975,\n",
       "  'chat': 976,\n",
       "  'longs': 977,\n",
       "  'tipi': 978,\n",
       "  'roues': 979,\n",
       "  'enclume': 980,\n",
       "  'violoncelle': 981,\n",
       "  'tranquille': 982,\n",
       "  'billard': 983,\n",
       "  'circuit': 984,\n",
       "  'motocross': 985,\n",
       "  'bibliothèque': 986,\n",
       "  'sous-vêtements': 987,\n",
       "  'hangar': 988,\n",
       "  'cyclistes': 989,\n",
       "  'grille': 990,\n",
       "  'employées': 991,\n",
       "  'assiette': 992,\n",
       "  'indiquant': 993,\n",
       "  'mongol': 994,\n",
       "  'néon': 995,\n",
       "  'deere': 996,\n",
       "  'john': 997,\n",
       "  'remorque': 998,\n",
       "  'baril': 999,\n",
       "  ...},\n",
       " 'id2token': {},\n",
       " 'dfs': {0: 1,\n",
       "  1: 1,\n",
       "  3: 650,\n",
       "  5: 111,\n",
       "  4: 295,\n",
       "  2: 31,\n",
       "  7: 1335,\n",
       "  6: 5,\n",
       "  8: 72,\n",
       "  9: 44,\n",
       "  13: 5419,\n",
       "  12: 1,\n",
       "  11: 1,\n",
       "  10: 4,\n",
       "  16: 2983,\n",
       "  15: 127,\n",
       "  14: 332,\n",
       "  19: 1,\n",
       "  18: 182,\n",
       "  17: 56,\n",
       "  20: 1382,\n",
       "  22: 178,\n",
       "  21: 88,\n",
       "  23: 8,\n",
       "  24: 30,\n",
       "  25: 1,\n",
       "  26: 89,\n",
       "  27: 82,\n",
       "  28: 115,\n",
       "  29: 125,\n",
       "  30: 5,\n",
       "  31: 10,\n",
       "  32: 1,\n",
       "  34: 178,\n",
       "  33: 23,\n",
       "  35: 669,\n",
       "  36: 126,\n",
       "  37: 704,\n",
       "  38: 44,\n",
       "  39: 58,\n",
       "  40: 29,\n",
       "  41: 961,\n",
       "  42: 67,\n",
       "  43: 3,\n",
       "  47: 7,\n",
       "  45: 1,\n",
       "  44: 25,\n",
       "  48: 1,\n",
       "  46: 35,\n",
       "  49: 80,\n",
       "  51: 59,\n",
       "  50: 46,\n",
       "  52: 13,\n",
       "  56: 23,\n",
       "  54: 447,\n",
       "  53: 849,\n",
       "  55: 10,\n",
       "  57: 405,\n",
       "  58: 264,\n",
       "  60: 195,\n",
       "  59: 2,\n",
       "  62: 17,\n",
       "  61: 65,\n",
       "  63: 8,\n",
       "  64: 147,\n",
       "  65: 98,\n",
       "  66: 1,\n",
       "  67: 1,\n",
       "  68: 1,\n",
       "  70: 64,\n",
       "  69: 3,\n",
       "  71: 5,\n",
       "  73: 55,\n",
       "  72: 228,\n",
       "  74: 224,\n",
       "  75: 275,\n",
       "  76: 1,\n",
       "  78: 28,\n",
       "  77: 8,\n",
       "  79: 268,\n",
       "  80: 8,\n",
       "  81: 1,\n",
       "  82: 18,\n",
       "  83: 4,\n",
       "  84: 34,\n",
       "  85: 13,\n",
       "  86: 3,\n",
       "  89: 3,\n",
       "  87: 71,\n",
       "  88: 211,\n",
       "  90: 38,\n",
       "  91: 165,\n",
       "  94: 167,\n",
       "  93: 2,\n",
       "  92: 2,\n",
       "  95: 385,\n",
       "  96: 44,\n",
       "  97: 30,\n",
       "  98: 4,\n",
       "  99: 8,\n",
       "  100: 30,\n",
       "  101: 138,\n",
       "  103: 36,\n",
       "  102: 156,\n",
       "  105: 67,\n",
       "  104: 1,\n",
       "  106: 10,\n",
       "  107: 3,\n",
       "  108: 25,\n",
       "  109: 50,\n",
       "  110: 205,\n",
       "  111: 259,\n",
       "  112: 341,\n",
       "  116: 105,\n",
       "  115: 71,\n",
       "  113: 168,\n",
       "  114: 109,\n",
       "  117: 1,\n",
       "  119: 14,\n",
       "  118: 16,\n",
       "  120: 38,\n",
       "  121: 15,\n",
       "  123: 6,\n",
       "  122: 1,\n",
       "  124: 1,\n",
       "  125: 3,\n",
       "  126: 10,\n",
       "  127: 71,\n",
       "  128: 14,\n",
       "  129: 93,\n",
       "  130: 7,\n",
       "  132: 405,\n",
       "  131: 10,\n",
       "  133: 5,\n",
       "  134: 95,\n",
       "  135: 4,\n",
       "  136: 7,\n",
       "  137: 3,\n",
       "  138: 38,\n",
       "  139: 43,\n",
       "  140: 4,\n",
       "  141: 1,\n",
       "  143: 3,\n",
       "  142: 12,\n",
       "  144: 2,\n",
       "  145: 7,\n",
       "  146: 10,\n",
       "  148: 3,\n",
       "  147: 1,\n",
       "  149: 384,\n",
       "  150: 1,\n",
       "  151: 2,\n",
       "  152: 15,\n",
       "  153: 80,\n",
       "  154: 52,\n",
       "  155: 33,\n",
       "  156: 5,\n",
       "  157: 8,\n",
       "  159: 10,\n",
       "  158: 1,\n",
       "  160: 177,\n",
       "  161: 77,\n",
       "  162: 169,\n",
       "  163: 16,\n",
       "  164: 15,\n",
       "  165: 4,\n",
       "  166: 57,\n",
       "  167: 18,\n",
       "  168: 3,\n",
       "  169: 52,\n",
       "  170: 52,\n",
       "  171: 1,\n",
       "  173: 14,\n",
       "  172: 8,\n",
       "  174: 2,\n",
       "  175: 1,\n",
       "  176: 1,\n",
       "  177: 1,\n",
       "  178: 22,\n",
       "  179: 84,\n",
       "  180: 1,\n",
       "  182: 251,\n",
       "  181: 1,\n",
       "  184: 6,\n",
       "  183: 3,\n",
       "  185: 30,\n",
       "  186: 30,\n",
       "  187: 1,\n",
       "  189: 2,\n",
       "  188: 4,\n",
       "  190: 12,\n",
       "  191: 1,\n",
       "  193: 43,\n",
       "  192: 1,\n",
       "  195: 43,\n",
       "  194: 4,\n",
       "  196: 2,\n",
       "  197: 16,\n",
       "  198: 4,\n",
       "  199: 7,\n",
       "  200: 15,\n",
       "  202: 9,\n",
       "  201: 88,\n",
       "  203: 5,\n",
       "  204: 52,\n",
       "  205: 62,\n",
       "  206: 1,\n",
       "  207: 33,\n",
       "  208: 13,\n",
       "  209: 15,\n",
       "  211: 1,\n",
       "  210: 1,\n",
       "  212: 10,\n",
       "  213: 36,\n",
       "  215: 11,\n",
       "  214: 24,\n",
       "  217: 1,\n",
       "  216: 6,\n",
       "  218: 3,\n",
       "  219: 7,\n",
       "  220: 28,\n",
       "  221: 32,\n",
       "  222: 76,\n",
       "  223: 57,\n",
       "  224: 12,\n",
       "  225: 34,\n",
       "  226: 16,\n",
       "  227: 2,\n",
       "  229: 11,\n",
       "  230: 8,\n",
       "  228: 2,\n",
       "  231: 2,\n",
       "  232: 1,\n",
       "  233: 1,\n",
       "  234: 31,\n",
       "  235: 6,\n",
       "  236: 1,\n",
       "  237: 16,\n",
       "  238: 5,\n",
       "  239: 5,\n",
       "  240: 3,\n",
       "  241: 1,\n",
       "  242: 4,\n",
       "  243: 170,\n",
       "  244: 6,\n",
       "  245: 5,\n",
       "  246: 10,\n",
       "  247: 14,\n",
       "  248: 18,\n",
       "  249: 4,\n",
       "  250: 8,\n",
       "  251: 12,\n",
       "  252: 15,\n",
       "  253: 12,\n",
       "  255: 14,\n",
       "  254: 13,\n",
       "  256: 21,\n",
       "  258: 6,\n",
       "  257: 5,\n",
       "  259: 6,\n",
       "  260: 1,\n",
       "  261: 15,\n",
       "  263: 12,\n",
       "  262: 65,\n",
       "  266: 6,\n",
       "  265: 5,\n",
       "  264: 7,\n",
       "  267: 3,\n",
       "  268: 1,\n",
       "  269: 33,\n",
       "  270: 4,\n",
       "  271: 1,\n",
       "  272: 14,\n",
       "  273: 13,\n",
       "  274: 31,\n",
       "  275: 98,\n",
       "  276: 31,\n",
       "  277: 93,\n",
       "  278: 33,\n",
       "  279: 8,\n",
       "  280: 13,\n",
       "  281: 15,\n",
       "  282: 14,\n",
       "  283: 3,\n",
       "  284: 23,\n",
       "  285: 1,\n",
       "  286: 9,\n",
       "  287: 12,\n",
       "  288: 5,\n",
       "  289: 30,\n",
       "  290: 3,\n",
       "  291: 18,\n",
       "  292: 8,\n",
       "  293: 29,\n",
       "  294: 44,\n",
       "  295: 28,\n",
       "  296: 12,\n",
       "  297: 3,\n",
       "  298: 1,\n",
       "  301: 22,\n",
       "  299: 1,\n",
       "  300: 1,\n",
       "  302: 1,\n",
       "  303: 9,\n",
       "  304: 37,\n",
       "  305: 8,\n",
       "  306: 4,\n",
       "  307: 2,\n",
       "  308: 1,\n",
       "  310: 75,\n",
       "  309: 16,\n",
       "  312: 3,\n",
       "  313: 2,\n",
       "  311: 3,\n",
       "  314: 59,\n",
       "  315: 1,\n",
       "  316: 1,\n",
       "  317: 1,\n",
       "  318: 3,\n",
       "  319: 1,\n",
       "  321: 15,\n",
       "  320: 3,\n",
       "  322: 1,\n",
       "  323: 22,\n",
       "  324: 13,\n",
       "  325: 5,\n",
       "  326: 23,\n",
       "  327: 5,\n",
       "  328: 30,\n",
       "  329: 6,\n",
       "  330: 15,\n",
       "  331: 3,\n",
       "  332: 16,\n",
       "  333: 14,\n",
       "  334: 1,\n",
       "  335: 22,\n",
       "  336: 13,\n",
       "  337: 3,\n",
       "  338: 2,\n",
       "  339: 3,\n",
       "  340: 2,\n",
       "  341: 16,\n",
       "  342: 22,\n",
       "  343: 5,\n",
       "  344: 61,\n",
       "  345: 7,\n",
       "  346: 2,\n",
       "  347: 3,\n",
       "  348: 4,\n",
       "  349: 1,\n",
       "  350: 2,\n",
       "  351: 4,\n",
       "  352: 4,\n",
       "  353: 31,\n",
       "  354: 39,\n",
       "  355: 1,\n",
       "  356: 5,\n",
       "  357: 3,\n",
       "  358: 4,\n",
       "  359: 16,\n",
       "  360: 18,\n",
       "  362: 7,\n",
       "  361: 3,\n",
       "  363: 1,\n",
       "  364: 6,\n",
       "  365: 3,\n",
       "  366: 1,\n",
       "  368: 17,\n",
       "  367: 18,\n",
       "  369: 8,\n",
       "  370: 2,\n",
       "  372: 58,\n",
       "  371: 34,\n",
       "  373: 5,\n",
       "  374: 1,\n",
       "  375: 4,\n",
       "  376: 20,\n",
       "  377: 2,\n",
       "  378: 12,\n",
       "  379: 8,\n",
       "  380: 11,\n",
       "  381: 3,\n",
       "  382: 2,\n",
       "  384: 2,\n",
       "  383: 9,\n",
       "  385: 1,\n",
       "  386: 1,\n",
       "  387: 8,\n",
       "  388: 22,\n",
       "  389: 1,\n",
       "  390: 1,\n",
       "  391: 3,\n",
       "  392: 13,\n",
       "  393: 22,\n",
       "  394: 49,\n",
       "  395: 1,\n",
       "  396: 3,\n",
       "  397: 5,\n",
       "  398: 4,\n",
       "  399: 1,\n",
       "  400: 3,\n",
       "  401: 2,\n",
       "  402: 7,\n",
       "  403: 9,\n",
       "  404: 4,\n",
       "  405: 1,\n",
       "  406: 10,\n",
       "  407: 1,\n",
       "  408: 8,\n",
       "  409: 12,\n",
       "  411: 1,\n",
       "  410: 15,\n",
       "  412: 13,\n",
       "  413: 3,\n",
       "  414: 6,\n",
       "  415: 26,\n",
       "  417: 5,\n",
       "  416: 1,\n",
       "  418: 8,\n",
       "  419: 2,\n",
       "  420: 17,\n",
       "  421: 1,\n",
       "  422: 114,\n",
       "  423: 2,\n",
       "  424: 23,\n",
       "  425: 5,\n",
       "  426: 5,\n",
       "  427: 4,\n",
       "  429: 14,\n",
       "  428: 2,\n",
       "  430: 12,\n",
       "  431: 2,\n",
       "  432: 3,\n",
       "  434: 1,\n",
       "  435: 1,\n",
       "  436: 1,\n",
       "  433: 1,\n",
       "  437: 1,\n",
       "  438: 12,\n",
       "  439: 9,\n",
       "  440: 4,\n",
       "  441: 8,\n",
       "  442: 2,\n",
       "  443: 6,\n",
       "  444: 1,\n",
       "  445: 6,\n",
       "  446: 27,\n",
       "  447: 1,\n",
       "  448: 1,\n",
       "  449: 1,\n",
       "  450: 1,\n",
       "  451: 1,\n",
       "  452: 1,\n",
       "  453: 6,\n",
       "  454: 7,\n",
       "  455: 26,\n",
       "  456: 18,\n",
       "  457: 4,\n",
       "  458: 1,\n",
       "  459: 4,\n",
       "  460: 2,\n",
       "  461: 9,\n",
       "  463: 7,\n",
       "  462: 2,\n",
       "  464: 1,\n",
       "  466: 10,\n",
       "  465: 14,\n",
       "  467: 1,\n",
       "  469: 74,\n",
       "  468: 34,\n",
       "  470: 7,\n",
       "  471: 13,\n",
       "  472: 3,\n",
       "  473: 11,\n",
       "  474: 1,\n",
       "  477: 2,\n",
       "  476: 2,\n",
       "  475: 1,\n",
       "  478: 1,\n",
       "  479: 3,\n",
       "  480: 1,\n",
       "  481: 13,\n",
       "  482: 3,\n",
       "  483: 19,\n",
       "  484: 1,\n",
       "  485: 1,\n",
       "  486: 5,\n",
       "  487: 5,\n",
       "  489: 23,\n",
       "  488: 5,\n",
       "  490: 1,\n",
       "  491: 12,\n",
       "  492: 1,\n",
       "  493: 1,\n",
       "  494: 1,\n",
       "  495: 1,\n",
       "  496: 3,\n",
       "  497: 7,\n",
       "  498: 1,\n",
       "  499: 4,\n",
       "  500: 4,\n",
       "  502: 3,\n",
       "  501: 4,\n",
       "  503: 11,\n",
       "  506: 5,\n",
       "  504: 3,\n",
       "  505: 6,\n",
       "  508: 2,\n",
       "  507: 1,\n",
       "  509: 3,\n",
       "  510: 7,\n",
       "  511: 23,\n",
       "  512: 15,\n",
       "  513: 2,\n",
       "  514: 3,\n",
       "  515: 4,\n",
       "  516: 8,\n",
       "  517: 4,\n",
       "  518: 2,\n",
       "  519: 2,\n",
       "  520: 1,\n",
       "  521: 8,\n",
       "  522: 4,\n",
       "  523: 10,\n",
       "  524: 7,\n",
       "  525: 1,\n",
       "  526: 23,\n",
       "  528: 1,\n",
       "  527: 1,\n",
       "  529: 2,\n",
       "  530: 4,\n",
       "  531: 21,\n",
       "  532: 2,\n",
       "  533: 3,\n",
       "  534: 13,\n",
       "  535: 5,\n",
       "  536: 3,\n",
       "  537: 3,\n",
       "  538: 1,\n",
       "  539: 10,\n",
       "  540: 32,\n",
       "  541: 3,\n",
       "  542: 1,\n",
       "  543: 2,\n",
       "  544: 8,\n",
       "  545: 5,\n",
       "  546: 1,\n",
       "  547: 1,\n",
       "  548: 8,\n",
       "  549: 2,\n",
       "  550: 4,\n",
       "  552: 17,\n",
       "  551: 29,\n",
       "  554: 2,\n",
       "  553: 2,\n",
       "  555: 3,\n",
       "  556: 4,\n",
       "  557: 1,\n",
       "  558: 3,\n",
       "  559: 1,\n",
       "  560: 32,\n",
       "  561: 2,\n",
       "  562: 5,\n",
       "  563: 8,\n",
       "  565: 47,\n",
       "  564: 1,\n",
       "  566: 3,\n",
       "  568: 2,\n",
       "  567: 1,\n",
       "  570: 20,\n",
       "  569: 1,\n",
       "  571: 17,\n",
       "  572: 52,\n",
       "  573: 17,\n",
       "  574: 8,\n",
       "  575: 11,\n",
       "  576: 42,\n",
       "  577: 5,\n",
       "  578: 1,\n",
       "  580: 3,\n",
       "  579: 1,\n",
       "  581: 19,\n",
       "  582: 3,\n",
       "  583: 35,\n",
       "  584: 1,\n",
       "  585: 2,\n",
       "  586: 24,\n",
       "  587: 1,\n",
       "  588: 4,\n",
       "  590: 15,\n",
       "  589: 5,\n",
       "  592: 1,\n",
       "  591: 3,\n",
       "  593: 1,\n",
       "  594: 1,\n",
       "  595: 3,\n",
       "  596: 35,\n",
       "  597: 5,\n",
       "  598: 1,\n",
       "  599: 12,\n",
       "  600: 7,\n",
       "  601: 1,\n",
       "  602: 1,\n",
       "  603: 14,\n",
       "  604: 13,\n",
       "  605: 1,\n",
       "  607: 5,\n",
       "  606: 2,\n",
       "  608: 7,\n",
       "  610: 39,\n",
       "  609: 1,\n",
       "  611: 6,\n",
       "  612: 1,\n",
       "  613: 23,\n",
       "  614: 10,\n",
       "  615: 9,\n",
       "  616: 3,\n",
       "  617: 3,\n",
       "  618: 15,\n",
       "  619: 1,\n",
       "  620: 9,\n",
       "  621: 15,\n",
       "  622: 2,\n",
       "  623: 2,\n",
       "  624: 1,\n",
       "  625: 10,\n",
       "  626: 2,\n",
       "  627: 20,\n",
       "  628: 1,\n",
       "  629: 7,\n",
       "  631: 7,\n",
       "  630: 1,\n",
       "  632: 9,\n",
       "  633: 6,\n",
       "  634: 10,\n",
       "  636: 10,\n",
       "  637: 17,\n",
       "  635: 3,\n",
       "  638: 8,\n",
       "  639: 5,\n",
       "  640: 2,\n",
       "  641: 10,\n",
       "  642: 3,\n",
       "  644: 4,\n",
       "  643: 1,\n",
       "  646: 5,\n",
       "  645: 1,\n",
       "  647: 2,\n",
       "  648: 16,\n",
       "  649: 13,\n",
       "  650: 2,\n",
       "  651: 22,\n",
       "  652: 1,\n",
       "  653: 6,\n",
       "  654: 1,\n",
       "  655: 1,\n",
       "  657: 4,\n",
       "  656: 1,\n",
       "  660: 1,\n",
       "  658: 1,\n",
       "  659: 1,\n",
       "  661: 6,\n",
       "  662: 2,\n",
       "  664: 4,\n",
       "  663: 2,\n",
       "  665: 25,\n",
       "  666: 5,\n",
       "  667: 1,\n",
       "  668: 1,\n",
       "  669: 4,\n",
       "  671: 27,\n",
       "  670: 25,\n",
       "  672: 11,\n",
       "  674: 6,\n",
       "  673: 4,\n",
       "  675: 3,\n",
       "  676: 3,\n",
       "  677: 4,\n",
       "  678: 4,\n",
       "  679: 2,\n",
       "  680: 31,\n",
       "  681: 3,\n",
       "  682: 4,\n",
       "  683: 4,\n",
       "  684: 5,\n",
       "  685: 2,\n",
       "  686: 6,\n",
       "  687: 4,\n",
       "  688: 8,\n",
       "  689: 7,\n",
       "  690: 2,\n",
       "  691: 19,\n",
       "  692: 13,\n",
       "  693: 13,\n",
       "  694: 1,\n",
       "  695: 4,\n",
       "  696: 1,\n",
       "  697: 1,\n",
       "  698: 8,\n",
       "  700: 14,\n",
       "  699: 2,\n",
       "  701: 6,\n",
       "  702: 2,\n",
       "  704: 8,\n",
       "  703: 23,\n",
       "  705: 1,\n",
       "  706: 5,\n",
       "  707: 8,\n",
       "  709: 10,\n",
       "  708: 5,\n",
       "  710: 4,\n",
       "  711: 2,\n",
       "  712: 11,\n",
       "  713: 8,\n",
       "  714: 4,\n",
       "  715: 10,\n",
       "  716: 28,\n",
       "  717: 20,\n",
       "  718: 2,\n",
       "  719: 7,\n",
       "  721: 1,\n",
       "  720: 1,\n",
       "  722: 8,\n",
       "  723: 1,\n",
       "  724: 7,\n",
       "  725: 21,\n",
       "  726: 4,\n",
       "  727: 8,\n",
       "  728: 1,\n",
       "  729: 2,\n",
       "  731: 3,\n",
       "  730: 1,\n",
       "  732: 3,\n",
       "  733: 8,\n",
       "  734: 1,\n",
       "  735: 16,\n",
       "  737: 11,\n",
       "  736: 2,\n",
       "  738: 19,\n",
       "  739: 1,\n",
       "  740: 19,\n",
       "  741: 5,\n",
       "  743: 2,\n",
       "  742: 6,\n",
       "  744: 4,\n",
       "  745: 1,\n",
       "  746: 1,\n",
       "  747: 18,\n",
       "  748: 1,\n",
       "  749: 8,\n",
       "  750: 5,\n",
       "  751: 1,\n",
       "  752: 5,\n",
       "  753: 6,\n",
       "  754: 2,\n",
       "  755: 1,\n",
       "  758: 4,\n",
       "  757: 2,\n",
       "  756: 4,\n",
       "  759: 1,\n",
       "  760: 2,\n",
       "  761: 13,\n",
       "  762: 5,\n",
       "  763: 1,\n",
       "  764: 8,\n",
       "  765: 4,\n",
       "  766: 3,\n",
       "  767: 1,\n",
       "  768: 3,\n",
       "  769: 5,\n",
       "  770: 2,\n",
       "  771: 1,\n",
       "  772: 4,\n",
       "  773: 1,\n",
       "  774: 5,\n",
       "  775: 1,\n",
       "  776: 25,\n",
       "  777: 1,\n",
       "  778: 8,\n",
       "  779: 9,\n",
       "  780: 3,\n",
       "  781: 5,\n",
       "  782: 3,\n",
       "  783: 1,\n",
       "  784: 3,\n",
       "  785: 2,\n",
       "  786: 2,\n",
       "  787: 1,\n",
       "  788: 1,\n",
       "  789: 3,\n",
       "  790: 1,\n",
       "  791: 2,\n",
       "  792: 7,\n",
       "  793: 2,\n",
       "  794: 12,\n",
       "  795: 9,\n",
       "  796: 4,\n",
       "  797: 3,\n",
       "  798: 1,\n",
       "  799: 3,\n",
       "  800: 4,\n",
       "  801: 19,\n",
       "  802: 1,\n",
       "  803: 6,\n",
       "  804: 2,\n",
       "  805: 2,\n",
       "  806: 1,\n",
       "  807: 10,\n",
       "  808: 2,\n",
       "  809: 1,\n",
       "  810: 1,\n",
       "  811: 1,\n",
       "  812: 2,\n",
       "  813: 11,\n",
       "  814: 12,\n",
       "  815: 8,\n",
       "  816: 5,\n",
       "  817: 1,\n",
       "  818: 9,\n",
       "  819: 8,\n",
       "  820: 5,\n",
       "  821: 1,\n",
       "  822: 1,\n",
       "  823: 3,\n",
       "  824: 4,\n",
       "  825: 11,\n",
       "  827: 7,\n",
       "  826: 3,\n",
       "  828: 4,\n",
       "  829: 2,\n",
       "  830: 18,\n",
       "  831: 4,\n",
       "  832: 1,\n",
       "  833: 8,\n",
       "  834: 1,\n",
       "  836: 11,\n",
       "  835: 16,\n",
       "  837: 1,\n",
       "  838: 6,\n",
       "  840: 1,\n",
       "  839: 1,\n",
       "  841: 3,\n",
       "  842: 1,\n",
       "  843: 1,\n",
       "  844: 1,\n",
       "  845: 3,\n",
       "  846: 7,\n",
       "  847: 18,\n",
       "  848: 6,\n",
       "  849: 3,\n",
       "  850: 5,\n",
       "  851: 10,\n",
       "  852: 2,\n",
       "  853: 1,\n",
       "  854: 17,\n",
       "  856: 2,\n",
       "  855: 1,\n",
       "  857: 8,\n",
       "  859: 3,\n",
       "  858: 5,\n",
       "  860: 5,\n",
       "  861: 2,\n",
       "  862: 1,\n",
       "  863: 7,\n",
       "  864: 8,\n",
       "  865: 1,\n",
       "  866: 3,\n",
       "  867: 9,\n",
       "  868: 1,\n",
       "  869: 5,\n",
       "  870: 2,\n",
       "  871: 6,\n",
       "  872: 13,\n",
       "  873: 5,\n",
       "  874: 5,\n",
       "  875: 16,\n",
       "  877: 2,\n",
       "  876: 6,\n",
       "  878: 1,\n",
       "  879: 5,\n",
       "  880: 6,\n",
       "  881: 1,\n",
       "  882: 1,\n",
       "  883: 6,\n",
       "  884: 3,\n",
       "  885: 1,\n",
       "  886: 4,\n",
       "  887: 5,\n",
       "  888: 1,\n",
       "  889: 5,\n",
       "  890: 5,\n",
       "  892: 2,\n",
       "  891: 6,\n",
       "  893: 1,\n",
       "  894: 3,\n",
       "  895: 2,\n",
       "  896: 2,\n",
       "  897: 4,\n",
       "  899: 6,\n",
       "  898: 4,\n",
       "  900: 1,\n",
       "  901: 2,\n",
       "  902: 1,\n",
       "  903: 2,\n",
       "  904: 4,\n",
       "  905: 1,\n",
       "  906: 2,\n",
       "  907: 3,\n",
       "  908: 1,\n",
       "  909: 4,\n",
       "  910: 16,\n",
       "  911: 14,\n",
       "  912: 1,\n",
       "  913: 3,\n",
       "  914: 7,\n",
       "  915: 1,\n",
       "  916: 1,\n",
       "  917: 1,\n",
       "  918: 1,\n",
       "  919: 5,\n",
       "  920: 1,\n",
       "  921: 2,\n",
       "  922: 2,\n",
       "  923: 2,\n",
       "  924: 12,\n",
       "  926: 1,\n",
       "  925: 1,\n",
       "  927: 2,\n",
       "  928: 1,\n",
       "  929: 1,\n",
       "  930: 2,\n",
       "  931: 2,\n",
       "  932: 2,\n",
       "  933: 1,\n",
       "  934: 2,\n",
       "  935: 1,\n",
       "  936: 8,\n",
       "  937: 6,\n",
       "  938: 2,\n",
       "  939: 1,\n",
       "  940: 7,\n",
       "  941: 2,\n",
       "  942: 8,\n",
       "  944: 1,\n",
       "  943: 3,\n",
       "  945: 1,\n",
       "  946: 3,\n",
       "  947: 7,\n",
       "  948: 1,\n",
       "  949: 6,\n",
       "  951: 1,\n",
       "  950: 1,\n",
       "  954: 1,\n",
       "  953: 1,\n",
       "  952: 1,\n",
       "  957: 1,\n",
       "  955: 2,\n",
       "  956: 1,\n",
       "  958: 2,\n",
       "  959: 1,\n",
       "  960: 2,\n",
       "  961: 3,\n",
       "  962: 3,\n",
       "  963: 1,\n",
       "  964: 3,\n",
       "  965: 14,\n",
       "  966: 2,\n",
       "  967: 7,\n",
       "  968: 4,\n",
       "  969: 5,\n",
       "  970: 1,\n",
       "  971: 3,\n",
       "  972: 2,\n",
       "  973: 2,\n",
       "  974: 8,\n",
       "  975: 2,\n",
       "  976: 13,\n",
       "  977: 19,\n",
       "  978: 1,\n",
       "  979: 3,\n",
       "  980: 1,\n",
       "  981: 2,\n",
       "  982: 1,\n",
       "  983: 1,\n",
       "  984: 1,\n",
       "  985: 2,\n",
       "  986: 2,\n",
       "  987: 4,\n",
       "  988: 1,\n",
       "  989: 6,\n",
       "  990: 6,\n",
       "  991: 1,\n",
       "  992: 8,\n",
       "  995: 1,\n",
       "  993: 1,\n",
       "  994: 1,\n",
       "  997: 4,\n",
       "  996: 3,\n",
       "  998: 6,\n",
       "  1001: 3,\n",
       "  ...},\n",
       " 'num_docs': 13836,\n",
       " 'num_pos': 37230,\n",
       " 'num_nnz': 37092}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus_dct.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3112"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_corpus_dct.token2id) \n",
    "# It should be kept in mind that the real number of the different tokens in the dataset is len(training_corpus_dct.token2id)-2\n",
    "# because in training_corpus_dct we added 'emptywordtoken' and 'unknownword'.\n",
    "# But in the codes below we will use len(training_corpus_dct.token2id) directly as vocabulary size, \n",
    "# as 'emptywordtoken' and 'unknownword' also have their embeddings in the embedding matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 1,\n",
       " 3: 650,\n",
       " 5: 111,\n",
       " 4: 295,\n",
       " 2: 31,\n",
       " 7: 1335,\n",
       " 6: 5,\n",
       " 8: 72,\n",
       " 9: 44,\n",
       " 13: 5419,\n",
       " 12: 1,\n",
       " 11: 1,\n",
       " 10: 4,\n",
       " 16: 2983,\n",
       " 15: 127,\n",
       " 14: 332,\n",
       " 19: 1,\n",
       " 18: 182,\n",
       " 17: 56,\n",
       " 20: 1382,\n",
       " 22: 178,\n",
       " 21: 88,\n",
       " 23: 8,\n",
       " 24: 30,\n",
       " 25: 1,\n",
       " 26: 89,\n",
       " 27: 82,\n",
       " 28: 115,\n",
       " 29: 125,\n",
       " 30: 5,\n",
       " 31: 10,\n",
       " 32: 1,\n",
       " 34: 178,\n",
       " 33: 23,\n",
       " 35: 669,\n",
       " 36: 126,\n",
       " 37: 704,\n",
       " 38: 44,\n",
       " 39: 58,\n",
       " 40: 29,\n",
       " 41: 961,\n",
       " 42: 67,\n",
       " 43: 3,\n",
       " 47: 7,\n",
       " 45: 1,\n",
       " 44: 25,\n",
       " 48: 1,\n",
       " 46: 35,\n",
       " 49: 80,\n",
       " 51: 59,\n",
       " 50: 46,\n",
       " 52: 13,\n",
       " 56: 23,\n",
       " 54: 447,\n",
       " 53: 849,\n",
       " 55: 10,\n",
       " 57: 405,\n",
       " 58: 264,\n",
       " 60: 195,\n",
       " 59: 2,\n",
       " 62: 17,\n",
       " 61: 65,\n",
       " 63: 8,\n",
       " 64: 147,\n",
       " 65: 98,\n",
       " 66: 1,\n",
       " 67: 1,\n",
       " 68: 1,\n",
       " 70: 64,\n",
       " 69: 3,\n",
       " 71: 5,\n",
       " 73: 55,\n",
       " 72: 228,\n",
       " 74: 224,\n",
       " 75: 275,\n",
       " 76: 1,\n",
       " 78: 28,\n",
       " 77: 8,\n",
       " 79: 268,\n",
       " 80: 8,\n",
       " 81: 1,\n",
       " 82: 18,\n",
       " 83: 4,\n",
       " 84: 34,\n",
       " 85: 13,\n",
       " 86: 3,\n",
       " 89: 3,\n",
       " 87: 71,\n",
       " 88: 211,\n",
       " 90: 38,\n",
       " 91: 165,\n",
       " 94: 167,\n",
       " 93: 2,\n",
       " 92: 2,\n",
       " 95: 385,\n",
       " 96: 44,\n",
       " 97: 30,\n",
       " 98: 4,\n",
       " 99: 8,\n",
       " 100: 30,\n",
       " 101: 138,\n",
       " 103: 36,\n",
       " 102: 156,\n",
       " 105: 67,\n",
       " 104: 1,\n",
       " 106: 10,\n",
       " 107: 3,\n",
       " 108: 25,\n",
       " 109: 50,\n",
       " 110: 205,\n",
       " 111: 259,\n",
       " 112: 341,\n",
       " 116: 105,\n",
       " 115: 71,\n",
       " 113: 168,\n",
       " 114: 109,\n",
       " 117: 1,\n",
       " 119: 14,\n",
       " 118: 16,\n",
       " 120: 38,\n",
       " 121: 15,\n",
       " 123: 6,\n",
       " 122: 1,\n",
       " 124: 1,\n",
       " 125: 3,\n",
       " 126: 10,\n",
       " 127: 71,\n",
       " 128: 14,\n",
       " 129: 93,\n",
       " 130: 7,\n",
       " 132: 405,\n",
       " 131: 10,\n",
       " 133: 5,\n",
       " 134: 95,\n",
       " 135: 4,\n",
       " 136: 7,\n",
       " 137: 3,\n",
       " 138: 38,\n",
       " 139: 43,\n",
       " 140: 4,\n",
       " 141: 1,\n",
       " 143: 3,\n",
       " 142: 12,\n",
       " 144: 2,\n",
       " 145: 7,\n",
       " 146: 10,\n",
       " 148: 3,\n",
       " 147: 1,\n",
       " 149: 384,\n",
       " 150: 1,\n",
       " 151: 2,\n",
       " 152: 15,\n",
       " 153: 80,\n",
       " 154: 52,\n",
       " 155: 33,\n",
       " 156: 5,\n",
       " 157: 8,\n",
       " 159: 10,\n",
       " 158: 1,\n",
       " 160: 177,\n",
       " 161: 77,\n",
       " 162: 169,\n",
       " 163: 16,\n",
       " 164: 15,\n",
       " 165: 4,\n",
       " 166: 57,\n",
       " 167: 18,\n",
       " 168: 3,\n",
       " 169: 52,\n",
       " 170: 52,\n",
       " 171: 1,\n",
       " 173: 14,\n",
       " 172: 8,\n",
       " 174: 2,\n",
       " 175: 1,\n",
       " 176: 1,\n",
       " 177: 1,\n",
       " 178: 22,\n",
       " 179: 84,\n",
       " 180: 1,\n",
       " 182: 251,\n",
       " 181: 1,\n",
       " 184: 6,\n",
       " 183: 3,\n",
       " 185: 30,\n",
       " 186: 30,\n",
       " 187: 1,\n",
       " 189: 2,\n",
       " 188: 4,\n",
       " 190: 12,\n",
       " 191: 1,\n",
       " 193: 43,\n",
       " 192: 1,\n",
       " 195: 43,\n",
       " 194: 4,\n",
       " 196: 2,\n",
       " 197: 16,\n",
       " 198: 4,\n",
       " 199: 7,\n",
       " 200: 15,\n",
       " 202: 9,\n",
       " 201: 88,\n",
       " 203: 5,\n",
       " 204: 52,\n",
       " 205: 62,\n",
       " 206: 1,\n",
       " 207: 33,\n",
       " 208: 13,\n",
       " 209: 15,\n",
       " 211: 1,\n",
       " 210: 1,\n",
       " 212: 10,\n",
       " 213: 36,\n",
       " 215: 11,\n",
       " 214: 24,\n",
       " 217: 1,\n",
       " 216: 6,\n",
       " 218: 3,\n",
       " 219: 7,\n",
       " 220: 28,\n",
       " 221: 32,\n",
       " 222: 76,\n",
       " 223: 57,\n",
       " 224: 12,\n",
       " 225: 34,\n",
       " 226: 16,\n",
       " 227: 2,\n",
       " 229: 11,\n",
       " 230: 8,\n",
       " 228: 2,\n",
       " 231: 2,\n",
       " 232: 1,\n",
       " 233: 1,\n",
       " 234: 31,\n",
       " 235: 6,\n",
       " 236: 1,\n",
       " 237: 16,\n",
       " 238: 5,\n",
       " 239: 5,\n",
       " 240: 3,\n",
       " 241: 1,\n",
       " 242: 4,\n",
       " 243: 170,\n",
       " 244: 6,\n",
       " 245: 5,\n",
       " 246: 10,\n",
       " 247: 14,\n",
       " 248: 18,\n",
       " 249: 4,\n",
       " 250: 8,\n",
       " 251: 12,\n",
       " 252: 15,\n",
       " 253: 12,\n",
       " 255: 14,\n",
       " 254: 13,\n",
       " 256: 21,\n",
       " 258: 6,\n",
       " 257: 5,\n",
       " 259: 6,\n",
       " 260: 1,\n",
       " 261: 15,\n",
       " 263: 12,\n",
       " 262: 65,\n",
       " 266: 6,\n",
       " 265: 5,\n",
       " 264: 7,\n",
       " 267: 3,\n",
       " 268: 1,\n",
       " 269: 33,\n",
       " 270: 4,\n",
       " 271: 1,\n",
       " 272: 14,\n",
       " 273: 13,\n",
       " 274: 31,\n",
       " 275: 98,\n",
       " 276: 31,\n",
       " 277: 93,\n",
       " 278: 33,\n",
       " 279: 8,\n",
       " 280: 13,\n",
       " 281: 15,\n",
       " 282: 14,\n",
       " 283: 3,\n",
       " 284: 23,\n",
       " 285: 1,\n",
       " 286: 9,\n",
       " 287: 12,\n",
       " 288: 5,\n",
       " 289: 30,\n",
       " 290: 3,\n",
       " 291: 18,\n",
       " 292: 8,\n",
       " 293: 29,\n",
       " 294: 44,\n",
       " 295: 28,\n",
       " 296: 12,\n",
       " 297: 3,\n",
       " 298: 1,\n",
       " 301: 22,\n",
       " 299: 1,\n",
       " 300: 1,\n",
       " 302: 1,\n",
       " 303: 9,\n",
       " 304: 37,\n",
       " 305: 8,\n",
       " 306: 4,\n",
       " 307: 2,\n",
       " 308: 1,\n",
       " 310: 75,\n",
       " 309: 16,\n",
       " 312: 3,\n",
       " 313: 2,\n",
       " 311: 3,\n",
       " 314: 59,\n",
       " 315: 1,\n",
       " 316: 1,\n",
       " 317: 1,\n",
       " 318: 3,\n",
       " 319: 1,\n",
       " 321: 15,\n",
       " 320: 3,\n",
       " 322: 1,\n",
       " 323: 22,\n",
       " 324: 13,\n",
       " 325: 5,\n",
       " 326: 23,\n",
       " 327: 5,\n",
       " 328: 30,\n",
       " 329: 6,\n",
       " 330: 15,\n",
       " 331: 3,\n",
       " 332: 16,\n",
       " 333: 14,\n",
       " 334: 1,\n",
       " 335: 22,\n",
       " 336: 13,\n",
       " 337: 3,\n",
       " 338: 2,\n",
       " 339: 3,\n",
       " 340: 2,\n",
       " 341: 16,\n",
       " 342: 22,\n",
       " 343: 5,\n",
       " 344: 61,\n",
       " 345: 7,\n",
       " 346: 2,\n",
       " 347: 3,\n",
       " 348: 4,\n",
       " 349: 1,\n",
       " 350: 2,\n",
       " 351: 4,\n",
       " 352: 4,\n",
       " 353: 31,\n",
       " 354: 39,\n",
       " 355: 1,\n",
       " 356: 5,\n",
       " 357: 3,\n",
       " 358: 4,\n",
       " 359: 16,\n",
       " 360: 18,\n",
       " 362: 7,\n",
       " 361: 3,\n",
       " 363: 1,\n",
       " 364: 6,\n",
       " 365: 3,\n",
       " 366: 1,\n",
       " 368: 17,\n",
       " 367: 18,\n",
       " 369: 8,\n",
       " 370: 2,\n",
       " 372: 58,\n",
       " 371: 34,\n",
       " 373: 5,\n",
       " 374: 1,\n",
       " 375: 4,\n",
       " 376: 20,\n",
       " 377: 2,\n",
       " 378: 12,\n",
       " 379: 8,\n",
       " 380: 11,\n",
       " 381: 3,\n",
       " 382: 2,\n",
       " 384: 2,\n",
       " 383: 9,\n",
       " 385: 1,\n",
       " 386: 1,\n",
       " 387: 8,\n",
       " 388: 22,\n",
       " 389: 1,\n",
       " 390: 1,\n",
       " 391: 3,\n",
       " 392: 13,\n",
       " 393: 22,\n",
       " 394: 49,\n",
       " 395: 1,\n",
       " 396: 3,\n",
       " 397: 5,\n",
       " 398: 4,\n",
       " 399: 1,\n",
       " 400: 3,\n",
       " 401: 2,\n",
       " 402: 7,\n",
       " 403: 9,\n",
       " 404: 4,\n",
       " 405: 1,\n",
       " 406: 10,\n",
       " 407: 1,\n",
       " 408: 8,\n",
       " 409: 12,\n",
       " 411: 1,\n",
       " 410: 15,\n",
       " 412: 13,\n",
       " 413: 3,\n",
       " 414: 6,\n",
       " 415: 26,\n",
       " 417: 5,\n",
       " 416: 1,\n",
       " 418: 8,\n",
       " 419: 2,\n",
       " 420: 17,\n",
       " 421: 1,\n",
       " 422: 114,\n",
       " 423: 2,\n",
       " 424: 23,\n",
       " 425: 5,\n",
       " 426: 5,\n",
       " 427: 4,\n",
       " 429: 14,\n",
       " 428: 2,\n",
       " 430: 12,\n",
       " 431: 2,\n",
       " 432: 3,\n",
       " 434: 1,\n",
       " 435: 1,\n",
       " 436: 1,\n",
       " 433: 1,\n",
       " 437: 1,\n",
       " 438: 12,\n",
       " 439: 9,\n",
       " 440: 4,\n",
       " 441: 8,\n",
       " 442: 2,\n",
       " 443: 6,\n",
       " 444: 1,\n",
       " 445: 6,\n",
       " 446: 27,\n",
       " 447: 1,\n",
       " 448: 1,\n",
       " 449: 1,\n",
       " 450: 1,\n",
       " 451: 1,\n",
       " 452: 1,\n",
       " 453: 6,\n",
       " 454: 7,\n",
       " 455: 26,\n",
       " 456: 18,\n",
       " 457: 4,\n",
       " 458: 1,\n",
       " 459: 4,\n",
       " 460: 2,\n",
       " 461: 9,\n",
       " 463: 7,\n",
       " 462: 2,\n",
       " 464: 1,\n",
       " 466: 10,\n",
       " 465: 14,\n",
       " 467: 1,\n",
       " 469: 74,\n",
       " 468: 34,\n",
       " 470: 7,\n",
       " 471: 13,\n",
       " 472: 3,\n",
       " 473: 11,\n",
       " 474: 1,\n",
       " 477: 2,\n",
       " 476: 2,\n",
       " 475: 1,\n",
       " 478: 1,\n",
       " 479: 3,\n",
       " 480: 1,\n",
       " 481: 13,\n",
       " 482: 3,\n",
       " 483: 19,\n",
       " 484: 1,\n",
       " 485: 1,\n",
       " 486: 5,\n",
       " 487: 5,\n",
       " 489: 23,\n",
       " 488: 5,\n",
       " 490: 1,\n",
       " 491: 12,\n",
       " 492: 1,\n",
       " 493: 1,\n",
       " 494: 1,\n",
       " 495: 1,\n",
       " 496: 3,\n",
       " 497: 7,\n",
       " 498: 1,\n",
       " 499: 4,\n",
       " 500: 4,\n",
       " 502: 3,\n",
       " 501: 4,\n",
       " 503: 11,\n",
       " 506: 5,\n",
       " 504: 3,\n",
       " 505: 6,\n",
       " 508: 2,\n",
       " 507: 1,\n",
       " 509: 3,\n",
       " 510: 7,\n",
       " 511: 23,\n",
       " 512: 15,\n",
       " 513: 2,\n",
       " 514: 3,\n",
       " 515: 4,\n",
       " 516: 8,\n",
       " 517: 4,\n",
       " 518: 2,\n",
       " 519: 2,\n",
       " 520: 1,\n",
       " 521: 8,\n",
       " 522: 4,\n",
       " 523: 10,\n",
       " 524: 7,\n",
       " 525: 1,\n",
       " 526: 23,\n",
       " 528: 1,\n",
       " 527: 1,\n",
       " 529: 2,\n",
       " 530: 4,\n",
       " 531: 21,\n",
       " 532: 2,\n",
       " 533: 3,\n",
       " 534: 13,\n",
       " 535: 5,\n",
       " 536: 3,\n",
       " 537: 3,\n",
       " 538: 1,\n",
       " 539: 10,\n",
       " 540: 32,\n",
       " 541: 3,\n",
       " 542: 1,\n",
       " 543: 2,\n",
       " 544: 8,\n",
       " 545: 5,\n",
       " 546: 1,\n",
       " 547: 1,\n",
       " 548: 8,\n",
       " 549: 2,\n",
       " 550: 4,\n",
       " 552: 17,\n",
       " 551: 29,\n",
       " 554: 2,\n",
       " 553: 2,\n",
       " 555: 3,\n",
       " 556: 4,\n",
       " 557: 1,\n",
       " 558: 3,\n",
       " 559: 1,\n",
       " 560: 32,\n",
       " 561: 2,\n",
       " 562: 5,\n",
       " 563: 8,\n",
       " 565: 47,\n",
       " 564: 1,\n",
       " 566: 3,\n",
       " 568: 2,\n",
       " 567: 1,\n",
       " 570: 20,\n",
       " 569: 1,\n",
       " 571: 17,\n",
       " 572: 52,\n",
       " 573: 17,\n",
       " 574: 8,\n",
       " 575: 11,\n",
       " 576: 42,\n",
       " 577: 5,\n",
       " 578: 1,\n",
       " 580: 3,\n",
       " 579: 1,\n",
       " 581: 19,\n",
       " 582: 3,\n",
       " 583: 35,\n",
       " 584: 1,\n",
       " 585: 2,\n",
       " 586: 24,\n",
       " 587: 1,\n",
       " 588: 4,\n",
       " 590: 15,\n",
       " 589: 5,\n",
       " 592: 1,\n",
       " 591: 3,\n",
       " 593: 1,\n",
       " 594: 1,\n",
       " 595: 3,\n",
       " 596: 35,\n",
       " 597: 5,\n",
       " 598: 1,\n",
       " 599: 12,\n",
       " 600: 7,\n",
       " 601: 1,\n",
       " 602: 1,\n",
       " 603: 14,\n",
       " 604: 13,\n",
       " 605: 1,\n",
       " 607: 5,\n",
       " 606: 2,\n",
       " 608: 7,\n",
       " 610: 39,\n",
       " 609: 1,\n",
       " 611: 6,\n",
       " 612: 1,\n",
       " 613: 23,\n",
       " 614: 10,\n",
       " 615: 9,\n",
       " 616: 3,\n",
       " 617: 3,\n",
       " 618: 15,\n",
       " 619: 1,\n",
       " 620: 9,\n",
       " 621: 15,\n",
       " 622: 2,\n",
       " 623: 2,\n",
       " 624: 1,\n",
       " 625: 10,\n",
       " 626: 2,\n",
       " 627: 20,\n",
       " 628: 1,\n",
       " 629: 7,\n",
       " 631: 7,\n",
       " 630: 1,\n",
       " 632: 9,\n",
       " 633: 6,\n",
       " 634: 10,\n",
       " 636: 10,\n",
       " 637: 17,\n",
       " 635: 3,\n",
       " 638: 8,\n",
       " 639: 5,\n",
       " 640: 2,\n",
       " 641: 10,\n",
       " 642: 3,\n",
       " 644: 4,\n",
       " 643: 1,\n",
       " 646: 5,\n",
       " 645: 1,\n",
       " 647: 2,\n",
       " 648: 16,\n",
       " 649: 13,\n",
       " 650: 2,\n",
       " 651: 22,\n",
       " 652: 1,\n",
       " 653: 6,\n",
       " 654: 1,\n",
       " 655: 1,\n",
       " 657: 4,\n",
       " 656: 1,\n",
       " 660: 1,\n",
       " 658: 1,\n",
       " 659: 1,\n",
       " 661: 6,\n",
       " 662: 2,\n",
       " 664: 4,\n",
       " 663: 2,\n",
       " 665: 25,\n",
       " 666: 5,\n",
       " 667: 1,\n",
       " 668: 1,\n",
       " 669: 4,\n",
       " 671: 27,\n",
       " 670: 25,\n",
       " 672: 11,\n",
       " 674: 6,\n",
       " 673: 4,\n",
       " 675: 3,\n",
       " 676: 3,\n",
       " 677: 4,\n",
       " 678: 4,\n",
       " 679: 2,\n",
       " 680: 31,\n",
       " 681: 3,\n",
       " 682: 4,\n",
       " 683: 4,\n",
       " 684: 5,\n",
       " 685: 2,\n",
       " 686: 6,\n",
       " 687: 4,\n",
       " 688: 8,\n",
       " 689: 7,\n",
       " 690: 2,\n",
       " 691: 19,\n",
       " 692: 13,\n",
       " 693: 13,\n",
       " 694: 1,\n",
       " 695: 4,\n",
       " 696: 1,\n",
       " 697: 1,\n",
       " 698: 8,\n",
       " 700: 14,\n",
       " 699: 2,\n",
       " 701: 6,\n",
       " 702: 2,\n",
       " 704: 8,\n",
       " 703: 23,\n",
       " 705: 1,\n",
       " 706: 5,\n",
       " 707: 8,\n",
       " 709: 10,\n",
       " 708: 5,\n",
       " 710: 4,\n",
       " 711: 2,\n",
       " 712: 11,\n",
       " 713: 8,\n",
       " 714: 4,\n",
       " 715: 10,\n",
       " 716: 28,\n",
       " 717: 20,\n",
       " 718: 2,\n",
       " 719: 7,\n",
       " 721: 1,\n",
       " 720: 1,\n",
       " 722: 8,\n",
       " 723: 1,\n",
       " 724: 7,\n",
       " 725: 21,\n",
       " 726: 4,\n",
       " 727: 8,\n",
       " 728: 1,\n",
       " 729: 2,\n",
       " 731: 3,\n",
       " 730: 1,\n",
       " 732: 3,\n",
       " 733: 8,\n",
       " 734: 1,\n",
       " 735: 16,\n",
       " 737: 11,\n",
       " 736: 2,\n",
       " 738: 19,\n",
       " 739: 1,\n",
       " 740: 19,\n",
       " 741: 5,\n",
       " 743: 2,\n",
       " 742: 6,\n",
       " 744: 4,\n",
       " 745: 1,\n",
       " 746: 1,\n",
       " 747: 18,\n",
       " 748: 1,\n",
       " 749: 8,\n",
       " 750: 5,\n",
       " 751: 1,\n",
       " 752: 5,\n",
       " 753: 6,\n",
       " 754: 2,\n",
       " 755: 1,\n",
       " 758: 4,\n",
       " 757: 2,\n",
       " 756: 4,\n",
       " 759: 1,\n",
       " 760: 2,\n",
       " 761: 13,\n",
       " 762: 5,\n",
       " 763: 1,\n",
       " 764: 8,\n",
       " 765: 4,\n",
       " 766: 3,\n",
       " 767: 1,\n",
       " 768: 3,\n",
       " 769: 5,\n",
       " 770: 2,\n",
       " 771: 1,\n",
       " 772: 4,\n",
       " 773: 1,\n",
       " 774: 5,\n",
       " 775: 1,\n",
       " 776: 25,\n",
       " 777: 1,\n",
       " 778: 8,\n",
       " 779: 9,\n",
       " 780: 3,\n",
       " 781: 5,\n",
       " 782: 3,\n",
       " 783: 1,\n",
       " 784: 3,\n",
       " 785: 2,\n",
       " 786: 2,\n",
       " 787: 1,\n",
       " 788: 1,\n",
       " 789: 3,\n",
       " 790: 1,\n",
       " 791: 2,\n",
       " 792: 7,\n",
       " 793: 2,\n",
       " 794: 12,\n",
       " 795: 9,\n",
       " 796: 4,\n",
       " 797: 3,\n",
       " 798: 1,\n",
       " 799: 3,\n",
       " 800: 4,\n",
       " 801: 19,\n",
       " 802: 1,\n",
       " 803: 6,\n",
       " 804: 2,\n",
       " 805: 2,\n",
       " 806: 1,\n",
       " 807: 10,\n",
       " 808: 2,\n",
       " 809: 1,\n",
       " 810: 1,\n",
       " 811: 1,\n",
       " 812: 2,\n",
       " 813: 11,\n",
       " 814: 12,\n",
       " 815: 8,\n",
       " 816: 5,\n",
       " 817: 1,\n",
       " 818: 9,\n",
       " 819: 8,\n",
       " 820: 5,\n",
       " 821: 1,\n",
       " 822: 1,\n",
       " 823: 3,\n",
       " 824: 4,\n",
       " 825: 11,\n",
       " 827: 7,\n",
       " 826: 3,\n",
       " 828: 4,\n",
       " 829: 2,\n",
       " 830: 18,\n",
       " 831: 4,\n",
       " 832: 1,\n",
       " 833: 8,\n",
       " 834: 1,\n",
       " 836: 11,\n",
       " 835: 16,\n",
       " 837: 1,\n",
       " 838: 6,\n",
       " 840: 1,\n",
       " 839: 1,\n",
       " 841: 3,\n",
       " 842: 1,\n",
       " 843: 1,\n",
       " 844: 1,\n",
       " 845: 3,\n",
       " 846: 7,\n",
       " 847: 18,\n",
       " 848: 6,\n",
       " 849: 3,\n",
       " 850: 5,\n",
       " 851: 10,\n",
       " 852: 2,\n",
       " 853: 1,\n",
       " 854: 17,\n",
       " 856: 2,\n",
       " 855: 1,\n",
       " 857: 8,\n",
       " 859: 3,\n",
       " 858: 5,\n",
       " 860: 5,\n",
       " 861: 2,\n",
       " 862: 1,\n",
       " 863: 7,\n",
       " 864: 8,\n",
       " 865: 1,\n",
       " 866: 3,\n",
       " 867: 9,\n",
       " 868: 1,\n",
       " 869: 5,\n",
       " 870: 2,\n",
       " 871: 6,\n",
       " 872: 13,\n",
       " 873: 5,\n",
       " 874: 5,\n",
       " 875: 16,\n",
       " 877: 2,\n",
       " 876: 6,\n",
       " 878: 1,\n",
       " 879: 5,\n",
       " 880: 6,\n",
       " 881: 1,\n",
       " 882: 1,\n",
       " 883: 6,\n",
       " 884: 3,\n",
       " 885: 1,\n",
       " 886: 4,\n",
       " 887: 5,\n",
       " 888: 1,\n",
       " 889: 5,\n",
       " 890: 5,\n",
       " 892: 2,\n",
       " 891: 6,\n",
       " 893: 1,\n",
       " 894: 3,\n",
       " 895: 2,\n",
       " 896: 2,\n",
       " 897: 4,\n",
       " 899: 6,\n",
       " 898: 4,\n",
       " 900: 1,\n",
       " 901: 2,\n",
       " 902: 1,\n",
       " 903: 2,\n",
       " 904: 4,\n",
       " 905: 1,\n",
       " 906: 2,\n",
       " 907: 3,\n",
       " 908: 1,\n",
       " 909: 4,\n",
       " 910: 16,\n",
       " 911: 14,\n",
       " 912: 1,\n",
       " 913: 3,\n",
       " 914: 7,\n",
       " 915: 1,\n",
       " 916: 1,\n",
       " 917: 1,\n",
       " 918: 1,\n",
       " 919: 5,\n",
       " 920: 1,\n",
       " 921: 2,\n",
       " 922: 2,\n",
       " 923: 2,\n",
       " 924: 12,\n",
       " 926: 1,\n",
       " 925: 1,\n",
       " 927: 2,\n",
       " 928: 1,\n",
       " 929: 1,\n",
       " 930: 2,\n",
       " 931: 2,\n",
       " 932: 2,\n",
       " 933: 1,\n",
       " 934: 2,\n",
       " 935: 1,\n",
       " 936: 8,\n",
       " 937: 6,\n",
       " 938: 2,\n",
       " 939: 1,\n",
       " 940: 7,\n",
       " 941: 2,\n",
       " 942: 8,\n",
       " 944: 1,\n",
       " 943: 3,\n",
       " 945: 1,\n",
       " 946: 3,\n",
       " 947: 7,\n",
       " 948: 1,\n",
       " 949: 6,\n",
       " 951: 1,\n",
       " 950: 1,\n",
       " 954: 1,\n",
       " 953: 1,\n",
       " 952: 1,\n",
       " 957: 1,\n",
       " 955: 2,\n",
       " 956: 1,\n",
       " 958: 2,\n",
       " 959: 1,\n",
       " 960: 2,\n",
       " 961: 3,\n",
       " 962: 3,\n",
       " 963: 1,\n",
       " 964: 3,\n",
       " 965: 14,\n",
       " 966: 2,\n",
       " 967: 7,\n",
       " 968: 4,\n",
       " 969: 5,\n",
       " 970: 1,\n",
       " 971: 3,\n",
       " 972: 2,\n",
       " 973: 2,\n",
       " 974: 8,\n",
       " 975: 2,\n",
       " 976: 13,\n",
       " 977: 19,\n",
       " 978: 1,\n",
       " 979: 3,\n",
       " 980: 1,\n",
       " 981: 2,\n",
       " 982: 1,\n",
       " 983: 1,\n",
       " 984: 1,\n",
       " 985: 2,\n",
       " 986: 2,\n",
       " 987: 4,\n",
       " 988: 1,\n",
       " 989: 6,\n",
       " 990: 6,\n",
       " 991: 1,\n",
       " 992: 8,\n",
       " 995: 1,\n",
       " 993: 1,\n",
       " 994: 1,\n",
       " 997: 4,\n",
       " 996: 3,\n",
       " 998: 6,\n",
       " 1001: 3,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus_dct.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 650, 111, 295, 31, 1335, 5, 72, 44, 5419, 1, 1, 4, 2983, 127, 332, 1, 182, 56, 1382, 178, 88, 8, 30, 1, 89, 82, 115, 125, 5, 10, 1, 178, 23, 669, 126, 704, 44, 58, 29, 961, 67, 3, 7, 1, 25, 1, 35, 80, 59, 46, 13, 23, 447, 849, 10, 405, 264, 195, 2, 17, 65, 8, 147, 98, 1, 1, 1, 64, 3, 5, 55, 228, 224, 275, 1, 28, 8, 268, 8, 1, 18, 4, 34, 13, 3, 3, 71, 211, 38, 165, 167, 2, 2, 385, 44, 30, 4, 8, 30, 138, 36, 156, 67, 1, 10, 3, 25, 50, 205, 259, 341, 105, 71, 168, 109, 1, 14, 16, 38, 15, 6, 1, 1, 3, 10, 71, 14, 93, 7, 405, 10, 5, 95, 4, 7, 3, 38, 43, 4, 1, 3, 12, 2, 7, 10, 3, 1, 384, 1, 2, 15, 80, 52, 33, 5, 8, 10, 1, 177, 77, 169, 16, 15, 4, 57, 18, 3, 52, 52, 1, 14, 8, 2, 1, 1, 1, 22, 84, 1, 251, 1, 6, 3, 30, 30, 1, 2, 4, 12, 1, 43, 1, 43, 4, 2, 16, 4, 7, 15, 9, 88, 5, 52, 62, 1, 33, 13, 15, 1, 1, 10, 36, 11, 24, 1, 6, 3, 7, 28, 32, 76, 57, 12, 34, 16, 2, 11, 8, 2, 2, 1, 1, 31, 6, 1, 16, 5, 5, 3, 1, 4, 170, 6, 5, 10, 14, 18, 4, 8, 12, 15, 12, 14, 13, 21, 6, 5, 6, 1, 15, 12, 65, 6, 5, 7, 3, 1, 33, 4, 1, 14, 13, 31, 98, 31, 93, 33, 8, 13, 15, 14, 3, 23, 1, 9, 12, 5, 30, 3, 18, 8, 29, 44, 28, 12, 3, 1, 22, 1, 1, 1, 9, 37, 8, 4, 2, 1, 75, 16, 3, 2, 3, 59, 1, 1, 1, 3, 1, 15, 3, 1, 22, 13, 5, 23, 5, 30, 6, 15, 3, 16, 14, 1, 22, 13, 3, 2, 3, 2, 16, 22, 5, 61, 7, 2, 3, 4, 1, 2, 4, 4, 31, 39, 1, 5, 3, 4, 16, 18, 7, 3, 1, 6, 3, 1, 17, 18, 8, 2, 58, 34, 5, 1, 4, 20, 2, 12, 8, 11, 3, 2, 2, 9, 1, 1, 8, 22, 1, 1, 3, 13, 22, 49, 1, 3, 5, 4, 1, 3, 2, 7, 9, 4, 1, 10, 1, 8, 12, 1, 15, 13, 3, 6, 26, 5, 1, 8, 2, 17, 1, 114, 2, 23, 5, 5, 4, 14, 2, 12, 2, 3, 1, 1, 1, 1, 1, 12, 9, 4, 8, 2, 6, 1, 6, 27, 1, 1, 1, 1, 1, 1, 6, 7, 26, 18, 4, 1, 4, 2, 9, 7, 2, 1, 10, 14, 1, 74, 34, 7, 13, 3, 11, 1, 2, 2, 1, 1, 3, 1, 13, 3, 19, 1, 1, 5, 5, 23, 5, 1, 12, 1, 1, 1, 1, 3, 7, 1, 4, 4, 3, 4, 11, 5, 3, 6, 2, 1, 3, 7, 23, 15, 2, 3, 4, 8, 4, 2, 2, 1, 8, 4, 10, 7, 1, 23, 1, 1, 2, 4, 21, 2, 3, 13, 5, 3, 3, 1, 10, 32, 3, 1, 2, 8, 5, 1, 1, 8, 2, 4, 17, 29, 2, 2, 3, 4, 1, 3, 1, 32, 2, 5, 8, 47, 1, 3, 2, 1, 20, 1, 17, 52, 17, 8, 11, 42, 5, 1, 3, 1, 19, 3, 35, 1, 2, 24, 1, 4, 15, 5, 1, 3, 1, 1, 3, 35, 5, 1, 12, 7, 1, 1, 14, 13, 1, 5, 2, 7, 39, 1, 6, 1, 23, 10, 9, 3, 3, 15, 1, 9, 15, 2, 2, 1, 10, 2, 20, 1, 7, 7, 1, 9, 6, 10, 10, 17, 3, 8, 5, 2, 10, 3, 4, 1, 5, 1, 2, 16, 13, 2, 22, 1, 6, 1, 1, 4, 1, 1, 1, 1, 6, 2, 4, 2, 25, 5, 1, 1, 4, 27, 25, 11, 6, 4, 3, 3, 4, 4, 2, 31, 3, 4, 4, 5, 2, 6, 4, 8, 7, 2, 19, 13, 13, 1, 4, 1, 1, 8, 14, 2, 6, 2, 8, 23, 1, 5, 8, 10, 5, 4, 2, 11, 8, 4, 10, 28, 20, 2, 7, 1, 1, 8, 1, 7, 21, 4, 8, 1, 2, 3, 1, 3, 8, 1, 16, 11, 2, 19, 1, 19, 5, 2, 6, 4, 1, 1, 18, 1, 8, 5, 1, 5, 6, 2, 1, 4, 2, 4, 1, 2, 13, 5, 1, 8, 4, 3, 1, 3, 5, 2, 1, 4, 1, 5, 1, 25, 1, 8, 9, 3, 5, 3, 1, 3, 2, 2, 1, 1, 3, 1, 2, 7, 2, 12, 9, 4, 3, 1, 3, 4, 19, 1, 6, 2, 2, 1, 10, 2, 1, 1, 1, 2, 11, 12, 8, 5, 1, 9, 8, 5, 1, 1, 3, 4, 11, 7, 3, 4, 2, 18, 4, 1, 8, 1, 11, 16, 1, 6, 1, 1, 3, 1, 1, 1, 3, 7, 18, 6, 3, 5, 10, 2, 1, 17, 2, 1, 8, 3, 5, 5, 2, 1, 7, 8, 1, 3, 9, 1, 5, 2, 6, 13, 5, 5, 16, 2, 6, 1, 5, 6, 1, 1, 6, 3, 1, 4, 5, 1, 5, 5, 2, 6, 1, 3, 2, 2, 4, 6, 4, 1, 2, 1, 2, 4, 1, 2, 3, 1, 4, 16, 14, 1, 3, 7, 1, 1, 1, 1, 5, 1, 2, 2, 2, 12, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 8, 6, 2, 1, 7, 2, 8, 1, 3, 1, 3, 7, 1, 6, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 3, 3, 1, 3, 14, 2, 7, 4, 5, 1, 3, 2, 2, 8, 2, 13, 19, 1, 3, 1, 2, 1, 1, 1, 2, 2, 4, 1, 6, 6, 1, 8, 1, 1, 1, 4, 3, 6, 3, 1, 3, 1, 1, 4, 1, 8, 1, 8, 7, 1, 13, 3, 3, 4, 16, 2, 3, 2, 8, 6, 1, 2, 2, 5, 1, 1, 1, 1, 1, 2, 5, 1, 3, 1, 11, 3, 3, 1, 4, 1, 6, 1, 1, 5, 1, 14, 3, 1, 1, 2, 1, 6, 5, 3, 2, 9, 3, 1, 1, 2, 1, 2, 1, 3, 2, 1, 1, 5, 4, 5, 2, 2, 1, 2, 3, 19, 3, 2, 1, 6, 4, 4, 7, 3, 4, 2, 1, 7, 1, 6, 2, 1, 2, 4, 14, 4, 2, 1, 1, 1, 1, 4, 13, 1, 15, 4, 1, 5, 7, 2, 5, 1, 2, 1, 11, 5, 1, 1, 3, 9, 14, 3, 1, 1, 27, 2, 1, 2, 3, 1, 1, 3, 1, 19, 1, 22, 7, 1, 1, 9, 1, 3, 1, 3, 3, 1, 3, 2, 6, 1, 3, 1, 1, 3, 1, 2, 2, 1, 1, 12, 11, 5, 4, 8, 2, 2, 1, 4, 5, 1, 6, 1, 1, 1, 1, 1, 5, 13, 14, 5, 4, 5, 7, 5, 3, 1, 2, 1, 1, 1, 2, 1, 3, 1, 3, 3, 3, 1, 2, 2, 8, 3, 2, 12, 3, 7, 1, 1, 2, 1, 1, 2, 3, 6, 1, 2, 7, 1, 2, 1, 5, 2, 4, 1, 1, 2, 4, 1, 2, 10, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 5, 5, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 4, 4, 1, 1, 7, 10, 1, 3, 1, 1, 11, 1, 2, 1, 2, 1, 3, 1, 1, 4, 1, 1, 1, 1, 2, 3, 10, 8, 2, 5, 1, 12, 2, 1, 5, 1, 10, 1, 2, 1, 5, 5, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 12, 1, 1, 1, 3, 1, 2, 1, 4, 1, 1, 3, 1, 2, 1, 1, 1, 1, 3, 1, 3, 1, 11, 1, 2, 1, 3, 1, 1, 1, 4, 9, 2, 1, 1, 1, 3, 1, 1, 3, 2, 2, 10, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 4, 2, 8, 2, 15, 1, 6, 1, 1, 1, 2, 1, 1, 8, 3, 1, 1, 1, 18, 1, 1, 1, 1, 2, 8, 1, 9, 6, 1, 1, 1, 5, 4, 1, 1, 1, 1, 7, 2, 1, 3, 3, 1, 2, 1, 2, 1, 5, 1, 1, 3, 4, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 3, 4, 1, 7, 2, 3, 1, 1, 8, 11, 1, 3, 1, 1, 1, 1, 3, 2, 3, 1, 8, 1, 3, 1, 1, 1, 2, 7, 6, 1, 1, 2, 3, 1, 1, 3, 1, 2, 1, 3, 5, 11, 1, 3, 2, 1, 6, 1, 1, 2, 3, 1, 1, 2, 3, 3, 4, 5, 3, 3, 1, 22, 2, 1, 1, 1, 2, 5, 1, 1, 2, 7, 7, 2, 1, 3, 6, 1, 4, 5, 1, 3, 1, 1, 3, 2, 1, 1, 1, 3, 1, 2, 1, 2, 2, 1, 1, 1, 2, 3, 1, 1, 2, 2, 9, 1, 1, 2, 1, 4, 1, 1, 1, 1, 4, 1, 10, 1, 1, 1, 2, 3, 1, 1, 3, 6, 5, 1, 3, 12, 1, 1, 4, 4, 1, 2, 3, 2, 1, 2, 1, 1, 5, 2, 3, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 5, 1, 3, 6, 4, 5, 1, 1, 4, 1, 3, 2, 1, 2, 1, 1, 4, 2, 2, 8, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 5, 2, 3, 1, 1, 1, 1, 3, 2, 2, 3, 1, 1, 1, 1, 4, 4, 1, 1, 1, 7, 5, 1, 1, 2, 6, 4, 2, 6, 2, 3, 1, 2, 4, 1, 4, 2, 3, 4, 6, 7, 4, 3, 1, 8, 1, 2, 2, 2, 1, 2, 1, 1, 4, 1, 2, 4, 1, 2, 1, 3, 2, 3, 2, 1, 2, 2, 7, 1, 1, 1, 1, 7, 4, 1, 1, 2, 1, 1, 1, 1, 6, 1, 1, 3, 1, 1, 1, 1, 3, 2, 10, 2, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 2, 1, 2, 3, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 9, 1, 5, 1, 3, 1, 6, 10, 1, 2, 1, 3, 6, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 3, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 3, 8, 10, 1, 1, 1, 1, 1, 1, 1, 1, 5, 3, 2, 1, 11, 1, 4, 3, 1, 3, 1, 1, 1, 1, 3, 2, 1, 1, 1, 4, 2, 2, 6, 2, 1, 1, 1, 2, 2, 1, 4, 2, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 8, 1, 1, 2, 1, 2, 1, 4, 4, 1, 1, 1, 3, 1, 2, 1, 4, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 3, 1, 1, 2, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 4, 2, 2, 1, 1, 1, 2, 4, 1, 1, 1, 3, 8, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 3, 1, 1, 1, 2, 1, 3, 3, 1, 1, 1, 2, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 3, 2, 2, 1, 2, 5, 2, 3, 2, 3, 1, 1, 1, 10, 3, 2, 1, 9, 1, 3, 10, 1, 1, 1, 1, 1, 2, 3, 2, 2, 2, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 5, 3, 1, 1, 1, 2, 10, 2, 1, 1, 1, 1, 2, 2, 1, 2, 5, 4, 6, 3, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 2, 2, 1, 1, 3, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 5, 4, 1, 1, 2, 2, 2, 1, 4, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 6, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 6, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 2, 1, 3, 1, 3, 2, 2, 1, 1, 1, 1, 2, 1, 6, 5, 2, 1, 3, 1, 4, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 2, 5, 2, 1, 1, 1, 7, 1, 1, 1, 1, 1, 4, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 2, 5, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 4, 2, 4, 2, 1, 1, 3, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 6, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 1, 3, 1, 2, 1, 1, 1, 3, 2, 1, 2, 4, 1, 1, 2, 2, 4, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2, 1, 3, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 3, 5, 2, 2, 1, 1, 2, 4, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 4, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 7, 3, 1, 1, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 11, 2, 1, 1, 8, 2, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 3, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 2, 1, 2, 1, 1, 1, 4, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 4, 1, 1, 2, 2, 1, 3, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 5, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "freq = list(training_corpus_dct.dfs.values())\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1059)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.tensor(freq) >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(667)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.tensor(freq) >= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMPTYWORDTOKEN',\n",
       " 'UNKNOWNWORD',\n",
       " 'deux jeunes hommes blancs',\n",
       " 'de buissons',\n",
       " 'plusieurs hommes',\n",
       " 'casque',\n",
       " 'un système de poulies géant',\n",
       " 'une petite fille',\n",
       " 'une maisonnette en bois',\n",
       " 'un homme',\n",
       " 'une chemise bleue',\n",
       " 'une échelle',\n",
       " 'une fenêtre',\n",
       " 'deux hommes',\n",
       " 'fourneaux',\n",
       " 'un homme',\n",
       " 'vert',\n",
       " 'une guitare',\n",
       " 'un autre homme',\n",
       " 'sa chemise',\n",
       " 'un homme',\n",
       " 'un ours en peluche',\n",
       " 'une fille branchée',\n",
       " 'son portable',\n",
       " 'la rue',\n",
       " 'une femme',\n",
       " 'un gros sac',\n",
       " 'une porte',\n",
       " 'des garçons',\n",
       " 'des barres',\n",
       " 'une classe de ballet , composée de cinq filles',\n",
       " 'quatre gars',\n",
       " 'des chapeaux',\n",
       " \"haut d' un escalier\",\n",
       " 'un chien noir',\n",
       " 'un chien à tâches',\n",
       " 'un homme',\n",
       " 'uniforme orange',\n",
       " 'un tracteur vert',\n",
       " 'plusieurs femmes',\n",
       " 'une femme',\n",
       " 'un haut noir',\n",
       " 'des lunettes',\n",
       " 'sucre',\n",
       " 'un bundt cake',\n",
       " 'une petite fille',\n",
       " 'un grand arc-en-ciel peint',\n",
       " 'un homme',\n",
       " 'un banc [',\n",
       " 'un chien blanc',\n",
       " 'cinq personnes',\n",
       " 'cercle',\n",
       " 'leurs instruments',\n",
       " 'un groupe de femmes âgées',\n",
       " 'la clarinette [',\n",
       " 'leur partition',\n",
       " 'une grande structure',\n",
       " 'la chaussée',\n",
       " 'une importante foule de gens',\n",
       " 'un homme',\n",
       " 'son dos',\n",
       " 'deux enfants',\n",
       " 'un petit manège à bascule',\n",
       " 'le sable',\n",
       " 'un homme',\n",
       " 'un gilet réfléchissant',\n",
       " 'un casque',\n",
       " 'un drapeau',\n",
       " 'la route',\n",
       " 'une personne',\n",
       " 'un manteau bleu',\n",
       " 'un trottoir encombré',\n",
       " 'une peinture représentant une scène de rue',\n",
       " 'un homme',\n",
       " 'un pantalon vert',\n",
       " 'la route',\n",
       " 'le petit enfant',\n",
       " 'rouge',\n",
       " 'un jeune homme',\n",
       " 'une veste noire et jaune',\n",
       " 'un homme',\n",
       " 'un urinoir',\n",
       " 'une tasse de café',\n",
       " 'cinq personnes',\n",
       " 'un vieil homme',\n",
       " 'une bière',\n",
       " 'un chien policier dressé',\n",
       " 'son maître',\n",
       " 'un fourgon de police',\n",
       " 'une personne',\n",
       " 'vélo',\n",
       " 'une route enneigée',\n",
       " 'cinq hommes',\n",
       " 'chemise blanche',\n",
       " 'une cravate',\n",
       " 'un pantalon noir',\n",
       " \"l' arrière d' un fourgon ouvert\",\n",
       " 'un homme',\n",
       " 'un chapeau',\n",
       " 'des machines',\n",
       " 'une femme noire',\n",
       " 'un homme blanc',\n",
       " 'de bougies [',\n",
       " 'des cartons',\n",
       " 'un asiatique',\n",
       " 'le trottoir',\n",
       " 'un homme',\n",
       " 'une voiture',\n",
       " 'conducteur',\n",
       " 'deux jeunes bambins',\n",
       " 'des gens',\n",
       " 'une personne',\n",
       " 'un étrange véhicule',\n",
       " 'un homme',\n",
       " 'un véhicule argenté',\n",
       " 'une belle mariée',\n",
       " 'le trottoir',\n",
       " 'son nouveau mari',\n",
       " 'un petit garçon',\n",
       " 'la gamecube',\n",
       " 'un mcdonald',\n",
       " 'un chien blanc',\n",
       " 'le bord de la plage',\n",
       " 'une balle orange',\n",
       " 'un groupe de gens',\n",
       " 'un homme',\n",
       " 'lunettes de soleil',\n",
       " \"d' une femme\",\n",
       " 'chemisier blanc',\n",
       " 'des gens',\n",
       " 'un homme',\n",
       " 'un chapeau en ballons',\n",
       " 'des tables de picnic',\n",
       " 'un garçon',\n",
       " 'trois enfants',\n",
       " 'du bois',\n",
       " 'un garçon',\n",
       " 'une veste rouge',\n",
       " \"l' eau\",\n",
       " 'un homme',\n",
       " 'chemise blanche',\n",
       " 'un homme',\n",
       " 'une veste rouge',\n",
       " 'un morceau de papier',\n",
       " 'des hommes',\n",
       " 'la rue',\n",
       " 'des enfants',\n",
       " 'un petit garçon',\n",
       " 'la rue',\n",
       " 'un homme',\n",
       " 'salopette',\n",
       " 'un mur de pierre',\n",
       " 'un chien noir',\n",
       " 'une bûche',\n",
       " 'un homme',\n",
       " 'costume',\n",
       " 'deux autres messieurs',\n",
       " 'un costume',\n",
       " 'un homme',\n",
       " 'une chemise rouge',\n",
       " 'vélo',\n",
       " \"l' eau\",\n",
       " 'un homme , pieds nus',\n",
       " 'un fort vert olive',\n",
       " 'des hotdogs',\n",
       " 'un petit réchaud',\n",
       " 'une tasse de plastique bleu',\n",
       " 'un chien',\n",
       " 'la neige',\n",
       " 'une foule',\n",
       " \"l' homme\",\n",
       " 'skis',\n",
       " 'les illustrations',\n",
       " 'la neige',\n",
       " 'sept alpinistes',\n",
       " \"d' un rocher\",\n",
       " 'un autre homme',\n",
       " 'une corde',\n",
       " \"la corps souple d' une jeune gymnaste\",\n",
       " \"la poutre d' équilibre\",\n",
       " 'un jeune garçon',\n",
       " 'un jouet atv',\n",
       " \"d' une piscine en caoutchouc\",\n",
       " 'une femme',\n",
       " 'coupe-vent rouge',\n",
       " 'un homme',\n",
       " 'un objet rouge [',\n",
       " 'un avion',\n",
       " 'un chien',\n",
       " 'un tuyau',\n",
       " 'un homme',\n",
       " 'une petite fille',\n",
       " 'leur chariot',\n",
       " 'un chien blanc',\n",
       " 'un jouet pour chiens jaune',\n",
       " 'un type',\n",
       " 'chemise verte',\n",
       " 'la main',\n",
       " 'une partie de son visage',\n",
       " 'un restaurant',\n",
       " 'un chien noir et blanc',\n",
       " 'un jouet jaune',\n",
       " 'deux randonneurs',\n",
       " 'un morceau de neige',\n",
       " 'un homme',\n",
       " 'sa nouvelle création en bois',\n",
       " 'un père âgé',\n",
       " 'son fils adulte',\n",
       " 'un voyageur barbu',\n",
       " 'une chemise rouge',\n",
       " 'une carte',\n",
       " 'un jeune garçon',\n",
       " 'un canard',\n",
       " \"d' eau\",\n",
       " 'un parc vert',\n",
       " 'un couple',\n",
       " \"l' herbe\",\n",
       " 'un bébé',\n",
       " 'une poussette',\n",
       " 'quelques hommes',\n",
       " 'un immeuble',\n",
       " 'une voiture en stationnement',\n",
       " 'le chien noir',\n",
       " \"l' eau\",\n",
       " 'un homme',\n",
       " \"la glace d' un étang gelé\",\n",
       " 'deux chiens beiges imposants',\n",
       " 'une plage de sable',\n",
       " 'une personne',\n",
       " 'bleu et rouge',\n",
       " 'deux pics à glace',\n",
       " 'trois personnes',\n",
       " 'un chemin',\n",
       " 'un homme',\n",
       " 'costume noir fait des pelletées de neige',\n",
       " 'la rue',\n",
       " 'un couple',\n",
       " 'leur gâteau de mariage',\n",
       " 'un chien noir mouillé',\n",
       " 'un jouet vert',\n",
       " \"l' herbe\",\n",
       " 'des villageois',\n",
       " 'leur récolte',\n",
       " 'un homme',\n",
       " 'blanc',\n",
       " 'du chanteur [',\n",
       " 'un t-shirt jaune',\n",
       " 'un garçon',\n",
       " 'son skateboard',\n",
       " 'une foule',\n",
       " \"l' eau\",\n",
       " 'un homme',\n",
       " 'un bébé',\n",
       " 'un kayak jaune',\n",
       " 'deux personnes',\n",
       " 'un banc',\n",
       " 'une femme',\n",
       " 'un chantier de construction',\n",
       " 'la rue',\n",
       " 'trois hommes',\n",
       " 'deux hommes',\n",
       " 'un banc',\n",
       " 'un panneau publicitaire',\n",
       " 'des lunettes',\n",
       " 'un groupe de jeunes',\n",
       " 'la rue',\n",
       " 'des drapeaux',\n",
       " 'trois hommes',\n",
       " 'un autre',\n",
       " 'le poisson',\n",
       " 'une femme',\n",
       " 'un débardeur blanc',\n",
       " 'une jupe [',\n",
       " 'deux hommes',\n",
       " 'deux femmes',\n",
       " 'des marches en extérieur',\n",
       " 'un jouet',\n",
       " 'sa bouche',\n",
       " 'un gardien de but de hockey',\n",
       " 'veste rouge',\n",
       " \"l' objectif\",\n",
       " 'le bâton',\n",
       " \"l' homme\",\n",
       " 'le sac à dos',\n",
       " 'une cour de bâtiment',\n",
       " \"une sculpture d' art.\",\n",
       " 'un tout petit',\n",
       " 'un chapeau rouge',\n",
       " 'un garde-corps',\n",
       " 'trois chiens',\n",
       " 'un champ herbeux',\n",
       " 'une personne',\n",
       " 'un homme',\n",
       " 'un gratte-ciel',\n",
       " 'une femme',\n",
       " 'son bébé',\n",
       " 'une poussette',\n",
       " 'un homme',\n",
       " 'une chemise rouge',\n",
       " 'des fruits',\n",
       " 'un jeune garçon blond',\n",
       " 'une fille aux cheveux noirs',\n",
       " 'une table pour les enfants',\n",
       " 'le garçon',\n",
       " 'sa nourriture',\n",
       " 'la table',\n",
       " 'un homme',\n",
       " 'noir',\n",
       " 'une guitare électrique',\n",
       " 'une fille',\n",
       " 'la balle',\n",
       " 'un homme',\n",
       " 'chemise noire',\n",
       " 'une guitare de couleur noire',\n",
       " 'un homme',\n",
       " 'une chemise noire',\n",
       " 'le béton',\n",
       " 'une femme',\n",
       " 'chemise blanche',\n",
       " 'une table',\n",
       " 'une femme',\n",
       " 'une couverture rouge',\n",
       " 'un homme solitaire',\n",
       " 'un pont',\n",
       " 'un enfant',\n",
       " 'un homme',\n",
       " 'son chien',\n",
       " 'les haricots verts',\n",
       " 'un barbecue',\n",
       " 'trois personnes',\n",
       " 'un rebord',\n",
       " 'une montagne',\n",
       " 'plusieurs personnes',\n",
       " 'une passerelle très grande',\n",
       " 'un jeune garçon',\n",
       " 'deux petites filles',\n",
       " 'un vieil homme [',\n",
       " 'homme asiatique',\n",
       " 'une femme blonde',\n",
       " \"la main à l' extérieur\",\n",
       " \"l' homme\",\n",
       " 'un homme âgé',\n",
       " 'cheveux gris',\n",
       " 'une chaise',\n",
       " 'un grand instrument',\n",
       " 'bambou',\n",
       " 'un homme',\n",
       " 'chemise blanche',\n",
       " 'un vélo',\n",
       " 'une rue très fréquentée',\n",
       " 'un homme',\n",
       " 'une échelle peinture',\n",
       " 'un homme de plus de 30 ans',\n",
       " 'deux femmes',\n",
       " 'un groupe de gens',\n",
       " 'des nouilles',\n",
       " 'une femme',\n",
       " 'un bol',\n",
       " 'de fruits',\n",
       " 'la tête [',\n",
       " 'un gars',\n",
       " 'bleu',\n",
       " 'un trou',\n",
       " 'quatre enfants',\n",
       " 'un vélo [',\n",
       " 'deux individus',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'une baignoire',\n",
       " 'un bébé dort',\n",
       " 'un costume rose rayé',\n",
       " \"un membre d' une tribu africaine\",\n",
       " 'robe tribale',\n",
       " 'un guerrier samouraï',\n",
       " 'robe noire',\n",
       " 'son épée',\n",
       " 'fourreau',\n",
       " \"un tapis d' entraînement à l' extérieur\",\n",
       " 'plusieurs jeunes',\n",
       " 'un rail',\n",
       " 'cinq randonneurs',\n",
       " 'un',\n",
       " 'les autres',\n",
       " 'une rivière rocheuse',\n",
       " 'un agent de sécurité',\n",
       " 'une sculpture [',\n",
       " 'deux femmes',\n",
       " 'une',\n",
       " 'vert',\n",
       " \"l' autre\",\n",
       " 'pourpre',\n",
       " 'un trottoir',\n",
       " 'deux filles',\n",
       " 'de quelques buissons',\n",
       " 'téléphone',\n",
       " 'une jeune fille',\n",
       " 'en multicolore',\n",
       " 'une boule orange',\n",
       " 'sa main droite',\n",
       " 'un herbe vert',\n",
       " 'une maison',\n",
       " 'un enfant',\n",
       " 'un jouet',\n",
       " 'le sol',\n",
       " 'un jeune planchiste',\n",
       " 'sa planche',\n",
       " 'un autre',\n",
       " 'deux enfants',\n",
       " \"l' herbe\",\n",
       " 'une jeune femme',\n",
       " 'une bouteille',\n",
       " 'un banc',\n",
       " \"la main d' un homme\",\n",
       " 'un pilote',\n",
       " 'son talkie-walkie',\n",
       " 'une fille',\n",
       " 'une grande rivière',\n",
       " 'une',\n",
       " 'des nattes',\n",
       " \"l' eau\",\n",
       " 'un couple',\n",
       " 'des pulls blancs',\n",
       " 'une table de restaurant',\n",
       " 'un repas',\n",
       " 'une table',\n",
       " 'deux ouvriers du bâtiment [',\n",
       " 'une poutre en acier',\n",
       " 'un enfant',\n",
       " 'un bol',\n",
       " 'deux enfants',\n",
       " 'un ballon',\n",
       " 'la boue',\n",
       " 'une petite fille',\n",
       " 'une brochure',\n",
       " 'deux femmes',\n",
       " 'des gens',\n",
       " \"le trottoir d' un parc\",\n",
       " 'un petit enfant',\n",
       " 'un grand plongeoir',\n",
       " 'la piscine',\n",
       " 'un chien de couleur claire',\n",
       " 'la plage',\n",
       " 'un homme',\n",
       " \"une bassine d' eau en bois\",\n",
       " 'un fruit',\n",
       " 'un homme',\n",
       " 'un banc',\n",
       " 'un arrêt de bus',\n",
       " 'une petite fille',\n",
       " 'chemise rouge',\n",
       " 'jean',\n",
       " 'un petit arbre',\n",
       " 'un autre petite fille',\n",
       " 'un homme',\n",
       " 'une voiture [',\n",
       " 'une femme',\n",
       " 'un t-shirt rouge',\n",
       " 'une couverture',\n",
       " 'un homme',\n",
       " 'une crêpe',\n",
       " 'plusieurs pompiers',\n",
       " 'plusieurs pompiers',\n",
       " 'un bâtiment',\n",
       " 'leurs camions',\n",
       " 'une plage',\n",
       " 'des gens',\n",
       " 'le rivage',\n",
       " 'des hommes',\n",
       " 'des casques',\n",
       " 'des gilets de sécurité',\n",
       " 'un vendeur de magazines',\n",
       " 'un collage très coloré de magazines',\n",
       " 'un homme',\n",
       " 'un casque',\n",
       " 'un t-shirt bleu',\n",
       " 'une salopette en jean bleue',\n",
       " 'la boulangerie',\n",
       " 'son apprenti',\n",
       " \"un groupe d' hommes torse nu\",\n",
       " \"l' ombre\",\n",
       " 'une plage tropicale',\n",
       " 'un garçon',\n",
       " 'son short de bain bleu',\n",
       " 'un skieur',\n",
       " 'une montagne enneigée',\n",
       " 'un garçon',\n",
       " 'une chemise rouge',\n",
       " 'vélo juste',\n",
       " 'un monticule de terre',\n",
       " 'des coureurs',\n",
       " 'trois garçons',\n",
       " 'un tas de sable',\n",
       " 'milieu',\n",
       " 'un homme âgé',\n",
       " 'une canne',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'un médecin',\n",
       " 'des infirmières',\n",
       " 'blouses bleues',\n",
       " 'un chien noir et blanc',\n",
       " 'un jouet jaune',\n",
       " 'un chien laineux',\n",
       " 'un doberman',\n",
       " 'un homme',\n",
       " 'une boule de bowling',\n",
       " 'une piste',\n",
       " 'un vieil homme ridé , barbu',\n",
       " 'noir',\n",
       " 'un magnifique âne blanc',\n",
       " 'des rochers blancs',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'un canapé bleu',\n",
       " 'un homme',\n",
       " 'un maillot jaune',\n",
       " 'un javelot',\n",
       " 'une piste',\n",
       " 'une foule',\n",
       " 'des montgolfières',\n",
       " 'une femme',\n",
       " 'un magazine',\n",
       " \"l' épaule d' une autre femme\",\n",
       " 'deux hommes',\n",
       " 'allumer des bougies',\n",
       " 'un jeune homme',\n",
       " 'un centre commercial',\n",
       " 'le petit garçon',\n",
       " 'vélo',\n",
       " 'un groupe de gens',\n",
       " 'une table',\n",
       " 'une pièce sombre',\n",
       " 'un homme',\n",
       " 'deux chiens',\n",
       " 'une plage',\n",
       " 'un garçon',\n",
       " 'de mousse',\n",
       " 'le visage',\n",
       " 'des dizaines de personnes',\n",
       " 'une jeune femme',\n",
       " 'un bikini de couleur claire',\n",
       " 'un homme',\n",
       " 'un chapeau de cowboy en paille',\n",
       " 'un garçon',\n",
       " 'un toboggan',\n",
       " 'une piscine',\n",
       " 'des tubes colorés',\n",
       " 'un homme',\n",
       " 'une combinaison de plongée',\n",
       " 'un tout-petit',\n",
       " 'un groupe de personnes',\n",
       " \"l' arrière d' un camion\",\n",
       " 'la route',\n",
       " 'une zone rurale',\n",
       " 'deux chefs',\n",
       " 'des hamburgers',\n",
       " \"la cuisine d' un restaurant\",\n",
       " 'deux jeunes garçons',\n",
       " 'des grimaces',\n",
       " 'une personne',\n",
       " 'un pantalon brun',\n",
       " 'étincelles',\n",
       " 'une femme',\n",
       " 'une colline',\n",
       " 'une croix blanche',\n",
       " 'une plage',\n",
       " 'quatre filles',\n",
       " \"l' herbe\",\n",
       " 'plusieurs hommes',\n",
       " 'des hommes [',\n",
       " 'chemin de fer',\n",
       " 'un homme',\n",
       " 'une fille',\n",
       " 'deux chevaux',\n",
       " 'un feu contenu',\n",
       " 'des travailleurs',\n",
       " 'des gilets réfléchissants',\n",
       " 'un wagon',\n",
       " 'un vieil homme',\n",
       " 'une classique , rustique , volkswagen beetle',\n",
       " 'une femme',\n",
       " 'une armature en métal blanc',\n",
       " 'le trottoir',\n",
       " 'trois chiens',\n",
       " 'une balle',\n",
       " 'un homme sans t-shirt',\n",
       " 'une femme',\n",
       " 'un ponton',\n",
       " 'des hommes',\n",
       " 'gilets de sécurité',\n",
       " 'une piste',\n",
       " 'un homme',\n",
       " 'son matériel',\n",
       " 'une femme',\n",
       " 'cheveux rouge',\n",
       " 'mascara',\n",
       " 'ces cils',\n",
       " 'un chien blanc',\n",
       " 'sa tête',\n",
       " 'une femme',\n",
       " 'short bleu',\n",
       " 't-shirt blanc',\n",
       " \"un rocher d' intérieur\",\n",
       " 'beaucoup de scooters',\n",
       " \"l' hélicoptère de la police du parc régional\",\n",
       " 'un homme',\n",
       " 'un gilet réfléchissant [',\n",
       " 'un échaffaudage',\n",
       " 'un groupe de quatorze personnes',\n",
       " 'une pièce',\n",
       " 'des tables pour diner',\n",
       " 'une scène',\n",
       " 'un adolescent',\n",
       " 'un toboggan gonflable',\n",
       " 'une famille',\n",
       " 'un tracteur',\n",
       " 'une vieille femme',\n",
       " 'des aliments',\n",
       " 'une cuisine',\n",
       " 'deux jeunes gens',\n",
       " 'une flamboyante jeune femme',\n",
       " 'un bikini rouge',\n",
       " 'une coiffe à plume rouge',\n",
       " 'deux skieurs',\n",
       " 'des skieurs',\n",
       " \"sommet d' une colline couverte de neige\",\n",
       " 'un chien brun',\n",
       " \"l' herbe\",\n",
       " 'une femme',\n",
       " 't-shirt vert',\n",
       " 'jean',\n",
       " 'un rebord',\n",
       " 'du café',\n",
       " 'la main',\n",
       " 'son sac',\n",
       " 'une grande porte',\n",
       " 'un document',\n",
       " 'des personnes',\n",
       " 'une femme',\n",
       " 'violet clair',\n",
       " 'un corsage',\n",
       " 'ses mains',\n",
       " 'ses genoux',\n",
       " 'une mère',\n",
       " 'ses enfants',\n",
       " 'une promenade [',\n",
       " 'six hommes',\n",
       " 'le sable',\n",
       " 'des palettes en bois',\n",
       " 'une femme',\n",
       " 'débardeur vert',\n",
       " 'trois enfants',\n",
       " 'un homme',\n",
       " 't-shirt noir',\n",
       " 'pantalon noir',\n",
       " \"le moteur d' une vieille automobile vert antique\",\n",
       " 'un jerrican jaune',\n",
       " \"l' herbe\",\n",
       " 'une femme',\n",
       " 'veste bleue',\n",
       " 'un poney brun',\n",
       " \"l' eau\",\n",
       " 'deux chevaux',\n",
       " 'une charette',\n",
       " 'une femme',\n",
       " 'une personne',\n",
       " 'une falaise',\n",
       " 'une corde',\n",
       " 'le groupe de randonneurs',\n",
       " 'une montagne',\n",
       " 'une femme',\n",
       " 'la craie',\n",
       " 'trois jeunes adultes',\n",
       " 'la fille',\n",
       " 'frapper un des garçons',\n",
       " 'le visage',\n",
       " 'le garçon',\n",
       " \"un groupe d' enfants\",\n",
       " 'les mains',\n",
       " 'un homme',\n",
       " 'un maillot',\n",
       " 'une plateforme de béton',\n",
       " \"une vaste étendue d' eau\",\n",
       " 'une femme',\n",
       " 'une machine à coudre',\n",
       " 'une femme',\n",
       " 'un t-shirt bland',\n",
       " 'une personne',\n",
       " 'une fille',\n",
       " 'un marché vendant',\n",
       " 'poivrons',\n",
       " 'une femme agée',\n",
       " 'une chaine',\n",
       " 'une canne',\n",
       " 'la main',\n",
       " 'un garçon',\n",
       " '4 bulles',\n",
       " 'un pré',\n",
       " 'un petit garçon',\n",
       " \"l' eau\",\n",
       " 'un chien',\n",
       " 'un tunnel',\n",
       " 'un chien jaune',\n",
       " 'un chien noir et blanc',\n",
       " 'la poussière',\n",
       " 'deux hommes',\n",
       " 'la plage',\n",
       " 'une petite fille',\n",
       " 'maillot de bain imprimé fleuri',\n",
       " 'une petite fille',\n",
       " 'maillot de bain',\n",
       " 'une poutre',\n",
       " 'la plage',\n",
       " 'un jeune garçon asiatique',\n",
       " 'une barrière',\n",
       " 'une rangée de casquettes colorées',\n",
       " 'un chien noir et blanc',\n",
       " 'une piscine',\n",
       " 'les garçons',\n",
       " 'deux personnes [',\n",
       " 'plusieurs personnes',\n",
       " 'une sortie en moto-neige',\n",
       " 'deux personnes',\n",
       " 'la neige',\n",
       " 'un jeune homme',\n",
       " 'un t-shirt noir',\n",
       " 'une chaise pliante',\n",
       " 'une grande pile',\n",
       " 'une femme',\n",
       " 'une rue en ville',\n",
       " 'une petite fille',\n",
       " 'des cheveux bruns',\n",
       " 'les pétales',\n",
       " 'une fleur',\n",
       " 'trois personnes',\n",
       " \"un quad à l' extérieur\",\n",
       " 'un homme',\n",
       " 'un quad',\n",
       " 'un homme',\n",
       " 'un quad',\n",
       " 'un petit bâtiment',\n",
       " 'une femme',\n",
       " 'cheveux foncés',\n",
       " 'un bikini',\n",
       " 'la plage',\n",
       " 'deux mains',\n",
       " 'de nourriture',\n",
       " 'une poêle en fer',\n",
       " 'une spatule',\n",
       " 'deux femmes',\n",
       " \"un champs entouré d' une barrière\",\n",
       " 'une vache',\n",
       " 'un gros bateau',\n",
       " 'la jetée',\n",
       " 'deux hommes',\n",
       " 'un homme',\n",
       " 'des sandales',\n",
       " 'un cardigan blanc',\n",
       " 'un banc vert',\n",
       " 'son téléphone portable',\n",
       " 'un homme',\n",
       " 'scène',\n",
       " 'un micro',\n",
       " 'three mecs',\n",
       " 'un éléphant',\n",
       " 'une structure en forme de maison',\n",
       " 'des arbres',\n",
       " 'un homme mexicain',\n",
       " 'le capot de son camion',\n",
       " 'un garçon',\n",
       " 'des lunettes jaunes',\n",
       " 'une fille rousse',\n",
       " 'un groupe de gens',\n",
       " 'différents types de drapeaux',\n",
       " 'un petit garçon blanc',\n",
       " 'un jouet renversé',\n",
       " 'petit garçon',\n",
       " 'un ballon de foot',\n",
       " 'un terrain',\n",
       " 'une femme',\n",
       " 'un mec',\n",
       " 'un congélateur',\n",
       " 'un groupe de gens',\n",
       " 'des tabourets',\n",
       " 'des gens',\n",
       " 'un drapeau américain [',\n",
       " 'une jeune fille',\n",
       " 'la peinture',\n",
       " 'un cycliste',\n",
       " 'vélo',\n",
       " 'une route en virage',\n",
       " 'une coline',\n",
       " 'une petite fille',\n",
       " 'en jeans',\n",
       " 'un champs',\n",
       " 'homme',\n",
       " 'une chemise bleu',\n",
       " 'un pantalon noir',\n",
       " 'un de ses pouces',\n",
       " 'des lunettes',\n",
       " 'son autre main',\n",
       " 'un couple',\n",
       " 'un escalator',\n",
       " 'un joueur de football',\n",
       " 'maillot vert',\n",
       " 'un ballon',\n",
       " 'les mains',\n",
       " 'quelques uns de ses coéquipiers',\n",
       " 'un joueur adverse',\n",
       " 'rouge',\n",
       " 'le ballon',\n",
       " 'des hommes',\n",
       " 'un mur',\n",
       " 'le désert',\n",
       " 'un groupe de jeunes amies',\n",
       " 'de maquillage',\n",
       " 'de bandeaux',\n",
       " 'un banc',\n",
       " 'la dame',\n",
       " 'un sac noir en bandoulière',\n",
       " 'un homme',\n",
       " 'un blouson noir',\n",
       " 'un groupe de gens',\n",
       " 'un chien noir',\n",
       " 'un jouet en corde',\n",
       " 'une jeune fille',\n",
       " 'une vieille caméra',\n",
       " 'fille',\n",
       " 'des vêtements bizarres',\n",
       " 'une brochure',\n",
       " 'un porche en bois',\n",
       " 'un homme',\n",
       " 'des habits funky',\n",
       " 'la guitare',\n",
       " 'un gardien de hockey',\n",
       " \"l' équipe opposée\",\n",
       " 'un adulte',\n",
       " 'un enfant',\n",
       " 'la plage',\n",
       " 'un homme',\n",
       " 'un tablier',\n",
       " 'le bord du trottoir',\n",
       " 'un chien marron et blanc',\n",
       " 'un frisbee',\n",
       " 'le public',\n",
       " 'deux joueurs de tennis',\n",
       " 'un court de tennis',\n",
       " 'deux jongleurs',\n",
       " 'torches enflammées',\n",
       " 'une foule de gens [',\n",
       " 'des marches',\n",
       " 'deux enfants',\n",
       " 'sans chaussures',\n",
       " 'un bébé',\n",
       " 'des galets',\n",
       " 'un garçon',\n",
       " 'une casquette gap',\n",
       " 'une grimace',\n",
       " 'cinq hommes',\n",
       " 'un',\n",
       " 'une chemise blanche',\n",
       " \"une photo d' un enfant\",\n",
       " 'une personne',\n",
       " 'un chapeau',\n",
       " 'un garçon',\n",
       " 'une fille',\n",
       " 'un haut vert speedo',\n",
       " 'des lunettes bleues',\n",
       " 'des garçons',\n",
       " 'un scooter',\n",
       " 'deux femmes',\n",
       " 'un homme',\n",
       " 'un jeu de cartes',\n",
       " 'la bière',\n",
       " 'des gens',\n",
       " 'du pabst blue ribbon',\n",
       " 'du coca light',\n",
       " 'un homme',\n",
       " 'des chaussures rouges',\n",
       " 'un t-shirt blanc',\n",
       " 'un pantalon gris',\n",
       " 'un alpiniste',\n",
       " 'une petite fille',\n",
       " \"l' eau\",\n",
       " 'une sculpture de grenouille',\n",
       " 'un chien',\n",
       " 'la plage',\n",
       " 'des gens',\n",
       " 'un',\n",
       " 'le journal',\n",
       " 'une fille',\n",
       " 'un short rouge',\n",
       " 'une chemise blanche',\n",
       " 'un trou',\n",
       " 'un oiseau noir',\n",
       " 'blanc',\n",
       " \"la main d' une personne\",\n",
       " 'des graines de tournesol',\n",
       " 'une femme',\n",
       " 'une chemise blanche',\n",
       " 'une jupe rose',\n",
       " 'une balle de tennis',\n",
       " 'un chien',\n",
       " 'le sable',\n",
       " 'un toit',\n",
       " 'un homme',\n",
       " 'un grand appareil en forme de caméra',\n",
       " 'un champ',\n",
       " 'un campeur',\n",
       " 'quelques véhicules garés',\n",
       " 'un petit garçon',\n",
       " 'les vagues',\n",
       " 'une femme',\n",
       " 'tenue musulmane',\n",
       " 'un jeune garçon',\n",
       " 'la rue',\n",
       " 'le petit chien',\n",
       " 'une femme',\n",
       " 'un trottoir',\n",
       " \"une plate-forme d' herbe surélevée\",\n",
       " 'un homme',\n",
       " 'pantalon rouge',\n",
       " 'une table de parc',\n",
       " 'un chien',\n",
       " 'sa gueule ouverte',\n",
       " 'un champ',\n",
       " 'une petite fille souriante',\n",
       " 'une piscine extérieure',\n",
       " 'un vélo',\n",
       " 'une rue',\n",
       " 'une corde',\n",
       " 'un gars',\n",
       " 'la corde',\n",
       " 'un homme',\n",
       " 'son enfant',\n",
       " 'un navire',\n",
       " 'un petit enfant',\n",
       " 'un lit',\n",
       " 'les hommes',\n",
       " 'une veste de sécurité orange',\n",
       " \"les réparations d' une rue\",\n",
       " 'un homme',\n",
       " 'un gilet de sécurité',\n",
       " 'les briques',\n",
       " 'un ouvrier',\n",
       " 'une rue',\n",
       " 'un homme',\n",
       " 'du sable blanc',\n",
       " 'un snowboard',\n",
       " 'un homme',\n",
       " 'un gilet orange',\n",
       " 'un immeuble',\n",
       " 'un mec',\n",
       " 'une chemise jaune',\n",
       " 'un pantalon brun clair',\n",
       " 'la foule',\n",
       " 'une jeune fille',\n",
       " 'une tenue de karaté',\n",
       " 'un grand trophée',\n",
       " 'un gamin',\n",
       " 'des flotteurs',\n",
       " 'un lac',\n",
       " 'une femme',\n",
       " 'rose',\n",
       " 'un hamburger',\n",
       " 'une spatule',\n",
       " 'un garçon',\n",
       " 'un t-shirt sale',\n",
       " \"l' eau de mer à hauteur de genoux\",\n",
       " 'un homme',\n",
       " \"l' arrière d' une statue de nu\",\n",
       " 'un petit bambin',\n",
       " 'blanc',\n",
       " 'une dame [',\n",
       " 'un drapeau',\n",
       " 'une personne',\n",
       " 'une structure',\n",
       " 'le lac',\n",
       " 'un jeune homme',\n",
       " 'une veste grise',\n",
       " \"le comptoir d' un magasin de bijoux\",\n",
       " 'des gens',\n",
       " 'les escaliers',\n",
       " 'une église',\n",
       " \"un certain nombre d' enfants\",\n",
       " \"la côte d' une ville\",\n",
       " 'une femme',\n",
       " 'deux hommes',\n",
       " 'un projet de menuiserie',\n",
       " 'des outils manuels',\n",
       " 'une femme',\n",
       " 'deux filles',\n",
       " 'rose',\n",
       " 'un homme',\n",
       " 'un costume noir',\n",
       " 'une mallette',\n",
       " 'une femme brune',\n",
       " 'la rue',\n",
       " 'une tasse',\n",
       " 'un petit garçon chauve',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(val_triple_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"un groupe d' hommes\",\n",
       " 'du coton',\n",
       " 'un camion',\n",
       " 'un homme',\n",
       " 'un canapé',\n",
       " 'un garçon',\n",
       " 'un casque',\n",
       " 'deux hommes',\n",
       " 'une tente de pêche',\n",
       " 'un lac gelé',\n",
       " 'un homme chauve',\n",
       " 'un gilet de sauvetage rouge',\n",
       " 'une femme',\n",
       " 'manteau rouge',\n",
       " 'un sac à main bleuté',\n",
       " 'origine asiatique',\n",
       " 'un chien brun',\n",
       " 'le chien noir',\n",
       " 'un jeune garçon',\n",
       " 'un maillot des giants',\n",
       " 'une batte de base-ball',\n",
       " 'une balle qui arrive',\n",
       " 'un homme',\n",
       " 'un bureau encombré',\n",
       " 'le téléphone',\n",
       " 'une femme souriante',\n",
       " 'un débardeur pêche',\n",
       " 'un vtt',\n",
       " 'un jeune enfant',\n",
       " 'des rochers tranchants',\n",
       " 'une personne',\n",
       " 'une motoneige',\n",
       " 'trois jeunes enfants',\n",
       " 'un baril bleu et blanc',\n",
       " 'une femme',\n",
       " 'son stand de fleurs séchées',\n",
       " 'une femme',\n",
       " 'son violon',\n",
       " 'trois personnes',\n",
       " 'deux motocross',\n",
       " 'un quad',\n",
       " \"l' herbe brunie\",\n",
       " 'un homme à moitié nu',\n",
       " 'son fauteuil dehors',\n",
       " 'un groupe de personnes',\n",
       " 'une cabane',\n",
       " 'une jeune femme',\n",
       " 'des tapis',\n",
       " 'trois filles',\n",
       " 'des grimaces',\n",
       " \"l' une\",\n",
       " 'un coup',\n",
       " 'un homme seul',\n",
       " 't-shirt noir',\n",
       " 'la foule',\n",
       " 'une femme',\n",
       " 'un homme',\n",
       " 'un pont de corde en bois',\n",
       " 'un panneau avertisseur',\n",
       " 'un homme',\n",
       " 'jupe',\n",
       " 'des couteaux',\n",
       " 'une fille asiatique',\n",
       " 'un chapeau',\n",
       " 'un tablier verts',\n",
       " 'des boissons',\n",
       " 'un plateau',\n",
       " 'des ouvriers du bâtiment',\n",
       " 'une machine',\n",
       " 'deux chiens',\n",
       " 'un jouet orange',\n",
       " 'un joli bébé',\n",
       " 'un autre enfant',\n",
       " 'trois hommes',\n",
       " 'une route',\n",
       " 'une personne',\n",
       " \"une vaste étendue d' eau\",\n",
       " 'un tracteur',\n",
       " 'un mur de soutènement',\n",
       " 'une jeune fille',\n",
       " 'un parc',\n",
       " 'un individu',\n",
       " 'la rue',\n",
       " \"l' étalage de peinture\",\n",
       " 'un enfant',\n",
       " 'des barres',\n",
       " 'une personne',\n",
       " 't-shirt à manches longues rouge',\n",
       " 'un mur',\n",
       " 'un lampadaire',\n",
       " 'un groupe de personnes',\n",
       " 'un homme',\n",
       " 'costume',\n",
       " 'un petit garçon',\n",
       " 'une femme',\n",
       " 'des gens',\n",
       " 'un homme',\n",
       " 'un sac à dos bleu',\n",
       " 'le journal',\n",
       " 'un gros chien brun',\n",
       " 'son visage',\n",
       " 'un garçon blond',\n",
       " 't-shirt bleu',\n",
       " 'une embarcation en nylon vert',\n",
       " 'un jeune garçon blanc',\n",
       " 'une terrasse',\n",
       " 'un grand balai',\n",
       " 'une personne',\n",
       " 'le point',\n",
       " 'une boule de bowling verte',\n",
       " 'une piste de bowling',\n",
       " 'un groupe',\n",
       " 'un public dans un bar',\n",
       " 'un vieil homme',\n",
       " 'un chien brun',\n",
       " 'une laisse rouge',\n",
       " 'un homme',\n",
       " 'une vieille voiture de course rouge',\n",
       " 'de jeunes adultes',\n",
       " 'rouges',\n",
       " 'jaunes',\n",
       " 'noirs',\n",
       " 'un jeune garçon',\n",
       " 'une pierre',\n",
       " 'une eau calme',\n",
       " 'deux femmes',\n",
       " 'des cheveux courts',\n",
       " 'la blonde',\n",
       " 'un personnage en costume perfectionné',\n",
       " 'une structure brillamment décorée',\n",
       " 'un chien',\n",
       " 'un chiffon',\n",
       " 'sa gueule',\n",
       " 'trois petits chiens',\n",
       " 'deux hommes',\n",
       " 'un kayak',\n",
       " 'une rivière',\n",
       " 'des arbres verts',\n",
       " 'deux filles',\n",
       " 'la rue',\n",
       " \"un groupe d' enfants\",\n",
       " \"l' arrière d' une camionnette\",\n",
       " 'un livre',\n",
       " 'des gens sur la plage',\n",
       " 'un cœur',\n",
       " 'le ciel',\n",
       " 'un écrivain céleste',\n",
       " 'une fille',\n",
       " 'le livre',\n",
       " 'sa main',\n",
       " 'papillon',\n",
       " 'un homme',\n",
       " 'un restaurant',\n",
       " 'un homme',\n",
       " 'un costume',\n",
       " 'des lunettes',\n",
       " 'un objet',\n",
       " 'les mains',\n",
       " 'un homme',\n",
       " 'combinaison noire',\n",
       " 'une vague',\n",
       " 'une femme',\n",
       " 'un sac à main rose',\n",
       " 'un banc',\n",
       " 'trois femmes',\n",
       " 'un avion rouge',\n",
       " 'la fumée rose',\n",
       " 'un homme',\n",
       " 'une paroi rocheuse',\n",
       " 'deux ouvriers du bâtiment',\n",
       " 'une femme',\n",
       " 'tenue colorée',\n",
       " 'un camion blanc',\n",
       " 'bouteilles',\n",
       " 'une femme',\n",
       " 'un chapeau bleu',\n",
       " 'une jupe jaune',\n",
       " 'des lilas',\n",
       " 'un homme',\n",
       " 'une tenue dorée',\n",
       " 'son vélo doré',\n",
       " 'un bébé',\n",
       " 'les feuilles',\n",
       " \"une branche d' arbre\",\n",
       " 'un concierge',\n",
       " 'deux petits garçons noirs',\n",
       " 'des bouteilles en plastique',\n",
       " 'un feu passe au vert',\n",
       " 'des gens',\n",
       " 'des motos',\n",
       " 'deux personnes',\n",
       " 'une paroi rocheuse',\n",
       " 'une corde',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'la plage',\n",
       " 'un enfant',\n",
       " 'un trampoline',\n",
       " 'des enfants',\n",
       " 'deux personnes',\n",
       " 'un grand globe',\n",
       " 'un enfant',\n",
       " 'deux hommes',\n",
       " 'tenues militaires',\n",
       " 'une femme',\n",
       " 'robe noire',\n",
       " 'un chariot',\n",
       " 'un thermos',\n",
       " 'une allée pavée',\n",
       " 'un policier',\n",
       " 'un véhicule',\n",
       " 'le bord de la route',\n",
       " 'un homme',\n",
       " 'une jetée',\n",
       " 'un lac paisible',\n",
       " \"un groupe d' officiers écossais\",\n",
       " 'une femme',\n",
       " 'un enfant',\n",
       " 'une porte',\n",
       " 'un trottoir gris',\n",
       " 'un homme',\n",
       " 'deux femmes',\n",
       " 'un pompier solitaire',\n",
       " 'un gros incendie',\n",
       " 'une personne',\n",
       " 't-shirt violet',\n",
       " \"le portrait d' une femme\",\n",
       " 'un mur blanc',\n",
       " 'une petite fille',\n",
       " 'sa jeune sœur',\n",
       " 'une infirmière',\n",
       " 'une jeune femme',\n",
       " 'une femme âgée',\n",
       " 'des saris traditionnels',\n",
       " 'du textile',\n",
       " 'trois personnes',\n",
       " 'des vêtements modernes',\n",
       " 'une femme',\n",
       " 'la neige profonde',\n",
       " 'une pente abrupte',\n",
       " 'le chauffeur de chez fedex',\n",
       " \"l' employé\",\n",
       " 'un casque vert',\n",
       " 'le matériel',\n",
       " 'le chien brun',\n",
       " 'un collier noir',\n",
       " 'un chien blanc et brun',\n",
       " 'une rampe jaune et bleue',\n",
       " 'un enfant',\n",
       " 'un livre',\n",
       " 'un vieux japonais',\n",
       " 'une petite machine rouge et grise',\n",
       " 'un jeune enfant',\n",
       " 'une femme',\n",
       " 'un coq en cage',\n",
       " 'un enfant [',\n",
       " 'spiderman',\n",
       " 'un homme',\n",
       " 'tenue marron',\n",
       " 'un sabre laser',\n",
       " 'une jeune femme',\n",
       " 'un micro',\n",
       " 'un homme',\n",
       " 'une guitare',\n",
       " 'deux enfants',\n",
       " 'des trous',\n",
       " 'beaucoup de fauteuils',\n",
       " 'seulement quelques personnes',\n",
       " 'des hommes',\n",
       " 'une plage',\n",
       " 'troncs',\n",
       " 'branches empilés',\n",
       " 'un jeune homme',\n",
       " 'un grand sac poubelle en plastique noir',\n",
       " 'un homme âgé en surpoids fait',\n",
       " 'une crêpe',\n",
       " 'le petit déjeuner',\n",
       " 'des hommes',\n",
       " 'costumes jaunes',\n",
       " 'un piano',\n",
       " 'un homme',\n",
       " 'de la contrebasse',\n",
       " 'plusieurs personnes',\n",
       " \"d' arbres\",\n",
       " 'crépuscule',\n",
       " 'un chien marron',\n",
       " 'un gros morceau de bois',\n",
       " 'un randonneur',\n",
       " \"un groupe d' enfants\",\n",
       " 'un pont',\n",
       " 'une femme',\n",
       " \"d' un homme [\",\n",
       " 'de la barbe à papa',\n",
       " 'deux femmes',\n",
       " \"une classe d' enfants\",\n",
       " \"d' un livre\",\n",
       " 'deux femmes brunes',\n",
       " \"d' enfants blonds\",\n",
       " 'une personne',\n",
       " 'un bonnet',\n",
       " 'une écharpe',\n",
       " 'deux personnes',\n",
       " 'une rue',\n",
       " 'un vieil homme',\n",
       " 'un chien',\n",
       " 'son autre chien',\n",
       " 'ses genoux',\n",
       " 'trois enfants',\n",
       " 'un homme',\n",
       " 'scène',\n",
       " 'la guitare',\n",
       " 'un garçon [',\n",
       " 'un bâton',\n",
       " 'une jeune fille',\n",
       " 'une jeep bleue roule',\n",
       " 'eau boueuse profonde',\n",
       " 'la femme',\n",
       " 'un chapeau noir',\n",
       " 'la neige tombe',\n",
       " 'un homme',\n",
       " 'la guitare',\n",
       " 'un chien',\n",
       " \"un petit plan d' eau peu profond\",\n",
       " 'une jeune femme asiatique',\n",
       " 'un quartier animé de la ville',\n",
       " 'un groupe de trois personnes',\n",
       " 'quatre personnes',\n",
       " 'un homme',\n",
       " 'des steaks',\n",
       " 'barbecue noir',\n",
       " 'un homme',\n",
       " 'une casquette rouge',\n",
       " 'un lampadaire',\n",
       " 'un jeune garçon',\n",
       " 't-shirt jaune',\n",
       " 'un anneau',\n",
       " \"d' autres enfants\",\n",
       " 'un petit enfant',\n",
       " 'fruits',\n",
       " 'un verre de jus de fruit',\n",
       " 'un homme',\n",
       " 'deux femmes',\n",
       " 'shorts',\n",
       " 'la rue',\n",
       " 'deux caniches',\n",
       " 'la neige',\n",
       " 'une petite fille rousse',\n",
       " 'un costume de spiderman',\n",
       " 'cheval à bascule',\n",
       " 'un homme',\n",
       " 'un lac',\n",
       " 'les skieurs',\n",
       " 'des gens',\n",
       " \"l' escalade\",\n",
       " 'plusieurs personnes',\n",
       " 'des femmes',\n",
       " 'bikinis',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'une table de restaurant',\n",
       " 'une mère',\n",
       " 'deux enfants',\n",
       " 'faisant de drôles de têtes',\n",
       " 'un labrador nage',\n",
       " \"l' eau\",\n",
       " 'un jouet rouge',\n",
       " 'sa gueule',\n",
       " 'quatre hommes',\n",
       " \"d' une voiture jaune\",\n",
       " \"un groupe d' hommes\",\n",
       " 'de femmes',\n",
       " \"d' enfants\",\n",
       " 'tous',\n",
       " 'couvre-chefs',\n",
       " 'un petit garçon',\n",
       " 'combinaison',\n",
       " 'un sol marron',\n",
       " 'une petite fille',\n",
       " 'des containers en plastique blancs',\n",
       " 'un chien jaune',\n",
       " 'une balle',\n",
       " 'sa gueule',\n",
       " 'un homme',\n",
       " 't-shirt rouge',\n",
       " 'deux filles',\n",
       " 'vieil édifice',\n",
       " 'homme',\n",
       " 'femme',\n",
       " 'un groupe',\n",
       " 'un théâtre en plein air',\n",
       " 'la rivière',\n",
       " 'deux femmes',\n",
       " 'une femme',\n",
       " 'chemise rose',\n",
       " 'un homme',\n",
       " 'pull rayé',\n",
       " 'des fils',\n",
       " 'un enfant',\n",
       " 'un rocher',\n",
       " 'un homme',\n",
       " 'une chaise',\n",
       " 'une bière',\n",
       " 'la main',\n",
       " 'quelque chose',\n",
       " 'bâton en bois',\n",
       " 'un policier',\n",
       " 'uniforme',\n",
       " 'une oreillette',\n",
       " 'homme',\n",
       " 'tenue de pompier',\n",
       " 'la route',\n",
       " 'semi-remorque rouge',\n",
       " 'un chien noir et blanc',\n",
       " 'eau transparente',\n",
       " 'un groupe',\n",
       " 'scène',\n",
       " 'instruments de musique',\n",
       " 'une autre personne',\n",
       " 'un homme',\n",
       " 'clavier',\n",
       " 'un micro',\n",
       " 'un jeune garçon',\n",
       " 'une femme',\n",
       " 'une carte',\n",
       " \"au bout d' un canapé\",\n",
       " 'une autre femme',\n",
       " 'un verre',\n",
       " 'ouvriers du bâtiment',\n",
       " 'un homme',\n",
       " 'la plage',\n",
       " \"l' océan\",\n",
       " 'une femme blonde',\n",
       " 'un chemisier bleu',\n",
       " 'un chapeau',\n",
       " 'deux hommes',\n",
       " 'une femme seule',\n",
       " 'un jeune homme blond',\n",
       " 'un micro',\n",
       " \"un bagagiste d' hôtel\",\n",
       " 'un trench-coat',\n",
       " 'un chariot de bagages',\n",
       " 'un chien',\n",
       " 'des plantes',\n",
       " 'un groupe',\n",
       " 'une foule de personnes',\n",
       " 'trois chiens',\n",
       " 'la neige',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'un arbre',\n",
       " 'un chien',\n",
       " 'attraper un ballon jaune et noir',\n",
       " 'une femme âgée',\n",
       " 'pull gris et rouge',\n",
       " 'un repas',\n",
       " 'une femme',\n",
       " 'manteau',\n",
       " 'une maison',\n",
       " 'une femme',\n",
       " 'une autre femme',\n",
       " \"la même tenue d' entraînement\",\n",
       " 'un enfant',\n",
       " \"d' une poussette\",\n",
       " 'une petite épée',\n",
       " 'un gars',\n",
       " 'cheveux frisés',\n",
       " \"le long d' une rampe\",\n",
       " 'lettres jaunes',\n",
       " 'un homme',\n",
       " 'une table ronde',\n",
       " 'le sol',\n",
       " 'un groupe de personnes',\n",
       " \"une grande étendue d' eau\",\n",
       " 'un homme',\n",
       " 'chemise jaune',\n",
       " 'le trottoir',\n",
       " 'une femme',\n",
       " 'jean [',\n",
       " 'quelque',\n",
       " 'à ordures',\n",
       " 'une femme',\n",
       " 'un loup et',\n",
       " 'air sévère',\n",
       " 'une personne',\n",
       " 'des hommes',\n",
       " 'des uniformes bleus',\n",
       " 'un 4x4',\n",
       " 'un fossé',\n",
       " 'un homme',\n",
       " 'autre homme',\n",
       " 'un joueur de football américain',\n",
       " 'blanc et rouge',\n",
       " 'un entraîneur',\n",
       " 'deux filles',\n",
       " \"d' un mur\",\n",
       " 'un homme',\n",
       " 'staff [',\n",
       " 'lunettes de soleil',\n",
       " 'la tête',\n",
       " 'des maillots rouges',\n",
       " 'des casques rouges',\n",
       " 'un garçon',\n",
       " 'vêtements noirs',\n",
       " 'une roue',\n",
       " 'un homme',\n",
       " 't-shirt vert',\n",
       " 'un enfant en pleurs',\n",
       " 'des coureurs',\n",
       " \"cinq membres d' un groupe\",\n",
       " 'trois femmes',\n",
       " 'une couverture',\n",
       " 'un bébé',\n",
       " 'un homme',\n",
       " 'un garçon',\n",
       " 'un autel',\n",
       " 'des cloches',\n",
       " 'un homme',\n",
       " 'des lunettes de soleil',\n",
       " 'un enfant',\n",
       " 'des lunettes de soleil à glisser',\n",
       " 'un toboggan',\n",
       " 'un chien',\n",
       " \"l' herbe\",\n",
       " 'la fille',\n",
       " 'la longue queue de cheval',\n",
       " 'le ballon',\n",
       " 'une autre joueuse',\n",
       " 'le terrain',\n",
       " 'deux homme',\n",
       " 'un sol bleu et jaune',\n",
       " 'une fille',\n",
       " 'maillot rouge et blanc',\n",
       " 'short bleu',\n",
       " 'un homme assis',\n",
       " 'ses mains',\n",
       " 'un chien brun',\n",
       " 'un bâton',\n",
       " 'une personne',\n",
       " \"l' eau\",\n",
       " 'un homme',\n",
       " 'chemise rayée rouge et blanche',\n",
       " 'un tabouret',\n",
       " 'un stand de hot-dog',\n",
       " 'un homme',\n",
       " 'deux hommes',\n",
       " 'un homme',\n",
       " 'un garçon',\n",
       " 'le chien',\n",
       " 'montgolfière',\n",
       " \"l' ombre d' un homme\",\n",
       " 'cet homme',\n",
       " 'un bonnet ou un chapeau blanc',\n",
       " 'une femme',\n",
       " 'tatouer des lignes noires',\n",
       " 'des paillettes',\n",
       " 'un petit enfant',\n",
       " 'en jean',\n",
       " 'un pneu',\n",
       " 'une foule de personnes',\n",
       " 'la rue',\n",
       " 'une série de tentes blanches',\n",
       " 'une foule de gens',\n",
       " 'le parc',\n",
       " 'une femme aux cheveux foncés',\n",
       " 'un chemisier bleu',\n",
       " 'de lunettes de soleil',\n",
       " 'une bannière',\n",
       " 'une jeune fille',\n",
       " 'cheveux tressés',\n",
       " 'dessus',\n",
       " \"beaucoup d' enfants asiatiques\",\n",
       " 'un panneau \" viet nam \"',\n",
       " 'un cow-boy',\n",
       " 'un cheval',\n",
       " 'le cheval',\n",
       " 'une mariée',\n",
       " 'un époux',\n",
       " \"deux agents d' intervention d' urgence\",\n",
       " 'des cales',\n",
       " 'un homme',\n",
       " 'la voie ferrée',\n",
       " 'du béton',\n",
       " 'des brouettes',\n",
       " 'des ouvriers du bâtiment',\n",
       " 'un mur',\n",
       " 'qui',\n",
       " 'un groupe',\n",
       " 'des hommes',\n",
       " 'combinaisons oranges',\n",
       " 'une machine',\n",
       " 'des rails de métro',\n",
       " 'de jeunes adultes',\n",
       " 'le gros chien brun',\n",
       " 'une eau peu profonde',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'un homme',\n",
       " 'une nacelle',\n",
       " 'une ligne électrique',\n",
       " 'deux enfants',\n",
       " 'vestes jaunes',\n",
       " 'la boue',\n",
       " 'plusieurs personnes',\n",
       " 'un looping',\n",
       " \"montagnes russes à l' envers\",\n",
       " 'une femme',\n",
       " 'un fauteuil',\n",
       " 'un groupe de personnes',\n",
       " 'façon imprécise',\n",
       " 'une jeune fille',\n",
       " 'un garçon',\n",
       " 'un t-shirt orange',\n",
       " 'un garçon',\n",
       " 't-shirt bleu',\n",
       " 'une petite fille',\n",
       " 'une petite fille blonde',\n",
       " 'un sandwich',\n",
       " 'quatre personnes',\n",
       " 'un vélo',\n",
       " 'un chien brun très humide',\n",
       " \"l' eau\",\n",
       " 'un chien',\n",
       " 'une balle',\n",
       " 'la gueule',\n",
       " 'un groupe de personnes',\n",
       " 'une barrière',\n",
       " 'un enfant',\n",
       " 'un sweat-shirt rouge',\n",
       " 'un arbre',\n",
       " 'un forain',\n",
       " \"l' argent de deux participants motivés\",\n",
       " 'un garçon',\n",
       " \"un groupe d' enfants assis\",\n",
       " 'deux enfants',\n",
       " \"au bord d' une fontaine\",\n",
       " 'un homme',\n",
       " 'son sweat',\n",
       " 'un kayak',\n",
       " 'ses pieds',\n",
       " 'un vieil homme',\n",
       " 'un dossier',\n",
       " 'la main',\n",
       " \"une jeune femme à l' air indifférent\",\n",
       " 'un homme âgé',\n",
       " 'un bar',\n",
       " 'un jeune garçon blond',\n",
       " 'un lit',\n",
       " 'un autre',\n",
       " 'un petit enfant',\n",
       " 'une batte de base-ball rouge',\n",
       " \"l' homme\",\n",
       " 'son téléphone',\n",
       " 'un magasin de sport',\n",
       " 'deux',\n",
       " 'un petit enfant',\n",
       " 'une femme',\n",
       " 't-shirt bleu',\n",
       " 'un instrument',\n",
       " 'une intersection bondée',\n",
       " 'un homme',\n",
       " 'une grande paroi rocheuse',\n",
       " 'un couple de randonneurs',\n",
       " 'quatre [',\n",
       " 'une rue',\n",
       " 'des arbres',\n",
       " 'quatre personnes',\n",
       " 'un garçon',\n",
       " 'planche métallique',\n",
       " 'un homme',\n",
       " 'une plage construisant [',\n",
       " 'le gros chien brun',\n",
       " 'le petit chien brun',\n",
       " 'hommes',\n",
       " 'tenues blanches',\n",
       " 'leurs mains',\n",
       " 'une femme',\n",
       " 'un frisbee',\n",
       " 'un chien',\n",
       " 'un joueur de baseball',\n",
       " 'tenue',\n",
       " 'un chien noir',\n",
       " 'un objet en plastique blanc',\n",
       " 'des gens',\n",
       " 'leurs affaires',\n",
       " \"l' eau\",\n",
       " 'un peloton de coureurs cyclistes',\n",
       " 'trois personnes',\n",
       " 'une table',\n",
       " \"œuvres d' art\",\n",
       " 'une femme blanche',\n",
       " 'un homme noir',\n",
       " 'un homme',\n",
       " 't-shirt blanc peignant',\n",
       " 'un chien brun , noir et blanc',\n",
       " 'un arbre',\n",
       " 'un homme',\n",
       " 'le visage peint en bleu et rouge',\n",
       " 'une femme',\n",
       " 'deux garçons',\n",
       " 'un jeu',\n",
       " 'des billes',\n",
       " 'deux hommes',\n",
       " 'le conducteur',\n",
       " 'son siège',\n",
       " 'un garçon',\n",
       " 'la balançoire',\n",
       " 'un homme noir',\n",
       " 'un autre homme noir',\n",
       " 'une personne',\n",
       " 'rouge',\n",
       " 'une randonnée',\n",
       " 'oranges',\n",
       " 'melons',\n",
       " 'plus',\n",
       " 'asiatique de fruits',\n",
       " 'une foule nombreuse',\n",
       " 'de grands bâtiments',\n",
       " 'trois femmes',\n",
       " 'une rue pavée',\n",
       " 'un chien',\n",
       " 'un homme',\n",
       " 'blouse blanche',\n",
       " 'du chiche-kebab',\n",
       " 'une personne',\n",
       " 'des cheveux roses fluo',\n",
       " 'un t-shirt jaune',\n",
       " 'une plage',\n",
       " 'un homme',\n",
       " 'une femme [',\n",
       " 'un homme',\n",
       " 't-shirt noir',\n",
       " 'pantalon cargo marron',\n",
       " 'une pelle',\n",
       " 'sa tête',\n",
       " 'un homme',\n",
       " \"le visage d' une femme\",\n",
       " 'lunettes',\n",
       " 'un enfant',\n",
       " 'un autre',\n",
       " 'la jeune fille',\n",
       " 'des oreilles de lapin',\n",
       " 'le jeune garçon',\n",
       " 'un jeune bébé',\n",
       " 'une tenue polaire rose',\n",
       " \"des feuilles d' automne\",\n",
       " \"un gros plan d' une femme\",\n",
       " 'de courts cheveux rouges',\n",
       " 'un footballeur',\n",
       " 'maillot vert',\n",
       " 'une fille',\n",
       " 'un obstacle',\n",
       " 'plusieurs enfants',\n",
       " 'la main tandis',\n",
       " 'un tapis coloré',\n",
       " 'des marins',\n",
       " \"en haut d' une passerelle\",\n",
       " 'un chien blanc',\n",
       " 'un petit frisbee en tissu',\n",
       " 'un homme',\n",
       " 't-shirt gris',\n",
       " 'un chien noir',\n",
       " 'un bâton [',\n",
       " 'deux chiens noirs',\n",
       " 'quatre personnes',\n",
       " 'tenues décontractées',\n",
       " 'des sacs poubelle',\n",
       " 'des gens',\n",
       " 'des chameaux',\n",
       " 'quatre chiens',\n",
       " 'un chien noir',\n",
       " 'un homme',\n",
       " 'uniforme militaire',\n",
       " 'un micro',\n",
       " \"un groupe d' asiatiques\",\n",
       " 'un nageur',\n",
       " 'une femme',\n",
       " 't-shirt',\n",
       " 'pantalon blancs',\n",
       " 'un canapé',\n",
       " 'une maison',\n",
       " 'un homme',\n",
       " 'des gestes avec ses mains',\n",
       " 'deux jeunes filles',\n",
       " 'une fille',\n",
       " 't-shirt blanc',\n",
       " 'des bulles',\n",
       " 'des garçons',\n",
       " 'des filles',\n",
       " \"un pays de l' est\",\n",
       " 'un champ',\n",
       " 'un enfant',\n",
       " 'sweat orange',\n",
       " 'bottes de foin',\n",
       " 'autres enfants',\n",
       " 'garçon',\n",
       " 'un skateboard',\n",
       " 'un homme',\n",
       " 'câbles',\n",
       " 'un bureau',\n",
       " 'un petit enfant',\n",
       " 'une table',\n",
       " 'un goûter',\n",
       " 'quatre enfants',\n",
       " 'sacs à dos',\n",
       " 'route de campagne',\n",
       " 'un homme',\n",
       " 'dreadlocks',\n",
       " \"l' oreille\",\n",
       " 'grands disques souples',\n",
       " 'un homme',\n",
       " 'un axe',\n",
       " 'un chien',\n",
       " 'une pelouse',\n",
       " 'une femme',\n",
       " 'un jeune enfant',\n",
       " 'un jeu de société',\n",
       " 'quatre enfants',\n",
       " 'un muret',\n",
       " 'le petit chien brun',\n",
       " 'les plantes en pots',\n",
       " 'feuilles mortes',\n",
       " 'deux hommes',\n",
       " 'un bâtiment',\n",
       " 'un troisième',\n",
       " 'son téléphone portable',\n",
       " 'des hommes',\n",
       " \"un écran d' ordinateur\",\n",
       " 'deux femmes',\n",
       " 'une photo',\n",
       " 'un appareil photo',\n",
       " 'une femme blonde',\n",
       " 'un chapeau de cowboy marron',\n",
       " 'un geste obscène',\n",
       " 'le chien blanc et marron',\n",
       " 'une adolescente',\n",
       " 'un livre',\n",
       " 'classe',\n",
       " 'notes',\n",
       " 'son bureau',\n",
       " 'deux petites filles',\n",
       " 'des feuilles',\n",
       " 'une mariée',\n",
       " 'la fleur de son mari',\n",
       " 'sa veste',\n",
       " 'son propre bouquet de fleurs',\n",
       " 'la femme',\n",
       " 'une rose orange',\n",
       " 'boutonnière',\n",
       " \"le col du veston de l' homme\",\n",
       " 'deux femmes',\n",
       " 'leurs poussettes',\n",
       " 'une allée couverte de feuilles',\n",
       " 'quatre femmes',\n",
       " 'costumes rigolos',\n",
       " 'cette vieille femme asiatique',\n",
       " 'filles',\n",
       " 'bikinis noirs',\n",
       " 'beach volley',\n",
       " 'un homme',\n",
       " 'lunettes',\n",
       " 'une petite fille',\n",
       " 'un gilet de sauvetage',\n",
       " 'trois enfants',\n",
       " 'hauts marron',\n",
       " 'jeans',\n",
       " 'feuilles [',\n",
       " 'une femme',\n",
       " 'une personne',\n",
       " 'nombreux sacs',\n",
       " 'un enfant',\n",
       " 'une scène bleue',\n",
       " 'une créature colorée',\n",
       " 'un garçon',\n",
       " 'cet enfant',\n",
       " 'un homme',\n",
       " \"l' eau\",\n",
       " 'des enfants',\n",
       " \"la fenêtre d' un bâtiment bleu\",\n",
       " 'des volets rouges',\n",
       " 'un homme en noir avec des cheveux poivre et sel',\n",
       " 'une barbe et des lunettes',\n",
       " \"l' herbe\",\n",
       " 'une femme',\n",
       " 'ses deux enfants',\n",
       " 'sur la plage',\n",
       " 'la femme',\n",
       " 'deux hommes',\n",
       " 'une rue en ville',\n",
       " 'un gars',\n",
       " 'un parc',\n",
       " 'un homme',\n",
       " 'une veste de ski de couleur',\n",
       " \"d' autres\",\n",
       " \"une rue d' europe\",\n",
       " 'une femme',\n",
       " 'un t-shirt jaune',\n",
       " 'des lunettes de soleil',\n",
       " 'un trottoir',\n",
       " 'deux femmes',\n",
       " 'de nombreuses maisons',\n",
       " 'deux gros chiens',\n",
       " 'sur une pelouse',\n",
       " 'les gens',\n",
       " 'plusieurs couches de vêtements',\n",
       " 'un groupe de personnes',\n",
       " 'une femme',\n",
       " 'un t-shirt noir',\n",
       " \"d' adultes et [\",\n",
       " 'et huit ballons roses',\n",
       " 'au plafond',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'une rue pavée',\n",
       " 'deux chiens',\n",
       " 'la neige',\n",
       " 'un petit',\n",
       " 'un homme',\n",
       " 'un t-shirt noir',\n",
       " 'la basse à sept cordes [',\n",
       " 'un garçon',\n",
       " 'un vieil homme',\n",
       " 'une canne',\n",
       " 'une fille',\n",
       " 'un maillot blanc',\n",
       " \"d' un short noir\",\n",
       " \"d' un bandeau\",\n",
       " 'au volley',\n",
       " 'deux hommes',\n",
       " 'une rue',\n",
       " 'de graffitis',\n",
       " 'un garçon',\n",
       " 't-shirt',\n",
       " 'short',\n",
       " 'une boule de neige',\n",
       " 'une montagne enneigée',\n",
       " 'une personne',\n",
       " 'deux hussards',\n",
       " 'des chevaux',\n",
       " 'tenues de cérémonie extravagantes',\n",
       " 'chacun',\n",
       " 'un sabre',\n",
       " 'leur main droite',\n",
       " 'un chien',\n",
       " 'la neige profonde',\n",
       " 'un groupe de personnes',\n",
       " 'un gros chien brun et blanc',\n",
       " 'une veste',\n",
       " 'la rue',\n",
       " 'deux adolescentes',\n",
       " 'une carte',\n",
       " 'une mère',\n",
       " 'fils',\n",
       " 'un homme',\n",
       " 't-shirt noir',\n",
       " 'un livre de recettes',\n",
       " 'une femme',\n",
       " 'blanc',\n",
       " 'une guitare noire',\n",
       " 'un snowboardeur',\n",
       " 'du télésiège',\n",
       " 'plusieurs personnes',\n",
       " 'une pièce en train',\n",
       " 'un homme',\n",
       " 'un chapeau',\n",
       " 'la manche',\n",
       " \"d' un instrument inhabituel\",\n",
       " 'la sortie du métro',\n",
       " 'un gars',\n",
       " 'un rebord de fenêtre',\n",
       " \"d' un vieux moulin\",\n",
       " 'une femme',\n",
       " 'un t-shirt blanc',\n",
       " 'un pantalon noir',\n",
       " 'hoop',\n",
       " 'un grand groupe de personnes',\n",
       " 'un vieil homme',\n",
       " 'tenue de course',\n",
       " 'deux hommes',\n",
       " 'costumes rouges',\n",
       " 'un jeune enfant',\n",
       " 'la moto',\n",
       " 'un enfant',\n",
       " \"d' un bonnet\",\n",
       " \"d' une veste\",\n",
       " 'un revêtement en pierre',\n",
       " 'un enfant',\n",
       " 'une foule',\n",
       " 'deux hommes âgés',\n",
       " 'des chapeaux',\n",
       " 'deux garçons',\n",
       " 'une tente sourient',\n",
       " 'une femme chaudement vêtue',\n",
       " 'noir',\n",
       " 'un petit chien',\n",
       " \"près d' une foule de curieux\",\n",
       " 'deux hommes',\n",
       " 'du matériel électronique',\n",
       " 'une femme',\n",
       " \"un sac de courses de chez trader joe s'\",\n",
       " 'un cycliste',\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_list = val_df[\"entity_content\"].values.tolist() \n",
    "corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [[w.lower() for w in word_tokenize(q, language=\"french\")] for q in corpus_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_corpus_dct = gensim.corpora.Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2756"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1266"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_corpus_dct.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(309)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(val_corpus_dct.dfs.values())\n",
    "torch.sum(torch.tensor(freq) >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['un homme',\n",
       " 'un chapeau orange',\n",
       " 'un terrier de boston',\n",
       " \"l' herbe verdoyante\",\n",
       " 'une clôture blanche',\n",
       " 'une fille',\n",
       " 'karaté',\n",
       " 'un bâton',\n",
       " 'cinq personnes',\n",
       " \"des vestes d' hiver\",\n",
       " 'des casques',\n",
       " 'la neige',\n",
       " 'des motoneiges',\n",
       " 'des gens',\n",
       " \"le toit d' une maison\",\n",
       " 'un homme',\n",
       " 'tenue claire photographie [',\n",
       " 'des costumes sombres',\n",
       " 'des chapeaux',\n",
       " 'une femme',\n",
       " 'une robe bustier',\n",
       " 'un groupe de personnes',\n",
       " 'un igloo',\n",
       " 'un garçon',\n",
       " 'uniforme rouge',\n",
       " 'marbre',\n",
       " 'le receveur',\n",
       " 'tenue bleue',\n",
       " 'un gars',\n",
       " 'un bâtiment',\n",
       " 'un homme',\n",
       " 'gilet',\n",
       " 'une chaise',\n",
       " 'des magazines',\n",
       " 'une mère',\n",
       " 'son jeune fils',\n",
       " 'des hommes',\n",
       " 'un joueur',\n",
       " 'le ballon',\n",
       " 'les mains',\n",
       " 'une femme',\n",
       " 'un plat de nourriture',\n",
       " 'un homme',\n",
       " 'une table [',\n",
       " 'un outil',\n",
       " 'trois personnes',\n",
       " 'une fille',\n",
       " 'une robe en jean',\n",
       " \"une poutre d' équilibre surélevée\",\n",
       " 'une blonde',\n",
       " 'la main',\n",
       " 'un gars',\n",
       " 'le sable',\n",
       " 'une femme',\n",
       " 'un pull gris',\n",
       " 'une casquette noire',\n",
       " 'la personne',\n",
       " 'maillot rayé',\n",
       " 'deux hommes',\n",
       " 'des statues',\n",
       " 'des femmes',\n",
       " 'des gens',\n",
       " 'un bâtiment',\n",
       " 'une adolescente',\n",
       " 'la trompette',\n",
       " 'le terrain',\n",
       " 'une femme',\n",
       " 'un saut périlleux',\n",
       " 'un trampoline',\n",
       " 'un homme',\n",
       " 'une série de jeux vidéo',\n",
       " 'une femme',\n",
       " 'une perceuse',\n",
       " 'un autre homme',\n",
       " 'une femme',\n",
       " 'sweat rose',\n",
       " 'tablier',\n",
       " 'une table',\n",
       " 'une éponge',\n",
       " 'un homme',\n",
       " \"les branches d' un arbre\",\n",
       " 'un groupe de garçons asiatiques',\n",
       " 'la viande',\n",
       " 'le barbecue',\n",
       " 'des femmes',\n",
       " 'des vêtements traditionnels',\n",
       " 'un homme',\n",
       " \"la tête d' un autre homme\",\n",
       " 'six personnes',\n",
       " 'vtt',\n",
       " 'un décor de jungle',\n",
       " 'deux filles blondes',\n",
       " 'un rebord',\n",
       " 'un enfant',\n",
       " \"l' eau\",\n",
       " 'trois personnes',\n",
       " 'une table de pique-nique',\n",
       " 'trois garçons',\n",
       " 'une jetée',\n",
       " 'maillots de bain',\n",
       " 'un employé',\n",
       " 'un sac',\n",
       " 'une femme',\n",
       " 'poisson',\n",
       " 'la glace',\n",
       " 'une jolie femme',\n",
       " 'la harpe',\n",
       " 'un bâtiment',\n",
       " 'un garde de sécurité en uniforme',\n",
       " 'une clôture',\n",
       " 'la jeune femme',\n",
       " 'la pizza',\n",
       " 'un homme torse nu',\n",
       " 'short',\n",
       " 'des rochers',\n",
       " 'une fille',\n",
       " 'un gilet de sauvetage',\n",
       " \"l' eau\",\n",
       " 'un homme',\n",
       " 'uniforme',\n",
       " 'un homme',\n",
       " 'chemise bleue',\n",
       " 'un camion',\n",
       " 'des gens',\n",
       " 'un enfant',\n",
       " 'les pieds',\n",
       " 'une forêt',\n",
       " 'un homme',\n",
       " 't-shirt rouge',\n",
       " 'deux hommes',\n",
       " 'des maillots de bain',\n",
       " 'une plage moyennement peuplée',\n",
       " 'un bébé',\n",
       " 'une autre personne',\n",
       " 'une figure paternelle',\n",
       " 'deux enfants',\n",
       " 'leur maison',\n",
       " 'jardinage [',\n",
       " 'une binette',\n",
       " \"l' herbe\",\n",
       " 'un arbre',\n",
       " 'un homme',\n",
       " 'des aliments',\n",
       " 'la cuisinière',\n",
       " 'un homme',\n",
       " 'jean',\n",
       " 'la plage',\n",
       " 'une balle rouge',\n",
       " 'des gens',\n",
       " 'le trottoir',\n",
       " 'une rangée de magasins',\n",
       " 'un wakeboardeur',\n",
       " 'un grand nombre de personnes',\n",
       " 'un homme',\n",
       " 'une tyrolienne',\n",
       " \"l' eau\",\n",
       " 'une femme',\n",
       " 'jean',\n",
       " 'une publicité',\n",
       " 'une femme',\n",
       " 'ses lunettes de soleil',\n",
       " 'un homme',\n",
       " 'polo rose',\n",
       " \"l' herbe\",\n",
       " 'un ballon',\n",
       " 'une voiture',\n",
       " 'la plage',\n",
       " 'deux hommes',\n",
       " 'noir',\n",
       " \"l' homme\",\n",
       " 'pantalon jaune',\n",
       " 'les bras',\n",
       " 'deux hommes',\n",
       " 'des casquettes',\n",
       " 'des bâtons de marche',\n",
       " \"une étendue d' eau\",\n",
       " 'une équipe de pom-pom girls',\n",
       " 'une chorégraphie',\n",
       " 'des chaises',\n",
       " 'un garçon',\n",
       " 'dames',\n",
       " 'un adulte',\n",
       " 'une fille',\n",
       " 'une foule de personnes',\n",
       " 'un homme',\n",
       " 'un banc',\n",
       " 'son chien',\n",
       " \"l' eau\",\n",
       " 'un garçon',\n",
       " 'son frère cadet',\n",
       " 'le terrain de jeu',\n",
       " 'une femme',\n",
       " 'bleu',\n",
       " 'un sac en cuir noir',\n",
       " 'un banc',\n",
       " 'des gens',\n",
       " 'une limousine',\n",
       " 'le chien brun',\n",
       " 'une femme',\n",
       " 'un panier de linge',\n",
       " 'tissus',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " 'un guitariste',\n",
       " 'un guitariste',\n",
       " 'une boîte de nuit',\n",
       " 'un enfant',\n",
       " 'une chaise de jardin',\n",
       " 'deux femmes',\n",
       " 'trois hommes',\n",
       " \"l' océan\",\n",
       " 'une artiste',\n",
       " 'un violon',\n",
       " 'une rue',\n",
       " 'une femme',\n",
       " 'une guitare bleue',\n",
       " 'une jeune fille',\n",
       " 'une piscine',\n",
       " 'plusieurs enfants',\n",
       " 'trois adolescents',\n",
       " 'un chien brun',\n",
       " \"l' herbe\",\n",
       " 'sa langue',\n",
       " 'des gens',\n",
       " \"l' herbe\",\n",
       " 'un bâtiment',\n",
       " 'un gars torse nu',\n",
       " 'trois femmes',\n",
       " 'une foule',\n",
       " 'un café',\n",
       " 'deux jeunes garçons',\n",
       " 'des fruits',\n",
       " 'le vélo',\n",
       " 'un homme',\n",
       " 't-shirt noir',\n",
       " 'casquette',\n",
       " 'jean',\n",
       " 'la percussion',\n",
       " 'un seau jaune retourné',\n",
       " 'une jeune artiste',\n",
       " \"un portrait d' une femme\",\n",
       " 'un mur',\n",
       " \"deux femmes membres de l' équipe américaine [\",\n",
       " 'deux autres coéquipières',\n",
       " 'un homme',\n",
       " 'une casserole de liquide',\n",
       " 'le garçon',\n",
       " 'le lac',\n",
       " 'un homme',\n",
       " 'un stand de hot-dog',\n",
       " 'un grand nombre de personnes',\n",
       " 'une femme blonde',\n",
       " 'des boissons',\n",
       " 'un petit enfant',\n",
       " 'un t-shirt bleu et blanc',\n",
       " 'un alligator en plastique jaune',\n",
       " 'une femme',\n",
       " 'cheveux roses',\n",
       " 'noir',\n",
       " 'un homme',\n",
       " \"l' homme\",\n",
       " 'tenue de cuisinier japonais',\n",
       " 'un repas',\n",
       " 'deux personnes',\n",
       " 'une fille',\n",
       " 'la rivière',\n",
       " 'pierre',\n",
       " 'pierre',\n",
       " 'un ouvrier',\n",
       " 'sa caisse à outils',\n",
       " 'deux femmes',\n",
       " 'un vieil homme',\n",
       " 'ses bras',\n",
       " 'un enfant',\n",
       " 'une tenue de karaté blanche',\n",
       " 'trois hommes',\n",
       " 'des gilets de la même couleur',\n",
       " 'dehors',\n",
       " 'une femme',\n",
       " 'un bébé',\n",
       " 'un chapeau rose',\n",
       " 'un homme [',\n",
       " \"un groupe d' enfants pour la plupart asiatiques\",\n",
       " 'des box',\n",
       " 'des chaises bleues',\n",
       " 'un jeune garçon',\n",
       " 'maillot de foot',\n",
       " 'ses mains',\n",
       " 'une femme heureuse',\n",
       " 'un rafraichissement',\n",
       " 'un ouvrier du bâtiment',\n",
       " 'un gros engin',\n",
       " 'une femme',\n",
       " 'la receveuse [',\n",
       " 'un homme',\n",
       " 'uniforme de travail',\n",
       " 'un outil',\n",
       " 'une autre personne',\n",
       " 'un groupe de personnes',\n",
       " 'le froid',\n",
       " 'un alpiniste',\n",
       " 'un casque bleu',\n",
       " 'une montagne',\n",
       " 'un homme',\n",
       " \"l' équilibre au sommet\",\n",
       " 'une statue ronde',\n",
       " 'un enfant',\n",
       " 'une table de restaurant',\n",
       " 'un masque en carton',\n",
       " 'un chien brun',\n",
       " 'un lac',\n",
       " 'un bâton',\n",
       " 'une mère',\n",
       " 'ses deux jeunes garçons',\n",
       " 'une eau très bleue',\n",
       " 'une côte rocheuse',\n",
       " 'un enfant',\n",
       " 'de chaises rouges',\n",
       " 'une fille',\n",
       " 'un vélo décoré',\n",
       " 'un jeune garçon',\n",
       " 'une autre fille',\n",
       " 'un chien noir',\n",
       " 'une balle',\n",
       " \"l' eau\",\n",
       " 'un homme',\n",
       " 'pantalon blanc',\n",
       " 't-shirt bleu',\n",
       " 'un punching-ball jaune',\n",
       " 'deux indiens',\n",
       " 'un garçon',\n",
       " 'un nez meurtri',\n",
       " 'sa main',\n",
       " 'deux silhouettes de personnes',\n",
       " 'un canoë',\n",
       " 'des gens',\n",
       " \"le quai à l' extérieur\",\n",
       " 'la fenêtre',\n",
       " 'un homme',\n",
       " 'un mur',\n",
       " 'du feu',\n",
       " 'la main',\n",
       " 'deux chiens bruns',\n",
       " 'la neige',\n",
       " 'un public dans un théâtre',\n",
       " 'un bébé',\n",
       " 'tenue de noël',\n",
       " 'un homme',\n",
       " \"un écran d' ordinateur\",\n",
       " 'cette femme',\n",
       " 'des gens',\n",
       " 'un',\n",
       " 'quatre chiens blancs',\n",
       " 'un mur rouge',\n",
       " 'la',\n",
       " 'le t-shirt bleu',\n",
       " 'un bébé',\n",
       " 'deux personnes',\n",
       " 'fauteuils de plage rayés',\n",
       " 'une femme âgée',\n",
       " 'un métier',\n",
       " 'tisser',\n",
       " 'un garçon',\n",
       " 'autres personnes',\n",
       " 'un homme',\n",
       " 'manteau bleu',\n",
       " \"l' épaule d' un jeune garçon\",\n",
       " 'trois chiens bruns',\n",
       " 'la femme',\n",
       " 'bleu',\n",
       " 'un garçon',\n",
       " \"la fenêtre d' un taxi qui passe\",\n",
       " 'un homme',\n",
       " 'sweat gris',\n",
       " 'un enfant',\n",
       " 'maillot jaune',\n",
       " 'un ouvrier',\n",
       " 'veste jaune',\n",
       " 'un bâtiment',\n",
       " 'un homme',\n",
       " 'un tas de tireuses à bière',\n",
       " 'des lumières de noël',\n",
       " 'plafond',\n",
       " 'un homme',\n",
       " 'une falaise',\n",
       " \"l' océan\",\n",
       " 'un homme',\n",
       " 'noir',\n",
       " 'son monospace',\n",
       " 'un fox terrier',\n",
       " 'un ballon',\n",
       " 'une policière',\n",
       " 'une casquette',\n",
       " 'un uniforme bleu marine',\n",
       " 'des lunettes de soleil',\n",
       " 'une famille',\n",
       " 'un homme',\n",
       " 'un casque vert',\n",
       " 'un gilet de sécurité jaune fronce les sourcils',\n",
       " 'un enfant',\n",
       " 'des ficelles roses',\n",
       " 'la tête',\n",
       " 'confettis',\n",
       " 'ballons',\n",
       " 'un chien',\n",
       " 'un nez retroussé',\n",
       " 'une berge',\n",
       " 'un homme',\n",
       " 'son stand',\n",
       " 'sa journée de travail',\n",
       " 'un homme',\n",
       " 'un t-shirt rouge',\n",
       " 'un taco',\n",
       " 'une jeune femme',\n",
       " 'blanc',\n",
       " 'une raquette de tennis',\n",
       " 'un garçon',\n",
       " 'un t-shirt rouge',\n",
       " 'une pelle jaune',\n",
       " 'un individu',\n",
       " 'une veste rose',\n",
       " 'un banc en bois',\n",
       " 'un homme',\n",
       " 'une chemise blanche',\n",
       " \"la fenêtre d' une construction métallique\",\n",
       " 'une femme',\n",
       " 'une petite statue blanche',\n",
       " 'six enfants torses nus',\n",
       " 'deux personnes',\n",
       " 'vélo',\n",
       " 'une fille',\n",
       " 'corde',\n",
       " 'un trottoir',\n",
       " 'un parking',\n",
       " 'un homme',\n",
       " 'un t-shirt orange',\n",
       " 'un casque',\n",
       " 'un petit garçon',\n",
       " 'des blocs en plastique',\n",
       " 'des voitures',\n",
       " 'des animaux',\n",
       " 'un adulte',\n",
       " 'une petite fille',\n",
       " 'un cadeau de noël',\n",
       " 'la femme',\n",
       " 'bleu',\n",
       " 'un appareil photo',\n",
       " 'deux autres femmes',\n",
       " 'une petite fille',\n",
       " 'le canapé confortable',\n",
       " 'un chien marron et noir',\n",
       " 'un sentier',\n",
       " 'deux chiens',\n",
       " 'un arbre',\n",
       " 'un manteau',\n",
       " 'un pantalon noirs',\n",
       " 'des marches',\n",
       " 'le chien',\n",
       " 'deux hommes',\n",
       " 'vert',\n",
       " 'la nourriture',\n",
       " 'un restaurant',\n",
       " 'un homme',\n",
       " 'une tenue de cuir noire',\n",
       " 'un chapeau de cowboy',\n",
       " 'un chien',\n",
       " 'un jouet jaune',\n",
       " 'un chien',\n",
       " 'une couverture',\n",
       " 'une famille',\n",
       " 'la plage',\n",
       " 'leur chien',\n",
       " 'une femme',\n",
       " 'un enfant',\n",
       " \"l' enfant\",\n",
       " 'deux hommes',\n",
       " 'une femme',\n",
       " \"un groupe d' hommes\",\n",
       " 'des troncs',\n",
       " \"l' eau\",\n",
       " 'un homme',\n",
       " 'un verre à pied',\n",
       " 'le journal',\n",
       " 'un homme [',\n",
       " 'piano',\n",
       " 'un jeune garçon',\n",
       " 'un maillot bleu',\n",
       " 'un short jaune',\n",
       " 'football',\n",
       " 'un homme',\n",
       " 'une structure en pierre',\n",
       " 'ses bras',\n",
       " 'un chien',\n",
       " \"l' eau\",\n",
       " 'deux femmes',\n",
       " 'des débardeurs',\n",
       " 'un homme',\n",
       " 'un fauteuil chez le coiffeur',\n",
       " 'un jeune enfant',\n",
       " 'bottes vertes',\n",
       " 'une flaque de boue',\n",
       " 'un homme',\n",
       " 'une tronçonneuse',\n",
       " 'bois',\n",
       " 'un homme',\n",
       " 'une table de pique-nique',\n",
       " 'un plateau',\n",
       " 'une bière',\n",
       " 'le garçon',\n",
       " 'un sweat noir',\n",
       " 'un jean',\n",
       " 'une batte de base-ball rouge',\n",
       " 'un homme barbu avec des cheveux foncés',\n",
       " 'des lunettes',\n",
       " 'une chemise hawaïenne',\n",
       " \"l' herbe\",\n",
       " 'des chiens',\n",
       " 'un technicien lumière',\n",
       " 'des tatouages tribaux',\n",
       " 'un projecteur',\n",
       " 'un balcon',\n",
       " 'deux bergers allemands',\n",
       " 'un groupe de personnes',\n",
       " 'un chien blanc et marron',\n",
       " 'un jouet',\n",
       " 'un homme',\n",
       " 'des cheveux blancs',\n",
       " \"l' accordéon\",\n",
       " 'une femme',\n",
       " 'cheveux bruns',\n",
       " 'un banc',\n",
       " 'un café',\n",
       " 'un homme',\n",
       " 'un vélo',\n",
       " 'la flûte de pan',\n",
       " 'deux enfants',\n",
       " 'un tronc',\n",
       " 'une corde',\n",
       " 'un homme',\n",
       " 'moto',\n",
       " 'une jeune femme',\n",
       " 'un tissu violet',\n",
       " 'son visage',\n",
       " 'une plate-forme en bois',\n",
       " 'la femme',\n",
       " 't-shirt marron',\n",
       " 'un banc rouge vif',\n",
       " 'un chien',\n",
       " 'une petite rivière',\n",
       " 'un tronc',\n",
       " 'un jeune homme',\n",
       " \"un t-shirt blanc et d' un short vert et noir\",\n",
       " 'une borne',\n",
       " 'un groupe de gens',\n",
       " 'des parapluies',\n",
       " 'un homme',\n",
       " 'une pancarte géante',\n",
       " 'son vélo',\n",
       " 'un homme',\n",
       " 'un tronc',\n",
       " \"un cours d' eau\",\n",
       " 'deux chiens',\n",
       " 'un groupe de personnes âgées',\n",
       " 'des instruments',\n",
       " 'une tente',\n",
       " \"l' eau\",\n",
       " \"une photo d' une rue bondée en ville\",\n",
       " 'une jeune femme blonde',\n",
       " 'une tige blanche',\n",
       " 'une journée ensoleillée',\n",
       " 'deux personnes',\n",
       " 't-shirts bleus',\n",
       " 'un mégaphone',\n",
       " 'un chien noir',\n",
       " 'un cow-boy',\n",
       " \"le dos d' un cheval\",\n",
       " 'une équipe de cheminots',\n",
       " 'un ouvrier',\n",
       " 'gilet orange',\n",
       " 'une pelle',\n",
       " 'deux ouvriers du bâtiment',\n",
       " 'trois hommes',\n",
       " 'une pente',\n",
       " 'une femme asiatique',\n",
       " 'robe de mariée à fleurs',\n",
       " 'un pont',\n",
       " \"ses demoiselles d' honneur\",\n",
       " 'un jeune homme',\n",
       " 'sa guitare',\n",
       " 'trois garçons',\n",
       " 'des éponges',\n",
       " 'trois ouvriers du bâtiment [',\n",
       " 'des gens',\n",
       " 'une forêt',\n",
       " 'canoës',\n",
       " 'une chorale',\n",
       " 'un groupe de jeunes adolescents',\n",
       " 'deux gars',\n",
       " \"un orange et l' autre bleu\",\n",
       " 'un ruisseau',\n",
       " 'deux ouvriers',\n",
       " 'une femme',\n",
       " 'un tricot rougeâtre',\n",
       " 'un jean',\n",
       " 'les mains',\n",
       " 'son genou gauche',\n",
       " 'deux artistes',\n",
       " 'un public [',\n",
       " 'un gi',\n",
       " 'un homme',\n",
       " 'manteau jaune',\n",
       " 'un feu',\n",
       " 'un garçon',\n",
       " 'parka',\n",
       " 'un homme',\n",
       " 'un garçon',\n",
       " 'une plage rocheuse',\n",
       " 'une femme',\n",
       " 'el corazon',\n",
       " 'des poids noirs',\n",
       " 'un garçon',\n",
       " 'un télescope',\n",
       " 'une jeune fille pieds nus',\n",
       " 'robe rose',\n",
       " 'beaucoup de gens',\n",
       " 'une tente dehors',\n",
       " 'un jeune',\n",
       " 'un t-shirt noir [',\n",
       " 'la percussion',\n",
       " 'un homme',\n",
       " 'des objets',\n",
       " 'bord de la route',\n",
       " 'la fille',\n",
       " 'jaune',\n",
       " 'la fille',\n",
       " 'orange',\n",
       " 'la fille',\n",
       " 'bleu',\n",
       " 'un chien',\n",
       " 'un obstacle dehors',\n",
       " 'un chien',\n",
       " 'un collier noir',\n",
       " 'la terre',\n",
       " 'les feuilles mortes',\n",
       " 'deux chiens bruns',\n",
       " 'un homme',\n",
       " 'une moustache',\n",
       " 'une barbe',\n",
       " 'une poêle à frire',\n",
       " 'des flammes',\n",
       " 'un homme',\n",
       " \"tenue d' époque révolutionnaire\",\n",
       " 'une cloche',\n",
       " 'un homme',\n",
       " 'sweat noir',\n",
       " 'un rivage rocailleux',\n",
       " 'deux chiens [',\n",
       " 'deux hommes',\n",
       " 'une voiture',\n",
       " 'un homme chinois',\n",
       " 'des voitures garées',\n",
       " 'deux femmes',\n",
       " 'des t-shirts similaires',\n",
       " 'un jeune enfant',\n",
       " 'un gilet de sauvetage orange',\n",
       " 'une rame',\n",
       " 'un kayak bleu',\n",
       " \"un plan d' eau\",\n",
       " 'des gens',\n",
       " 'un sentier',\n",
       " 'trois jeunes adultes',\n",
       " 'une foule de gens',\n",
       " 'la femme',\n",
       " 'une femme',\n",
       " 'un enfant',\n",
       " \"la porte d' entrée de leur maison pittoresque\",\n",
       " 'un homme noir',\n",
       " 'ses deux amis blancs',\n",
       " 'leurs têtes',\n",
       " 'une fille',\n",
       " 'un pantalon de camouflage',\n",
       " 'un hummer',\n",
       " 'un chien brun clair',\n",
       " 'un garçon',\n",
       " 'un gros insecte',\n",
       " 'son nez',\n",
       " 'un homme chauve',\n",
       " 'son chien marron et noir',\n",
       " 'une foule',\n",
       " 'un lévrier muselé',\n",
       " 'jaune et noir',\n",
       " 'un homme',\n",
       " 'sandales',\n",
       " 'le trottoir',\n",
       " 'quelques sacs',\n",
       " 'un homme',\n",
       " 'une femme',\n",
       " \"pied d' une grille\",\n",
       " 'un enfant',\n",
       " 'les machines à café',\n",
       " 'un magasin',\n",
       " 'un homme',\n",
       " 'un gobelet jaune',\n",
       " 'personnes',\n",
       " 'un garçon',\n",
       " 'une voiture',\n",
       " 'des fleurs',\n",
       " 'le capot',\n",
       " 'une femme',\n",
       " 'robe à fleurs',\n",
       " 'des enfants',\n",
       " 'une fourgonnette',\n",
       " 'un homme [',\n",
       " 'une jeune femme',\n",
       " 'un t-shirt noir',\n",
       " 'un jean',\n",
       " 'une femme',\n",
       " 'un chapeau',\n",
       " 'une falaise',\n",
       " 'un grand caniche noir',\n",
       " \"l' herbe\",\n",
       " 'un jouet',\n",
       " 'sa gueule',\n",
       " 'un garçon',\n",
       " 'short',\n",
       " 'un petit garçon',\n",
       " 'un pantalon rouge',\n",
       " 'la rue',\n",
       " 'une femme',\n",
       " 'parapluies',\n",
       " 'son téléphone',\n",
       " 'huit hommes',\n",
       " 'instruments',\n",
       " 'un guitariste',\n",
       " 'un homme',\n",
       " 'combinaison orange',\n",
       " 'un casque',\n",
       " 'un tuyau bleu',\n",
       " 'un homme',\n",
       " 'deux filles',\n",
       " 'un poisson',\n",
       " 'des cannes à pêche',\n",
       " \"un plan d' eau\",\n",
       " 'un homme',\n",
       " 'polo rouge',\n",
       " 'chien',\n",
       " 'un garçon',\n",
       " 'maillot de bain rouge et blanc',\n",
       " 'une belle piscine',\n",
       " 'une femme asiatique',\n",
       " 'ses cheveux',\n",
       " 'une femme âgée',\n",
       " 'un jeune enfant',\n",
       " 't-shirt rose',\n",
       " 'des blocs multicolores',\n",
       " 'un petit chien noir',\n",
       " 'des barrières',\n",
       " 'un homme brun',\n",
       " 'chemise verte',\n",
       " 'la trompette [',\n",
       " 'homme',\n",
       " 'téléphone',\n",
       " 'les pieds',\n",
       " \"un groupe d' enfants\",\n",
       " 'un tapis bleu',\n",
       " 'des bols',\n",
       " 'un garçon noir',\n",
       " 'un petit chien',\n",
       " 'deux gros chiens',\n",
       " 'des gens',\n",
       " 'cercle',\n",
       " 'un chien',\n",
       " 'une balle de softball',\n",
       " 'un enfant blond',\n",
       " 'une balançoire',\n",
       " 'un homme',\n",
       " 'deux femmes',\n",
       " 'vin blanc',\n",
       " 'un homme asiatique',\n",
       " 'la nourriture',\n",
       " 'un chien brun',\n",
       " 'un frisbee vert',\n",
       " 'des fans',\n",
       " 'le groupe',\n",
       " 'un jeune garçon',\n",
       " 'une sculpture en sable représentant une pyramide',\n",
       " 'trois jeunes enfants',\n",
       " \"la pelouse d' un jardin\",\n",
       " 'un homme',\n",
       " \"une œuvre d' art\",\n",
       " 'un chariot',\n",
       " 'un homme',\n",
       " 'un vélo',\n",
       " 'un garçon',\n",
       " 'des bottes bleues et jaunes',\n",
       " 'la terre',\n",
       " 'une femme',\n",
       " 'veste orange',\n",
       " 'un banc',\n",
       " 'un homme',\n",
       " 'skateboard',\n",
       " 'un homme',\n",
       " \"tenue d' arts martiaux\",\n",
       " 'les airs',\n",
       " 'une femme',\n",
       " 'des sachets de fruits',\n",
       " 'un trottoir',\n",
       " 'deux équipes de football',\n",
       " 'un enfant',\n",
       " 't-shirt bleu',\n",
       " 'un banc',\n",
       " 'un gardien de but',\n",
       " 'maillot jaune',\n",
       " 'un groupe de jeunes',\n",
       " 'des shots',\n",
       " 'un jeune homme',\n",
       " 'une rampe rose',\n",
       " 'un jeune garçon',\n",
       " 'un lit superposé',\n",
       " 'un lit plus petit',\n",
       " 'deux personnes',\n",
       " 'des costumes bizarres de type alien',\n",
       " 'un bleu',\n",
       " 'un violet',\n",
       " 'une route',\n",
       " 'un homme',\n",
       " 'un maillot bleu',\n",
       " 'un numéro',\n",
       " \"un employé d' usine asiatique\",\n",
       " 'un homme [',\n",
       " 'des basketteurs',\n",
       " 'un joueur de football américain',\n",
       " 'une tenue orange',\n",
       " 'le ballon',\n",
       " 'deux skateurs',\n",
       " \"d' autres\",\n",
       " 'une équipe',\n",
       " 'blanc et or',\n",
       " \"le bord d' un terrain de football américain\",\n",
       " 'une petite fille',\n",
       " 'sa trottinette',\n",
       " \"un groupe d' enfants asiatiques\",\n",
       " 't-shirts',\n",
       " 'casquettes blancs',\n",
       " 'une foule',\n",
       " 'des piétons',\n",
       " 'un carton',\n",
       " 'un chien brun',\n",
       " 'deux hommes',\n",
       " 'uniformes militaires',\n",
       " 'une femme',\n",
       " 'les participants',\n",
       " 'des ombrelles',\n",
       " 'des drapeaux de prière',\n",
       " 'un cycliste',\n",
       " 'un obstacle',\n",
       " 'un couple',\n",
       " 'des chaises de jardin blanches',\n",
       " 'de jeunes enfants',\n",
       " 'un surfeur',\n",
       " 'combinaison bleue',\n",
       " 'les vagues',\n",
       " 'le garçon',\n",
       " 'son frère qui joue au football',\n",
       " 'deux jeunes hommes',\n",
       " 'équipes de football',\n",
       " 'le ballon',\n",
       " 'des gens',\n",
       " 'une rue en pente pavée',\n",
       " 'vendeurs chinois',\n",
       " 'un jeune garçon',\n",
       " 'un pantalon blanc',\n",
       " 'le canapé',\n",
       " 'un garçon',\n",
       " 't-shirt orange',\n",
       " 'un sac',\n",
       " 'legos',\n",
       " 'une femme',\n",
       " 'sandales marron',\n",
       " 'un jean',\n",
       " 'un t-shirt blanc',\n",
       " 'un bébé',\n",
       " 'un grand arbre',\n",
       " 'trois personnes',\n",
       " 'des pancartes politiques',\n",
       " 'un policier',\n",
       " 'une voiture',\n",
       " 'une rue en ville',\n",
       " 'deux hommes',\n",
       " 'des bonnets',\n",
       " 'un garçon',\n",
       " 'un ballon de football',\n",
       " 'un jeune garçon',\n",
       " 'un bonnet bleu',\n",
       " 'la tête',\n",
       " 'un homme roux',\n",
       " 'des dreadlocks',\n",
       " 'la guitare acoustique',\n",
       " 'un homme',\n",
       " 'un sandwich',\n",
       " 'sa petite fille',\n",
       " 'ses genoux',\n",
       " 'un enfant afro-américain',\n",
       " 'quelque chose',\n",
       " 'ceux présents',\n",
       " 'la photo',\n",
       " 'une femme',\n",
       " 'une foule de gens',\n",
       " 'un mégaphone',\n",
       " 'des spectateurs déguisés',\n",
       " 'un policier en uniforme',\n",
       " 'un homme',\n",
       " 'costume',\n",
       " 'une corbeille de fruits',\n",
       " 'une foule',\n",
       " 'une fille',\n",
       " 'blanc',\n",
       " 'une fille',\n",
       " 'vert',\n",
       " 'une station de lavage de voiture bleue',\n",
       " 'un homme',\n",
       " 'du matériel électronique',\n",
       " 'une personne',\n",
       " \"une vague s' écrasant\",\n",
       " \"l' océan\",\n",
       " \"un officier de l' armée\",\n",
       " 'quelque chose',\n",
       " 'une mariée',\n",
       " 'un époux',\n",
       " 'le voile de la mariée',\n",
       " 'la police antiémeute',\n",
       " 'un jeune homme',\n",
       " 'un foulard rouge',\n",
       " 'le visage',\n",
       " 'un chien noir et blanc',\n",
       " 'un obstacle',\n",
       " 'une femme',\n",
       " 'un pull',\n",
       " 'un livre [',\n",
       " 'plusieurs adolescents',\n",
       " 'une rambarde',\n",
       " \"l' homme\",\n",
       " 't-shirt blanc',\n",
       " 'un adolescent',\n",
       " 'une partie de son estomac',\n",
       " 'des gens',\n",
       " 'différents types de baguettes',\n",
       " 'différents types de tambours',\n",
       " 'trois agriculteurs',\n",
       " 'riz',\n",
       " 'un champ de riz',\n",
       " 'deux femmes',\n",
       " 'un homme',\n",
       " 'un livre',\n",
       " \"trois jambes d' enfants\",\n",
       " 'un cuisinier',\n",
       " 'beaucoup de gens',\n",
       " 'une rue',\n",
       " \"l' ado\",\n",
       " 'son vélo',\n",
       " 'une petite fille',\n",
       " \"bord d' une plage\",\n",
       " 'des ailes',\n",
       " 'deux hommes',\n",
       " \"l' arrière d' un camion\",\n",
       " 'un objet métallique',\n",
       " 'quatre personnes',\n",
       " 'une femme',\n",
       " 'jupe rose',\n",
       " 'un bébé',\n",
       " 'un joueur de hockey',\n",
       " 'maillot jaune',\n",
       " 'le but',\n",
       " 'un homme',\n",
       " 'un grand panneau',\n",
       " 'trois garçons',\n",
       " 't-shirts verts',\n",
       " 'pantalons beiges',\n",
       " \"sommet d' un toboggan\",\n",
       " 'un homme',\n",
       " 'un chien',\n",
       " 'ses jambes',\n",
       " 'le chien blanc',\n",
       " 'une eau peu profonde',\n",
       " \"des percussionnistes de l' oregon\",\n",
       " 'la fanfare',\n",
       " \"un groupe d' enfants\",\n",
       " 'un adulte',\n",
       " 'un groupe de femmes',\n",
       " 'des instruments de musique',\n",
       " 'une petite fille',\n",
       " 'robe à carreaux violette',\n",
       " 'le sol',\n",
       " 'un homme',\n",
       " 'cheveux grisonnants',\n",
       " 'la barbe',\n",
       " 'deux chiens noirs',\n",
       " 'un chiot noir',\n",
       " 'un chien blanc',\n",
       " 'un homme',\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_triple_filepath)\n",
    "corpus_list = test_df[\"entity_content\"].values.tolist() \n",
    "corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [[w.lower() for w in word_tokenize(q, language=\"french\")] for q in corpus_list]\n",
    "test_corpus_dct = gensim.corpora.Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_corpus_dct.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(330)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(test_corpus_dct.dfs.values())\n",
    "torch.sum(torch.tensor(freq) >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For English\n",
    "general_df = pd.read_csv(train_triple_filepath_en)\n",
    "corpus_list_en = general_df[\"entity_content\"].values.tolist() \n",
    "corpus_list_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_en = [[w.lower() for w in word_tokenize(q)] for q in corpus_list_en]\n",
    "general_corpus_dct_en = gensim.corpora.Dictionary(corpus_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish vocabulary dictionary from training set: English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token2id': {'emptywordtoken': 0,\n",
       "  'unknownword': 1,\n",
       "  'guys': 2,\n",
       "  'two': 3,\n",
       "  'young': 4,\n",
       "  'hair': 5,\n",
       "  'shaggy': 6,\n",
       "  'hands': 7,\n",
       "  'their': 8,\n",
       "  ',': 9,\n",
       "  'males': 10,\n",
       "  'white': 11,\n",
       "  'bushes': 12,\n",
       "  'many': 13,\n",
       "  'men': 14,\n",
       "  'green': 15,\n",
       "  'shirts': 16,\n",
       "  'a': 17,\n",
       "  'man': 18,\n",
       "  'blue': 19,\n",
       "  'shirt': 20,\n",
       "  'friends': 21,\n",
       "  'several': 22,\n",
       "  'hard': 23,\n",
       "  'hats': 24,\n",
       "  'giant': 25,\n",
       "  'pulley': 26,\n",
       "  'system': 27,\n",
       "  'workers': 28,\n",
       "  'equipment': 29,\n",
       "  'of': 30,\n",
       "  'piece': 31,\n",
       "  'machine': 32,\n",
       "  'four': 33,\n",
       "  'structure': 34,\n",
       "  'tall': 35,\n",
       "  'three': 36,\n",
       "  'large': 37,\n",
       "  'rig': 38,\n",
       "  'child': 39,\n",
       "  'dress': 40,\n",
       "  'pink': 41,\n",
       "  'set': 42,\n",
       "  'stairs': 43,\n",
       "  'an': 44,\n",
       "  'entry': 45,\n",
       "  'way': 46,\n",
       "  'girl': 47,\n",
       "  'little': 48,\n",
       "  'the': 49,\n",
       "  'her': 50,\n",
       "  'playhouse': 51,\n",
       "  'wooden': 52,\n",
       "  'someone': 53,\n",
       "  'hat': 54,\n",
       "  'stair': 55,\n",
       "  'window': 56,\n",
       "  'ladder': 57,\n",
       "  'building': 58,\n",
       "  'jeans': 59,\n",
       "  'windows': 60,\n",
       "  'one': 61,\n",
       "  'gray': 62,\n",
       "  'black': 63,\n",
       "  'stove': 64,\n",
       "  'guy': 65,\n",
       "  'food': 66,\n",
       "  'meal': 67,\n",
       "  'people': 68,\n",
       "  'guitar': 69,\n",
       "  'other': 70,\n",
       "  'his': 71,\n",
       "  'costume': 72,\n",
       "  'players': 73,\n",
       "  \"'s\": 74,\n",
       "  'another': 75,\n",
       "  'coat': 76,\n",
       "  'boys': 77,\n",
       "  'chair': 78,\n",
       "  'animal': 79,\n",
       "  'lion': 80,\n",
       "  'stuffed': 81,\n",
       "  'finishing': 82,\n",
       "  'touches': 83,\n",
       "  'toy': 84,\n",
       "  'rollerskates': 85,\n",
       "  'cellphone': 86,\n",
       "  'lot': 87,\n",
       "  'parking': 88,\n",
       "  'trendy': 89,\n",
       "  'street': 90,\n",
       "  'adult': 91,\n",
       "  'rollerblades': 92,\n",
       "  'cellular': 93,\n",
       "  'phone': 94,\n",
       "  'skating': 95,\n",
       "  'woman': 96,\n",
       "  'asian': 97,\n",
       "  'suit': 98,\n",
       "  'dark-haired': 99,\n",
       "  'brown-haired': 100,\n",
       "  'pipes': 101,\n",
       "  'metal': 102,\n",
       "  'railing': 103,\n",
       "  'hip': 104,\n",
       "  'outfits': 105,\n",
       "  'purse': 106,\n",
       "  'gate': 107,\n",
       "  'rail': 108,\n",
       "  'youths': 109,\n",
       "  'roadside': 110,\n",
       "  'poles': 111,\n",
       "  'no': 112,\n",
       "  'ballet': 113,\n",
       "  'dancers': 114,\n",
       "  'five': 115,\n",
       "  'girls': 116,\n",
       "  'feet': 117,\n",
       "  'class': 118,\n",
       "  'sneakers': 119,\n",
       "  'flight': 120,\n",
       "  'top': 121,\n",
       "  'casually': 122,\n",
       "  'dressed': 123,\n",
       "  'stone': 124,\n",
       "  'wall': 125,\n",
       "  'staircase': 126,\n",
       "  'excited': 127,\n",
       "  'faces': 128,\n",
       "  'dog': 129,\n",
       "  'brown': 130,\n",
       "  'spots': 131,\n",
       "  'tri-colored': 132,\n",
       "  'road': 133,\n",
       "  'breeds': 134,\n",
       "  'different': 135,\n",
       "  'dogs': 136,\n",
       "  'pavement': 137,\n",
       "  'spotted': 138,\n",
       "  'clothes': 139,\n",
       "  'reflective': 140,\n",
       "  'safety': 141,\n",
       "  'ear': 142,\n",
       "  'protection': 143,\n",
       "  'deere': 144,\n",
       "  'john': 145,\n",
       "  'tractor': 146,\n",
       "  'driver': 147,\n",
       "  'clothing': 148,\n",
       "  'easy': 149,\n",
       "  'see': 150,\n",
       "  'to': 151,\n",
       "  'orange': 152,\n",
       "  'uniform': 153,\n",
       "  'headphones': 154,\n",
       "  'paved': 155,\n",
       "  'main': 156,\n",
       "  'some': 157,\n",
       "  'women': 158,\n",
       "  'buildings': 159,\n",
       "  'group': 160,\n",
       "  'dark': 161,\n",
       "  'glasses': 162,\n",
       "  'powder': 163,\n",
       "  'cake': 164,\n",
       "  'sifter': 165,\n",
       "  'lady': 166,\n",
       "  'powdered': 167,\n",
       "  'sugar': 168,\n",
       "  'bundt': 169,\n",
       "  'sprinkles': 170,\n",
       "  'jacket': 171,\n",
       "  'chocolate': 172,\n",
       "  'standing': 173,\n",
       "  'pan': 174,\n",
       "  'small': 175,\n",
       "  'grass': 176,\n",
       "  'fingerpaints': 177,\n",
       "  'canvas': 178,\n",
       "  'rainbow': 179,\n",
       "  'paint': 180,\n",
       "  'painted': 181,\n",
       "  'bowl': 182,\n",
       "  'pigtails': 183,\n",
       "  'painting': 184,\n",
       "  'bench': 185,\n",
       "  'and': 186,\n",
       "  'leash': 187,\n",
       "  'shirtless': 188,\n",
       "  'park': 189,\n",
       "  'adults': 190,\n",
       "  'chairs': 191,\n",
       "  'circle': 192,\n",
       "  'instruments': 193,\n",
       "  'musical': 194,\n",
       "  'type': 195,\n",
       "  'musicians': 196,\n",
       "  'music': 197,\n",
       "  'sheet': 198,\n",
       "  'flutes': 199,\n",
       "  'clarinets': 200,\n",
       "  'elderly': 201,\n",
       "  'instrument': 202,\n",
       "  'stringed': 203,\n",
       "  'at': 204,\n",
       "  'instrumentalists': 205,\n",
       "  'least': 206,\n",
       "  'bunch': 207,\n",
       "  'person': 208,\n",
       "  'roadway': 209,\n",
       "  'bridge': 210,\n",
       "  'out': 211,\n",
       "  'washed': 212,\n",
       "  'supports': 213,\n",
       "  't-shirt': 214,\n",
       "  'crowd': 215,\n",
       "  'goatee': 216,\n",
       "  'gloves': 217,\n",
       "  'latex': 218,\n",
       "  'gun': 219,\n",
       "  'tattoo': 220,\n",
       "  'back': 221,\n",
       "  'children': 222,\n",
       "  'boy': 223,\n",
       "  'seesaw': 224,\n",
       "  'sand': 225,\n",
       "  'teeter': 226,\n",
       "  'totter': 227,\n",
       "  '2': 228,\n",
       "  'kids': 229,\n",
       "  'vest': 230,\n",
       "  'intersection': 231,\n",
       "  'flag': 232,\n",
       "  'caution': 233,\n",
       "  'bright': 234,\n",
       "  'corner': 235,\n",
       "  'spray': 236,\n",
       "  'construction': 237,\n",
       "  'worker': 238,\n",
       "  'red': 239,\n",
       "  'long': 240,\n",
       "  'beret': 241,\n",
       "  'beige': 242,\n",
       "  'raincoat': 243,\n",
       "  'artists': 244,\n",
       "  'paintings': 245,\n",
       "  'busy': 246,\n",
       "  'sidewalk': 247,\n",
       "  'scene': 248,\n",
       "  'place': 249,\n",
       "  'public': 250,\n",
       "  'others': 251,\n",
       "  'passerby': 252,\n",
       "  'art': 253,\n",
       "  'fair': 254,\n",
       "  'outdoor': 255,\n",
       "  'foot': 256,\n",
       "  'basket': 257,\n",
       "  'waste': 258,\n",
       "  'pants': 259,\n",
       "  'cart': 260,\n",
       "  'janitor': 261,\n",
       "  'dolly': 262,\n",
       "  'tools': 263,\n",
       "  'ropes': 264,\n",
       "  'rope': 265,\n",
       "  'roping': 266,\n",
       "  'net': 267,\n",
       "  'toothpick': 268,\n",
       "  'something': 269,\n",
       "  'flower': 270,\n",
       "  'teen': 271,\n",
       "  'object': 272,\n",
       "  'unknown': 273,\n",
       "  'crane': 274,\n",
       "  'origami': 275,\n",
       "  'blond': 276,\n",
       "  'yellow': 277,\n",
       "  'pole': 278,\n",
       "  'vault': 279,\n",
       "  'smiling': 280,\n",
       "  'sky': 281,\n",
       "  'baseball': 282,\n",
       "  'cap': 283,\n",
       "  'coffee': 284,\n",
       "  'mug': 285,\n",
       "  'ball': 286,\n",
       "  'cup': 287,\n",
       "  'urinals': 288,\n",
       "  'urinal': 289,\n",
       "  'clear': 290,\n",
       "  'skies': 291,\n",
       "  'sun': 292,\n",
       "  'silhouettes': 293,\n",
       "  'beer': 294,\n",
       "  'glass': 295,\n",
       "  'table': 296,\n",
       "  'drink': 297,\n",
       "  'old': 298,\n",
       "  'officer': 299,\n",
       "  'front': 300,\n",
       "  'van': 301,\n",
       "  'police': 302,\n",
       "  'trained': 303,\n",
       "  'handler': 304,\n",
       "  'security': 305,\n",
       "  'watch': 306,\n",
       "  'policeman': 307,\n",
       "  'german': 308,\n",
       "  'shepherd': 309,\n",
       "  'search': 310,\n",
       "  '``': 311,\n",
       "  'conditions': 312,\n",
       "  'snow': 313,\n",
       "  'details': 314,\n",
       "  'heavy': 315,\n",
       "  'bicycle': 316,\n",
       "  'bike': 317,\n",
       "  'snowy': 318,\n",
       "  'tie': 319,\n",
       "  'slacks': 320,\n",
       "  'open': 321,\n",
       "  '5': 322,\n",
       "  'suits': 323,\n",
       "  'short-sleeved': 324,\n",
       "  'ties': 325,\n",
       "  'colleges': 326,\n",
       "  'stop': 327,\n",
       "  'tan': 328,\n",
       "  'older': 329,\n",
       "  'camp': 330,\n",
       "  'machines': 331,\n",
       "  'machinery': 332,\n",
       "  'backwards': 333,\n",
       "  'caucasian': 334,\n",
       "  'dark-skinned': 335,\n",
       "  'sleeveless': 336,\n",
       "  'conveyor': 337,\n",
       "  'jars': 338,\n",
       "  'packing': 339,\n",
       "  'candles': 340,\n",
       "  'boxes': 341,\n",
       "  'manager': 342,\n",
       "  'warehouse': 343,\n",
       "  'employee': 344,\n",
       "  'assembly': 345,\n",
       "  'line': 346,\n",
       "  'outfit': 347,\n",
       "  'broom': 348,\n",
       "  'architecture': 349,\n",
       "  'traditional': 350,\n",
       "  'baby': 351,\n",
       "  'bottoms': 352,\n",
       "  'dirt': 353,\n",
       "  'kimono': 354,\n",
       "  'walkway': 355,\n",
       "  'florescent': 356,\n",
       "  'vests': 357,\n",
       "  'cars': 358,\n",
       "  'parked': 359,\n",
       "  'car': 360,\n",
       "  'row': 361,\n",
       "  'checkpoint': 362,\n",
       "  'ranger': 363,\n",
       "  'tourist': 364,\n",
       "  'snack': 365,\n",
       "  'toddlers': 366,\n",
       "  'infants': 367,\n",
       "  'babies': 368,\n",
       "  'female': 369,\n",
       "  'chips': 370,\n",
       "  'mobile': 371,\n",
       "  'silver': 372,\n",
       "  'vehicle': 373,\n",
       "  'weird': 374,\n",
       "  'segway': 375,\n",
       "  'product': 376,\n",
       "  'showing': 377,\n",
       "  'modern': 378,\n",
       "  'strange': 379,\n",
       "  'onlookers': 380,\n",
       "  'barrier': 381,\n",
       "  'off': 382,\n",
       "  'roped': 383,\n",
       "  'futuristic': 384,\n",
       "  'looking': 385,\n",
       "  'single-person': 386,\n",
       "  '4-wheeled': 387,\n",
       "  'bride': 388,\n",
       "  'groom': 389,\n",
       "  'pathway': 390,\n",
       "  'brick': 391,\n",
       "  'beautiful': 392,\n",
       "  'husband': 393,\n",
       "  'new': 394,\n",
       "  'couple': 395,\n",
       "  'married': 396,\n",
       "  'recently': 397,\n",
       "  'controller': 398,\n",
       "  'gamecube': 399,\n",
       "  'nintendo': 400,\n",
       "  'mcdonald': 401,\n",
       "  'game': 402,\n",
       "  'video': 403,\n",
       "  'kiosk': 404,\n",
       "  'kid': 405,\n",
       "  'ears': 406,\n",
       "  'water': 407,\n",
       "  'head': 408,\n",
       "  'shore': 409,\n",
       "  'beach': 410,\n",
       "  'edge': 411,\n",
       "  'its': 412,\n",
       "  'picnic': 413,\n",
       "  'tables': 414,\n",
       "  'reunion': 415,\n",
       "  'bounce': 416,\n",
       "  'moon': 417,\n",
       "  'or': 418,\n",
       "  'spanish': 419,\n",
       "  'sunglasses': 420,\n",
       "  'blouse': 421,\n",
       "  'balloon': 422,\n",
       "  'design': 423,\n",
       "  'burger': 424,\n",
       "  'coolers': 425,\n",
       "  'gray-haired': 426,\n",
       "  'sandwich': 427,\n",
       "  'youngsters': 428,\n",
       "  'mat': 429,\n",
       "  'wood': 430,\n",
       "  'students': 431,\n",
       "  'martial': 432,\n",
       "  'balconies': 433,\n",
       "  'pipe': 434,\n",
       "  'balcony': 435,\n",
       "  'lower': 436,\n",
       "  'liquid': 437,\n",
       "  'sweatshirt': 438,\n",
       "  'bottle': 439,\n",
       "  'contents': 440,\n",
       "  'paper': 441,\n",
       "  'hand': 442,\n",
       "  'eyes': 443,\n",
       "  'face': 444,\n",
       "  'each': 445,\n",
       "  'rock': 446,\n",
       "  'overalls': 447,\n",
       "  'stony': 448,\n",
       "  'mottled': 449,\n",
       "  'collar': 450,\n",
       "  'fallen': 451,\n",
       "  'tree': 452,\n",
       "  'log': 453,\n",
       "  'stump': 454,\n",
       "  'business': 455,\n",
       "  'placards': 456,\n",
       "  'assembles': 457,\n",
       "  'gentleman': 458,\n",
       "  'long-sleeved': 459,\n",
       "  'body': 460,\n",
       "  'river': 461,\n",
       "  'barefooted': 462,\n",
       "  'olive': 463,\n",
       "  'shorts': 464,\n",
       "  'hotdogs': 465,\n",
       "  'grill': 466,\n",
       "  'propane': 467,\n",
       "  'plastic': 468,\n",
       "  'sausages': 469,\n",
       "  'surface': 470,\n",
       "  'covered': 471,\n",
       "  'field': 472,\n",
       "  'scooter': 473,\n",
       "  'those': 474,\n",
       "  'skis': 475,\n",
       "  'framed': 476,\n",
       "  'pictures': 477,\n",
       "  'skier': 478,\n",
       "  'trees': 479,\n",
       "  'artwork': 480,\n",
       "  'climbers': 481,\n",
       "  'seven': 482,\n",
       "  'climbing': 483,\n",
       "  'collage': 484,\n",
       "  'cliff': 485,\n",
       "  'gymnast': 486,\n",
       "  'balance': 487,\n",
       "  'beam': 488,\n",
       "  'leotard': 489,\n",
       "  'gymnastics': 490,\n",
       "  'audience': 491,\n",
       "  'supple': 492,\n",
       "  'wheeler': 493,\n",
       "  'pool': 494,\n",
       "  'atv': 495,\n",
       "  'rubber': 496,\n",
       "  'miniature': 497,\n",
       "  'lawn': 498,\n",
       "  'quad': 499,\n",
       "  'headscarf': 500,\n",
       "  'bay': 501,\n",
       "  'over': 502,\n",
       "  'scenic': 503,\n",
       "  'view': 504,\n",
       "  'binoculars': 505,\n",
       "  'pay': 506,\n",
       "  'mounted': 507,\n",
       "  'telescope': 508,\n",
       "  'windbreaker': 509,\n",
       "  'rooftop': 510,\n",
       "  'spaceship': 511,\n",
       "  'ticket': 512,\n",
       "  'plane': 513,\n",
       "  'airplane': 514,\n",
       "  'nose': 515,\n",
       "  'sprinkler': 516,\n",
       "  'garden': 517,\n",
       "  'hose': 518,\n",
       "  'daughter': 519,\n",
       "  'stroller': 520,\n",
       "  'thrown': 521,\n",
       "  'nearby': 522,\n",
       "  'mouth': 523,\n",
       "  'colored': 524,\n",
       "  'part': 525,\n",
       "  'booth': 526,\n",
       "  'restaurant': 527,\n",
       "  'sweater': 528,\n",
       "  'grassy': 529,\n",
       "  'hikers': 530,\n",
       "  'patch': 531,\n",
       "  'facial': 532,\n",
       "  'cabinet': 533,\n",
       "  'hutch': 534,\n",
       "  'doors': 535,\n",
       "  'long-sleeve': 536,\n",
       "  'middle-aged': 537,\n",
       "  'beard': 538,\n",
       "  'handmade': 539,\n",
       "  'creation': 540,\n",
       "  'floor': 541,\n",
       "  'father': 542,\n",
       "  'grown': 543,\n",
       "  'son': 544,\n",
       "  'camping': 545,\n",
       "  'living': 546,\n",
       "  'items': 547,\n",
       "  'bearded': 548,\n",
       "  'map': 549,\n",
       "  'traveler': 550,\n",
       "  'lake': 551,\n",
       "  'duck': 552,\n",
       "  'lone': 553,\n",
       "  'city': 554,\n",
       "  'skyline': 555,\n",
       "  'waters': 556,\n",
       "  'infant': 557,\n",
       "  'male': 558,\n",
       "  'pond': 559,\n",
       "  'side': 560,\n",
       "  'newborn': 561,\n",
       "  'shelter': 562,\n",
       "  'bicycles': 563,\n",
       "  'bikes': 564,\n",
       "  'curved': 565,\n",
       "  'roof': 566,\n",
       "  'tonight': 567,\n",
       "  'wagon': 568,\n",
       "  'dome': 569,\n",
       "  'station': 570,\n",
       "  'frolicks': 571,\n",
       "  'tags': 572,\n",
       "  'frozen': 573,\n",
       "  'ice': 574,\n",
       "  'hole': 575,\n",
       "  'soft': 576,\n",
       "  'sandy': 577,\n",
       "  'climber': 578,\n",
       "  'picks': 579,\n",
       "  'crampons': 580,\n",
       "  'waterfall': 581,\n",
       "  'ocean': 582,\n",
       "  'path': 583,\n",
       "  'attire': 584,\n",
       "  'shovels': 585,\n",
       "  'roads': 586,\n",
       "  'sidewalks': 587,\n",
       "  'slush': 588,\n",
       "  'wedding': 589,\n",
       "  'flowers': 590,\n",
       "  'wet': 591,\n",
       "  'item': 592,\n",
       "  'rows': 593,\n",
       "  'vegetables': 594,\n",
       "  'harvest': 595,\n",
       "  'vegetable': 596,\n",
       "  'blankets': 597,\n",
       "  'villagers': 598,\n",
       "  'crops': 599,\n",
       "  'onions': 600,\n",
       "  'very': 601,\n",
       "  'band': 602,\n",
       "  'singer': 603,\n",
       "  'tattoos': 604,\n",
       "  'microphone': 605,\n",
       "  'sign': 606,\n",
       "  '13': 607,\n",
       "  'lucky': 608,\n",
       "  'punk': 609,\n",
       "  'rocker': 610,\n",
       "  'blond-hair': 611,\n",
       "  'short': 612,\n",
       "  'striped': 613,\n",
       "  'skateboard': 614,\n",
       "  'this': 615,\n",
       "  'jackets': 616,\n",
       "  'life': 617,\n",
       "  'canoe': 618,\n",
       "  'kayak': 619,\n",
       "  'gentle': 620,\n",
       "  'big': 621,\n",
       "  'smile': 622,\n",
       "  'ladies': 623,\n",
       "  'site': 624,\n",
       "  'area': 625,\n",
       "  'light': 626,\n",
       "  'post': 627,\n",
       "  'younger': 628,\n",
       "  'luggage': 629,\n",
       "  'billboard': 630,\n",
       "  'suitcase': 631,\n",
       "  'prescription': 632,\n",
       "  'advertisement': 633,\n",
       "  'picture': 634,\n",
       "  'flags': 635,\n",
       "  'oriental': 636,\n",
       "  'outside': 637,\n",
       "  'waving': 638,\n",
       "  'cleaning': 639,\n",
       "  'fish': 640,\n",
       "  'cigarette': 641,\n",
       "  'match': 642,\n",
       "  'vendor': 643,\n",
       "  'sellers': 644,\n",
       "  'stock': 645,\n",
       "  'red-hair': 646,\n",
       "  'red-haired': 647,\n",
       "  'skirt': 648,\n",
       "  'tank': 649,\n",
       "  'college-aged': 650,\n",
       "  'individuals': 651,\n",
       "  'females': 652,\n",
       "  'concrete': 653,\n",
       "  'steps': 654,\n",
       "  'entrance': 655,\n",
       "  'outdoors': 656,\n",
       "  'multiple': 657,\n",
       "  'school': 658,\n",
       "  'snaps': 659,\n",
       "  'goal': 660,\n",
       "  'hockey': 661,\n",
       "  'stick': 662,\n",
       "  'right': 663,\n",
       "  'goalie': 664,\n",
       "  'rink': 665,\n",
       "  'backpack': 666,\n",
       "  'courtyard': 667,\n",
       "  'sculpture': 668,\n",
       "  'newspaper': 669,\n",
       "  'office': 670,\n",
       "  'statue': 671,\n",
       "  'toddler': 672,\n",
       "  'fenced': 673,\n",
       "  'patio': 674,\n",
       "  'bars': 675,\n",
       "  'me': 676,\n",
       "  'jail': 677,\n",
       "  'railings': 678,\n",
       "  'fence': 679,\n",
       "  'hill': 680,\n",
       "  'skyscraper': 681,\n",
       "  'matching': 682,\n",
       "  'turban': 683,\n",
       "  'african': 684,\n",
       "  'grocery': 685,\n",
       "  'stand': 686,\n",
       "  'fruits': 687,\n",
       "  'fruit': 688,\n",
       "  'produce': 689,\n",
       "  'band-aid': 690,\n",
       "  'plate': 691,\n",
       "  'blond-haired': 692,\n",
       "  'both': 693,\n",
       "  'treat': 694,\n",
       "  'pizza': 695,\n",
       "  'dish': 696,\n",
       "  'tin': 697,\n",
       "  'baked': 698,\n",
       "  'good': 699,\n",
       "  'wild': 700,\n",
       "  'center': 701,\n",
       "  'stage': 702,\n",
       "  'electric': 703,\n",
       "  'helmet': 704,\n",
       "  'bat': 705,\n",
       "  'tennis': 706,\n",
       "  'softball': 707,\n",
       "  'batter': 708,\n",
       "  'stickers': 709,\n",
       "  'long-haired': 710,\n",
       "  'musician': 711,\n",
       "  'artist': 712,\n",
       "  'black-colored': 713,\n",
       "  'dirty': 714,\n",
       "  'unfinished': 715,\n",
       "  'cement': 716,\n",
       "  'tape': 717,\n",
       "  'filler': 718,\n",
       "  'trench': 719,\n",
       "  'smoothing': 720,\n",
       "  'hooded': 721,\n",
       "  'dinner': 722,\n",
       "  'entrees': 723,\n",
       "  'martini': 724,\n",
       "  'dining': 725,\n",
       "  'fancy': 726,\n",
       "  'blanket': 727,\n",
       "  'cloudy': 728,\n",
       "  'solitary': 729,\n",
       "  'expression': 730,\n",
       "  'sad': 731,\n",
       "  'beans': 732,\n",
       "  'hilltop': 733,\n",
       "  'valley': 734,\n",
       "  'mountainside': 735,\n",
       "  'ledge': 736,\n",
       "  'moutains': 737,\n",
       "  'tourists': 738,\n",
       "  'walking': 739,\n",
       "  'footbridge': 740,\n",
       "  'tree-covered': 741,\n",
       "  'arched': 742,\n",
       "  'jersey': 743,\n",
       "  'rafts': 744,\n",
       "  'kayakers': 745,\n",
       "  'corn': 746,\n",
       "  'elder': 747,\n",
       "  'multiracial': 748,\n",
       "  'oboe': 749,\n",
       "  'purple': 750,\n",
       "  'percussion': 751,\n",
       "  'spectators': 752,\n",
       "  'bamboo': 753,\n",
       "  'bassoon': 754,\n",
       "  'wind': 755,\n",
       "  'bus': 756,\n",
       "  'material': 757,\n",
       "  'blank': 758,\n",
       "  'earphones': 759,\n",
       "  '30': 760,\n",
       "  'somethings': 761,\n",
       "  'bags': 762,\n",
       "  'shopping': 763,\n",
       "  'betty': 764,\n",
       "  'boop': 765,\n",
       "  'crosswalk': 766,\n",
       "  'numerous': 767,\n",
       "  'chinese': 768,\n",
       "  'six': 769,\n",
       "  'noddles': 770,\n",
       "  'asians': 771,\n",
       "  'assorted': 772,\n",
       "  'pineapples': 773,\n",
       "  'bananas': 774,\n",
       "  'papayas': 775,\n",
       "  'work': 776,\n",
       "  'shovel': 777,\n",
       "  'deep': 778,\n",
       "  'whole': 779,\n",
       "  'septic': 780,\n",
       "  '3': 781,\n",
       "  'american': 782,\n",
       "  'peers': 783,\n",
       "  'all': 784,\n",
       "  'bandanna': 785,\n",
       "  'graphic': 786,\n",
       "  'oblong': 787,\n",
       "  'smoke': 788,\n",
       "  'handkerchief': 789,\n",
       "  'tub': 790,\n",
       "  'steam': 791,\n",
       "  'vat': 792,\n",
       "  'pantaloons': 793,\n",
       "  'sleepy': 794,\n",
       "  'sleeping': 795,\n",
       "  'individual': 796,\n",
       "  'beads': 797,\n",
       "  'decorations': 798,\n",
       "  'native': 799,\n",
       "  'cobs': 800,\n",
       "  'necklaces': 801,\n",
       "  'shells': 802,\n",
       "  'member': 803,\n",
       "  'tribe': 804,\n",
       "  'tribal': 805,\n",
       "  'piercings': 806,\n",
       "  'lots': 807,\n",
       "  'jewelry': 808,\n",
       "  'samurai': 809,\n",
       "  'warrior': 810,\n",
       "  'full': 811,\n",
       "  'sword': 812,\n",
       "  'sheath': 813,\n",
       "  'training': 814,\n",
       "  'arts': 815,\n",
       "  'fighting': 816,\n",
       "  'gear': 817,\n",
       "  'wields': 818,\n",
       "  'hills': 819,\n",
       "  'rolling': 820,\n",
       "  'karate': 821,\n",
       "  'teens': 822,\n",
       "  'bed': 823,\n",
       "  'dried': 824,\n",
       "  'up': 825,\n",
       "  'rocks': 826,\n",
       "  'rocky': 827,\n",
       "  'walls': 828,\n",
       "  'dense': 829,\n",
       "  'forest': 830,\n",
       "  'riverbed': 831,\n",
       "  'creek': 832,\n",
       "  'cool': 833,\n",
       "  'scenery': 834,\n",
       "  'strewn': 835,\n",
       "  'stream': 836,\n",
       "  'badge': 837,\n",
       "  'guard': 838,\n",
       "  'white-haired': 839,\n",
       "  'colorful': 840,\n",
       "  'dresses': 841,\n",
       "  'indian': 842,\n",
       "  'saris': 843,\n",
       "  'separate': 844,\n",
       "  'flip-flops': 845,\n",
       "  'pair': 846,\n",
       "  'plants': 847,\n",
       "  'sandals': 848,\n",
       "  'phones': 849,\n",
       "  'shrubbery': 850,\n",
       "  'multicolored': 851,\n",
       "  'house': 852,\n",
       "  'home': 853,\n",
       "  'yard': 854,\n",
       "  'soccer': 855,\n",
       "  'backyard': 856,\n",
       "  'black-haired': 857,\n",
       "  'tile': 858,\n",
       "  'legos': 859,\n",
       "  'skateboarder': 860,\n",
       "  'board': 861,\n",
       "  'platform': 862,\n",
       "  'skateboarders': 863,\n",
       "  'teenager': 864,\n",
       "  'trolley': 865,\n",
       "  'mass': 866,\n",
       "  'transit': 867,\n",
       "  'talkie': 868,\n",
       "  'walkie': 869,\n",
       "  'family': 870,\n",
       "  'paddle': 871,\n",
       "  'splashes': 872,\n",
       "  'shallow': 873,\n",
       "  'surf': 874,\n",
       "  'sweaters': 875,\n",
       "  'khaki': 876,\n",
       "  'wine': 877,\n",
       "  'appetizers': 878,\n",
       "  'plates': 879,\n",
       "  'wineglasses': 880,\n",
       "  'rack': 881,\n",
       "  'elegant': 882,\n",
       "  'constructions': 883,\n",
       "  'seat': 884,\n",
       "  'steel': 885,\n",
       "  'i-beam': 886,\n",
       "  'mixer': 887,\n",
       "  'blender': 888,\n",
       "  'mud': 889,\n",
       "  'puddle': 890,\n",
       "  'pamphlet': 891,\n",
       "  'train': 892,\n",
       "  'book': 893,\n",
       "  'rides': 894,\n",
       "  'brochure': 895,\n",
       "  'ride': 896,\n",
       "  'magizine': 897,\n",
       "  'marathon': 898,\n",
       "  'joggers': 899,\n",
       "  'diving': 900,\n",
       "  'swimming': 901,\n",
       "  'high': 902,\n",
       "  'dive': 903,\n",
       "  'end': 904,\n",
       "  'light-colored': 905,\n",
       "  'only': 906,\n",
       "  'pale': 907,\n",
       "  'basin': 908,\n",
       "  'huge': 909,\n",
       "  'plaid': 910,\n",
       "  'about': 911,\n",
       "  'branches': 912,\n",
       "  'soldier': 913,\n",
       "  'belt': 914,\n",
       "  'pancake': 915,\n",
       "  'omelet': 916,\n",
       "  'skillet': 917,\n",
       "  'firefighters': 918,\n",
       "  'uniforms': 919,\n",
       "  'reflections': 920,\n",
       "  'firemen': 921,\n",
       "  'few': 922,\n",
       "  'firetruck': 923,\n",
       "  'firetrucks': 924,\n",
       "  'lights': 925,\n",
       "  'on-duty': 926,\n",
       "  'ceiling': 927,\n",
       "  'stripe': 928,\n",
       "  'yellow-and-black': 929,\n",
       "  'warning': 930,\n",
       "  'boots': 931,\n",
       "  'magazines': 932,\n",
       "  'candy': 933,\n",
       "  'coke-a-cola': 934,\n",
       "  'products': 935,\n",
       "  'counter': 936,\n",
       "  'magazine': 937,\n",
       "  'clerk': 938,\n",
       "  'newsstand': 939,\n",
       "  'merchandise': 940,\n",
       "  'earth': 941,\n",
       "  'moving': 942,\n",
       "  'track': 943,\n",
       "  'surveying': 944,\n",
       "  'dry': 945,\n",
       "  'jean': 946,\n",
       "  'fists': 947,\n",
       "  'dough': 948,\n",
       "  'bakery': 949,\n",
       "  'apprentice': 950,\n",
       "  'photo': 951,\n",
       "  'tired': 952,\n",
       "  'bread': 953,\n",
       "  'shade': 954,\n",
       "  'tropical': 955,\n",
       "  'trunks': 956,\n",
       "  'arms': 957,\n",
       "  'swim': 958,\n",
       "  'landscape': 959,\n",
       "  'hiker': 960,\n",
       "  'bluff': 961,\n",
       "  'mountains': 962,\n",
       "  'mountain': 963,\n",
       "  'snow-covered': 964,\n",
       "  'mountaintop': 965,\n",
       "  'mound': 966,\n",
       "  'hovel': 967,\n",
       "  'backhoe': 968,\n",
       "  'pile': 969,\n",
       "  'racing': 970,\n",
       "  'helmets': 971,\n",
       "  'puddles': 972,\n",
       "  'bicyclers': 973,\n",
       "  'wheels': 974,\n",
       "  'bikers': 975,\n",
       "  'riders': 976,\n",
       "  'middle': 977,\n",
       "  'cane': 978,\n",
       "  'bush': 979,\n",
       "  'short-sleeve': 980,\n",
       "  'surgeon': 981,\n",
       "  'scrubs': 982,\n",
       "  'teal': 983,\n",
       "  'doctor': 984,\n",
       "  'nurses': 985,\n",
       "  'staff': 986,\n",
       "  'surgical': 987,\n",
       "  'assistants': 988,\n",
       "  'team': 989,\n",
       "  'frisbee': 990,\n",
       "  'woolly': 991,\n",
       "  'doberman': 992,\n",
       "  'bowling': 993,\n",
       "  'lane': 994,\n",
       "  'pins': 995,\n",
       "  'balls': 996,\n",
       "  'cosmic': 997,\n",
       "  'imagery': 998,\n",
       "  'including': 999,\n",
       "  ...},\n",
       " 'id2token': {},\n",
       " 'dfs': {0: 1,\n",
       "  1: 1,\n",
       "  3: 19353,\n",
       "  4: 11942,\n",
       "  2: 601,\n",
       "  6: 45,\n",
       "  5: 1995,\n",
       "  8: 2776,\n",
       "  7: 1330,\n",
       "  9: 1322,\n",
       "  11: 11620,\n",
       "  10: 233,\n",
       "  13: 1110,\n",
       "  12: 81,\n",
       "  14: 8629,\n",
       "  15: 4470,\n",
       "  16: 839,\n",
       "  17: 214432,\n",
       "  18: 38854,\n",
       "  19: 10014,\n",
       "  20: 11839,\n",
       "  21: 364,\n",
       "  22: 1881,\n",
       "  23: 449,\n",
       "  24: 763,\n",
       "  25: 184,\n",
       "  26: 18,\n",
       "  27: 23,\n",
       "  28: 1015,\n",
       "  31: 643,\n",
       "  30: 20460,\n",
       "  29: 402,\n",
       "  32: 483,\n",
       "  33: 1972,\n",
       "  35: 381,\n",
       "  34: 296,\n",
       "  36: 5163,\n",
       "  37: 3988,\n",
       "  38: 9,\n",
       "  39: 4557,\n",
       "  41: 2555,\n",
       "  40: 1963,\n",
       "  42: 224,\n",
       "  43: 401,\n",
       "  44: 11746,\n",
       "  45: 8,\n",
       "  46: 40,\n",
       "  48: 4230,\n",
       "  47: 8601,\n",
       "  49: 34427,\n",
       "  50: 4901,\n",
       "  51: 16,\n",
       "  52: 887,\n",
       "  53: 626,\n",
       "  54: 3645,\n",
       "  55: 27,\n",
       "  56: 853,\n",
       "  57: 298,\n",
       "  58: 2436,\n",
       "  59: 1741,\n",
       "  60: 158,\n",
       "  61: 5034,\n",
       "  62: 1876,\n",
       "  63: 11030,\n",
       "  64: 83,\n",
       "  65: 1332,\n",
       "  66: 1363,\n",
       "  67: 202,\n",
       "  68: 15591,\n",
       "  69: 1816,\n",
       "  70: 2305,\n",
       "  71: 8939,\n",
       "  73: 1026,\n",
       "  72: 490,\n",
       "  75: 2315,\n",
       "  74: 1415,\n",
       "  76: 1192,\n",
       "  77: 1787,\n",
       "  78: 937,\n",
       "  81: 177,\n",
       "  79: 254,\n",
       "  80: 40,\n",
       "  82: 2,\n",
       "  83: 2,\n",
       "  84: 951,\n",
       "  85: 52,\n",
       "  86: 679,\n",
       "  88: 152,\n",
       "  87: 352,\n",
       "  89: 9,\n",
       "  90: 4224,\n",
       "  91: 438,\n",
       "  92: 64,\n",
       "  93: 15,\n",
       "  94: 506,\n",
       "  95: 16,\n",
       "  96: 20165,\n",
       "  97: 1961,\n",
       "  98: 1192,\n",
       "  99: 253,\n",
       "  100: 119,\n",
       "  101: 34,\n",
       "  102: 573,\n",
       "  103: 276,\n",
       "  104: 22,\n",
       "  105: 261,\n",
       "  106: 272,\n",
       "  107: 128,\n",
       "  108: 238,\n",
       "  109: 35,\n",
       "  110: 24,\n",
       "  111: 123,\n",
       "  112: 251,\n",
       "  115: 788,\n",
       "  113: 51,\n",
       "  114: 195,\n",
       "  116: 2291,\n",
       "  117: 248,\n",
       "  118: 123,\n",
       "  119: 105,\n",
       "  121: 1564,\n",
       "  120: 67,\n",
       "  122: 31,\n",
       "  123: 253,\n",
       "  124: 550,\n",
       "  125: 1935,\n",
       "  126: 120,\n",
       "  127: 41,\n",
       "  128: 189,\n",
       "  129: 8099,\n",
       "  130: 3951,\n",
       "  131: 27,\n",
       "  132: 10,\n",
       "  133: 1166,\n",
       "  136: 2080,\n",
       "  135: 231,\n",
       "  134: 4,\n",
       "  137: 128,\n",
       "  138: 44,\n",
       "  140: 99,\n",
       "  141: 346,\n",
       "  139: 674,\n",
       "  142: 107,\n",
       "  143: 29,\n",
       "  145: 25,\n",
       "  144: 16,\n",
       "  146: 129,\n",
       "  147: 118,\n",
       "  149: 2,\n",
       "  151: 25,\n",
       "  150: 2,\n",
       "  148: 897,\n",
       "  152: 2745,\n",
       "  153: 1025,\n",
       "  154: 208,\n",
       "  155: 103,\n",
       "  156: 23,\n",
       "  157: 2529,\n",
       "  158: 4853,\n",
       "  159: 361,\n",
       "  160: 7095,\n",
       "  161: 1061,\n",
       "  162: 1483,\n",
       "  163: 16,\n",
       "  164: 247,\n",
       "  165: 3,\n",
       "  166: 1870,\n",
       "  167: 4,\n",
       "  168: 5,\n",
       "  169: 2,\n",
       "  170: 3,\n",
       "  171: 3043,\n",
       "  172: 53,\n",
       "  173: 72,\n",
       "  174: 78,\n",
       "  175: 3140,\n",
       "  176: 1720,\n",
       "  177: 2,\n",
       "  178: 56,\n",
       "  179: 87,\n",
       "  180: 238,\n",
       "  181: 152,\n",
       "  182: 255,\n",
       "  183: 59,\n",
       "  184: 204,\n",
       "  185: 1547,\n",
       "  186: 5318,\n",
       "  187: 193,\n",
       "  188: 475,\n",
       "  189: 665,\n",
       "  190: 573,\n",
       "  191: 448,\n",
       "  192: 71,\n",
       "  195: 133,\n",
       "  194: 215,\n",
       "  193: 462,\n",
       "  196: 233,\n",
       "  198: 118,\n",
       "  197: 136,\n",
       "  199: 9,\n",
       "  200: 5,\n",
       "  201: 936,\n",
       "  203: 46,\n",
       "  202: 366,\n",
       "  204: 36,\n",
       "  206: 26,\n",
       "  205: 2,\n",
       "  207: 306,\n",
       "  208: 4008,\n",
       "  209: 21,\n",
       "  212: 2,\n",
       "  211: 19,\n",
       "  210: 460,\n",
       "  213: 5,\n",
       "  214: 1194,\n",
       "  215: 2549,\n",
       "  216: 32,\n",
       "  218: 13,\n",
       "  217: 336,\n",
       "  220: 180,\n",
       "  219: 176,\n",
       "  221: 632,\n",
       "  222: 3927,\n",
       "  223: 8383,\n",
       "  224: 21,\n",
       "  225: 820,\n",
       "  226: 10,\n",
       "  227: 10,\n",
       "  228: 394,\n",
       "  229: 1062,\n",
       "  230: 669,\n",
       "  231: 31,\n",
       "  232: 487,\n",
       "  233: 29,\n",
       "  234: 645,\n",
       "  235: 185,\n",
       "  236: 83,\n",
       "  237: 944,\n",
       "  238: 620,\n",
       "  239: 8808,\n",
       "  240: 1069,\n",
       "  241: 45,\n",
       "  242: 183,\n",
       "  243: 39,\n",
       "  244: 44,\n",
       "  245: 35,\n",
       "  246: 290,\n",
       "  247: 1880,\n",
       "  248: 67,\n",
       "  250: 156,\n",
       "  249: 33,\n",
       "  251: 592,\n",
       "  252: 13,\n",
       "  255: 371,\n",
       "  253: 239,\n",
       "  254: 27,\n",
       "  256: 191,\n",
       "  258: 3,\n",
       "  257: 270,\n",
       "  259: 1795,\n",
       "  260: 720,\n",
       "  261: 18,\n",
       "  262: 13,\n",
       "  263: 111,\n",
       "  264: 76,\n",
       "  265: 490,\n",
       "  266: 2,\n",
       "  267: 332,\n",
       "  268: 3,\n",
       "  269: 676,\n",
       "  270: 260,\n",
       "  271: 70,\n",
       "  273: 19,\n",
       "  272: 387,\n",
       "  275: 2,\n",
       "  274: 77,\n",
       "  276: 1437,\n",
       "  277: 3976,\n",
       "  278: 522,\n",
       "  279: 9,\n",
       "  280: 478,\n",
       "  281: 259,\n",
       "  282: 1102,\n",
       "  283: 950,\n",
       "  284: 235,\n",
       "  285: 40,\n",
       "  286: 3206,\n",
       "  287: 321,\n",
       "  288: 1,\n",
       "  289: 4,\n",
       "  290: 122,\n",
       "  291: 23,\n",
       "  292: 135,\n",
       "  293: 10,\n",
       "  295: 433,\n",
       "  294: 341,\n",
       "  296: 2422,\n",
       "  297: 371,\n",
       "  298: 1367,\n",
       "  299: 212,\n",
       "  300: 207,\n",
       "  301: 163,\n",
       "  303: 1,\n",
       "  302: 436,\n",
       "  304: 6,\n",
       "  305: 82,\n",
       "  306: 50,\n",
       "  307: 92,\n",
       "  308: 37,\n",
       "  309: 26,\n",
       "  310: 4,\n",
       "  311: 307,\n",
       "  312: 3,\n",
       "  313: 1719,\n",
       "  314: 2,\n",
       "  315: 158,\n",
       "  316: 1334,\n",
       "  317: 2172,\n",
       "  318: 318,\n",
       "  319: 213,\n",
       "  320: 68,\n",
       "  321: 372,\n",
       "  322: 120,\n",
       "  323: 309,\n",
       "  324: 52,\n",
       "  325: 22,\n",
       "  326: 1,\n",
       "  327: 110,\n",
       "  328: 792,\n",
       "  329: 2047,\n",
       "  330: 22,\n",
       "  331: 54,\n",
       "  332: 116,\n",
       "  333: 34,\n",
       "  334: 116,\n",
       "  335: 130,\n",
       "  336: 87,\n",
       "  337: 19,\n",
       "  339: 2,\n",
       "  338: 13,\n",
       "  340: 74,\n",
       "  341: 125,\n",
       "  343: 22,\n",
       "  342: 4,\n",
       "  344: 42,\n",
       "  345: 3,\n",
       "  346: 463,\n",
       "  347: 644,\n",
       "  348: 99,\n",
       "  350: 188,\n",
       "  349: 12,\n",
       "  351: 1491,\n",
       "  352: 42,\n",
       "  353: 1008,\n",
       "  354: 27,\n",
       "  355: 178,\n",
       "  356: 8,\n",
       "  357: 316,\n",
       "  359: 86,\n",
       "  358: 339,\n",
       "  360: 1450,\n",
       "  361: 139,\n",
       "  362: 2,\n",
       "  363: 6,\n",
       "  364: 64,\n",
       "  365: 68,\n",
       "  366: 58,\n",
       "  367: 10,\n",
       "  369: 1265,\n",
       "  368: 42,\n",
       "  370: 32,\n",
       "  372: 269,\n",
       "  371: 64,\n",
       "  374: 24,\n",
       "  373: 335,\n",
       "  375: 14,\n",
       "  377: 4,\n",
       "  376: 35,\n",
       "  378: 34,\n",
       "  379: 66,\n",
       "  380: 312,\n",
       "  383: 3,\n",
       "  382: 22,\n",
       "  381: 71,\n",
       "  384: 4,\n",
       "  385: 159,\n",
       "  386: 2,\n",
       "  387: 1,\n",
       "  388: 254,\n",
       "  389: 148,\n",
       "  390: 52,\n",
       "  391: 668,\n",
       "  392: 280,\n",
       "  394: 161,\n",
       "  393: 20,\n",
       "  397: 9,\n",
       "  396: 42,\n",
       "  395: 1358,\n",
       "  400: 9,\n",
       "  399: 4,\n",
       "  398: 8,\n",
       "  401: 33,\n",
       "  403: 149,\n",
       "  402: 462,\n",
       "  404: 31,\n",
       "  405: 550,\n",
       "  406: 112,\n",
       "  407: 4264,\n",
       "  408: 1394,\n",
       "  409: 223,\n",
       "  411: 297,\n",
       "  410: 1579,\n",
       "  412: 899,\n",
       "  413: 117,\n",
       "  414: 251,\n",
       "  415: 6,\n",
       "  417: 15,\n",
       "  416: 25,\n",
       "  418: 342,\n",
       "  419: 22,\n",
       "  420: 1143,\n",
       "  421: 158,\n",
       "  422: 250,\n",
       "  423: 47,\n",
       "  424: 9,\n",
       "  425: 11,\n",
       "  426: 76,\n",
       "  427: 64,\n",
       "  428: 17,\n",
       "  429: 130,\n",
       "  430: 436,\n",
       "  431: 296,\n",
       "  432: 143,\n",
       "  433: 13,\n",
       "  434: 122,\n",
       "  436: 19,\n",
       "  435: 139,\n",
       "  437: 82,\n",
       "  438: 450,\n",
       "  439: 335,\n",
       "  440: 28,\n",
       "  441: 593,\n",
       "  442: 1697,\n",
       "  443: 333,\n",
       "  444: 1296,\n",
       "  445: 179,\n",
       "  446: 1066,\n",
       "  447: 144,\n",
       "  448: 8,\n",
       "  449: 3,\n",
       "  450: 213,\n",
       "  451: 80,\n",
       "  452: 1290,\n",
       "  453: 133,\n",
       "  454: 49,\n",
       "  455: 176,\n",
       "  456: 3,\n",
       "  457: 2,\n",
       "  458: 360,\n",
       "  459: 127,\n",
       "  460: 556,\n",
       "  461: 515,\n",
       "  462: 29,\n",
       "  463: 31,\n",
       "  464: 1848,\n",
       "  465: 37,\n",
       "  467: 7,\n",
       "  466: 275,\n",
       "  468: 450,\n",
       "  469: 20,\n",
       "  470: 117,\n",
       "  471: 213,\n",
       "  472: 1653,\n",
       "  473: 216,\n",
       "  474: 13,\n",
       "  475: 102,\n",
       "  476: 31,\n",
       "  477: 135,\n",
       "  478: 262,\n",
       "  479: 781,\n",
       "  480: 74,\n",
       "  481: 34,\n",
       "  482: 153,\n",
       "  483: 61,\n",
       "  484: 4,\n",
       "  485: 229,\n",
       "  486: 142,\n",
       "  487: 46,\n",
       "  488: 106,\n",
       "  489: 52,\n",
       "  490: 23,\n",
       "  491: 348,\n",
       "  492: 1,\n",
       "  493: 32,\n",
       "  494: 1051,\n",
       "  495: 66,\n",
       "  496: 81,\n",
       "  497: 33,\n",
       "  498: 315,\n",
       "  499: 22,\n",
       "  500: 86,\n",
       "  502: 18,\n",
       "  503: 26,\n",
       "  504: 149,\n",
       "  501: 26,\n",
       "  506: 34,\n",
       "  505: 53,\n",
       "  507: 15,\n",
       "  508: 179,\n",
       "  509: 19,\n",
       "  510: 40,\n",
       "  511: 1,\n",
       "  512: 24,\n",
       "  513: 108,\n",
       "  514: 131,\n",
       "  515: 160,\n",
       "  516: 46,\n",
       "  517: 126,\n",
       "  518: 141,\n",
       "  519: 158,\n",
       "  520: 238,\n",
       "  521: 3,\n",
       "  522: 62,\n",
       "  523: 1124,\n",
       "  524: 632,\n",
       "  525: 70,\n",
       "  527: 304,\n",
       "  526: 152,\n",
       "  528: 741,\n",
       "  529: 440,\n",
       "  530: 116,\n",
       "  531: 50,\n",
       "  532: 40,\n",
       "  534: 1,\n",
       "  533: 21,\n",
       "  535: 75,\n",
       "  536: 88,\n",
       "  537: 323,\n",
       "  538: 417,\n",
       "  539: 14,\n",
       "  540: 8,\n",
       "  541: 792,\n",
       "  542: 231,\n",
       "  543: 15,\n",
       "  544: 220,\n",
       "  545: 24,\n",
       "  546: 34,\n",
       "  547: 250,\n",
       "  548: 267,\n",
       "  549: 96,\n",
       "  550: 9,\n",
       "  551: 559,\n",
       "  553: 159,\n",
       "  552: 63,\n",
       "  554: 785,\n",
       "  555: 32,\n",
       "  556: 88,\n",
       "  557: 149,\n",
       "  558: 1354,\n",
       "  559: 157,\n",
       "  560: 513,\n",
       "  561: 98,\n",
       "  562: 15,\n",
       "  563: 242,\n",
       "  564: 370,\n",
       "  565: 26,\n",
       "  566: 321,\n",
       "  567: 1,\n",
       "  568: 115,\n",
       "  569: 10,\n",
       "  570: 142,\n",
       "  572: 28,\n",
       "  571: 1,\n",
       "  573: 41,\n",
       "  574: 636,\n",
       "  575: 167,\n",
       "  576: 24,\n",
       "  577: 152,\n",
       "  578: 149,\n",
       "  579: 4,\n",
       "  580: 2,\n",
       "  581: 113,\n",
       "  582: 702,\n",
       "  583: 539,\n",
       "  584: 279,\n",
       "  585: 50,\n",
       "  586: 4,\n",
       "  587: 10,\n",
       "  588: 3,\n",
       "  589: 145,\n",
       "  590: 520,\n",
       "  591: 239,\n",
       "  592: 75,\n",
       "  593: 45,\n",
       "  594: 244,\n",
       "  596: 60,\n",
       "  595: 6,\n",
       "  597: 53,\n",
       "  598: 19,\n",
       "  599: 26,\n",
       "  601: 479,\n",
       "  600: 10,\n",
       "  602: 1029,\n",
       "  603: 182,\n",
       "  604: 103,\n",
       "  605: 1049,\n",
       "  606: 1075,\n",
       "  608: 2,\n",
       "  607: 18,\n",
       "  609: 19,\n",
       "  610: 12,\n",
       "  612: 371,\n",
       "  611: 339,\n",
       "  613: 1204,\n",
       "  614: 642,\n",
       "  615: 523,\n",
       "  617: 212,\n",
       "  616: 318,\n",
       "  618: 163,\n",
       "  619: 128,\n",
       "  620: 3,\n",
       "  621: 639,\n",
       "  622: 114,\n",
       "  623: 412,\n",
       "  624: 70,\n",
       "  625: 449,\n",
       "  626: 672,\n",
       "  627: 121,\n",
       "  628: 264,\n",
       "  629: 128,\n",
       "  630: 69,\n",
       "  631: 82,\n",
       "  632: 2,\n",
       "  633: 107,\n",
       "  634: 556,\n",
       "  635: 280,\n",
       "  636: 157,\n",
       "  637: 485,\n",
       "  638: 5,\n",
       "  639: 39,\n",
       "  640: 331,\n",
       "  641: 373,\n",
       "  642: 21,\n",
       "  643: 284,\n",
       "  644: 2,\n",
       "  645: 8,\n",
       "  646: 167,\n",
       "  647: 111,\n",
       "  648: 520,\n",
       "  649: 642,\n",
       "  650: 5,\n",
       "  651: 184,\n",
       "  652: 156,\n",
       "  653: 403,\n",
       "  654: 462,\n",
       "  655: 77,\n",
       "  656: 129,\n",
       "  657: 141,\n",
       "  658: 217,\n",
       "  659: 2,\n",
       "  661: 384,\n",
       "  660: 134,\n",
       "  662: 628,\n",
       "  663: 237,\n",
       "  664: 133,\n",
       "  665: 53,\n",
       "  666: 565,\n",
       "  667: 43,\n",
       "  668: 175,\n",
       "  669: 323,\n",
       "  670: 76,\n",
       "  671: 357,\n",
       "  672: 585,\n",
       "  673: 58,\n",
       "  674: 64,\n",
       "  675: 90,\n",
       "  676: 12,\n",
       "  677: 1,\n",
       "  678: 24,\n",
       "  679: 754,\n",
       "  680: 483,\n",
       "  681: 13,\n",
       "  682: 95,\n",
       "  683: 57,\n",
       "  684: 488,\n",
       "  685: 115,\n",
       "  686: 362,\n",
       "  687: 83,\n",
       "  688: 290,\n",
       "  689: 142,\n",
       "  690: 1,\n",
       "  691: 193,\n",
       "  692: 165,\n",
       "  693: 142,\n",
       "  694: 30,\n",
       "  695: 80,\n",
       "  697: 13,\n",
       "  696: 67,\n",
       "  698: 27,\n",
       "  699: 32,\n",
       "  700: 35,\n",
       "  701: 57,\n",
       "  702: 660,\n",
       "  703: 244,\n",
       "  704: 1051,\n",
       "  705: 156,\n",
       "  706: 801,\n",
       "  707: 77,\n",
       "  708: 56,\n",
       "  709: 7,\n",
       "  710: 105,\n",
       "  711: 179,\n",
       "  712: 215,\n",
       "  713: 2,\n",
       "  714: 163,\n",
       "  715: 21,\n",
       "  716: 238,\n",
       "  717: 57,\n",
       "  718: 1,\n",
       "  719: 49,\n",
       "  720: 2,\n",
       "  721: 150,\n",
       "  722: 104,\n",
       "  723: 1,\n",
       "  724: 10,\n",
       "  725: 35,\n",
       "  726: 61,\n",
       "  727: 278,\n",
       "  728: 42,\n",
       "  729: 15,\n",
       "  731: 22,\n",
       "  730: 37,\n",
       "  732: 18,\n",
       "  733: 5,\n",
       "  734: 29,\n",
       "  735: 22,\n",
       "  736: 215,\n",
       "  737: 1,\n",
       "  738: 111,\n",
       "  739: 59,\n",
       "  740: 15,\n",
       "  741: 1,\n",
       "  742: 14,\n",
       "  743: 371,\n",
       "  744: 21,\n",
       "  745: 18,\n",
       "  746: 67,\n",
       "  747: 30,\n",
       "  748: 1,\n",
       "  749: 6,\n",
       "  750: 1153,\n",
       "  751: 13,\n",
       "  752: 298,\n",
       "  753: 48,\n",
       "  754: 1,\n",
       "  755: 26,\n",
       "  756: 103,\n",
       "  757: 65,\n",
       "  758: 11,\n",
       "  759: 36,\n",
       "  760: 7,\n",
       "  761: 1,\n",
       "  763: 332,\n",
       "  762: 434,\n",
       "  764: 2,\n",
       "  765: 2,\n",
       "  766: 119,\n",
       "  767: 55,\n",
       "  768: 206,\n",
       "  769: 363,\n",
       "  770: 1,\n",
       "  771: 50,\n",
       "  772: 18,\n",
       "  773: 11,\n",
       "  774: 39,\n",
       "  775: 1,\n",
       "  776: 219,\n",
       "  777: 183,\n",
       "  778: 83,\n",
       "  779: 24,\n",
       "  780: 1,\n",
       "  781: 274,\n",
       "  782: 521,\n",
       "  783: 16,\n",
       "  784: 635,\n",
       "  785: 143,\n",
       "  786: 19,\n",
       "  787: 3,\n",
       "  788: 85,\n",
       "  789: 13,\n",
       "  790: 96,\n",
       "  791: 26,\n",
       "  792: 6,\n",
       "  793: 1,\n",
       "  794: 7,\n",
       "  795: 89,\n",
       "  796: 108,\n",
       "  797: 47,\n",
       "  798: 38,\n",
       "  799: 106,\n",
       "  800: 1,\n",
       "  801: 32,\n",
       "  802: 9,\n",
       "  803: 105,\n",
       "  804: 13,\n",
       "  805: 34,\n",
       "  806: 11,\n",
       "  807: 141,\n",
       "  808: 84,\n",
       "  809: 3,\n",
       "  810: 10,\n",
       "  811: 249,\n",
       "  812: 62,\n",
       "  813: 1,\n",
       "  814: 22,\n",
       "  815: 125,\n",
       "  816: 3,\n",
       "  817: 487,\n",
       "  818: 1,\n",
       "  820: 35,\n",
       "  819: 40,\n",
       "  821: 88,\n",
       "  822: 48,\n",
       "  824: 16,\n",
       "  825: 67,\n",
       "  823: 377,\n",
       "  826: 499,\n",
       "  827: 235,\n",
       "  828: 121,\n",
       "  829: 3,\n",
       "  830: 162,\n",
       "  831: 2,\n",
       "  832: 57,\n",
       "  833: 15,\n",
       "  834: 15,\n",
       "  835: 4,\n",
       "  836: 141,\n",
       "  837: 13,\n",
       "  838: 111,\n",
       "  839: 43,\n",
       "  840: 823,\n",
       "  841: 288,\n",
       "  842: 284,\n",
       "  843: 18,\n",
       "  844: 22,\n",
       "  846: 165,\n",
       "  845: 85,\n",
       "  847: 147,\n",
       "  848: 210,\n",
       "  849: 24,\n",
       "  850: 13,\n",
       "  851: 178,\n",
       "  852: 408,\n",
       "  853: 112,\n",
       "  854: 192,\n",
       "  855: 1324,\n",
       "  856: 60,\n",
       "  857: 49,\n",
       "  858: 77,\n",
       "  859: 19,\n",
       "  860: 387,\n",
       "  861: 494,\n",
       "  862: 189,\n",
       "  863: 26,\n",
       "  864: 106,\n",
       "  865: 48,\n",
       "  866: 11,\n",
       "  867: 13,\n",
       "  869: 8,\n",
       "  868: 8,\n",
       "  870: 506,\n",
       "  871: 63,\n",
       "  872: 10,\n",
       "  873: 152,\n",
       "  874: 88,\n",
       "  875: 34,\n",
       "  876: 166,\n",
       "  877: 116,\n",
       "  878: 1,\n",
       "  879: 86,\n",
       "  880: 21,\n",
       "  881: 48,\n",
       "  882: 13,\n",
       "  883: 10,\n",
       "  884: 167,\n",
       "  885: 73,\n",
       "  886: 2,\n",
       "  887: 32,\n",
       "  888: 3,\n",
       "  889: 155,\n",
       "  890: 111,\n",
       "  892: 224,\n",
       "  891: 11,\n",
       "  893: 670,\n",
       "  894: 8,\n",
       "  895: 11,\n",
       "  896: 223,\n",
       "  897: 1,\n",
       "  898: 59,\n",
       "  899: 17,\n",
       "  900: 81,\n",
       "  901: 351,\n",
       "  902: 259,\n",
       "  903: 30,\n",
       "  904: 106,\n",
       "  905: 9,\n",
       "  906: 88,\n",
       "  907: 63,\n",
       "  908: 9,\n",
       "  909: 195,\n",
       "  910: 468,\n",
       "  911: 31,\n",
       "  912: 56,\n",
       "  913: 124,\n",
       "  914: 127,\n",
       "  915: 19,\n",
       "  916: 2,\n",
       "  917: 15,\n",
       "  918: 100,\n",
       "  919: 627,\n",
       "  920: 8,\n",
       "  921: 80,\n",
       "  922: 328,\n",
       "  923: 106,\n",
       "  924: 10,\n",
       "  925: 183,\n",
       "  926: 1,\n",
       "  927: 57,\n",
       "  929: 2,\n",
       "  928: 56,\n",
       "  930: 6,\n",
       "  931: 418,\n",
       "  932: 37,\n",
       "  933: 102,\n",
       "  934: 1,\n",
       "  935: 51,\n",
       "  936: 266,\n",
       "  937: 95,\n",
       "  939: 13,\n",
       "  938: 12,\n",
       "  940: 46,\n",
       "  941: 16,\n",
       "  942: 32,\n",
       "  943: 484,\n",
       "  944: 2,\n",
       "  945: 57,\n",
       "  946: 153,\n",
       "  947: 14,\n",
       "  948: 50,\n",
       "  949: 16,\n",
       "  950: 1,\n",
       "  951: 138,\n",
       "  952: 21,\n",
       "  953: 114,\n",
       "  954: 64,\n",
       "  955: 30,\n",
       "  956: 220,\n",
       "  957: 666,\n",
       "  958: 185,\n",
       "  959: 66,\n",
       "  960: 132,\n",
       "  961: 4,\n",
       "  962: 292,\n",
       "  964: 59,\n",
       "  963: 672,\n",
       "  965: 23,\n",
       "  966: 96,\n",
       "  967: 1,\n",
       "  968: 16,\n",
       "  969: 279,\n",
       "  970: 142,\n",
       "  971: 248,\n",
       "  972: 13,\n",
       "  973: 11,\n",
       "  974: 73,\n",
       "  975: 109,\n",
       "  976: 127,\n",
       "  977: 296,\n",
       "  978: 163,\n",
       "  979: 44,\n",
       "  980: 30,\n",
       "  981: 17,\n",
       "  983: 94,\n",
       "  982: 50,\n",
       "  984: 79,\n",
       "  985: 29,\n",
       "  987: 31,\n",
       "  986: 37,\n",
       "  988: 2,\n",
       "  989: 860,\n",
       "  990: 411,\n",
       "  991: 1,\n",
       "  992: 17,\n",
       "  993: 172,\n",
       "  994: 102,\n",
       "  995: 63,\n",
       "  997: 1,\n",
       "  998: 3,\n",
       "  999: 1,\n",
       "  996: 186,\n",
       "  ...},\n",
       " 'num_docs': 413629,\n",
       " 'num_pos': 978824,\n",
       " 'num_nnz': 976849}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_en = pd.read_csv(train_triple_filepath_en)\n",
    "corpus_list_en = train_df_en[\"entity_content\"].values.tolist()\n",
    "corpus_list_en = ['EMPTYWORDTOKEN', 'UNKNOWNWORD'] + corpus_list_en  # 'EMPTYWORDTOKEN' is the token for empty word. It is needed because the input data for word embedding layer require padding. \n",
    "if cfg.STEMMING:\n",
    "    corpus_en = [[stemmer.stem(w) for w in word_tokenize(q)] for q in corpus_list_en]\n",
    "else: \n",
    "    corpus_en = [[w.lower() for w in word_tokenize(q)] for q in corpus_list_en]\n",
    "# corpus is a list of list of string\n",
    "\n",
    "training_corpus_dct_en = gensim.corpora.Dictionary(corpus_en)\n",
    "training_corpus_dct_en.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14384"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_corpus_dct_en.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 1,\n",
       " 3: 19353,\n",
       " 4: 11942,\n",
       " 2: 601,\n",
       " 6: 45,\n",
       " 5: 1995,\n",
       " 8: 2776,\n",
       " 7: 1330,\n",
       " 9: 1322,\n",
       " 11: 11620,\n",
       " 10: 233,\n",
       " 13: 1110,\n",
       " 12: 81,\n",
       " 14: 8629,\n",
       " 15: 4470,\n",
       " 16: 839,\n",
       " 17: 214432,\n",
       " 18: 38854,\n",
       " 19: 10014,\n",
       " 20: 11839,\n",
       " 21: 364,\n",
       " 22: 1881,\n",
       " 23: 449,\n",
       " 24: 763,\n",
       " 25: 184,\n",
       " 26: 18,\n",
       " 27: 23,\n",
       " 28: 1015,\n",
       " 31: 643,\n",
       " 30: 20460,\n",
       " 29: 402,\n",
       " 32: 483,\n",
       " 33: 1972,\n",
       " 35: 381,\n",
       " 34: 296,\n",
       " 36: 5163,\n",
       " 37: 3988,\n",
       " 38: 9,\n",
       " 39: 4557,\n",
       " 41: 2555,\n",
       " 40: 1963,\n",
       " 42: 224,\n",
       " 43: 401,\n",
       " 44: 11746,\n",
       " 45: 8,\n",
       " 46: 40,\n",
       " 48: 4230,\n",
       " 47: 8601,\n",
       " 49: 34427,\n",
       " 50: 4901,\n",
       " 51: 16,\n",
       " 52: 887,\n",
       " 53: 626,\n",
       " 54: 3645,\n",
       " 55: 27,\n",
       " 56: 853,\n",
       " 57: 298,\n",
       " 58: 2436,\n",
       " 59: 1741,\n",
       " 60: 158,\n",
       " 61: 5034,\n",
       " 62: 1876,\n",
       " 63: 11030,\n",
       " 64: 83,\n",
       " 65: 1332,\n",
       " 66: 1363,\n",
       " 67: 202,\n",
       " 68: 15591,\n",
       " 69: 1816,\n",
       " 70: 2305,\n",
       " 71: 8939,\n",
       " 73: 1026,\n",
       " 72: 490,\n",
       " 75: 2315,\n",
       " 74: 1415,\n",
       " 76: 1192,\n",
       " 77: 1787,\n",
       " 78: 937,\n",
       " 81: 177,\n",
       " 79: 254,\n",
       " 80: 40,\n",
       " 82: 2,\n",
       " 83: 2,\n",
       " 84: 951,\n",
       " 85: 52,\n",
       " 86: 679,\n",
       " 88: 152,\n",
       " 87: 352,\n",
       " 89: 9,\n",
       " 90: 4224,\n",
       " 91: 438,\n",
       " 92: 64,\n",
       " 93: 15,\n",
       " 94: 506,\n",
       " 95: 16,\n",
       " 96: 20165,\n",
       " 97: 1961,\n",
       " 98: 1192,\n",
       " 99: 253,\n",
       " 100: 119,\n",
       " 101: 34,\n",
       " 102: 573,\n",
       " 103: 276,\n",
       " 104: 22,\n",
       " 105: 261,\n",
       " 106: 272,\n",
       " 107: 128,\n",
       " 108: 238,\n",
       " 109: 35,\n",
       " 110: 24,\n",
       " 111: 123,\n",
       " 112: 251,\n",
       " 115: 788,\n",
       " 113: 51,\n",
       " 114: 195,\n",
       " 116: 2291,\n",
       " 117: 248,\n",
       " 118: 123,\n",
       " 119: 105,\n",
       " 121: 1564,\n",
       " 120: 67,\n",
       " 122: 31,\n",
       " 123: 253,\n",
       " 124: 550,\n",
       " 125: 1935,\n",
       " 126: 120,\n",
       " 127: 41,\n",
       " 128: 189,\n",
       " 129: 8099,\n",
       " 130: 3951,\n",
       " 131: 27,\n",
       " 132: 10,\n",
       " 133: 1166,\n",
       " 136: 2080,\n",
       " 135: 231,\n",
       " 134: 4,\n",
       " 137: 128,\n",
       " 138: 44,\n",
       " 140: 99,\n",
       " 141: 346,\n",
       " 139: 674,\n",
       " 142: 107,\n",
       " 143: 29,\n",
       " 145: 25,\n",
       " 144: 16,\n",
       " 146: 129,\n",
       " 147: 118,\n",
       " 149: 2,\n",
       " 151: 25,\n",
       " 150: 2,\n",
       " 148: 897,\n",
       " 152: 2745,\n",
       " 153: 1025,\n",
       " 154: 208,\n",
       " 155: 103,\n",
       " 156: 23,\n",
       " 157: 2529,\n",
       " 158: 4853,\n",
       " 159: 361,\n",
       " 160: 7095,\n",
       " 161: 1061,\n",
       " 162: 1483,\n",
       " 163: 16,\n",
       " 164: 247,\n",
       " 165: 3,\n",
       " 166: 1870,\n",
       " 167: 4,\n",
       " 168: 5,\n",
       " 169: 2,\n",
       " 170: 3,\n",
       " 171: 3043,\n",
       " 172: 53,\n",
       " 173: 72,\n",
       " 174: 78,\n",
       " 175: 3140,\n",
       " 176: 1720,\n",
       " 177: 2,\n",
       " 178: 56,\n",
       " 179: 87,\n",
       " 180: 238,\n",
       " 181: 152,\n",
       " 182: 255,\n",
       " 183: 59,\n",
       " 184: 204,\n",
       " 185: 1547,\n",
       " 186: 5318,\n",
       " 187: 193,\n",
       " 188: 475,\n",
       " 189: 665,\n",
       " 190: 573,\n",
       " 191: 448,\n",
       " 192: 71,\n",
       " 195: 133,\n",
       " 194: 215,\n",
       " 193: 462,\n",
       " 196: 233,\n",
       " 198: 118,\n",
       " 197: 136,\n",
       " 199: 9,\n",
       " 200: 5,\n",
       " 201: 936,\n",
       " 203: 46,\n",
       " 202: 366,\n",
       " 204: 36,\n",
       " 206: 26,\n",
       " 205: 2,\n",
       " 207: 306,\n",
       " 208: 4008,\n",
       " 209: 21,\n",
       " 212: 2,\n",
       " 211: 19,\n",
       " 210: 460,\n",
       " 213: 5,\n",
       " 214: 1194,\n",
       " 215: 2549,\n",
       " 216: 32,\n",
       " 218: 13,\n",
       " 217: 336,\n",
       " 220: 180,\n",
       " 219: 176,\n",
       " 221: 632,\n",
       " 222: 3927,\n",
       " 223: 8383,\n",
       " 224: 21,\n",
       " 225: 820,\n",
       " 226: 10,\n",
       " 227: 10,\n",
       " 228: 394,\n",
       " 229: 1062,\n",
       " 230: 669,\n",
       " 231: 31,\n",
       " 232: 487,\n",
       " 233: 29,\n",
       " 234: 645,\n",
       " 235: 185,\n",
       " 236: 83,\n",
       " 237: 944,\n",
       " 238: 620,\n",
       " 239: 8808,\n",
       " 240: 1069,\n",
       " 241: 45,\n",
       " 242: 183,\n",
       " 243: 39,\n",
       " 244: 44,\n",
       " 245: 35,\n",
       " 246: 290,\n",
       " 247: 1880,\n",
       " 248: 67,\n",
       " 250: 156,\n",
       " 249: 33,\n",
       " 251: 592,\n",
       " 252: 13,\n",
       " 255: 371,\n",
       " 253: 239,\n",
       " 254: 27,\n",
       " 256: 191,\n",
       " 258: 3,\n",
       " 257: 270,\n",
       " 259: 1795,\n",
       " 260: 720,\n",
       " 261: 18,\n",
       " 262: 13,\n",
       " 263: 111,\n",
       " 264: 76,\n",
       " 265: 490,\n",
       " 266: 2,\n",
       " 267: 332,\n",
       " 268: 3,\n",
       " 269: 676,\n",
       " 270: 260,\n",
       " 271: 70,\n",
       " 273: 19,\n",
       " 272: 387,\n",
       " 275: 2,\n",
       " 274: 77,\n",
       " 276: 1437,\n",
       " 277: 3976,\n",
       " 278: 522,\n",
       " 279: 9,\n",
       " 280: 478,\n",
       " 281: 259,\n",
       " 282: 1102,\n",
       " 283: 950,\n",
       " 284: 235,\n",
       " 285: 40,\n",
       " 286: 3206,\n",
       " 287: 321,\n",
       " 288: 1,\n",
       " 289: 4,\n",
       " 290: 122,\n",
       " 291: 23,\n",
       " 292: 135,\n",
       " 293: 10,\n",
       " 295: 433,\n",
       " 294: 341,\n",
       " 296: 2422,\n",
       " 297: 371,\n",
       " 298: 1367,\n",
       " 299: 212,\n",
       " 300: 207,\n",
       " 301: 163,\n",
       " 303: 1,\n",
       " 302: 436,\n",
       " 304: 6,\n",
       " 305: 82,\n",
       " 306: 50,\n",
       " 307: 92,\n",
       " 308: 37,\n",
       " 309: 26,\n",
       " 310: 4,\n",
       " 311: 307,\n",
       " 312: 3,\n",
       " 313: 1719,\n",
       " 314: 2,\n",
       " 315: 158,\n",
       " 316: 1334,\n",
       " 317: 2172,\n",
       " 318: 318,\n",
       " 319: 213,\n",
       " 320: 68,\n",
       " 321: 372,\n",
       " 322: 120,\n",
       " 323: 309,\n",
       " 324: 52,\n",
       " 325: 22,\n",
       " 326: 1,\n",
       " 327: 110,\n",
       " 328: 792,\n",
       " 329: 2047,\n",
       " 330: 22,\n",
       " 331: 54,\n",
       " 332: 116,\n",
       " 333: 34,\n",
       " 334: 116,\n",
       " 335: 130,\n",
       " 336: 87,\n",
       " 337: 19,\n",
       " 339: 2,\n",
       " 338: 13,\n",
       " 340: 74,\n",
       " 341: 125,\n",
       " 343: 22,\n",
       " 342: 4,\n",
       " 344: 42,\n",
       " 345: 3,\n",
       " 346: 463,\n",
       " 347: 644,\n",
       " 348: 99,\n",
       " 350: 188,\n",
       " 349: 12,\n",
       " 351: 1491,\n",
       " 352: 42,\n",
       " 353: 1008,\n",
       " 354: 27,\n",
       " 355: 178,\n",
       " 356: 8,\n",
       " 357: 316,\n",
       " 359: 86,\n",
       " 358: 339,\n",
       " 360: 1450,\n",
       " 361: 139,\n",
       " 362: 2,\n",
       " 363: 6,\n",
       " 364: 64,\n",
       " 365: 68,\n",
       " 366: 58,\n",
       " 367: 10,\n",
       " 369: 1265,\n",
       " 368: 42,\n",
       " 370: 32,\n",
       " 372: 269,\n",
       " 371: 64,\n",
       " 374: 24,\n",
       " 373: 335,\n",
       " 375: 14,\n",
       " 377: 4,\n",
       " 376: 35,\n",
       " 378: 34,\n",
       " 379: 66,\n",
       " 380: 312,\n",
       " 383: 3,\n",
       " 382: 22,\n",
       " 381: 71,\n",
       " 384: 4,\n",
       " 385: 159,\n",
       " 386: 2,\n",
       " 387: 1,\n",
       " 388: 254,\n",
       " 389: 148,\n",
       " 390: 52,\n",
       " 391: 668,\n",
       " 392: 280,\n",
       " 394: 161,\n",
       " 393: 20,\n",
       " 397: 9,\n",
       " 396: 42,\n",
       " 395: 1358,\n",
       " 400: 9,\n",
       " 399: 4,\n",
       " 398: 8,\n",
       " 401: 33,\n",
       " 403: 149,\n",
       " 402: 462,\n",
       " 404: 31,\n",
       " 405: 550,\n",
       " 406: 112,\n",
       " 407: 4264,\n",
       " 408: 1394,\n",
       " 409: 223,\n",
       " 411: 297,\n",
       " 410: 1579,\n",
       " 412: 899,\n",
       " 413: 117,\n",
       " 414: 251,\n",
       " 415: 6,\n",
       " 417: 15,\n",
       " 416: 25,\n",
       " 418: 342,\n",
       " 419: 22,\n",
       " 420: 1143,\n",
       " 421: 158,\n",
       " 422: 250,\n",
       " 423: 47,\n",
       " 424: 9,\n",
       " 425: 11,\n",
       " 426: 76,\n",
       " 427: 64,\n",
       " 428: 17,\n",
       " 429: 130,\n",
       " 430: 436,\n",
       " 431: 296,\n",
       " 432: 143,\n",
       " 433: 13,\n",
       " 434: 122,\n",
       " 436: 19,\n",
       " 435: 139,\n",
       " 437: 82,\n",
       " 438: 450,\n",
       " 439: 335,\n",
       " 440: 28,\n",
       " 441: 593,\n",
       " 442: 1697,\n",
       " 443: 333,\n",
       " 444: 1296,\n",
       " 445: 179,\n",
       " 446: 1066,\n",
       " 447: 144,\n",
       " 448: 8,\n",
       " 449: 3,\n",
       " 450: 213,\n",
       " 451: 80,\n",
       " 452: 1290,\n",
       " 453: 133,\n",
       " 454: 49,\n",
       " 455: 176,\n",
       " 456: 3,\n",
       " 457: 2,\n",
       " 458: 360,\n",
       " 459: 127,\n",
       " 460: 556,\n",
       " 461: 515,\n",
       " 462: 29,\n",
       " 463: 31,\n",
       " 464: 1848,\n",
       " 465: 37,\n",
       " 467: 7,\n",
       " 466: 275,\n",
       " 468: 450,\n",
       " 469: 20,\n",
       " 470: 117,\n",
       " 471: 213,\n",
       " 472: 1653,\n",
       " 473: 216,\n",
       " 474: 13,\n",
       " 475: 102,\n",
       " 476: 31,\n",
       " 477: 135,\n",
       " 478: 262,\n",
       " 479: 781,\n",
       " 480: 74,\n",
       " 481: 34,\n",
       " 482: 153,\n",
       " 483: 61,\n",
       " 484: 4,\n",
       " 485: 229,\n",
       " 486: 142,\n",
       " 487: 46,\n",
       " 488: 106,\n",
       " 489: 52,\n",
       " 490: 23,\n",
       " 491: 348,\n",
       " 492: 1,\n",
       " 493: 32,\n",
       " 494: 1051,\n",
       " 495: 66,\n",
       " 496: 81,\n",
       " 497: 33,\n",
       " 498: 315,\n",
       " 499: 22,\n",
       " 500: 86,\n",
       " 502: 18,\n",
       " 503: 26,\n",
       " 504: 149,\n",
       " 501: 26,\n",
       " 506: 34,\n",
       " 505: 53,\n",
       " 507: 15,\n",
       " 508: 179,\n",
       " 509: 19,\n",
       " 510: 40,\n",
       " 511: 1,\n",
       " 512: 24,\n",
       " 513: 108,\n",
       " 514: 131,\n",
       " 515: 160,\n",
       " 516: 46,\n",
       " 517: 126,\n",
       " 518: 141,\n",
       " 519: 158,\n",
       " 520: 238,\n",
       " 521: 3,\n",
       " 522: 62,\n",
       " 523: 1124,\n",
       " 524: 632,\n",
       " 525: 70,\n",
       " 527: 304,\n",
       " 526: 152,\n",
       " 528: 741,\n",
       " 529: 440,\n",
       " 530: 116,\n",
       " 531: 50,\n",
       " 532: 40,\n",
       " 534: 1,\n",
       " 533: 21,\n",
       " 535: 75,\n",
       " 536: 88,\n",
       " 537: 323,\n",
       " 538: 417,\n",
       " 539: 14,\n",
       " 540: 8,\n",
       " 541: 792,\n",
       " 542: 231,\n",
       " 543: 15,\n",
       " 544: 220,\n",
       " 545: 24,\n",
       " 546: 34,\n",
       " 547: 250,\n",
       " 548: 267,\n",
       " 549: 96,\n",
       " 550: 9,\n",
       " 551: 559,\n",
       " 553: 159,\n",
       " 552: 63,\n",
       " 554: 785,\n",
       " 555: 32,\n",
       " 556: 88,\n",
       " 557: 149,\n",
       " 558: 1354,\n",
       " 559: 157,\n",
       " 560: 513,\n",
       " 561: 98,\n",
       " 562: 15,\n",
       " 563: 242,\n",
       " 564: 370,\n",
       " 565: 26,\n",
       " 566: 321,\n",
       " 567: 1,\n",
       " 568: 115,\n",
       " 569: 10,\n",
       " 570: 142,\n",
       " 572: 28,\n",
       " 571: 1,\n",
       " 573: 41,\n",
       " 574: 636,\n",
       " 575: 167,\n",
       " 576: 24,\n",
       " 577: 152,\n",
       " 578: 149,\n",
       " 579: 4,\n",
       " 580: 2,\n",
       " 581: 113,\n",
       " 582: 702,\n",
       " 583: 539,\n",
       " 584: 279,\n",
       " 585: 50,\n",
       " 586: 4,\n",
       " 587: 10,\n",
       " 588: 3,\n",
       " 589: 145,\n",
       " 590: 520,\n",
       " 591: 239,\n",
       " 592: 75,\n",
       " 593: 45,\n",
       " 594: 244,\n",
       " 596: 60,\n",
       " 595: 6,\n",
       " 597: 53,\n",
       " 598: 19,\n",
       " 599: 26,\n",
       " 601: 479,\n",
       " 600: 10,\n",
       " 602: 1029,\n",
       " 603: 182,\n",
       " 604: 103,\n",
       " 605: 1049,\n",
       " 606: 1075,\n",
       " 608: 2,\n",
       " 607: 18,\n",
       " 609: 19,\n",
       " 610: 12,\n",
       " 612: 371,\n",
       " 611: 339,\n",
       " 613: 1204,\n",
       " 614: 642,\n",
       " 615: 523,\n",
       " 617: 212,\n",
       " 616: 318,\n",
       " 618: 163,\n",
       " 619: 128,\n",
       " 620: 3,\n",
       " 621: 639,\n",
       " 622: 114,\n",
       " 623: 412,\n",
       " 624: 70,\n",
       " 625: 449,\n",
       " 626: 672,\n",
       " 627: 121,\n",
       " 628: 264,\n",
       " 629: 128,\n",
       " 630: 69,\n",
       " 631: 82,\n",
       " 632: 2,\n",
       " 633: 107,\n",
       " 634: 556,\n",
       " 635: 280,\n",
       " 636: 157,\n",
       " 637: 485,\n",
       " 638: 5,\n",
       " 639: 39,\n",
       " 640: 331,\n",
       " 641: 373,\n",
       " 642: 21,\n",
       " 643: 284,\n",
       " 644: 2,\n",
       " 645: 8,\n",
       " 646: 167,\n",
       " 647: 111,\n",
       " 648: 520,\n",
       " 649: 642,\n",
       " 650: 5,\n",
       " 651: 184,\n",
       " 652: 156,\n",
       " 653: 403,\n",
       " 654: 462,\n",
       " 655: 77,\n",
       " 656: 129,\n",
       " 657: 141,\n",
       " 658: 217,\n",
       " 659: 2,\n",
       " 661: 384,\n",
       " 660: 134,\n",
       " 662: 628,\n",
       " 663: 237,\n",
       " 664: 133,\n",
       " 665: 53,\n",
       " 666: 565,\n",
       " 667: 43,\n",
       " 668: 175,\n",
       " 669: 323,\n",
       " 670: 76,\n",
       " 671: 357,\n",
       " 672: 585,\n",
       " 673: 58,\n",
       " 674: 64,\n",
       " 675: 90,\n",
       " 676: 12,\n",
       " 677: 1,\n",
       " 678: 24,\n",
       " 679: 754,\n",
       " 680: 483,\n",
       " 681: 13,\n",
       " 682: 95,\n",
       " 683: 57,\n",
       " 684: 488,\n",
       " 685: 115,\n",
       " 686: 362,\n",
       " 687: 83,\n",
       " 688: 290,\n",
       " 689: 142,\n",
       " 690: 1,\n",
       " 691: 193,\n",
       " 692: 165,\n",
       " 693: 142,\n",
       " 694: 30,\n",
       " 695: 80,\n",
       " 697: 13,\n",
       " 696: 67,\n",
       " 698: 27,\n",
       " 699: 32,\n",
       " 700: 35,\n",
       " 701: 57,\n",
       " 702: 660,\n",
       " 703: 244,\n",
       " 704: 1051,\n",
       " 705: 156,\n",
       " 706: 801,\n",
       " 707: 77,\n",
       " 708: 56,\n",
       " 709: 7,\n",
       " 710: 105,\n",
       " 711: 179,\n",
       " 712: 215,\n",
       " 713: 2,\n",
       " 714: 163,\n",
       " 715: 21,\n",
       " 716: 238,\n",
       " 717: 57,\n",
       " 718: 1,\n",
       " 719: 49,\n",
       " 720: 2,\n",
       " 721: 150,\n",
       " 722: 104,\n",
       " 723: 1,\n",
       " 724: 10,\n",
       " 725: 35,\n",
       " 726: 61,\n",
       " 727: 278,\n",
       " 728: 42,\n",
       " 729: 15,\n",
       " 731: 22,\n",
       " 730: 37,\n",
       " 732: 18,\n",
       " 733: 5,\n",
       " 734: 29,\n",
       " 735: 22,\n",
       " 736: 215,\n",
       " 737: 1,\n",
       " 738: 111,\n",
       " 739: 59,\n",
       " 740: 15,\n",
       " 741: 1,\n",
       " 742: 14,\n",
       " 743: 371,\n",
       " 744: 21,\n",
       " 745: 18,\n",
       " 746: 67,\n",
       " 747: 30,\n",
       " 748: 1,\n",
       " 749: 6,\n",
       " 750: 1153,\n",
       " 751: 13,\n",
       " 752: 298,\n",
       " 753: 48,\n",
       " 754: 1,\n",
       " 755: 26,\n",
       " 756: 103,\n",
       " 757: 65,\n",
       " 758: 11,\n",
       " 759: 36,\n",
       " 760: 7,\n",
       " 761: 1,\n",
       " 763: 332,\n",
       " 762: 434,\n",
       " 764: 2,\n",
       " 765: 2,\n",
       " 766: 119,\n",
       " 767: 55,\n",
       " 768: 206,\n",
       " 769: 363,\n",
       " 770: 1,\n",
       " 771: 50,\n",
       " 772: 18,\n",
       " 773: 11,\n",
       " 774: 39,\n",
       " 775: 1,\n",
       " 776: 219,\n",
       " 777: 183,\n",
       " 778: 83,\n",
       " 779: 24,\n",
       " 780: 1,\n",
       " 781: 274,\n",
       " 782: 521,\n",
       " 783: 16,\n",
       " 784: 635,\n",
       " 785: 143,\n",
       " 786: 19,\n",
       " 787: 3,\n",
       " 788: 85,\n",
       " 789: 13,\n",
       " 790: 96,\n",
       " 791: 26,\n",
       " 792: 6,\n",
       " 793: 1,\n",
       " 794: 7,\n",
       " 795: 89,\n",
       " 796: 108,\n",
       " 797: 47,\n",
       " 798: 38,\n",
       " 799: 106,\n",
       " 800: 1,\n",
       " 801: 32,\n",
       " 802: 9,\n",
       " 803: 105,\n",
       " 804: 13,\n",
       " 805: 34,\n",
       " 806: 11,\n",
       " 807: 141,\n",
       " 808: 84,\n",
       " 809: 3,\n",
       " 810: 10,\n",
       " 811: 249,\n",
       " 812: 62,\n",
       " 813: 1,\n",
       " 814: 22,\n",
       " 815: 125,\n",
       " 816: 3,\n",
       " 817: 487,\n",
       " 818: 1,\n",
       " 820: 35,\n",
       " 819: 40,\n",
       " 821: 88,\n",
       " 822: 48,\n",
       " 824: 16,\n",
       " 825: 67,\n",
       " 823: 377,\n",
       " 826: 499,\n",
       " 827: 235,\n",
       " 828: 121,\n",
       " 829: 3,\n",
       " 830: 162,\n",
       " 831: 2,\n",
       " 832: 57,\n",
       " 833: 15,\n",
       " 834: 15,\n",
       " 835: 4,\n",
       " 836: 141,\n",
       " 837: 13,\n",
       " 838: 111,\n",
       " 839: 43,\n",
       " 840: 823,\n",
       " 841: 288,\n",
       " 842: 284,\n",
       " 843: 18,\n",
       " 844: 22,\n",
       " 846: 165,\n",
       " 845: 85,\n",
       " 847: 147,\n",
       " 848: 210,\n",
       " 849: 24,\n",
       " 850: 13,\n",
       " 851: 178,\n",
       " 852: 408,\n",
       " 853: 112,\n",
       " 854: 192,\n",
       " 855: 1324,\n",
       " 856: 60,\n",
       " 857: 49,\n",
       " 858: 77,\n",
       " 859: 19,\n",
       " 860: 387,\n",
       " 861: 494,\n",
       " 862: 189,\n",
       " 863: 26,\n",
       " 864: 106,\n",
       " 865: 48,\n",
       " 866: 11,\n",
       " 867: 13,\n",
       " 869: 8,\n",
       " 868: 8,\n",
       " 870: 506,\n",
       " 871: 63,\n",
       " 872: 10,\n",
       " 873: 152,\n",
       " 874: 88,\n",
       " 875: 34,\n",
       " 876: 166,\n",
       " 877: 116,\n",
       " 878: 1,\n",
       " 879: 86,\n",
       " 880: 21,\n",
       " 881: 48,\n",
       " 882: 13,\n",
       " 883: 10,\n",
       " 884: 167,\n",
       " 885: 73,\n",
       " 886: 2,\n",
       " 887: 32,\n",
       " 888: 3,\n",
       " 889: 155,\n",
       " 890: 111,\n",
       " 892: 224,\n",
       " 891: 11,\n",
       " 893: 670,\n",
       " 894: 8,\n",
       " 895: 11,\n",
       " 896: 223,\n",
       " 897: 1,\n",
       " 898: 59,\n",
       " 899: 17,\n",
       " 900: 81,\n",
       " 901: 351,\n",
       " 902: 259,\n",
       " 903: 30,\n",
       " 904: 106,\n",
       " 905: 9,\n",
       " 906: 88,\n",
       " 907: 63,\n",
       " 908: 9,\n",
       " 909: 195,\n",
       " 910: 468,\n",
       " 911: 31,\n",
       " 912: 56,\n",
       " 913: 124,\n",
       " 914: 127,\n",
       " 915: 19,\n",
       " 916: 2,\n",
       " 917: 15,\n",
       " 918: 100,\n",
       " 919: 627,\n",
       " 920: 8,\n",
       " 921: 80,\n",
       " 922: 328,\n",
       " 923: 106,\n",
       " 924: 10,\n",
       " 925: 183,\n",
       " 926: 1,\n",
       " 927: 57,\n",
       " 929: 2,\n",
       " 928: 56,\n",
       " 930: 6,\n",
       " 931: 418,\n",
       " 932: 37,\n",
       " 933: 102,\n",
       " 934: 1,\n",
       " 935: 51,\n",
       " 936: 266,\n",
       " 937: 95,\n",
       " 939: 13,\n",
       " 938: 12,\n",
       " 940: 46,\n",
       " 941: 16,\n",
       " 942: 32,\n",
       " 943: 484,\n",
       " 944: 2,\n",
       " 945: 57,\n",
       " 946: 153,\n",
       " 947: 14,\n",
       " 948: 50,\n",
       " 949: 16,\n",
       " 950: 1,\n",
       " 951: 138,\n",
       " 952: 21,\n",
       " 953: 114,\n",
       " 954: 64,\n",
       " 955: 30,\n",
       " 956: 220,\n",
       " 957: 666,\n",
       " 958: 185,\n",
       " 959: 66,\n",
       " 960: 132,\n",
       " 961: 4,\n",
       " 962: 292,\n",
       " 964: 59,\n",
       " 963: 672,\n",
       " 965: 23,\n",
       " 966: 96,\n",
       " 967: 1,\n",
       " 968: 16,\n",
       " 969: 279,\n",
       " 970: 142,\n",
       " 971: 248,\n",
       " 972: 13,\n",
       " 973: 11,\n",
       " 974: 73,\n",
       " 975: 109,\n",
       " 976: 127,\n",
       " 977: 296,\n",
       " 978: 163,\n",
       " 979: 44,\n",
       " 980: 30,\n",
       " 981: 17,\n",
       " 983: 94,\n",
       " 982: 50,\n",
       " 984: 79,\n",
       " 985: 29,\n",
       " 987: 31,\n",
       " 986: 37,\n",
       " 988: 2,\n",
       " 989: 860,\n",
       " 990: 411,\n",
       " 991: 1,\n",
       " 992: 17,\n",
       " 993: 172,\n",
       " 994: 102,\n",
       " 995: 63,\n",
       " 997: 1,\n",
       " 998: 3,\n",
       " 999: 1,\n",
       " 996: 186,\n",
       " ...}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus_dct_en.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to test some different strategies to handle words. Normally it is not needed to be run\n",
    "train_df_en2 = pd.read_csv(train_triple_filepath_en)\n",
    "corpus_list_en2 = train_df_en2[\"entity_content\"].values.tolist()\n",
    "corpus_list_en2 = ['EMPTYWORDTOKEN', 'UNKNOWNWORD'] + corpus_list_en2  # 'EMPTYWORDTOKEN' is the token for empty word. It is needed because the input data for word embedding layer require padding. \n",
    "if cfg.STEMMING:\n",
    "    corpus_en = [[stemmer.stem(w) for w in word_tokenize(q)] for q in corpus_list_en]\n",
    "else: \n",
    "    corpus_en2 = [[w.lower() for w in word_tokenize(q, language=\"english\")] for q in corpus_list_en2]\n",
    "# corpus is a list of list of string\n",
    "\n",
    "training_corpus_dct_en2 = gensim.corpora.Dictionary(corpus_en2)\n",
    "training_corpus_dct_en2.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_dct_en.token2id == training_corpus_dct_en2.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_list_sorted_by_freq(dict_index_freq):\n",
    "    freq_list = [(k, v) for k, v in dict_index_freq.items()]\n",
    "    freq_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    return freq_list # Return: a list of tuple. meaning: (index_of_word, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_list_fr = vocab_list_sorted_by_freq(training_corpus_dct.dfs)\n",
    "freq_list_en = vocab_list_sorted_by_freq(training_corpus_dct_en.dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17, 214432),\n",
       " (18, 38854),\n",
       " (49, 34427),\n",
       " (30, 20460),\n",
       " (96, 20165),\n",
       " (3, 19353),\n",
       " (68, 15591),\n",
       " (4, 11942),\n",
       " (20, 11839),\n",
       " (44, 11746),\n",
       " (11, 11620),\n",
       " (63, 11030),\n",
       " (19, 10014),\n",
       " (71, 8939),\n",
       " (239, 8808),\n",
       " (14, 8629),\n",
       " (47, 8601),\n",
       " (223, 8383),\n",
       " (129, 8099),\n",
       " (160, 7095),\n",
       " (186, 5318),\n",
       " (36, 5163),\n",
       " (61, 5034),\n",
       " (50, 4901),\n",
       " (158, 4853),\n",
       " (39, 4557),\n",
       " (15, 4470),\n",
       " (407, 4264),\n",
       " (48, 4230),\n",
       " (90, 4224),\n",
       " (208, 4008),\n",
       " (37, 3988),\n",
       " (277, 3976),\n",
       " (130, 3951),\n",
       " (222, 3927),\n",
       " (54, 3645),\n",
       " (286, 3206),\n",
       " (175, 3140),\n",
       " (171, 3043),\n",
       " (8, 2776),\n",
       " (152, 2745),\n",
       " (41, 2555),\n",
       " (215, 2549),\n",
       " (157, 2529),\n",
       " (58, 2436),\n",
       " (296, 2422),\n",
       " (75, 2315),\n",
       " (70, 2305),\n",
       " (116, 2291),\n",
       " (317, 2172),\n",
       " (136, 2080),\n",
       " (1337, 2074),\n",
       " (329, 2047),\n",
       " (5, 1995),\n",
       " (33, 1972),\n",
       " (40, 1963),\n",
       " (97, 1961),\n",
       " (125, 1935),\n",
       " (22, 1881),\n",
       " (247, 1880),\n",
       " (62, 1876),\n",
       " (166, 1870),\n",
       " (464, 1848),\n",
       " (69, 1816),\n",
       " (259, 1795),\n",
       " (77, 1787),\n",
       " (59, 1741),\n",
       " (176, 1720),\n",
       " (313, 1719),\n",
       " (442, 1697),\n",
       " (472, 1653),\n",
       " (410, 1579),\n",
       " (121, 1564),\n",
       " (185, 1547),\n",
       " (351, 1491),\n",
       " (162, 1483),\n",
       " (360, 1450),\n",
       " (276, 1437),\n",
       " (74, 1415),\n",
       " (408, 1394),\n",
       " (298, 1367),\n",
       " (66, 1363),\n",
       " (395, 1358),\n",
       " (558, 1354),\n",
       " (316, 1334),\n",
       " (65, 1332),\n",
       " (7, 1330),\n",
       " (855, 1324),\n",
       " (9, 1322),\n",
       " (444, 1296),\n",
       " (452, 1290),\n",
       " (369, 1265),\n",
       " (613, 1204),\n",
       " (214, 1194),\n",
       " (76, 1192),\n",
       " (98, 1192),\n",
       " (133, 1166),\n",
       " (750, 1153),\n",
       " (420, 1143),\n",
       " (523, 1124),\n",
       " (13, 1110),\n",
       " (282, 1102),\n",
       " (606, 1075),\n",
       " (240, 1069),\n",
       " (446, 1066),\n",
       " (229, 1062),\n",
       " (161, 1061),\n",
       " (494, 1051),\n",
       " (704, 1051),\n",
       " (605, 1049),\n",
       " (1006, 1048),\n",
       " (602, 1029),\n",
       " (73, 1026),\n",
       " (153, 1025),\n",
       " (28, 1015),\n",
       " (353, 1008),\n",
       " (84, 951),\n",
       " (283, 950),\n",
       " (237, 944),\n",
       " (78, 937),\n",
       " (201, 936),\n",
       " (412, 899),\n",
       " (148, 897),\n",
       " (52, 887),\n",
       " (1496, 882),\n",
       " (1350, 873),\n",
       " (989, 860),\n",
       " (56, 853),\n",
       " (16, 839),\n",
       " (840, 823),\n",
       " (225, 820),\n",
       " (706, 801),\n",
       " (328, 792),\n",
       " (541, 792),\n",
       " (115, 788),\n",
       " (554, 785),\n",
       " (479, 781),\n",
       " (24, 763),\n",
       " (679, 754),\n",
       " (528, 741),\n",
       " (3316, 740),\n",
       " (260, 720),\n",
       " (1228, 708),\n",
       " (582, 702),\n",
       " (1894, 688),\n",
       " (86, 679),\n",
       " (269, 676),\n",
       " (139, 674),\n",
       " (626, 672),\n",
       " (963, 672),\n",
       " (893, 670),\n",
       " (230, 669),\n",
       " (391, 668),\n",
       " (1053, 667),\n",
       " (957, 666),\n",
       " (189, 665),\n",
       " (702, 660),\n",
       " (234, 645),\n",
       " (347, 644),\n",
       " (31, 643),\n",
       " (614, 642),\n",
       " (649, 642),\n",
       " (621, 639),\n",
       " (1356, 638),\n",
       " (574, 636),\n",
       " (784, 635),\n",
       " (221, 632),\n",
       " (524, 632),\n",
       " (662, 628),\n",
       " (919, 627),\n",
       " (53, 626),\n",
       " (238, 620),\n",
       " (2, 601),\n",
       " (1349, 598),\n",
       " (441, 593),\n",
       " (251, 592),\n",
       " (672, 585),\n",
       " (102, 573),\n",
       " (190, 573),\n",
       " (666, 565),\n",
       " (551, 559),\n",
       " (460, 556),\n",
       " (634, 556),\n",
       " (124, 550),\n",
       " (405, 550),\n",
       " (1395, 545),\n",
       " (583, 539),\n",
       " (615, 523),\n",
       " (278, 522),\n",
       " (782, 521),\n",
       " (590, 520),\n",
       " (648, 520),\n",
       " (461, 515),\n",
       " (560, 513),\n",
       " (94, 506),\n",
       " (870, 506),\n",
       " (826, 499),\n",
       " (1043, 498),\n",
       " (861, 494),\n",
       " (1653, 491),\n",
       " (72, 490),\n",
       " (265, 490),\n",
       " (684, 488),\n",
       " (232, 487),\n",
       " (817, 487),\n",
       " (637, 485),\n",
       " (943, 484),\n",
       " (32, 483),\n",
       " (680, 483),\n",
       " (601, 479),\n",
       " (280, 478),\n",
       " (2331, 478),\n",
       " (188, 475),\n",
       " (910, 468),\n",
       " (346, 463),\n",
       " (193, 462),\n",
       " (402, 462),\n",
       " (654, 462),\n",
       " (210, 460),\n",
       " (438, 450),\n",
       " (468, 450),\n",
       " (23, 449),\n",
       " (625, 449),\n",
       " (191, 448),\n",
       " (1077, 448),\n",
       " (1498, 445),\n",
       " (529, 440),\n",
       " (91, 438),\n",
       " (302, 436),\n",
       " (430, 436),\n",
       " (762, 434),\n",
       " (295, 433),\n",
       " (1368, 428),\n",
       " (1008, 424),\n",
       " (931, 418),\n",
       " (538, 417),\n",
       " (623, 412),\n",
       " (990, 411),\n",
       " (852, 408),\n",
       " (653, 403),\n",
       " (29, 402),\n",
       " (43, 401),\n",
       " (1242, 396),\n",
       " (1827, 395),\n",
       " (228, 394),\n",
       " (1899, 389),\n",
       " (272, 387),\n",
       " (860, 387),\n",
       " (1590, 385),\n",
       " (661, 384),\n",
       " (1030, 384),\n",
       " (35, 381),\n",
       " (823, 377),\n",
       " (2556, 374),\n",
       " (641, 373),\n",
       " (321, 372),\n",
       " (255, 371),\n",
       " (297, 371),\n",
       " (612, 371),\n",
       " (743, 371),\n",
       " (564, 370),\n",
       " (1079, 369),\n",
       " (202, 366),\n",
       " (21, 364),\n",
       " (769, 363),\n",
       " (686, 362),\n",
       " (159, 361),\n",
       " (458, 360),\n",
       " (671, 357),\n",
       " (1166, 356),\n",
       " (87, 352),\n",
       " (901, 351),\n",
       " (1045, 349),\n",
       " (1405, 349),\n",
       " (491, 348),\n",
       " (1400, 347),\n",
       " (141, 346),\n",
       " (418, 342),\n",
       " (294, 341),\n",
       " (358, 339),\n",
       " (611, 339),\n",
       " (217, 336),\n",
       " (373, 335),\n",
       " (439, 335),\n",
       " (443, 333),\n",
       " (267, 332),\n",
       " (763, 332),\n",
       " (640, 331),\n",
       " (1379, 330),\n",
       " (922, 328),\n",
       " (1183, 327),\n",
       " (3142, 327),\n",
       " (537, 323),\n",
       " (669, 323),\n",
       " (1027, 322),\n",
       " (287, 321),\n",
       " (566, 321),\n",
       " (1555, 321),\n",
       " (3520, 319),\n",
       " (318, 318),\n",
       " (616, 318),\n",
       " (1600, 317),\n",
       " (357, 316),\n",
       " (498, 315),\n",
       " (1864, 315),\n",
       " (380, 312),\n",
       " (1255, 311),\n",
       " (1144, 310),\n",
       " (323, 309),\n",
       " (311, 307),\n",
       " (207, 306),\n",
       " (1018, 306),\n",
       " (527, 304),\n",
       " (1457, 300),\n",
       " (2405, 299),\n",
       " (57, 298),\n",
       " (752, 298),\n",
       " (411, 297),\n",
       " (1116, 297),\n",
       " (34, 296),\n",
       " (431, 296),\n",
       " (977, 296),\n",
       " (1427, 295),\n",
       " (1328, 294),\n",
       " (962, 292),\n",
       " (246, 290),\n",
       " (688, 290),\n",
       " (1375, 290),\n",
       " (3907, 289),\n",
       " (841, 288),\n",
       " (643, 284),\n",
       " (842, 284),\n",
       " (1035, 284),\n",
       " (1900, 283),\n",
       " (392, 280),\n",
       " (635, 280),\n",
       " (584, 279),\n",
       " (969, 279),\n",
       " (727, 278),\n",
       " (1610, 278),\n",
       " (103, 276),\n",
       " (1112, 276),\n",
       " (466, 275),\n",
       " (1110, 275),\n",
       " (781, 274),\n",
       " (106, 272),\n",
       " (257, 270),\n",
       " (372, 269),\n",
       " (2091, 268),\n",
       " (548, 267),\n",
       " (1750, 267),\n",
       " (936, 266),\n",
       " (628, 264),\n",
       " (478, 262),\n",
       " (105, 261),\n",
       " (1467, 261),\n",
       " (270, 260),\n",
       " (281, 259),\n",
       " (902, 259),\n",
       " (182, 255),\n",
       " (79, 254),\n",
       " (388, 254),\n",
       " (1858, 254),\n",
       " (99, 253),\n",
       " (123, 253),\n",
       " (112, 251),\n",
       " (414, 251),\n",
       " (422, 250),\n",
       " (547, 250),\n",
       " (1293, 250),\n",
       " (811, 249),\n",
       " (117, 248),\n",
       " (971, 248),\n",
       " (164, 247),\n",
       " (1264, 246),\n",
       " (594, 244),\n",
       " (703, 244),\n",
       " (1252, 244),\n",
       " (1740, 244),\n",
       " (563, 242),\n",
       " (1058, 241),\n",
       " (253, 239),\n",
       " (591, 239),\n",
       " (2329, 239),\n",
       " (108, 238),\n",
       " (180, 238),\n",
       " (520, 238),\n",
       " (716, 238),\n",
       " (663, 237),\n",
       " (284, 235),\n",
       " (827, 235),\n",
       " (1040, 235),\n",
       " (1319, 235),\n",
       " (1888, 234),\n",
       " (1995, 234),\n",
       " (10, 233),\n",
       " (196, 233),\n",
       " (135, 231),\n",
       " (542, 231),\n",
       " (1016, 231),\n",
       " (1764, 230),\n",
       " (3729, 230),\n",
       " (485, 229),\n",
       " (3790, 229),\n",
       " (1013, 227),\n",
       " (2130, 226),\n",
       " (1718, 225),\n",
       " (42, 224),\n",
       " (892, 224),\n",
       " (409, 223),\n",
       " (896, 223),\n",
       " (1921, 222),\n",
       " (544, 220),\n",
       " (956, 220),\n",
       " (776, 219),\n",
       " (658, 217),\n",
       " (473, 216),\n",
       " (194, 215),\n",
       " (712, 215),\n",
       " (736, 215),\n",
       " (1033, 215),\n",
       " (1012, 214),\n",
       " (319, 213),\n",
       " (450, 213),\n",
       " (471, 213),\n",
       " (299, 212),\n",
       " (617, 212),\n",
       " (848, 210),\n",
       " (154, 208),\n",
       " (300, 207),\n",
       " (768, 206),\n",
       " (1181, 206),\n",
       " (2259, 205),\n",
       " (184, 204),\n",
       " (2506, 203),\n",
       " (67, 202),\n",
       " (1274, 201),\n",
       " (1878, 200),\n",
       " (1933, 200),\n",
       " (1861, 199),\n",
       " (1876, 197),\n",
       " (1378, 196),\n",
       " (114, 195),\n",
       " (909, 195),\n",
       " (2189, 194),\n",
       " (2251, 194),\n",
       " (187, 193),\n",
       " (691, 193),\n",
       " (854, 192),\n",
       " (2134, 192),\n",
       " (2546, 192),\n",
       " (256, 191),\n",
       " (1551, 191),\n",
       " (2751, 191),\n",
       " (1047, 190),\n",
       " (128, 189),\n",
       " (862, 189),\n",
       " (350, 188),\n",
       " (1275, 188),\n",
       " (996, 186),\n",
       " (1042, 186),\n",
       " (1390, 186),\n",
       " (235, 185),\n",
       " (958, 185),\n",
       " (2449, 185),\n",
       " (25, 184),\n",
       " (651, 184),\n",
       " (1327, 184),\n",
       " (242, 183),\n",
       " (777, 183),\n",
       " (925, 183),\n",
       " (1339, 183),\n",
       " (603, 182),\n",
       " (220, 180),\n",
       " (1175, 180),\n",
       " (445, 179),\n",
       " (508, 179),\n",
       " (711, 179),\n",
       " (1075, 179),\n",
       " (355, 178),\n",
       " (851, 178),\n",
       " (1232, 178),\n",
       " (81, 177),\n",
       " (2261, 177),\n",
       " (3187, 177),\n",
       " (219, 176),\n",
       " (455, 176),\n",
       " (1132, 176),\n",
       " (1724, 176),\n",
       " (668, 175),\n",
       " (1170, 174),\n",
       " (1613, 174),\n",
       " (993, 172),\n",
       " (1579, 172),\n",
       " (2505, 172),\n",
       " (1584, 171),\n",
       " (1198, 170),\n",
       " (1201, 170),\n",
       " (1544, 170),\n",
       " (1637, 170),\n",
       " (2262, 169),\n",
       " (575, 167),\n",
       " (646, 167),\n",
       " (884, 167),\n",
       " (1015, 167),\n",
       " (876, 166),\n",
       " (1182, 166),\n",
       " (692, 165),\n",
       " (846, 165),\n",
       " (1049, 165),\n",
       " (1440, 165),\n",
       " (301, 163),\n",
       " (618, 163),\n",
       " (714, 163),\n",
       " (978, 163),\n",
       " (1685, 163),\n",
       " (830, 162),\n",
       " (2018, 162),\n",
       " (2173, 162),\n",
       " (394, 161),\n",
       " (1565, 161),\n",
       " (1703, 161),\n",
       " (2571, 161),\n",
       " (515, 160),\n",
       " (385, 159),\n",
       " (553, 159),\n",
       " (2542, 159),\n",
       " (60, 158),\n",
       " (315, 158),\n",
       " (421, 158),\n",
       " (519, 158),\n",
       " (559, 157),\n",
       " (636, 157),\n",
       " (1096, 157),\n",
       " (3374, 157),\n",
       " (250, 156),\n",
       " (652, 156),\n",
       " (705, 156),\n",
       " (1303, 156),\n",
       " (1385, 156),\n",
       " (1656, 156),\n",
       " (889, 155),\n",
       " (3231, 155),\n",
       " (3282, 155),\n",
       " (482, 153),\n",
       " (946, 153),\n",
       " (88, 152),\n",
       " (181, 152),\n",
       " (526, 152),\n",
       " (577, 152),\n",
       " (873, 152),\n",
       " (1063, 152),\n",
       " (1626, 151),\n",
       " (721, 150),\n",
       " (1329, 150),\n",
       " (403, 149),\n",
       " (504, 149),\n",
       " (557, 149),\n",
       " (578, 149),\n",
       " (1044, 149),\n",
       " (1844, 149),\n",
       " (2763, 149),\n",
       " (389, 148),\n",
       " (1289, 148),\n",
       " (847, 147),\n",
       " (589, 145),\n",
       " (447, 144),\n",
       " (1473, 144),\n",
       " (2095, 144),\n",
       " (432, 143),\n",
       " (785, 143),\n",
       " (1793, 143),\n",
       " (1898, 143),\n",
       " (486, 142),\n",
       " (570, 142),\n",
       " (689, 142),\n",
       " (693, 142),\n",
       " (970, 142),\n",
       " (2417, 142),\n",
       " (518, 141),\n",
       " (657, 141),\n",
       " (807, 141),\n",
       " (836, 141),\n",
       " (1216, 141),\n",
       " (2613, 141),\n",
       " (1218, 140),\n",
       " (361, 139),\n",
       " (435, 139),\n",
       " (951, 138),\n",
       " (2177, 138),\n",
       " (4104, 138),\n",
       " (1072, 137),\n",
       " (1747, 137),\n",
       " (2728, 137),\n",
       " (197, 136),\n",
       " (292, 135),\n",
       " (477, 135),\n",
       " (1135, 135),\n",
       " (4018, 135),\n",
       " (660, 134),\n",
       " (1139, 134),\n",
       " (1956, 134),\n",
       " (2552, 134),\n",
       " (2819, 134),\n",
       " (195, 133),\n",
       " (453, 133),\n",
       " (664, 133),\n",
       " (960, 132),\n",
       " (1629, 132),\n",
       " (1952, 132),\n",
       " (2093, 132),\n",
       " (2147, 132),\n",
       " (514, 131),\n",
       " (1399, 131),\n",
       " (335, 130),\n",
       " (429, 130),\n",
       " (2816, 130),\n",
       " (146, 129),\n",
       " (656, 129),\n",
       " (1430, 129),\n",
       " (1845, 129),\n",
       " (107, 128),\n",
       " (137, 128),\n",
       " (619, 128),\n",
       " (629, 128),\n",
       " (1017, 128),\n",
       " (1111, 128),\n",
       " (1246, 128),\n",
       " (1296, 128),\n",
       " (1957, 128),\n",
       " (459, 127),\n",
       " (914, 127),\n",
       " (976, 127),\n",
       " (2420, 127),\n",
       " (2971, 127),\n",
       " (517, 126),\n",
       " (2245, 126),\n",
       " (2510, 126),\n",
       " (2710, 126),\n",
       " (2943, 126),\n",
       " (341, 125),\n",
       " (815, 125),\n",
       " (913, 124),\n",
       " (111, 123),\n",
       " (118, 123),\n",
       " (1239, 123),\n",
       " (1321, 123),\n",
       " (2406, 123),\n",
       " (290, 122),\n",
       " (434, 122),\n",
       " (1041, 122),\n",
       " (1280, 122),\n",
       " (1761, 122),\n",
       " (627, 121),\n",
       " (828, 121),\n",
       " (1460, 121),\n",
       " (1545, 121),\n",
       " (2174, 121),\n",
       " (2298, 121),\n",
       " (2581, 121),\n",
       " (126, 120),\n",
       " (322, 120),\n",
       " (1269, 120),\n",
       " (1464, 120),\n",
       " (1812, 120),\n",
       " (1961, 120),\n",
       " (2113, 120),\n",
       " (2643, 120),\n",
       " (3022, 120),\n",
       " (100, 119),\n",
       " (766, 119),\n",
       " (1129, 119),\n",
       " (1391, 119),\n",
       " (1466, 119),\n",
       " (2062, 119),\n",
       " (2511, 119),\n",
       " (147, 118),\n",
       " (198, 118),\n",
       " (1642, 118),\n",
       " (3420, 118),\n",
       " (413, 117),\n",
       " (470, 117),\n",
       " (1067, 117),\n",
       " (1474, 117),\n",
       " (1714, 117),\n",
       " (332, 116),\n",
       " (334, 116),\n",
       " (530, 116),\n",
       " (877, 116),\n",
       " (1215, 116),\n",
       " (1282, 116),\n",
       " (1381, 116),\n",
       " (3767, 116),\n",
       " (568, 115),\n",
       " (685, 115),\n",
       " (1014, 115),\n",
       " (1458, 115),\n",
       " (2031, 115),\n",
       " (2767, 115),\n",
       " (622, 114),\n",
       " (953, 114),\n",
       " (1034, 114),\n",
       " (1038, 114),\n",
       " (1502, 114),\n",
       " (1766, 114),\n",
       " (2985, 114),\n",
       " (581, 113),\n",
       " (1029, 113),\n",
       " (2127, 113),\n",
       " (2828, 113),\n",
       " (3542, 113),\n",
       " (5217, 113),\n",
       " (406, 112),\n",
       " (853, 112),\n",
       " (1317, 112),\n",
       " (1407, 112),\n",
       " (1495, 112),\n",
       " (2410, 112),\n",
       " (3403, 112),\n",
       " (263, 111),\n",
       " (647, 111),\n",
       " (738, 111),\n",
       " (838, 111),\n",
       " (890, 111),\n",
       " (1227, 111),\n",
       " (2300, 111),\n",
       " (3317, 111),\n",
       " (327, 110),\n",
       " (1146, 110),\n",
       " (1151, 110),\n",
       " (2272, 110),\n",
       " (2426, 110),\n",
       " (3207, 110),\n",
       " (975, 109),\n",
       " (1114, 109),\n",
       " (2033, 109),\n",
       " (513, 108),\n",
       " (796, 108),\n",
       " (1180, 108),\n",
       " (2032, 108),\n",
       " (3967, 108),\n",
       " (142, 107),\n",
       " (633, 107),\n",
       " (1455, 107),\n",
       " (1538, 107),\n",
       " (2711, 107),\n",
       " (3156, 107),\n",
       " (488, 106),\n",
       " (799, 106),\n",
       " (864, 106),\n",
       " (904, 106),\n",
       " (923, 106),\n",
       " (1404, 106),\n",
       " (119, 105),\n",
       " (710, 105),\n",
       " (803, 105),\n",
       " (2646, 105),\n",
       " (3679, 105),\n",
       " (722, 104),\n",
       " (1333, 104),\n",
       " (1706, 104),\n",
       " (1755, 104),\n",
       " (1932, 104),\n",
       " (2003, 104),\n",
       " (155, 103),\n",
       " (604, 103),\n",
       " (756, 103),\n",
       " (1192, 103),\n",
       " (1200, 103),\n",
       " (1347, 103),\n",
       " (1873, 103),\n",
       " (2757, 103),\n",
       " (475, 102),\n",
       " (933, 102),\n",
       " (994, 102),\n",
       " (1086, 102),\n",
       " (1245, 102),\n",
       " (1426, 102),\n",
       " (1726, 102),\n",
       " (1085, 101),\n",
       " (1341, 101),\n",
       " (1398, 101),\n",
       " (1454, 101),\n",
       " (2014, 101),\n",
       " (2332, 101),\n",
       " (2516, 101),\n",
       " (918, 100),\n",
       " (1469, 100),\n",
       " (1556, 100),\n",
       " (1875, 100),\n",
       " (2414, 100),\n",
       " (140, 99),\n",
       " (348, 99),\n",
       " (1125, 99),\n",
       " (1769, 99),\n",
       " (2064, 99),\n",
       " (3169, 99),\n",
       " (4080, 99),\n",
       " (561, 98),\n",
       " (1251, 98),\n",
       " (2704, 98),\n",
       " (1371, 97),\n",
       " (2286, 97),\n",
       " (2514, 97),\n",
       " (549, 96),\n",
       " (790, 96),\n",
       " (966, 96),\n",
       " (1611, 96),\n",
       " (1704, 96),\n",
       " (1810, 96),\n",
       " (2396, 96),\n",
       " (682, 95),\n",
       " (937, 95),\n",
       " (2605, 95),\n",
       " (983, 94),\n",
       " (1145, 94),\n",
       " (1177, 94),\n",
       " (1408, 94),\n",
       " (1546, 94),\n",
       " (1904, 94),\n",
       " (1627, 93),\n",
       " (1736, 93),\n",
       " (2280, 93),\n",
       " (2861, 93),\n",
       " (307, 92),\n",
       " (1003, 92),\n",
       " (1243, 92),\n",
       " (1523, 92),\n",
       " (1822, 92),\n",
       " (1442, 91),\n",
       " (1450, 91),\n",
       " (2209, 91),\n",
       " (2210, 91),\n",
       " (2954, 91),\n",
       " (675, 90),\n",
       " (1334, 90),\n",
       " (1603, 90),\n",
       " (3163, 90),\n",
       " (3964, 90),\n",
       " (795, 89),\n",
       " (1134, 89),\n",
       " (1295, 89),\n",
       " (3141, 89),\n",
       " (536, 88),\n",
       " (556, 88),\n",
       " (821, 88),\n",
       " (874, 88),\n",
       " (906, 88),\n",
       " (1813, 88),\n",
       " (2274, 88),\n",
       " (3100, 88),\n",
       " (179, 87),\n",
       " (336, 87),\n",
       " (1223, 87),\n",
       " (1394, 87),\n",
       " (1859, 87),\n",
       " (1941, 87),\n",
       " (1983, 87),\n",
       " (359, 86),\n",
       " (500, 86),\n",
       " (879, 86),\n",
       " (1484, 86),\n",
       " (1578, 86),\n",
       " (1866, 86),\n",
       " (3238, 86),\n",
       " (788, 85),\n",
       " (845, 85),\n",
       " (1907, 85),\n",
       " (808, 84),\n",
       " (1479, 84),\n",
       " (1574, 84),\n",
       " (2035, 84),\n",
       " (2131, 84),\n",
       " (2182, 84),\n",
       " (2234, 84),\n",
       " (2268, 84),\n",
       " (2302, 84),\n",
       " (64, 83),\n",
       " (236, 83),\n",
       " (687, 83),\n",
       " (778, 83),\n",
       " (1105, 83),\n",
       " (1297, 83),\n",
       " (1616, 83),\n",
       " (1911, 83),\n",
       " (1974, 83),\n",
       " (2621, 83),\n",
       " (2830, 83),\n",
       " (305, 82),\n",
       " (437, 82),\n",
       " (631, 82),\n",
       " (1204, 82),\n",
       " (1343, 82),\n",
       " (1487, 82),\n",
       " (1746, 82),\n",
       " (1999, 82),\n",
       " (2162, 82),\n",
       " (2319, 82),\n",
       " (3761, 82),\n",
       " (12, 81),\n",
       " (496, 81),\n",
       " (900, 81),\n",
       " (1934, 81),\n",
       " (2744, 81),\n",
       " (2787, 81),\n",
       " (451, 80),\n",
       " (695, 80),\n",
       " (921, 80),\n",
       " (1025, 80),\n",
       " (1188, 80),\n",
       " (1236, 80),\n",
       " (1419, 80),\n",
       " (1465, 80),\n",
       " (1518, 80),\n",
       " (2559, 80),\n",
       " (984, 79),\n",
       " (1571, 79),\n",
       " (1742, 79),\n",
       " (1752, 79),\n",
       " (2123, 79),\n",
       " (174, 78),\n",
       " (1095, 78),\n",
       " (1099, 78),\n",
       " (1528, 78),\n",
       " (1768, 78),\n",
       " (2108, 78),\n",
       " (2279, 78),\n",
       " (2306, 78),\n",
       " (4917, 78),\n",
       " (274, 77),\n",
       " (655, 77),\n",
       " (707, 77),\n",
       " (858, 77),\n",
       " (1078, 77),\n",
       " (1577, 77),\n",
       " (2117, 77),\n",
       " (3134, 77),\n",
       " (4467, 77),\n",
       " (264, 76),\n",
       " (426, 76),\n",
       " (670, 76),\n",
       " (1490, 76),\n",
       " (1799, 76),\n",
       " (2672, 76),\n",
       " (3764, 76),\n",
       " (4476, 76),\n",
       " (4566, 76),\n",
       " (535, 75),\n",
       " (592, 75),\n",
       " (1130, 75),\n",
       " (1532, 75),\n",
       " (1870, 75),\n",
       " (2528, 75),\n",
       " (2579, 75),\n",
       " (2765, 75),\n",
       " (3058, 75),\n",
       " (6079, 75),\n",
       " (340, 74),\n",
       " (480, 74),\n",
       " (1186, 74),\n",
       " (1261, 74),\n",
       " (1402, 74),\n",
       " (1515, 74),\n",
       " (1678, 74),\n",
       " (2146, 74),\n",
       " (885, 73),\n",
       " (974, 73),\n",
       " (1219, 73),\n",
       " (1281, 73),\n",
       " (1516, 73),\n",
       " (1570, 73),\n",
       " (2795, 73),\n",
       " (4083, 73),\n",
       " (4951, 73),\n",
       " (173, 72),\n",
       " (1005, 72),\n",
       " (1988, 72),\n",
       " (2103, 72),\n",
       " (2961, 72),\n",
       " (3001, 72),\n",
       " (4014, 72),\n",
       " (5168, 72),\n",
       " (5693, 72),\n",
       " (192, 71),\n",
       " (381, 71),\n",
       " (1262, 71),\n",
       " (1354, 71),\n",
       " (1364, 71),\n",
       " (1488, 71),\n",
       " (1566, 71),\n",
       " (1723, 71),\n",
       " (1737, 71),\n",
       " (2625, 71),\n",
       " (2670, 71),\n",
       " (3293, 71),\n",
       " (3406, 71),\n",
       " (3686, 71),\n",
       " (271, 70),\n",
       " (525, 70),\n",
       " (624, 70),\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_list_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3112"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_list_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_comparison = []\n",
    "for i in range(len(freq_list_fr)):\n",
    "    fr_word = training_corpus_dct[freq_list_fr[i][0]]\n",
    "    en_word = training_corpus_dct_en[freq_list_en[i][0]]\n",
    "    freq_comparison.append((fr_word, en_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1k sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3k sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_comparison = []\n",
    "for i in range(len(freq_list_fr)):\n",
    "    fr_word = training_corpus_dct[freq_list_fr[i][0]]\n",
    "    en_word = training_corpus_dct_en[freq_list_en[i][0]]\n",
    "    freq_comparison.append((fr_word, en_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('un', 'a'),\n",
       " ('une', 'man'),\n",
       " ('homme', 'the'),\n",
       " ('de', 'of'),\n",
       " ('des', 'woman'),\n",
       " (\"'\", 'two'),\n",
       " ('femme', 'people'),\n",
       " ('la', 'young'),\n",
       " ('deux', 'shirt'),\n",
       " ('d', 'an'),\n",
       " ('chien', 'white'),\n",
       " ('l', 'black'),\n",
       " ('le', 'blue'),\n",
       " ('garçon', 'his'),\n",
       " ('jeune', 'red'),\n",
       " ('fille', 'men'),\n",
       " ('hommes', 'girl'),\n",
       " ('personnes', 'boy'),\n",
       " ('groupe', 'dog'),\n",
       " ('noir', 'group'),\n",
       " ('rouge', 'and'),\n",
       " ('les', 'three'),\n",
       " ('[', 'one'),\n",
       " ('blanc', 'her'),\n",
       " ('gens', 'women'),\n",
       " ('enfant', 'child'),\n",
       " ('à', 'green'),\n",
       " ('en', 'water'),\n",
       " ('chemise', 'little'),\n",
       " ('son', 'street'),\n",
       " ('trois', 'person'),\n",
       " ('t-shirt', 'large'),\n",
       " ('eau', 'yellow'),\n",
       " ('et', 'brown'),\n",
       " ('petit', 'children'),\n",
       " ('enfants', 'hat'),\n",
       " ('bleu', 'ball'),\n",
       " ('femmes', 'small'),\n",
       " ('personne', 'jacket'),\n",
       " ('petite', 'their'),\n",
       " ('rue', 'orange'),\n",
       " ('sa', 'pink'),\n",
       " ('autre', 'crowd'),\n",
       " ('brun', 'some'),\n",
       " ('jeunes', 'building'),\n",
       " ('jaune', 'table'),\n",
       " ('veste', 'another'),\n",
       " ('lunettes', 'other'),\n",
       " ('cheveux', 'girls'),\n",
       " ('chapeau', 'bike'),\n",
       " ('blanche', 'dogs'),\n",
       " ('table', 'player'),\n",
       " ('vert', 'older'),\n",
       " ('bleue', 'hair'),\n",
       " ('chiens', 'four'),\n",
       " ('neige', 'dress'),\n",
       " ('guitare', 'asian'),\n",
       " ('filles', 'wall'),\n",
       " ('plage', 'several'),\n",
       " ('du', 'sidewalk'),\n",
       " ('herbe', 'gray'),\n",
       " ('rose', 'lady'),\n",
       " ('ses', 'shorts'),\n",
       " ('plusieurs', 'guitar'),\n",
       " ('foule', 'pants'),\n",
       " ('noire', 'boys'),\n",
       " ('vélo', 'jeans'),\n",
       " ('garçons', 'grass'),\n",
       " ('trottoir', 'snow'),\n",
       " ('orange', 'hand'),\n",
       " ('bâtiment', 'field'),\n",
       " ('grand', 'beach'),\n",
       " ('main', 'top'),\n",
       " ('ballon', 'bench'),\n",
       " ('quatre', 'baby'),\n",
       " ('robe', 'glasses'),\n",
       " ('sac', 'car'),\n",
       " ('short', 'blond'),\n",
       " ('mur', \"'s\"),\n",
       " ('bébé', 'head'),\n",
       " ('bois', 'old'),\n",
       " ('banc', 'food'),\n",
       " ('balle', 'couple'),\n",
       " ('costume', 'male'),\n",
       " ('autres', 'bicycle'),\n",
       " ('verte', 'guy'),\n",
       " ('marron', 'hands'),\n",
       " ('pantalon', 'soccer'),\n",
       " ('maillot', ','),\n",
       " ('vêtements', 'face'),\n",
       " ('gars', 'tree'),\n",
       " ('casque', 'female'),\n",
       " ('gros', 'striped'),\n",
       " ('sable', 't-shirt'),\n",
       " ('gris', 'coat'),\n",
       " ('voiture', 'suit'),\n",
       " ('jouet', 'road'),\n",
       " ('piscine', 'purple'),\n",
       " ('tennis', 'sunglasses'),\n",
       " ('arbre', 'mouth'),\n",
       " ('tenue', 'many'),\n",
       " ('dos', 'baseball'),\n",
       " ('vieil', 'sign'),\n",
       " ('asiatique', 'long'),\n",
       " ('tête', 'rock'),\n",
       " ('manteau', 'kids'),\n",
       " ('âgé', 'dark'),\n",
       " ('cinq', 'pool'),\n",
       " ('casquette', 'helmet'),\n",
       " ('rouges', 'microphone'),\n",
       " ('grande', 'horse'),\n",
       " ('quelques', 'band'),\n",
       " ('bain', 'players'),\n",
       " ('mains', 'uniform'),\n",
       " ('soleil', 'workers'),\n",
       " ('visage', 'dirt'),\n",
       " ('champ', 'toy'),\n",
       " ('nourriture', 'cap'),\n",
       " ('couple', 'construction'),\n",
       " ('terrain', 'chair'),\n",
       " ('dame', 'elderly'),\n",
       " ('blancs', 'its'),\n",
       " ('chemin', 'clothing'),\n",
       " ('aux', 'wooden'),\n",
       " ('noirs', 'football'),\n",
       " ('jean', 'bag'),\n",
       " ('cheval', 'team'),\n",
       " ('fenêtre', 'window'),\n",
       " ('gilet', 'shirts'),\n",
       " ('route', 'colorful'),\n",
       " ('rocher', 'sand'),\n",
       " ('corde', 'tennis'),\n",
       " ('montagne', 'tan'),\n",
       " ('téléphone', 'floor'),\n",
       " ('porte', 'five'),\n",
       " ('blonde', 'city'),\n",
       " ('football', 'trees'),\n",
       " ('leurs', 'hats'),\n",
       " ('parc', 'fence'),\n",
       " ('chaise', 'sweater'),\n",
       " ('au', 'basketball'),\n",
       " ('beaucoup', 'cart'),\n",
       " ('quelque', 'motorcycle'),\n",
       " ('océan', 'ocean'),\n",
       " ('camion', 'umbrella'),\n",
       " ('famille', 'cellphone'),\n",
       " (',', 'something'),\n",
       " ('scène', 'clothes'),\n",
       " ('moto', 'light'),\n",
       " ('chose', 'mountain'),\n",
       " ('fleurs', 'book'),\n",
       " ('adulte', 'vest'),\n",
       " ('photo', 'brick'),\n",
       " ('portable', 'truck'),\n",
       " ('haut', 'arms'),\n",
       " ('pont', 'park'),\n",
       " ('sécurité', 'stage'),\n",
       " ('colline', 'bright'),\n",
       " ('machine', 'outfit'),\n",
       " ('ville', 'piece'),\n",
       " ('micro', 'skateboard'),\n",
       " ('gueule', 'tank'),\n",
       " ('blanches', 'big'),\n",
       " ('plastique', 'camera'),\n",
       " ('plus', 'ice'),\n",
       " ('rivière', 'all'),\n",
       " ('planche', 'back'),\n",
       " ('ouvriers', 'colored'),\n",
       " ('piste', 'stick'),\n",
       " ('canapé', 'uniforms'),\n",
       " ('plan', 'someone'),\n",
       " ('bras', 'worker'),\n",
       " ('âgée', 'guys'),\n",
       " ('bouche', 'store'),\n",
       " ('arbres', 'paper'),\n",
       " ('petits', 'others'),\n",
       " ('terre', 'toddler'),\n",
       " ('équipe', 'metal'),\n",
       " ('lac', 'adults'),\n",
       " ('baseball', 'backpack'),\n",
       " ('adultes', 'lake'),\n",
       " ('chaussures', 'body'),\n",
       " ('clôture', 'picture'),\n",
       " ('livre', 'stone'),\n",
       " ('verre', 'kid'),\n",
       " ('beige', 'shoes'),\n",
       " ('longs', 'path'),\n",
       " ('quelqu', 'this'),\n",
       " ('sacs', 'pole'),\n",
       " ('leur', 'american'),\n",
       " ('pierre', 'flowers'),\n",
       " ('panneau', 'skirt'),\n",
       " ('très', 'river'),\n",
       " ('gilets', 'side'),\n",
       " ('nu', 'phone'),\n",
       " ('vieille', 'family'),\n",
       " ('bonnet', 'rocks'),\n",
       " ('blonds', 'cowboy'),\n",
       " ('barbe', 'board'),\n",
       " ('asiatiques', 'swing'),\n",
       " ('uniforme', 'costume'),\n",
       " ('torse', 'rope'),\n",
       " ('cuisine', 'african'),\n",
       " ('joueur', 'flag'),\n",
       " ('tablier', 'gear'),\n",
       " ('frisbee', 'outside'),\n",
       " ('magasin', 'track'),\n",
       " ('pull', 'machine'),\n",
       " ('café', 'hill'),\n",
       " ('morceau', 'very'),\n",
       " ('objet', 'smiling'),\n",
       " ('immeuble', 'wave'),\n",
       " ('gâteau', 'shirtless'),\n",
       " ('rayé', 'plaid'),\n",
       " ('maison', 'line'),\n",
       " ('repas', 'instruments'),\n",
       " ('casques', 'game'),\n",
       " ('brune', 'steps'),\n",
       " ('amis', 'bridge'),\n",
       " ('ordinateur', 'sweatshirt'),\n",
       " ('noires', 'plastic'),\n",
       " ('balançoire', 'hard'),\n",
       " ('montagnes', 'area'),\n",
       " ('bière', 'chairs'),\n",
       " ('bord', 'fire'),\n",
       " ('papier', 'number'),\n",
       " ('chariot', 'grassy'),\n",
       " ('randonneurs', 'adult'),\n",
       " ('débardeur', 'police'),\n",
       " ('bâton', 'wood'),\n",
       " ('béton', 'bags'),\n",
       " ('tapis', 'glass'),\n",
       " ('boule', 'scarf'),\n",
       " ('colorés', 'couch'),\n",
       " ('bruns', 'boots'),\n",
       " ('jeu', 'beard'),\n",
       " ('lit', 'ladies'),\n",
       " ('ouvrier', 'frisbee'),\n",
       " ('salle', 'house'),\n",
       " ('bleus', 'concrete'),\n",
       " ('tasse', 'equipment'),\n",
       " ('enneigée', 'stairs'),\n",
       " ('pieds', 'fountain'),\n",
       " ('construction', 'computer'),\n",
       " ('marches', '2'),\n",
       " ('fruits', 'graffiti'),\n",
       " ('couverture', 'object'),\n",
       " ('sol', 'skateboarder'),\n",
       " ('feu', 'rider'),\n",
       " ('clair', 'hockey'),\n",
       " ('toit', 'ramp'),\n",
       " ('grosse', 'tall'),\n",
       " ('avec', 'bed'),\n",
       " ('cigarette', 'race'),\n",
       " ('quai', 'cigarette'),\n",
       " ('long', 'open'),\n",
       " ('vieux', 'outdoor'),\n",
       " ('collier', 'drink'),\n",
       " ('chapeaux', 'short'),\n",
       " ('structure', 'jersey'),\n",
       " ('restaurant', 'bikes'),\n",
       " ('extérieur', 'horses'),\n",
       " ('blond', 'instrument'),\n",
       " ('couleur', 'friends'),\n",
       " ('rocheuse', 'six'),\n",
       " ('bouteille', 'stand'),\n",
       " ('rochers', 'buildings'),\n",
       " ('combinaison', 'gentleman'),\n",
       " ('mère', 'statue'),\n",
       " ('falaise', 'door'),\n",
       " ('jaunes', 'lot'),\n",
       " ('appareil', 'swimming'),\n",
       " ('chauve', 'slide'),\n",
       " ('seau', 'shop'),\n",
       " ('sweat-shirt', 'audience'),\n",
       " ('laisse', 'cream'),\n",
       " ('spectateurs', 'safety'),\n",
       " ('chat', 'or'),\n",
       " ('microphone', 'beer'),\n",
       " ('rayée', 'cars'),\n",
       " ('chaises', 'blond-hair'),\n",
       " ('véhicule', 'gloves'),\n",
       " ('poutre', 'vehicle'),\n",
       " ('poussette', 'bottle'),\n",
       " ('poisson', 'eyes'),\n",
       " ('jupe', 'net'),\n",
       " ('cour', 'shopping'),\n",
       " ('barbecue', 'fish'),\n",
       " ('instrument', 'apron'),\n",
       " ('tas', 'few'),\n",
       " ('toboggan', 'mother'),\n",
       " ('travailleurs', 'volleyball'),\n",
       " ('métal', 'middle-aged'),\n",
       " ('marché', 'newspaper'),\n",
       " ('journal', 'room'),\n",
       " ('fontaine', 'cup'),\n",
       " ('sentier', 'roof'),\n",
       " ('fauteuil', 'snowboarder'),\n",
       " ('plein', 'surfer'),\n",
       " ('dans', 'snowy'),\n",
       " ('cow-boy', 'jackets'),\n",
       " ('feuilles', 'box'),\n",
       " ('``', 'vests'),\n",
       " ('fils', 'lawn'),\n",
       " ('glace', 'drums'),\n",
       " ('canne', 'onlookers'),\n",
       " ('six', 'goggles'),\n",
       " ('barrière', 'costumes'),\n",
       " ('joueurs', 'suits'),\n",
       " ('ligne', '``'),\n",
       " ('vélos', 'bunch'),\n",
       " ('rampe', 'shoulder'),\n",
       " ('monsieur', 'restaurant'),\n",
       " ('carreaux', 'bucket'),\n",
       " ('écran', 'leaves'),\n",
       " ('gants', 'ladder'),\n",
       " ('foulard', 'spectators'),\n",
       " ('air', 'edge'),\n",
       " ('poteau', 'mask'),\n",
       " ('sweat', 'structure'),\n",
       " ('bottes', 'students'),\n",
       " ('côté', 'middle'),\n",
       " ('roulettes', 'bird'),\n",
       " ('hiver', 'biker'),\n",
       " ('joueuse', 'mountains'),\n",
       " ('peluche', 'busy'),\n",
       " ('escalier', 'fruit'),\n",
       " ('peinture', 'teams'),\n",
       " ('police', 'bull'),\n",
       " ('arrière', 'dresses'),\n",
       " ('mariée', 'vendor'),\n",
       " ('tables', 'indian'),\n",
       " ('père', 'bathing'),\n",
       " ('chantier', 'leather'),\n",
       " ('bikini', 'beautiful'),\n",
       " ('violet', 'flags'),\n",
       " ('jetée', 'attire'),\n",
       " ('foot', 'pile'),\n",
       " ('ouverte', 'blanket'),\n",
       " ('gamin', 'desk'),\n",
       " ('grise', 'railing'),\n",
       " ('comptoir', 'dock'),\n",
       " ('nombre', 'grill'),\n",
       " ('voie', 'various'),\n",
       " ('filet', '3'),\n",
       " ('voitures', 'purse'),\n",
       " ('ski', 'basket'),\n",
       " ('animal', 'silver'),\n",
       " ('s', 'gold'),\n",
       " ('eaux', 'bearded'),\n",
       " ('pompier', 'legs'),\n",
       " ('imposant', 'counter'),\n",
       " ('raquette', 'younger'),\n",
       " ('masque', 'skier'),\n",
       " ('robes', 'outfits'),\n",
       " ('maillots', 'surfboard'),\n",
       " ('course', 'flower'),\n",
       " ('parapluie', 'sky'),\n",
       " ('défilé', 'high'),\n",
       " ('pour', 'bowl'),\n",
       " ('verts', 'animal'),\n",
       " ('bol', 'bride'),\n",
       " ('bleues', 'trail'),\n",
       " ('sombre', 'dark-haired'),\n",
       " ('sans', 'dressed'),\n",
       " ('skieurs', 'no'),\n",
       " ('souriante', 'tables'),\n",
       " ('briques', 'balloon'),\n",
       " ('statue', 'items'),\n",
       " ('tente', 'bald'),\n",
       " ('foncé', 'full'),\n",
       " ('vestes', 'feet'),\n",
       " ('sur', 'helmets'),\n",
       " ('nombreux', 'cake'),\n",
       " ('randonneur', 'winter'),\n",
       " ('miroir', 'vegetables'),\n",
       " ('aire', 'electric'),\n",
       " ('uniformes', 'drinks'),\n",
       " ('yeux', 'display'),\n",
       " ('jeux', 'bicycles'),\n",
       " ('âge', 'kitchen'),\n",
       " ('échelle', 'art'),\n",
       " ('tracteur', 'wet'),\n",
       " ('instruments', 'military'),\n",
       " ('âgées', 'rail'),\n",
       " ('drapeau', 'paint'),\n",
       " ('ballons', 'stroller'),\n",
       " ('nus', 'cement'),\n",
       " ('étang', 'right'),\n",
       " ('drapeaux', 'coffee'),\n",
       " ('électrique', 'rocky'),\n",
       " ('petites', 'bikini'),\n",
       " ('trou', 'parade'),\n",
       " ('ombre', 'screen'),\n",
       " ('milieu', 'bar'),\n",
       " ('bowling', 'males'),\n",
       " ('paille', 'musicians'),\n",
       " ('chefs', 'different'),\n",
       " ('matériel', 'father'),\n",
       " ('foncés', 'brunette'),\n",
       " ('vache', 'tent'),\n",
       " ('américain', 'signs'),\n",
       " ('jeans', 'cliff'),\n",
       " ('caméra', 'violin'),\n",
       " ('public', 'balloons'),\n",
       " ('escaliers', 'sports'),\n",
       " ('marchandises', 'laptop'),\n",
       " ('épaules', 'set'),\n",
       " ('chemises', 'train'),\n",
       " ('poubelle', 'shore'),\n",
       " ('échafaudage', 'ride'),\n",
       " ('protection', 'leg'),\n",
       " ('pantalons', 'son'),\n",
       " ('bâtons', 'trunks'),\n",
       " ('ordinateurs', 'work'),\n",
       " ('manger', 'school'),\n",
       " ('capuche', 'scooter'),\n",
       " ('cette', 'musical'),\n",
       " ('oranges', 'artist'),\n",
       " ('moyen', 'ledge'),\n",
       " ('jardin', 'bubbles'),\n",
       " ('clients', 'teenage'),\n",
       " ('viande', 'tie'),\n",
       " ('artiste', 'collar'),\n",
       " ('costumes', 'covered'),\n",
       " ('assiette', 'officer'),\n",
       " ('travail', 'life'),\n",
       " ('microscope', 'sandals'),\n",
       " ('paroi', 'headphones'),\n",
       " ('musique', 'front'),\n",
       " ('afro-américain', 'chinese'),\n",
       " ('peu', 'fishing'),\n",
       " ('ciel', 'left'),\n",
       " ('chef', 'painting'),\n",
       " ('t-shirts', 'mirror'),\n",
       " ('grandes', 'meal'),\n",
       " ('ciment', 'wheel'),\n",
       " ('graffitis', 'clown'),\n",
       " ('ruisseau', 'members'),\n",
       " ('canot', 'coats'),\n",
       " ('cadeau', 'meat'),\n",
       " ('panier', 'waves'),\n",
       " ('poil', 'dancers'),\n",
       " ('classe', 'huge'),\n",
       " ('cravate', 'cat'),\n",
       " ('bougies', 'microscope'),\n",
       " ('belle', 'leash'),\n",
       " ('tuyau', 'plate'),\n",
       " ('canard', 'yard'),\n",
       " ('.', 'drum'),\n",
       " ('boue', 'umbrellas'),\n",
       " ('vendeur', 'foot'),\n",
       " ('pièce', 'doorway'),\n",
       " ('gonflable', 'runner'),\n",
       " ('sommet', 'toys'),\n",
       " ('genoux', 'faces'),\n",
       " ('bulles', 'platform'),\n",
       " ('pile', 'traditional'),\n",
       " ('sandales', 'empty'),\n",
       " ('oiseau', 'balls'),\n",
       " ('vagues', 'straw'),\n",
       " ('sale', 'performer'),\n",
       " ('mer', 'corner'),\n",
       " ('signe', 'swim'),\n",
       " ('grill', 'accordion'),\n",
       " ('pelle', 'giant'),\n",
       " ('nez', 'individuals'),\n",
       " ('tour', 'cyclist'),\n",
       " ('manches', 'beige'),\n",
       " ('violette', 'shovel'),\n",
       " ('pêcheur', 'lights'),\n",
       " ('argile', 'opposing'),\n",
       " ('batterie', 'singer'),\n",
       " ('cuisinier', 'tattoo'),\n",
       " ('boisson', 'lap'),\n",
       " ('langue', 'each'),\n",
       " ('harnais', 'telescope'),\n",
       " ('ordures', 'musician'),\n",
       " ('pente', 'tracks'),\n",
       " ('poteaux', 'walkway'),\n",
       " ('motos', 'multicolored'),\n",
       " ('2', 'market'),\n",
       " ('qui', 'stuffed'),\n",
       " ('pêche', 'tire'),\n",
       " ('cours', 'runners'),\n",
       " ('bouclés', 'gun'),\n",
       " ('boîte', 'business'),\n",
       " ('métallique', 'these'),\n",
       " ('tissu', 'christmas'),\n",
       " ('courts', 'sculpture'),\n",
       " ('orchestre', 'pedestrians'),\n",
       " ('tableau', 'base'),\n",
       " ('polo', 'bowling'),\n",
       " ('pyjama', 'brightly'),\n",
       " ('policier', 'makeup'),\n",
       " ('sept', 'bicyclist'),\n",
       " ('barbu', 'golden'),\n",
       " ('fait', 'sled'),\n",
       " ('skateboard', 'hoodie'),\n",
       " ('gardien', 'books'),\n",
       " ('hockey', 'ski'),\n",
       " ('sculpture', 'hole'),\n",
       " ('multicolore', 'red-hair'),\n",
       " ('coloré', 'seat'),\n",
       " ('tout-petit', 'hot'),\n",
       " ('ces', 'khaki'),\n",
       " ('intérieur', 'pier'),\n",
       " ('adolescent', 'blond-haired'),\n",
       " ('colorées', 'pair'),\n",
       " ('plate-forme', 'wetsuit'),\n",
       " ('bambin', 'device'),\n",
       " ('écharpe', 'van'),\n",
       " ('entre', 'canoe'),\n",
       " ('certains', 'dirty'),\n",
       " ('parking', 'cane'),\n",
       " ('marteau', 'sticks'),\n",
       " ('pain', 'forest'),\n",
       " ('noël', 'officers'),\n",
       " ('roses', 'chef'),\n",
       " ('vitrine', 'new'),\n",
       " ('argent', 'cheerleaders'),\n",
       " ('clavier', 'friend'),\n",
       " ('martiaux', 'trampoline'),\n",
       " ('stand', 'nose'),\n",
       " ('pierres', 'looking'),\n",
       " ('multicolores', 'lone'),\n",
       " ('tenues', 'cloth'),\n",
       " ('grands', 'windows'),\n",
       " ('tabouret', 'heavy'),\n",
       " ('cyclistes', 'blouse'),\n",
       " ('grille', 'daughter'),\n",
       " ('remorque', 'pond'),\n",
       " ('équipement', 'oriental'),\n",
       " ('verres', 'sort'),\n",
       " ('militaire', 'third'),\n",
       " ('kaki', 'public'),\n",
       " ('plat', 'females'),\n",
       " ('train', 'bat'),\n",
       " ('souriant', 'camouflage'),\n",
       " ('pavée', 'court'),\n",
       " ('terrasse', 'playground'),\n",
       " ('écouteurs', 'mud'),\n",
       " ('carton', 'photographer'),\n",
       " ('base-ball', 'racket'),\n",
       " ('frère', 'seven'),\n",
       " ('bouteilles', 'jean'),\n",
       " ('chiot', 'parking'),\n",
       " ('sauvetage', 'painted'),\n",
       " ('objets', 'booth'),\n",
       " ('légumes', 'sandy'),\n",
       " ('cordes', 'shallow'),\n",
       " ('roux', 'tongue'),\n",
       " ('longues', 'shoulders'),\n",
       " ('tronc', 'hooded'),\n",
       " ('taureau', 'denim'),\n",
       " ('vif', 'video'),\n",
       " ('cascade', 'view'),\n",
       " ('sport', 'infant'),\n",
       " ('couleurs', 'climber'),\n",
       " ('plantes', 'teenagers'),\n",
       " ('buissons', 'robe'),\n",
       " ('ours', 'neck'),\n",
       " ('peint', 'groom'),\n",
       " ('ouvert', 'cow'),\n",
       " ('chemisier', 'plants'),\n",
       " ('type', 'wedding'),\n",
       " ('mariage', 'overalls'),\n",
       " ('mouillé', 'woods'),\n",
       " ('kayak', 'papers'),\n",
       " ('but', 'martial'),\n",
       " ('art', 'bandanna'),\n",
       " ('rebord', 'protective'),\n",
       " ('agent', 'mural'),\n",
       " ('pourpre', 'gymnast'),\n",
       " ('acier', 'station'),\n",
       " ('pompiers', 'produce'),\n",
       " ('skieur', 'both'),\n",
       " ('magazine', 'racing'),\n",
       " ('zone', 'trash'),\n",
       " ('croix', 'hose'),\n",
       " ('fer', 'multiple'),\n",
       " ('vaste', 'lots'),\n",
       " ('étendue', 'stream'),\n",
       " ('coudre', 'heads'),\n",
       " ('rangée', 'guitars'),\n",
       " ('rousse', 'happy'),\n",
       " ('cycliste', 'row'),\n",
       " ('blouson', 'balcony'),\n",
       " ('court', 'photo'),\n",
       " ('cartes', 'crowded'),\n",
       " ('alpiniste', 'dancer'),\n",
       " ('véhicules', 'railroad'),\n",
       " ('église', 'pot'),\n",
       " ('outils', 'referee'),\n",
       " ('affiche', 'music'),\n",
       " ('passagers', 'sun'),\n",
       " ('livres', 'pictures'),\n",
       " ('ferrée', 'motorcycles'),\n",
       " ('traîneau', 'hoop'),\n",
       " ('portables', 'goal'),\n",
       " ('lumières', 'scaffolding'),\n",
       " ('bassin', 'piano'),\n",
       " ('articles', 'saxophone'),\n",
       " ('bout', 'pitcher'),\n",
       " ('jouets', 'type'),\n",
       " ('image', 'log'),\n",
       " ('brouette', 'goalie'),\n",
       " ('trottinette', 'hiker'),\n",
       " ('bâtiments', '4'),\n",
       " ('vertes', 'keyboard'),\n",
       " ('haute', 'navy'),\n",
       " ('visière', 'stool'),\n",
       " ('ceintures', 'airplane'),\n",
       " ('arts', 'cone'),\n",
       " ('blocs', 'dark-skinned'),\n",
       " ('roue', 'mat'),\n",
       " ('balles', 'alley'),\n",
       " ('rayures', 'tractor'),\n",
       " ('poils', 'outdoors'),\n",
       " ('casserole', 'finger'),\n",
       " ('longue', 'muddy'),\n",
       " ('traditionnel', 'gate'),\n",
       " ('ou', 'pavement'),\n",
       " ('peau', 'kayak'),\n",
       " ('jambes', 'luggage'),\n",
       " ('bouée', 'same'),\n",
       " ('travailleur', 'deck'),\n",
       " ('accordéon', 'swimsuit'),\n",
       " ('certaines', 'fans'),\n",
       " ('nuages', 'polo'),\n",
       " ('trampoline', 'long-sleeved'),\n",
       " ('hautes', 'belt'),\n",
       " ('serviette', 'riders'),\n",
       " ('golf', 'garbage'),\n",
       " ('enseigne', 'banner'),\n",
       " ('origine', 'garden'),\n",
       " ('indienne', 'streets'),\n",
       " ('siège', 'guitarist'),\n",
       " ('oiseaux', 'teeth'),\n",
       " ('adolescents', 'bmx'),\n",
       " ('eux', 'boxes'),\n",
       " ('cuir', 'arts'),\n",
       " ('passage', 'soldier'),\n",
       " ('dames', 'poles'),\n",
       " ('blouse', 'class'),\n",
       " ('gril', 'container'),\n",
       " ('pied', 'colors'),\n",
       " ('rive', 'hay'),\n",
       " ('couvert', 'clear'),\n",
       " ('pattes', 'pipe'),\n",
       " ('métier', 'floral'),\n",
       " ('habillé', 'hammer'),\n",
       " ('salon', 'goods'),\n",
       " ('camouflage', 'post'),\n",
       " ('boueuse', 'walls'),\n",
       " ('motifs', 'cones'),\n",
       " ('animaux', 'traffic'),\n",
       " ('embrasure', 'mustache'),\n",
       " ('manteaux', 'curly'),\n",
       " ('rambarde', 'wheelchair'),\n",
       " ('sombres', 'staircase'),\n",
       " ('coiffure', '5'),\n",
       " ('vêtement', 'bubble'),\n",
       " ('seaux', 'tool'),\n",
       " ('profonde', 'teacher'),\n",
       " ('bureau', 'professional'),\n",
       " ('snowboardeur', 'acoustic'),\n",
       " ('géant', 'fabric'),\n",
       " ('partition', 'robes'),\n",
       " ('réfléchissant', 'brown-haired'),\n",
       " ('machines', 'crosswalk'),\n",
       " ('conducteur', 'harness'),\n",
       " ('salopette', 'performers'),\n",
       " ('gymnaste', 'snowboard'),\n",
       " ('caoutchouc', 'checkered'),\n",
       " ('avion', 'drummer'),\n",
       " ('chanteur', 'driver'),\n",
       " ('publicitaire', 'sheet'),\n",
       " ('herbeux', 'bicyclists'),\n",
       " ('individus', 'cyclists'),\n",
       " ('claire', 'picnic'),\n",
       " ('arrêt', 'surface'),\n",
       " ('bus', 'chain'),\n",
       " ('rivage', 'golf'),\n",
       " ('monticule', 'swimmer'),\n",
       " ('épaule', 'machinery'),\n",
       " ('mousse', 'caucasian'),\n",
       " ('chevaux', 'hikers'),\n",
       " ('ponton', 'wine'),\n",
       " ('aliments', 'shoe'),\n",
       " ('coiffe', 'fingers'),\n",
       " ('tunnel', 'curb'),\n",
       " ('poussière', 'towel'),\n",
       " ('fleuri', 'wagon'),\n",
       " ('quad', 'grocery'),\n",
       " ('poêle', 'air'),\n",
       " ('bateau', 'tube'),\n",
       " ('forme', 'crew'),\n",
       " ('escalator', 'puppy'),\n",
       " ('désert', 'smile'),\n",
       " ('scooter', 'bread'),\n",
       " ('projet', 'raft'),\n",
       " ('scie', 'ship'),\n",
       " ('énorme', 'pieces'),\n",
       " ('motards', 'animals'),\n",
       " ('assis', 'soldiers'),\n",
       " ('décorations', 'waterfall'),\n",
       " ('plafond', 'inflatable'),\n",
       " ('kilt', 'heels'),\n",
       " ('joue', 'birds'),\n",
       " ('flaque', 'pajamas'),\n",
       " ('pinceau', 'santa'),\n",
       " ('jumelles', 'ears'),\n",
       " ('bavoir', 'home'),\n",
       " ('buisson', 'cafe'),\n",
       " ('bagages', 'motorbike'),\n",
       " ('taille', 'church'),\n",
       " ('dehors', 'dance'),\n",
       " ('maman', 'jerseys'),\n",
       " ('tongs', 'tools'),\n",
       " ('château', 'red-haired'),\n",
       " ('a', 'tourists'),\n",
       " ('gazonné', 'guard'),\n",
       " ('clown', 'puddle'),\n",
       " ('sales', 't-shirts'),\n",
       " ('sandwich', 'socks'),\n",
       " ('officiers', 'laundry'),\n",
       " ('brunes', 'stop'),\n",
       " ('gant', 'ring'),\n",
       " ('toile', 'bottles'),\n",
       " ('vin', 'chest'),\n",
       " ('sous-vêtements', 'garb'),\n",
       " ('john', 'hurdle'),\n",
       " ('ensemble', 'bikers'),\n",
       " ('pneus', 'neon'),\n",
       " ('bien', 'knee'),\n",
       " ('foncée', 'plane'),\n",
       " ('herbeuse', 'individual'),\n",
       " ('blondes', 'sea'),\n",
       " ('marchand', 'ponytail'),\n",
       " ('acoustique', 'podium'),\n",
       " ('balustrade', 'ear'),\n",
       " ('cabane', 'advertisement'),\n",
       " ('bondée', 'obstacle'),\n",
       " ('portes', 'roller'),\n",
       " ('pas', 'haircut'),\n",
       " ('herbes', 'sheep'),\n",
       " ('couloir', 'beam'),\n",
       " ('balcon', 'native'),\n",
       " ('humide', 'teenager'),\n",
       " ('gym', 'end'),\n",
       " ('roche', 'firetruck'),\n",
       " ('saxophone', 'poster'),\n",
       " ('camp', 'sneakers'),\n",
       " ('tube', 'long-haired'),\n",
       " ('parasol', 'member'),\n",
       " ('coin', 'maroon'),\n",
       " ('membres', 'army'),\n",
       " ('cou', 'dinner'),\n",
       " ('colorée', 'escalator'),\n",
       " ('piétons', 'baskets'),\n",
       " ('oreilles', 'flowered'),\n",
       " ('crayon', 'benches'),\n",
       " ('basket', 'jumpsuit'),\n",
       " ('balai', 'paved'),\n",
       " ('tous', 'tattoos'),\n",
       " ('dents', 'bus'),\n",
       " ('talons', 'hood'),\n",
       " ('boissons', 'carriage'),\n",
       " ('musiciens', 'backpacks'),\n",
       " ('numéro', 'beverage'),\n",
       " ('jeep', 'athletic'),\n",
       " ('gravier', 'skis'),\n",
       " ('camionnette', 'candy'),\n",
       " ('vive', 'lane'),\n",
       " ('bols', 'caps'),\n",
       " ('fenêtres', 'print'),\n",
       " ('boueux', 'round'),\n",
       " ('marche', 'bottom'),\n",
       " ('foin', 'gentlemen'),\n",
       " ('troisième', 'rugby'),\n",
       " ('citrouille', 'funny'),\n",
       " ('violon', 'athlete'),\n",
       " ('âgés', 'trumpet'),\n",
       " ('bébés', 'seated'),\n",
       " ('brillant', 'bucking'),\n",
       " ('photographe', 'firefighters'),\n",
       " ('soldats', 'palm'),\n",
       " ('écoliers', 'slope'),\n",
       " ('caisse', 'customers'),\n",
       " ('perles', 'skirts'),\n",
       " ('jupes', 'reflective'),\n",
       " ('nombreuses', 'broom'),\n",
       " ('3', 'closeup'),\n",
       " ('flûte', 'tops'),\n",
       " ('piéton', 'headband'),\n",
       " ('bloc', 'stripes'),\n",
       " ('nouveau-né', 'hula'),\n",
       " ('vague', 'newborn'),\n",
       " ('professeur', 'redheaded'),\n",
       " ('rocheuses', 'kind'),\n",
       " ('métalliques', 'necklace'),\n",
       " ('est', 'lab'),\n",
       " ('rodéo', 'rodeo'),\n",
       " ('équipes', 'map'),\n",
       " ('assiettes', 'tub'),\n",
       " ('barres', 'mound'),\n",
       " ('arc-en-ciel', 'computers'),\n",
       " ('chaussée', 'barefoot'),\n",
       " ('importante', 'student'),\n",
       " ('représentant', 'mohawk'),\n",
       " ('fourgon', 'matching'),\n",
       " ('cartons', 'magazine'),\n",
       " ('étrange', 'string'),\n",
       " ('nouveau', 'teal'),\n",
       " ('bûche', 'gathering'),\n",
       " ('alpinistes', 'formal'),\n",
       " ('carte', 'motorcyclist'),\n",
       " ('villageois', 'figure'),\n",
       " ('tout', 'homeless'),\n",
       " ('solitaire', 'wire'),\n",
       " ('passerelle', 'mom'),\n",
       " ('bambou', 'model'),\n",
       " ('membre', 'running'),\n",
       " ('africaine', 'policeman'),\n",
       " ('épée', 'desert'),\n",
       " ('entraînement', 'tunnel'),\n",
       " ('droite', 'look'),\n",
       " ('pilote', 'guns'),\n",
       " ('nattes', 'vehicles'),\n",
       " ('plongeoir', 'branch'),\n",
       " ('camions', 'motocross'),\n",
       " ('magazines', 'racer'),\n",
       " ('boulangerie', \"'\"),\n",
       " ('médecin', 'bars'),\n",
       " ('âne', 'balding'),\n",
       " ('montgolfières', 'plant'),\n",
       " ('centre', 'catcher'),\n",
       " ('plongée', 'choir'),\n",
       " ('wagon', 'sleeping'),\n",
       " ('promenade', 'japanese'),\n",
       " ('poney', 'microphones'),\n",
       " ('craie', 'tents'),\n",
       " ('4', 'long-sleeve'),\n",
       " ('imprimé', 'waters'),\n",
       " ('casquettes', 'karate'),\n",
       " ('pliante', 'surf'),\n",
       " ('fleur', 'only'),\n",
       " ('capot', 'opponent'),\n",
       " ('différents', 'polka'),\n",
       " ('types', 'bass'),\n",
       " ('mec', 'rainbow'),\n",
       " ('adverse', 'sleeveless'),\n",
       " ('maquillage', 'sewing'),\n",
       " ('porche', 'wooded'),\n",
       " ('torches', 'rain'),\n",
       " ('galets', 'pigeons'),\n",
       " ('blue', 'blocks'),\n",
       " ('light', 'parked'),\n",
       " ('extérieure', 'headscarf'),\n",
       " ('navire', 'plates'),\n",
       " ('bijoux', 'naked'),\n",
       " ('côte', 'passengers'),\n",
       " ('debout', 'tray'),\n",
       " ('pistes', 'cups'),\n",
       " ('dreadlocks', 'smoke'),\n",
       " ('complexe', 'flip-flops'),\n",
       " ('surface', 'cardboard'),\n",
       " ('grue', 'jewelry'),\n",
       " ('monde', 'half'),\n",
       " ('gazon', 'sofa'),\n",
       " ('5', 'button'),\n",
       " ('hauts', 'eye'),\n",
       " ('nourrisson', 'peace'),\n",
       " ('seule', 'color'),\n",
       " ('bulle', 'low'),\n",
       " ('terrier', 'lit'),\n",
       " ('carnaval', 'stove'),\n",
       " ('publicité', 'spray'),\n",
       " ('grosses', 'fruits'),\n",
       " ('monocycle', 'deep'),\n",
       " ('murs', 'smaller'),\n",
       " ('bonnets', 'elephant'),\n",
       " ('tuiles', 'day'),\n",
       " ('afro-américains', 'narrow'),\n",
       " ('agents', 'backs'),\n",
       " ('cuillère', 'scuba'),\n",
       " ('dessin', 'course'),\n",
       " ('imposante', 'security'),\n",
       " ('reflet', 'liquid'),\n",
       " ('marbre', 'suitcase'),\n",
       " ('hanches', 'steep'),\n",
       " ('plateau', 'block'),\n",
       " ('roues', 'star'),\n",
       " ('deere', 'dishes'),\n",
       " ('fortune', 'fisherman'),\n",
       " ('baril', 'carpet'),\n",
       " ('jambe', 'subway'),\n",
       " ('gauche', 'fur'),\n",
       " ('bon', 'bushes'),\n",
       " ('chandail', 'rubber'),\n",
       " ('travaille', 'diving'),\n",
       " ('face', 'lamp'),\n",
       " ('poissons', 'fresh'),\n",
       " ('officier', 'skater'),\n",
       " ('pancarte', 'fallen'),\n",
       " ('bonbons', 'pizza'),\n",
       " ('pâle', 'firemen'),\n",
       " ('bicyclette', 'eight'),\n",
       " ('estrade', 'gas'),\n",
       " ('pavé', 'porch'),\n",
       " ('four', 'ribbon'),\n",
       " ('façon', 'cobblestone'),\n",
       " ('vidéo', 'play'),\n",
       " ('hawaïenne', 'uniformed'),\n",
       " ('chaîne', 'doctor'),\n",
       " ('restauration', 'dreadlocks'),\n",
       " ('rues', 'objects'),\n",
       " ('rails', 'taxi'),\n",
       " ('natation', 'knife'),\n",
       " ('chiots', 'pan'),\n",
       " ('banjo', 'project'),\n",
       " ('immeubles', 'frame'),\n",
       " ('ce', 'swimmers'),\n",
       " ('plongeur', 'athletes'),\n",
       " ('ange', 'barbecue'),\n",
       " ('africain', 'knees'),\n",
       " ('danseurs', 'electronic'),\n",
       " ('batte', 'greyhound'),\n",
       " ('se', 'crane'),\n",
       " ('tomates', 'entrance'),\n",
       " ('sourire', 'softball'),\n",
       " ('employé', 'tile'),\n",
       " ('obstacle', 'barrel'),\n",
       " ('escalade', 'gravel'),\n",
       " ('jolie', 'image'),\n",
       " ('écharpes', 'tower'),\n",
       " ('bac', 'barber'),\n",
       " ('jet', 'ropes'),\n",
       " ('imperméable', 'gray-haired'),\n",
       " ('marine', 'office'),\n",
       " ('silhouette', 'wear'),\n",
       " ('pot', 'castle'),\n",
       " ('bondé', 'coach'),\n",
       " ('fil', 'sink'),\n",
       " ('dj', 'buckets'),\n",
       " ('or', 'bouquet'),\n",
       " ('décontractée', 'doors'),\n",
       " ('photos', 'item'),\n",
       " ('dune', 'indoor'),\n",
       " ('robot', 'furry'),\n",
       " ('différentes', 'wide'),\n",
       " ('tentes', 'wings'),\n",
       " ('volley', 'single'),\n",
       " ('dorée', 'gym'),\n",
       " ('exposition', 'orchestra'),\n",
       " ('lampadaire', 'jockey'),\n",
       " ('campagne', 'candles'),\n",
       " ('morceaux', 'artwork'),\n",
       " ('pleine', 'youth'),\n",
       " ('gâteaux', 'stack'),\n",
       " ('coffre', 'eastern'),\n",
       " ('féminin', 'collared'),\n",
       " ('coup', 'style'),\n",
       " ('anniversaire', 'groups'),\n",
       " ('chaussettes', 'steel'),\n",
       " ('couvertures', 'wheels'),\n",
       " ('salade', 'african-american'),\n",
       " ('tambour', 'square'),\n",
       " ('motocyclette', 'chicken'),\n",
       " ('heureux', 'pillow'),\n",
       " ('branche', 'well'),\n",
       " ('calmes', 'puck'),\n",
       " ('attelage', 'numbers'),\n",
       " ('allée', 'standing'),\n",
       " ('tricycle', 'donkey'),\n",
       " ('cage', 'handstand'),\n",
       " ('radeau', 'pottery'),\n",
       " ('portant', 'lift'),\n",
       " ('collines', 'shadow'),\n",
       " ('liquide', 'ethnic'),\n",
       " ('rondins', 'calf'),\n",
       " ('cabine', 'apple'),\n",
       " ('endormi', 'circle'),\n",
       " ('cow-boys', 'barrier'),\n",
       " ('bande', 'folding'),\n",
       " ('boisé', 'vendors'),\n",
       " ('chaque', 'step'),\n",
       " ('décor', 'gown'),\n",
       " ('plancher', 'local'),\n",
       " ('éclairée', 'pit'),\n",
       " ('paysage', 'parents'),\n",
       " ('évier', 'things'),\n",
       " ('trépied', 'fireman'),\n",
       " ('brillantes', 'lunch'),\n",
       " ('feuille', 'patterned'),\n",
       " ('forêt', 'kite'),\n",
       " ('déchets', 'teen'),\n",
       " ('vives', 'part'),\n",
       " ('armes', 'site'),\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "man\n",
      "the\n",
      "of\n",
      "woman\n",
      "two\n",
      "people\n",
      "young\n",
      "shirt\n",
      "an\n",
      "white\n",
      "black\n",
      "blue\n",
      "his\n",
      "red\n",
      "men\n",
      "girl\n",
      "boy\n",
      "dog\n",
      "group\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(freq_comparison[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word look up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'punching-ball'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2ac1189ca598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_corpus_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"punching-ball\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'punching-ball'"
     ]
    }
   ],
   "source": [
    "training_corpus_dct.token2id[\"punching-ball\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'monospace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-110ff56761b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_corpus_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"monospace\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'monospace'"
     ]
    }
   ],
   "source": [
    "training_corpus_dct.token2id[\"monospace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'parapluies'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f3eab1706941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_corpus_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"parapluies\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'parapluies'"
     ]
    }
   ],
   "source": [
    "training_corpus_dct.token2id[\"parapluies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = torchtext.vocab.GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noted that in GloVe, there is no unknown word token, nor empty word token. \n",
    "Here we use index=1, which is '.' as empty word token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = train_df[\"entity_content\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.STEMMING:\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    corpus = [[stemmer.stem(w) for w in word_tokenize(q)] for q in corpus_list]\n",
    "else: \n",
    "    corpus = [[w.lower() for w in word_tokenize(q)] for q in corpus_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['two', 'young', 'guys'],\n",
       " ['shaggy', 'hair'],\n",
       " ['their', 'hands'],\n",
       " ['two', 'young', ',', 'white', 'males'],\n",
       " ['many', 'bushes'],\n",
       " ['two', 'men'],\n",
       " ['green', 'shirts'],\n",
       " ['a', 'man'],\n",
       " ['a', 'blue', 'shirt'],\n",
       " ['two', 'friends'],\n",
       " ['several', 'men'],\n",
       " ['hard', 'hats'],\n",
       " ['a', 'giant', 'pulley', 'system'],\n",
       " ['workers'],\n",
       " ['a', 'piece', 'of', 'equipment'],\n",
       " ['two', 'men'],\n",
       " ['a', 'machine'],\n",
       " ['hard', 'hats'],\n",
       " ['four', 'men'],\n",
       " ['a', 'tall', 'structure'],\n",
       " ['three', 'men'],\n",
       " ['a', 'large', 'rig'],\n",
       " ['a', 'child'],\n",
       " ['a', 'pink', 'dress'],\n",
       " ['a', 'set', 'of', 'stairs'],\n",
       " ['an', 'entry', 'way'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['a', 'pink', 'dress'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['the', 'stairs'],\n",
       " ['her', 'playhouse'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['a', 'wooden', 'playhouse'],\n",
       " ['a', 'girl'],\n",
       " ['someone'],\n",
       " ['a', 'blue', 'shirt'],\n",
       " ['hat'],\n",
       " ['stair'],\n",
       " ['a', 'window'],\n",
       " ['a', 'man'],\n",
       " ['a', 'blue', 'shirt'],\n",
       " ['a', 'ladder'],\n",
       " ['a', 'window'],\n",
       " ['a', 'man'],\n",
       " ['a', 'ladder'],\n",
       " ['the', 'window', 'of', 'a', 'tall', 'building'],\n",
       " ['man'],\n",
       " ['blue', 'shirt'],\n",
       " ['jeans'],\n",
       " ['ladder'],\n",
       " ['windows'],\n",
       " ['a', 'man'],\n",
       " ['a', 'ladder'],\n",
       " ['a', 'window'],\n",
       " ['two', 'men'],\n",
       " ['one'],\n",
       " ['a', 'gray', 'shirt'],\n",
       " ['one'],\n",
       " ['a', 'black', 'shirt'],\n",
       " ['a', 'stove'],\n",
       " ['two', 'guy'],\n",
       " ['two', 'men'],\n",
       " ['food'],\n",
       " ['a', 'stove'],\n",
       " ['two', 'men'],\n",
       " ['the', 'stove'],\n",
       " ['food'],\n",
       " ['two', 'men'],\n",
       " ['a', 'meal'],\n",
       " ['two', 'people'],\n",
       " ['the', 'guitar'],\n",
       " ['the', 'other'],\n",
       " ['a', 'man'],\n",
       " ['green'],\n",
       " ['a', 'guitar'],\n",
       " ['the', 'other', 'man'],\n",
       " ['his', 'shirt'],\n",
       " ['a', 'man'],\n",
       " ['the', 'guitar', 'players', 'costume'],\n",
       " ['a', 'guy'],\n",
       " ['another', 'man', \"'s\", 'coat'],\n",
       " ['the', 'two', 'boys'],\n",
       " ['guitar'],\n",
       " ['a', 'man'],\n",
       " ['a', 'chair'],\n",
       " ['a', 'large', 'stuffed', 'animal', 'of', 'a', 'lion'],\n",
       " ['a', 'man'],\n",
       " ['a', 'chair'],\n",
       " ['a', 'large', 'stuffed', 'animal'],\n",
       " ['a', 'man'],\n",
       " ['the', 'finishing', 'touches'],\n",
       " ['a', 'stuffed', 'lion'],\n",
       " ['a', 'man'],\n",
       " ['a', 'large', 'stuffed', 'lion', 'toy'],\n",
       " ['a', 'man'],\n",
       " ['a', 'stuffed', 'lion'],\n",
       " ['a', 'girl'],\n",
       " ['rollerskates'],\n",
       " ['her', 'cellphone'],\n",
       " ['a', 'parking', 'lot'],\n",
       " ['a', 'trendy', 'girl'],\n",
       " ['her', 'cellphone'],\n",
       " ['the', 'street'],\n",
       " ['a', 'young', 'adult'],\n",
       " ['rollerblades'],\n",
       " ['a', 'cellular', 'phone'],\n",
       " ['a', 'young', 'girl'],\n",
       " ['her', 'cellphone'],\n",
       " ['skating'],\n",
       " ['woman'],\n",
       " ['cellphone'],\n",
       " ['rollerskates'],\n",
       " ['an', 'asian', 'man'],\n",
       " ['a', 'black', 'suit'],\n",
       " ['a', 'dark-haired', 'woman'],\n",
       " ['a', 'brown-haired', 'woman'],\n",
       " ['three', 'people'],\n",
       " ['large', 'pipes'],\n",
       " ['a', 'metal', 'railing'],\n",
       " ['a', 'young', 'woman'],\n",
       " ['two', 'young', 'people'],\n",
       " ['hip', 'black', 'outfits'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'large', 'purse'],\n",
       " ['a', 'gate'],\n",
       " ['several', 'people'],\n",
       " ['a', 'building'],\n",
       " ['two', 'men'],\n",
       " ['a', 'rail'],\n",
       " ['shirts'],\n",
       " ['two', 'youths'],\n",
       " ['a', 'roadside', 'railing'],\n",
       " ['boys'],\n",
       " ['poles'],\n",
       " ['two', 'men'],\n",
       " ['no', 'shirts'],\n",
       " ['a', 'rail'],\n",
       " ['two', 'guys'],\n",
       " ['a', 'gate'],\n",
       " ['five', 'ballet', 'dancers'],\n",
       " ['a', 'window'],\n",
       " ['ballet', 'dancers'],\n",
       " ['five', 'girls'],\n",
       " ['five', 'girls'],\n",
       " ['feet'],\n",
       " ['a', 'ballet', 'class', 'of', 'five', 'girls'],\n",
       " ['three', 'young', 'men'],\n",
       " ['a', 'young', 'woman'],\n",
       " ['sneakers'],\n",
       " ['the', 'top', 'of', 'a', 'flight'],\n",
       " ['four', 'casually', 'dressed', 'guys'],\n",
       " ['a', 'stone', 'wall'],\n",
       " ['four', 'guys'],\n",
       " ['hats'],\n",
       " ['one'],\n",
       " ['the', 'top', 'of', 'a', 'staircase'],\n",
       " ['four', 'men'],\n",
       " ['excited', 'faces'],\n",
       " ['the', 'top', 'of', 'stairs'],\n",
       " ['four', 'people'],\n",
       " ['a', 'black', 'dog'],\n",
       " ['a', 'white', 'dog'],\n",
       " ['brown', 'spots'],\n",
       " ['the', 'street'],\n",
       " ['a', 'black', 'dog'],\n",
       " ['a', 'tri-colored', 'dog'],\n",
       " ['the', 'road'],\n",
       " ['two', 'dogs', 'of', 'different', 'breeds'],\n",
       " ['the', 'road'],\n",
       " ['two', 'dogs'],\n",
       " ['pavement'],\n",
       " ['a', 'black', 'dog'],\n",
       " ['a', 'spotted', 'dog'],\n",
       " ['a', 'man'],\n",
       " ['reflective', 'safety', 'clothes'],\n",
       " ['ear', 'protection'],\n",
       " ['a', 'john', 'deere', 'tractor'],\n",
       " ['a', 'road'],\n",
       " ['john', 'deere'],\n",
       " ['a', 'street'],\n",
       " ['the', 'driver'],\n",
       " ['easy', 'to', 'see', 'clothing'],\n",
       " ['a', 'man'],\n",
       " ['orange', 'uniform'],\n",
       " ['a', 'green', 'tractor'],\n",
       " ['a', 'man'],\n",
       " ['headphones'],\n",
       " ['a', 'paved', 'street'],\n",
       " ['a', 'man'],\n",
       " ['a', 'john', 'deere', 'tractor'],\n",
       " ['a', 'main', 'road'],\n",
       " ['some', 'women'],\n",
       " ['buildings'],\n",
       " ['several', 'women'],\n",
       " ['tall', 'buildings'],\n",
       " ['a', 'group', 'of', 'women'],\n",
       " ['several', 'women'],\n",
       " ['women'],\n",
       " ['a', 'young', 'woman'],\n",
       " ['dark', 'hair'],\n",
       " ['glasses'],\n",
       " ['white', 'powder'],\n",
       " ['a', 'cake'],\n",
       " ['a', 'sifter'],\n",
       " ['a', 'lady'],\n",
       " ['a', 'black', 'top'],\n",
       " ['glasses'],\n",
       " ['powdered', 'sugar'],\n",
       " ['a', 'bundt', 'cake'],\n",
       " ['a', 'woman'],\n",
       " ['glasses', 'sprinkles'],\n",
       " ['sugar'],\n",
       " ['her', 'bundt', 'cake'],\n",
       " ['girl'],\n",
       " ['black', 'jacket'],\n",
       " ['powdered', 'sugar'],\n",
       " ['a', 'chocolate', 'cake'],\n",
       " ['a', 'standing', 'woman'],\n",
       " ['a', 'pan'],\n",
       " ['a', 'cake'],\n",
       " ['a', 'small', 'girl'],\n",
       " ['the', 'grass'],\n",
       " ['fingerpaints'],\n",
       " ['a', 'white', 'canvas'],\n",
       " ['a', 'rainbow'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['paint'],\n",
       " ['a', 'painted', 'rainbow'],\n",
       " ['her', 'hands'],\n",
       " ['a', 'bowl'],\n",
       " ['a', 'girl'],\n",
       " ['pigtails'],\n",
       " ['a', 'rainbow', 'painting'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['a', 'large', 'painted', 'rainbow'],\n",
       " ['young', 'girl'],\n",
       " ['pigtails'],\n",
       " ['the', 'grass'],\n",
       " ['a', 'man'],\n",
       " ['a', 'bench'],\n",
       " ['a', 'white', 'and', 'black', 'dog'],\n",
       " ['a', 'man'],\n",
       " ['the', 'bench'],\n",
       " ['a', 'white', 'dog'],\n",
       " ['man'],\n",
       " ['bench'],\n",
       " ['leash', 'of', 'dog'],\n",
       " ['a', 'shirtless', 'man'],\n",
       " ['a', 'park', 'bench'],\n",
       " ['his', 'dog'],\n",
       " ['a', 'man'],\n",
       " ['a', 'bench'],\n",
       " ['his', 'dog'],\n",
       " ['a', 'group', 'of', 'adults'],\n",
       " ['chairs'],\n",
       " ['a', 'circle'],\n",
       " ['a', 'type', 'of', 'musical', 'instruments'],\n",
       " ['five', 'musicians'],\n",
       " ['a', 'man'],\n",
       " ['four', 'women'],\n",
       " ['sheet', 'music'],\n",
       " ['flutes'],\n",
       " ['people'],\n",
       " ['a', 'circle'],\n",
       " ['some'],\n",
       " ['musical', 'instruments'],\n",
       " ['people'],\n",
       " ['five', 'people'],\n",
       " ['a', 'circle'],\n",
       " ['instruments'],\n",
       " ['two', 'women'],\n",
       " ['glasses'],\n",
       " ['clarinets'],\n",
       " ['an', 'elderly', 'woman'],\n",
       " ['a', 'stringed', 'instrument'],\n",
       " ['at', 'least', 'four', 'instrumentalists'],\n",
       " ['clarinets'],\n",
       " ['other', 'instruments'],\n",
       " ['four', 'women'],\n",
       " ['a', 'musical', 'instrument'],\n",
       " ['a', 'bunch', 'of', 'elderly', 'women'],\n",
       " ['their', 'clarinets'],\n",
       " ['sheet', 'music'],\n",
       " ['a', 'group', 'of', 'four', 'women'],\n",
       " ['their', 'instruments'],\n",
       " ['a', 'person'],\n",
       " ['gray'],\n",
       " ['a', 'structure'],\n",
       " ['a', 'large', 'structure'],\n",
       " ['a', 'roadway'],\n",
       " ['a', 'man'],\n",
       " ['a', 'gray', 'coat'],\n",
       " ['a', 'washed', 'out', 'bridge'],\n",
       " ['a', 'man'],\n",
       " ['wooden', 'supports'],\n",
       " ['a', 'man'],\n",
       " ['a', 'jacket'],\n",
       " ['jeans'],\n",
       " ['a', 'bridge'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 't-shirt'],\n",
       " ['a', 'crowd'],\n",
       " ['a', 'large', 'crowd', 'of', 'people'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['a', 'crowd'],\n",
       " ['crowd'],\n",
       " ['a', 'man'],\n",
       " ['a', 'goatee'],\n",
       " ['a', 'black', 'shirt'],\n",
       " ['white', 'latex', 'gloves'],\n",
       " ['a', 'tattoo', 'gun'],\n",
       " ['a', 'tattoo'],\n",
       " ['someone', \"'s\", 'back'],\n",
       " ['a', 'man'],\n",
       " ['a', 'tattoo'],\n",
       " ['a', 'another', \"'s\", 'man'],\n",
       " ['a', 'man'],\n",
       " ['a', 'black', 'shirt'],\n",
       " ['another', 'man'],\n",
       " ['a', 'tattoo'],\n",
       " ['a', 'man'],\n",
       " ['tattoo'],\n",
       " ['his', 'back'],\n",
       " ['a', 'man'],\n",
       " ['a', 'tattoo'],\n",
       " ['his', 'back'],\n",
       " ['two', 'children'],\n",
       " ['a', 'girl'],\n",
       " ['a', 'boy'],\n",
       " ['two', 'children'],\n",
       " ['a', 'small', 'seesaw'],\n",
       " ['the', 'sand'],\n",
       " ['two', 'children'],\n",
       " ['a', 'teeter', 'totter'],\n",
       " ['2', 'kids'],\n",
       " ['a', 'seesaw'],\n",
       " ['two', 'kids'],\n",
       " ['a', 'seesaw'],\n",
       " ['a', 'man'],\n",
       " ['a', 'blue', 'hard', 'hat'],\n",
       " ['orange', 'safety', 'vest'],\n",
       " ['an', 'intersection'],\n",
       " ['a', 'flag'],\n",
       " ['a', 'man'],\n",
       " ['a', 'hard', 'hat'],\n",
       " ['a', 'caution', 'vest'],\n",
       " ['the', 'street'],\n",
       " ['an', 'orange', 'flag'],\n",
       " ['a', 'man'],\n",
       " ['bright', 'vest'],\n",
       " ['hard', 'hat'],\n",
       " ['a', 'flag'],\n",
       " ['a', 'street', 'corner'],\n",
       " ['spray', 'paint'],\n",
       " ['a', 'construction', 'worker'],\n",
       " ['the', 'street'],\n",
       " ['a', 'red', 'flag'],\n",
       " ['a', 'man'],\n",
       " ['a', 'reflective', 'vest'],\n",
       " ['a', 'hard', 'hat'],\n",
       " ['a', 'flag'],\n",
       " ['the', 'road'],\n",
       " ['a', 'person'],\n",
       " ['long', 'gray', 'hair'],\n",
       " ['a', 'beret'],\n",
       " ['beige', 'and', 'white'],\n",
       " ['a', 'blue', 'raincoat'],\n",
       " ['other', 'artists'],\n",
       " ['paintings'],\n",
       " ['a', 'person'],\n",
       " ['a', 'blue', 'coat'],\n",
       " ['a', 'busy', 'sidewalk'],\n",
       " ['painting', 'of', 'a', 'street', 'scene'],\n",
       " ['a', 'person'],\n",
       " ['gray', 'hair'],\n",
       " ['a', 'public', 'place'],\n",
       " ['others'],\n",
       " ['lady'],\n",
       " ['blue', 'coat'],\n",
       " ['white', 'and', 'brown', 'hat'],\n",
       " ['a', 'painting'],\n",
       " ['passerby'],\n",
       " ['painting'],\n",
       " ['an', 'outdoor', 'art', 'fair'],\n",
       " ['a', 'man'],\n",
       " ['one', 'foot'],\n",
       " ['a', 'waste', 'basket'],\n",
       " ['a', 'man'],\n",
       " ['green', 'pants'],\n",
       " ['blue', 'shirt'],\n",
       " ['a', 'cart'],\n",
       " ['janitor'],\n",
       " ['dolly'],\n",
       " ['janitor', 'tools'],\n",
       " ['a', 'man'],\n",
       " ['green', 'pants'],\n",
       " ['the', 'road'],\n",
       " ['a', 'man'],\n",
       " ['bright', 'pants'],\n",
       " ['a', 'cart'],\n",
       " ['a', 'small', 'child'],\n",
       " ['the', 'red', 'ropes'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['pink'],\n",
       " ['a', 'rope', 'bridge'],\n",
       " ['the', 'small', 'child'],\n",
       " ['a', 'red'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['red', 'roping'],\n",
       " ['a', 'child'],\n",
       " ['a', 'rope', 'net'],\n",
       " ['young', 'man'],\n",
       " ['jacket'],\n",
       " ['a', 'toothpick'],\n",
       " ['something'],\n",
       " ['a', 'young', 'man'],\n",
       " ['a', 'piece', 'of', 'flower'],\n",
       " ['his', 'hands'],\n",
       " ['a', 'teen'],\n",
       " ['an', 'unknown', 'object'],\n",
       " ['a', 'young', 'man'],\n",
       " ['an', 'origami', 'crane'],\n",
       " ['young', 'blond', 'man'],\n",
       " ['a', 'blue', 'and', 'yellow', 'jacket'],\n",
       " ['a', 'net'],\n",
       " ['a', 'young', 'man'],\n",
       " ['a', 'black', 'and', 'yellow', 'jacket'],\n",
       " ['a', 'young', 'man'],\n",
       " ['a', 'pole', 'vault'],\n",
       " ['a', 'man'],\n",
       " ['a', 'pole'],\n",
       " ['a', 'smiling', 'man'],\n",
       " ['the', 'sky'],\n",
       " ['a', 'man'],\n",
       " ['a', 'baseball', 'cap'],\n",
       " ['black', 'jacket'],\n",
       " ['a', 'coffee', 'mug'],\n",
       " ['a', 'man'],\n",
       " ['a', 'ball', 'cap'],\n",
       " ['a', 'coffee', 'cup'],\n",
       " ['urinals'],\n",
       " ['a', 'man'],\n",
       " ['a', 'urinal'],\n",
       " ['a', 'cup', 'of', 'coffee'],\n",
       " ['a', 'man'],\n",
       " ['a', 'coffee', 'cup'],\n",
       " ['a', 'man'],\n",
       " ['a', 'urinal'],\n",
       " ['a', 'coffee', 'cup'],\n",
       " ['five', 'people'],\n",
       " ['four', 'people'],\n",
       " ['clear', 'blue', 'skies'],\n",
       " ['four', 'people'],\n",
       " ['the', 'sun'],\n",
       " ['four', 'silhouettes'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['the', 'sun'],\n",
       " ['a', 'man'],\n",
       " ['black', 'hair'],\n",
       " ['a', 'glass', 'of', 'beer'],\n",
       " ['a', 'man'],\n",
       " ['a', 'table'],\n",
       " ['a', 'drink'],\n",
       " ['a', 'man'],\n",
       " ['a', 'table'],\n",
       " ['a', 'beer'],\n",
       " ['a', 'dark-haired', 'man'],\n",
       " ['a', 'old', 'man'],\n",
       " ['a', 'beer'],\n",
       " ['an', 'officer'],\n",
       " ['a', 'reflective', 'vest'],\n",
       " ['the', 'front', 'of', 'his', 'van'],\n",
       " ['his', 'dog'],\n",
       " ['a', 'trained', 'police', 'dog'],\n",
       " ['his', 'handler'],\n",
       " ['the', 'police', 'van'],\n",
       " ['a', 'security', 'man'],\n",
       " ['his', 'watch', 'dog'],\n",
       " ['a', 'policeman'],\n",
       " ['a', 'german', 'shepherd', 'dog'],\n",
       " ['a', 'policeman'],\n",
       " ['a', 'street'],\n",
       " ['a', 'search', 'dog'],\n",
       " ['the', '``', 'white', 'out', '``', 'conditions', 'of', 'snow'],\n",
       " ['the', 'details', 'of', 'a', 'man'],\n",
       " ['a', 'heavy', 'jacket'],\n",
       " ['red', 'hat'],\n",
       " ['a', 'bicycle'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['a', 'bike'],\n",
       " ['a', 'snow'],\n",
       " ['a', 'boy'],\n",
       " ['the', 'snow'],\n",
       " ['his', 'bike'],\n",
       " ['a', 'person'],\n",
       " ['a', 'bike'],\n",
       " ['a', 'snowy', 'road'],\n",
       " ['a', 'person'],\n",
       " ['a', 'bike'],\n",
       " ['snow'],\n",
       " ['five', 'men'],\n",
       " ['white', 'shirts'],\n",
       " ['tie'],\n",
       " ['black', 'slacks'],\n",
       " ['the', 'back', 'of', 'an', 'open', 'van'],\n",
       " ['small', 'group', 'of', '5', 'white', 'males'],\n",
       " ['white', 'suits'],\n",
       " ['the', 'back', 'of', 'a', 'van'],\n",
       " ['a', 'parking', 'lot'],\n",
       " ['five', 'men'],\n",
       " ['white', 'short-sleeved', 'shirts'],\n",
       " ['ties'],\n",
       " ['a', 'parking', 'lot'],\n",
       " ['a', 'group', 'of', 'men'],\n",
       " ['ties'],\n",
       " ['the', 'street'],\n",
       " ['colleges', 'stop'],\n",
       " ['a', 'tan', 'man'],\n",
       " ['hat'],\n",
       " ['older', 'man'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 'shirt'],\n",
       " ['black', 'camp'],\n",
       " ['many', 'machines'],\n",
       " ['a', 'man'],\n",
       " ['hat'],\n",
       " ['machinery'],\n",
       " ['a', 'man'],\n",
       " ['a', 'backwards', 'cap'],\n",
       " ['a', 'caucasian', 'man'],\n",
       " ['a', 'short-sleeved', 'black', 'shirt'],\n",
       " ['a', 'dark-skinned', 'woman'],\n",
       " ['a', 'sleeveless', 'dress'],\n",
       " ['a', 'conveyor'],\n",
       " ['a', 'black', 'woman'],\n",
       " ['a', 'white', 'man'],\n",
       " ['packing', 'jars'],\n",
       " ['candles'],\n",
       " ['boxes'],\n",
       " ['a', 'woman'],\n",
       " ['white', 'tall', 'candles'],\n",
       " ['a', 'man'],\n",
       " ['a', 'green', 'shirt'],\n",
       " ['a', 'warehouse', 'manager'],\n",
       " ['an', 'employee'],\n",
       " ['two', 'people'],\n",
       " ['an', 'assembly', 'line'],\n",
       " ['man'],\n",
       " ['a', 'blue', 'and', 'white', 'outfit'],\n",
       " ['a', 'broom'],\n",
       " ['a', 'traditional', 'asian', 'architecture'],\n",
       " ['a', 'asian', 'man'],\n",
       " ['a', 'white', 'top'],\n",
       " ['baby', 'blue', 'bottoms'],\n",
       " ['a', 'broom'],\n",
       " ['the', 'dirt', 'of', 'the', 'pavement'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 'and', 'blue', 'kimono'],\n",
       " ['a', 'broom'],\n",
       " ['pavement'],\n",
       " ['man'],\n",
       " ['the', 'street'],\n",
       " ['asian', 'man'],\n",
       " ['the', 'walkway'],\n",
       " ['two', 'men'],\n",
       " ['florescent', 'vests'],\n",
       " ['parked', 'cars'],\n",
       " ['a', 'small', 'building'],\n",
       " ['a', 'driver'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'bike'],\n",
       " ['a', 'man'],\n",
       " ['a', 'car'],\n",
       " ['the', 'driver'],\n",
       " ['a', 'man'],\n",
       " ['a', 'bicycle'],\n",
       " ['a', 'man'],\n",
       " ['a', 'bicycle'],\n",
       " ['a', 'row', 'of', 'cars'],\n",
       " ['a', 'checkpoint'],\n",
       " ['a', 'park', 'ranger'],\n",
       " ['a', 'tourist'],\n",
       " ['two', 'cars'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['a', 'pink', 'shirt'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['an', 'orange', 'shirt'],\n",
       " ['two', 'young', 'children'],\n",
       " ['a', 'snack'],\n",
       " ['two', 'young', 'toddlers'],\n",
       " ['two', 'infants'],\n",
       " ['2', 'female', 'babies'],\n",
       " ['chips'],\n",
       " ['a', 'person'],\n",
       " ['tan', 'pants'],\n",
       " ['a', 'silver', 'mobile', 'object'],\n",
       " ['people'],\n",
       " ['people'],\n",
       " ['a', 'person'],\n",
       " ['a', 'weird', 'vehicle'],\n",
       " ['a', 'man'],\n",
       " ['a', 'blue', 'shirt'],\n",
       " ['a', 'segway', 'type', 'vehicle'],\n",
       " ['a', 'showing', 'of', 'product'],\n",
       " ['a', 'crowd'],\n",
       " ['modern', 'art'],\n",
       " ['a', 'man'],\n",
       " ['a', 'strange', 'silver', 'object'],\n",
       " ['a', 'person'],\n",
       " ['many', 'onlookers'],\n",
       " ['a', 'roped', 'off', 'barrier'],\n",
       " ['a', 'person'],\n",
       " ['a', 'futuristic', 'looking', 'vehicle'],\n",
       " ['a', 'man'],\n",
       " ['a', 'crowd'],\n",
       " ['a', 'person'],\n",
       " ['a', 'futuristic', 'single-person', 'vehicle'],\n",
       " ['man'],\n",
       " ['silver', '4-wheeled', 'chair'],\n",
       " ['a', 'man'],\n",
       " ['a', 'silver', 'vehicle'],\n",
       " ['bride'],\n",
       " ['groom'],\n",
       " ['pathway'],\n",
       " ['brick', 'building'],\n",
       " ['a', 'beautiful', 'bride'],\n",
       " ['a', 'sidewalk'],\n",
       " ['her', 'new', 'husband'],\n",
       " ['a', 'recently', 'married', 'couple'],\n",
       " ['a', 'groom'],\n",
       " ['bride'],\n",
       " ['a', 'couple'],\n",
       " ['a', 'little', 'boy'],\n",
       " ['a', 'nintendo', 'gamecube', 'controller'],\n",
       " ['a', 'mcdonald'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['a', 'video', 'game'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['a', 'gamecube', 'kiosk'],\n",
       " ['mcdonald'],\n",
       " ['a', 'little', 'boy'],\n",
       " ['gamecube'],\n",
       " ['a', 'mcdonald'],\n",
       " ['a', 'little', 'kid'],\n",
       " ['gamecube'],\n",
       " ['mcdonald'],\n",
       " ['white', 'dog'],\n",
       " ['brown', 'ears'],\n",
       " ['water'],\n",
       " ['head'],\n",
       " ['dog'],\n",
       " ['orange', 'ball'],\n",
       " ['feet'],\n",
       " ['shore'],\n",
       " ['water'],\n",
       " ['a', 'white', 'dog'],\n",
       " ['the', 'edge', 'of', 'a', 'beach'],\n",
       " ['an', 'orange', 'ball'],\n",
       " ['white', 'dog'],\n",
       " ['a', 'red', 'ball'],\n",
       " ['the', 'shore'],\n",
       " ['the', 'water'],\n",
       " ['a', 'dog'],\n",
       " ['its', 'head'],\n",
       " ['the', 'shore'],\n",
       " ['a', 'red', 'ball'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['picnic', 'tables'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['the', 'reunion'],\n",
       " ['a', 'moon', 'bounce'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['two', 'asian', 'or', 'spanish', 'people'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'man'],\n",
       " ['a', 'glass', 'window'],\n",
       " ['cars'],\n",
       " ['a', 'man'],\n",
       " ['sunglasses'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'black', 'and', 'white', 'blouse'],\n",
       " ['a', 'man'],\n",
       " ['sunglasses'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'man'],\n",
       " ['woman'],\n",
       " ['an', 'asian', 'couple'],\n",
       " ['the', 'bench'],\n",
       " ['women'],\n",
       " ['a', 'picnic', 'table'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 't-shirt'],\n",
       " ['a', 'yellow', 'and', 'orange', 'balloon', 'design'],\n",
       " ['his', 'head'],\n",
       " ['an', 'elderly', 'woman'],\n",
       " ['a', 'burger'],\n",
       " ['the', 'man'],\n",
       " ['his', 'hat'],\n",
       " ['a', 'man'],\n",
       " ['a', 'balloon', 'hat'],\n",
       " ['people'],\n",
       " ['picnic', 'tables'],\n",
       " ['two', 'older', 'women'],\n",
       " ['a', 'table'],\n",
       " ['two', 'coolers'],\n",
       " ['a', 'gray-haired', 'person'],\n",
       " ['glasses'],\n",
       " ['a', 'sandwich'],\n",
       " ['two', 'people'],\n",
       " ['a', 'crowd'],\n",
       " ['three', 'youngsters'],\n",
       " ['the', 'mat'],\n",
       " ['a', 'boy'],\n",
       " ['three', 'kids'],\n",
       " ['wood'],\n",
       " ['a', 'boy'],\n",
       " ['three', 'other', 'students'],\n",
       " ['a', 'crowd'],\n",
       " ['a', 'group', 'of', 'five', 'martial', 'artists'],\n",
       " ['a', 'crowd', 'of', 'people'],\n",
       " ['people'],\n",
       " ['two', 'balconies'],\n",
       " ['a', 'man'],\n",
       " ['a', 'pipe'],\n",
       " ['the', 'lower', 'balcony'],\n",
       " ['liquid'],\n",
       " ['a', 'kid'],\n",
       " ['a', 'red', 'sweatshirt'],\n",
       " ['something'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 'shirt'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['a', 'bottle'],\n",
       " ['the', 'railing', 'of', 'a', 'balcony'],\n",
       " ['the', 'man'],\n",
       " ['a', 'boy'],\n",
       " ['a', 'red', 'jacket'],\n",
       " ['water'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 'shirt'],\n",
       " ['a', 'young', 'man'],\n",
       " ['the', 'contents', 'of', 'a', 'bottle'],\n",
       " ['a', 'man'],\n",
       " ['a', 'red', 'jacket'],\n",
       " ['a', 'piece', 'of', 'paper'],\n",
       " ['a', 'man'],\n",
       " ['a', 'red', 'coat'],\n",
       " ['his', 'hand'],\n",
       " ['his', 'head'],\n",
       " ['a', 'man'],\n",
       " ['a', 'red', 'jacket'],\n",
       " ['his', 'eyes'],\n",
       " ['a', 'busy', 'street'],\n",
       " ['an', 'elderly', 'man'],\n",
       " ['a', 'red', 'jacket'],\n",
       " ['his', 'face'],\n",
       " ['man'],\n",
       " ['red', 'jacket'],\n",
       " ['face'],\n",
       " ['two', 'men'],\n",
       " ['children'],\n",
       " ['the', 'street'],\n",
       " ['two', 'men'],\n",
       " ['each'],\n",
       " ['a', 'small', 'child'],\n",
       " ['a', 'paved', 'road'],\n",
       " ['two', 'men'],\n",
       " ['their', 'two', 'young', 'children'],\n",
       " ['men'],\n",
       " ['a', 'street'],\n",
       " ['children'],\n",
       " ['two', 'men'],\n",
       " ['children'],\n",
       " ['smiling', 'boy'],\n",
       " ['white', 'shirt'],\n",
       " ['blue', 'jeans'],\n",
       " ['rock', 'wall'],\n",
       " ['man'],\n",
       " ['overalls'],\n",
       " ['a', 'little', 'boy'],\n",
       " ['the', 'street'],\n",
       " ['a', 'man'],\n",
       " ['overalls'],\n",
       " ['a', 'stone', 'wall'],\n",
       " ['a', 'young', 'child'],\n",
       " ['a', 'stone', 'paved', 'street'],\n",
       " ['a', 'metal', 'pole'],\n",
       " ['a', 'man'],\n",
       " ['a', 'boy'],\n",
       " ['a', 'stony', 'wall'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['the', 'street'],\n",
       " ['a', 'mottled', 'black', 'and', 'gray', 'dog'],\n",
       " ['a', 'blue', 'collar'],\n",
       " ['a', 'fallen', 'tree'],\n",
       " ['a', 'gray', 'dog'],\n",
       " ['a', 'fallen', 'tree'],\n",
       " ['a', 'large', 'black', 'dog'],\n",
       " ['a', 'fallen', 'log'],\n",
       " ['the', 'black', 'dog'],\n",
       " ['the', 'tree', 'stump'],\n",
       " ['a', 'black', 'dog'],\n",
       " ['a', 'log'],\n",
       " ['men'],\n",
       " ['the', 'business', 'suits'],\n",
       " ['the', 'street'],\n",
       " ['people'],\n",
       " ['placards'],\n",
       " ['the', 'street'],\n",
       " ['a', 'man'],\n",
       " ['a', 'suit'],\n",
       " ['an', 'intersection'],\n",
       " ['a', 'large', 'group', 'of', 'people', 'assembles'],\n",
       " ['a', 'man'],\n",
       " ['a', 'suit'],\n",
       " ['two', 'other', 'gentleman'],\n",
       " ['a', 'suit'],\n",
       " ['a', 'man'],\n",
       " ['a', 'suit'],\n",
       " ['the', 'street'],\n",
       " ['a', 'man'],\n",
       " ['a', 'suit'],\n",
       " ['the', 'street'],\n",
       " ['a', 'man'],\n",
       " ['a', 'red', 'long-sleeved', 'shirt'],\n",
       " ['a', 'body', 'of', 'water'],\n",
       " ['a', 'bridge'],\n",
       " ['a', 'man'],\n",
       " ['his', 'bike'],\n",
       " ['the', 'bridge'],\n",
       " ['the', 'river'],\n",
       " ['a', 'man'],\n",
       " ['red'],\n",
       " ['a', 'bicycle'],\n",
       " ['a', 'glass', 'structure'],\n",
       " ['man'],\n",
       " ['a', 'red', 'shirt'],\n",
       " ['his', 'bicycle'],\n",
       " ['water'],\n",
       " ['a', 'man'],\n",
       " ['a', 'red', 'shirt'],\n",
       " ['his', 'bicycle'],\n",
       " ['a', 'barefooted', 'man'],\n",
       " ['olive', 'green', 'shorts'],\n",
       " ['hotdogs'],\n",
       " ['a', 'small', 'propane', 'grill'],\n",
       " ['a', 'blue', 'plastic', 'cup'],\n",
       " ['a', 'guy'],\n",
       " ['shorts'],\n",
       " ['a', 'white', 't-shirt'],\n",
       " ['a', 'grill'],\n",
       " ['hotdogs'],\n",
       " ['a', 'young', 'man'],\n",
       " ['sunglasses'],\n",
       " ['a', 'blue', 'cup'],\n",
       " ['a', 'grill'],\n",
       " ['sausages'],\n",
       " ['a', 'young', 'man'],\n",
       " ['a', 'white', 'shirt'],\n",
       " ['hotdogs'],\n",
       " ['a', 'small', 'grill'],\n",
       " ['a', 'man'],\n",
       " ['his', 'cup'],\n",
       " ['hotdogs'],\n",
       " ['the', 'white', 'and', 'brown', 'dog'],\n",
       " ['the', 'surface', 'of', 'the', 'snow'],\n",
       " ['a', 'white', 'and', 'brown', 'dog'],\n",
       " ['a', 'snow', 'covered', 'field'],\n",
       " ['a', 'brown', 'and', 'white', 'dog'],\n",
       " ['the', 'snow'],\n",
       " ['a', 'dog'],\n",
       " ['snow'],\n",
       " ['a', 'dog'],\n",
       " ['the', 'snow'],\n",
       " ['man'],\n",
       " ['scooter'],\n",
       " ['some', 'of', 'those'],\n",
       " ['large', 'crowd'],\n",
       " ['a', 'crowd'],\n",
       " ['people'],\n",
       " ['an', 'older', 'woman'],\n",
       " ['a', 'crowd', 'of', 'people'],\n",
       " ['a', 'crowd', 'of', 'people'],\n",
       " ['a', 'person'],\n",
       " ['skis'],\n",
       " ['framed', 'pictures'],\n",
       " ['the', 'snow'],\n",
       " ['a', 'man'],\n",
       " ['a', 'hat'],\n",
       " ['pictures'],\n",
       " ['a', 'skier'],\n",
       " ['a', 'blue', 'hat'],\n",
       " ['a', 'man'],\n",
       " ['another', 'man'],\n",
       " ['paintings'],\n",
       " ['the', 'snow'],\n",
       " ['a', 'skier'],\n",
       " ['framed', 'pictures'],\n",
       " ['the', 'snow'],\n",
       " ['trees'],\n",
       " ['man'],\n",
       " ['skis'],\n",
       " ['artwork'],\n",
       " ['the', 'snow'],\n",
       " ['several', 'climbers'],\n",
       " ['the', 'rock'],\n",
       " ['the', 'man'],\n",
       " ['red'],\n",
       " ['the', 'line'],\n",
       " ['seven', 'climbers'],\n",
       " ['a', 'rock', 'face'],\n",
       " ['another', 'man'],\n",
       " ['the', 'rope'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['a', 'rock', 'climbing', 'wall'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['a', 'rock'],\n",
       " ['one', 'man'],\n",
       " ['a', 'collage', 'of', 'one', 'person'],\n",
       " ['a', 'cliff'],\n",
       " ['a', 'young', 'gymnast'],\n",
       " ['a', 'balance', 'beam'],\n",
       " ['a', 'woman'],\n",
       " ['an', 'orange', 'leotard'],\n",
       " ['gymnastics'],\n",
       " ['an', 'audience'],\n",
       " ['a', 'gymnast'],\n",
       " ['the', 'balance', 'beam'],\n",
       " ['an', 'audience'],\n",
       " ['the', 'young', 'gymnast', \"'s\", 'supple', 'body'],\n",
       " ['the', 'balance', 'beam'],\n",
       " ['a', 'gymnast'],\n",
       " ['the', 'balance', 'beam'],\n",
       " ['a', 'boy'],\n",
       " ['a', 'black', 't-shirt'],\n",
       " ['blue', 'jeans'],\n",
       " ['a', 'toy'],\n",
       " ['three', 'wheeler'],\n",
       " ['a', 'small', 'pool'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['a', 'toy', 'atv'],\n",
       " ['a', 'rubber', 'pool'],\n",
       " ['a', 'boy'],\n",
       " ['a', 'red', 'toy'],\n",
       " ['a', 'pool'],\n",
       " ['a', 'boy'],\n",
       " ['a', 'miniature', 'car'],\n",
       " ['a', 'lawn'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['his', 'toy', 'quad'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'red', 'jacket'],\n",
       " ['headscarf'],\n",
       " ['over', 'a', 'scenic', 'view', 'of', 'a', 'bay'],\n",
       " ['a', 'set', 'of', 'pay', 'binoculars'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'headscarf'],\n",
       " ['a', 'window'],\n",
       " ['a', 'mounted', 'telescope'],\n",
       " ['woman'],\n",
       " ['red', 'windbreaker'],\n",
       " ['a', 'rooftop'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'headscarf'],\n",
       " ['a', 'telescope'],\n",
       " ['bay'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'telescope'],\n",
       " ['a', 'red', 'coat'],\n",
       " ['a', 'man'],\n",
       " ['a', 'black', 'coat'],\n",
       " ['a', 'red', 'spaceship'],\n",
       " ['a', 'parking', 'ticket'],\n",
       " ['its', 'window'],\n",
       " ['a', 'man'],\n",
       " ['a', 'small', 'red', 'object'],\n",
       " ['a', 'plane'],\n",
       " ['a', 'man'],\n",
       " ['a', 'black', 'jacket'],\n",
       " ['the', 'street'],\n",
       " ['a', 'man'],\n",
       " ['a', 'black', 'jacket'],\n",
       " ['a', 'street'],\n",
       " ['man'],\n",
       " ['black', 'coat'],\n",
       " ['airplane', 'nose'],\n",
       " ['large', 'brown', 'dog'],\n",
       " ['the', 'sprinkler'],\n",
       " ['the', 'grass'],\n",
       " ['a', 'brown', 'dog'],\n",
       " ['the', 'water'],\n",
       " ['a', 'sprinkler'],\n",
       " ['a', 'lawn'],\n",
       " ['a', 'brown', 'dog'],\n",
       " ['a', 'lawn'],\n",
       " ['a', 'garden', 'hose'],\n",
       " ['a', 'brown', 'dog'],\n",
       " ['the', 'hose'],\n",
       " ['a', 'dog'],\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "class DDPNDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, cfg, phase):\n",
    "        'Initialization'\n",
    "        #self.labels = labels\n",
    "        #self.list_IDs = list_IDs\n",
    "        self.cfg = cfg\n",
    "        self.phase = phase\n",
    "        self.df_triple = pd.read_csv(self.cfg.triple_filepaths[self.phase])  # Triple means (image, ground_truth_bounding_box, query)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.df_triple.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        imageID = str(self.df_triple.iloc[index][\"imgId\"])\n",
    "        entityID = str(self.df_triple.iloc[index][\"entityId\"])\n",
    "        \n",
    "        # Load data and get label\n",
    "        # X = torch.load('data/' + ID + '.pt')\n",
    "        # X should be all the inputs, include visual features and text query\n",
    "        zf = np.load(features_dir+imageID+'.jpg.npz')\n",
    "        num_bbox = zf['num_bbox']\n",
    "        visual_feat = zf['x']  # visual_feat's shape here is supposed to be (2048, num_bbox) for resnet, (4096, num_bbox) for vgg16\n",
    "        visual_feat = np.transpose(visual_feat) # now (num_bbox, 2048) for resnet, (num_bbox, 4096) for vgg16\n",
    "        spatial_feat = zf['bbox'] # spatial_feat's shape here is supposed to be (num_bbox, 4)\n",
    "        x1 = spatial_feat[:,0]\n",
    "        y1 = spatial_feat[:,1]\n",
    "        x2 = spatial_feat[:,2]\n",
    "        y2 = spatial_feat[:,3]\n",
    "        image_w = zf['image_w']\n",
    "        image_h = zf['image_h']\n",
    "        spatial_feat = np.column_stack((x1/image_w, y1/image_h, x2/image_w, y2/image_h, (x2-x1)*(y2-y1)/(image_w*image_h)))\n",
    "        \n",
    "        # Concatenate visual features and spatial features\n",
    "        X = np.column_stack((visual_feat, spatial_feat))\n",
    "        \n",
    "        # If there are fewer than self.cfg.RPN_TOPN=100 proposals, add 0 rows below\n",
    "        for i in range(X.shape[0], self.cfg.RPN_TOPN):\n",
    "            zero_row = np.zeros((1,X.shape[1]))\n",
    "            X = np.vstack((X, zero_row))\n",
    "        # Convert numpy array to torch tensor \n",
    "        X = torch.from_numpy(X)\n",
    "        X = X.float()\n",
    "        \n",
    "        query = self.df_triple.iloc[index][\"entity_content\"]\n",
    "        \n",
    "        # Get ground truth bounding box\n",
    "        gt_bbox = self._get_bounding_box(imageID, entityID) # gt_bbox is a triple in format (x1, y1, x2, y2)\n",
    "        # Get the bounding box boundary regard as image size\n",
    "        gt_bbox[0] /= float(image_w)\n",
    "        gt_bbox[2] /= float(image_w)\n",
    "        gt_bbox[1] /= float(image_h)\n",
    "        gt_bbox[3] /= float(image_h)\n",
    "        # Convert list to torch tensor\n",
    "        gt_bbox = torch.tensor(gt_bbox) \n",
    "        \n",
    "        additional_info = (imageID, entityID, image_w, image_h) # those info are not directly used in training, but used in visualization\n",
    "\n",
    "        return (X, query), gt_bbox, additional_info  \n",
    "    \n",
    "    def _get_bounding_box(self, image_id, object_id): # image_id and object_id are expected to be string\n",
    "         \n",
    "        xml_tree = ET.parse(self.cfg.xml_dirpath + image_id + '.xml')\n",
    "        root = xml_tree.getroot()\n",
    "        boxes = []  # To deal with one object, multiple bounding boxes\n",
    "        for obj in root.findall('object'):\n",
    "            for name in obj.findall('name'):\n",
    "                if name.text == object_id:\n",
    "                    bndbox = obj.find(\"bndbox\")\n",
    "                    x1 = int(bndbox.find(\"xmin\").text)\n",
    "                    y1 = int(bndbox.find(\"ymin\").text)\n",
    "                    x2 = int(bndbox.find(\"xmax\").text)\n",
    "                    y2 = int(bndbox.find(\"ymax\").text)\n",
    "                    \n",
    "                    boxes.append([x1, y1, x2, y2])\n",
    "        if len(boxes)==0:\n",
    "            raise Exception(\"Entity not found. Image id: \"+image_id+\", Entity id: \"+object_id)\n",
    "        boxes_array = np.array(boxes)\n",
    "        # When there are multiple bounding boxes, draw the minimum box which contains all these invidual boxes\n",
    "        x1 = np.min(boxes_array[:,0])\n",
    "        y1 = np.min(boxes_array[:,1])\n",
    "        x2 = np.max(boxes_array[:,2])\n",
    "        y2 = np.max(boxes_array[:,3])\n",
    "                    \n",
    "        return [x1, y1, x2, y2]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-801709dedfb8>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-801709dedfb8>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    print(_get_bounding_box(str(1000092795), str(1))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# For testing \n",
    "def _get_bounding_box(image_id, object_id): # image_id and object_id are expected to be string\n",
    "    xml_dirpath = \"/home/wenjian/Internship/data/flickr30kentities/annotations/Annotations/\"\n",
    "\n",
    "    xml_tree = ET.parse(xml_dirpath + image_id + '.xml')\n",
    "    root = xml_tree.getroot()\n",
    "    boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        #for name in obj:\n",
    "        for name in obj.findall('name'):\n",
    "            print(name)\n",
    "            if name.text == object_id:\n",
    "                bndbox = obj.find(\"bndbox\")\n",
    "                x1 = int(bndbox.find(\"xmin\").text)\n",
    "                y1 = int(bndbox.find(\"ymin\").text)\n",
    "                x2 = int(bndbox.find(\"xmax\").text)\n",
    "                y2 = int(bndbox.find(\"ymax\").text)\n",
    "\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "    if len(boxes)==0:\n",
    "        raise Exception(\"Entity not found. Image id: \"+image_id+\", Entity id: \"+object_id)\n",
    "    boxes_array = np.array(boxes)\n",
    "\n",
    "    x1 = np.min(boxes_array[:,0])\n",
    "    y1 = np.min(boxes_array[:,1])\n",
    "    x2 = np.max(boxes_array[:,2])\n",
    "    y2 = np.max(boxes_array[:,3])\n",
    "\n",
    "    return [x1, y1, x2, y2] \n",
    "\n",
    "print(_get_bounding_box(str(36979), str(137644)))  # Expected result: [2, 40, 500, 373]\n",
    "print(_get_bounding_box(str(1000092795), str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = DDPNDataset(cfg, 'train')\n",
    "validation_set = DDPNDataset(cfg, 'val')\n",
    "test_set = DDPNDataset(cfg, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13834"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[2.1639e+00, 2.7124e-04, 3.4098e-02,  ..., 3.3158e-01, 9.5879e-01,\n",
       "           9.9444e-02],\n",
       "          [3.9815e+00, 5.4929e-02, 1.3764e-01,  ..., 9.9900e-01, 8.1457e-01,\n",
       "           1.1381e-01],\n",
       "          [1.9902e-01, 0.0000e+00, 0.0000e+00,  ..., 5.3924e-01, 9.4424e-01,\n",
       "           3.5721e-02],\n",
       "          ...,\n",
       "          [1.6851e-01, 4.5680e-01, 2.3356e-01,  ..., 9.9900e-01, 9.9833e-01,\n",
       "           5.1626e-01],\n",
       "          [2.0157e-01, 8.3949e-04, 2.3945e-01,  ..., 7.9054e-01, 9.9833e-01,\n",
       "           5.7698e-01],\n",
       "          [1.0633e+00, 1.3354e-02, 2.8126e-03,  ..., 7.3670e-01, 9.7744e-01,\n",
       "           3.3200e-01]]), 'une fenêtre'),\n",
       " tensor([0.4440, 0.0030, 0.6900, 0.6156]),\n",
       " ('1000344755', '27', array(500), array(333)))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 413627 triples in the training set\n",
    "\n",
    "training_set[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.9460, 0.0000, 0.0000,  ..., 0.9983, 0.9990, 0.1519],\n",
       "         [0.0000, 0.0000, 0.3983,  ..., 0.4634, 0.7727, 0.1531],\n",
       "         [2.3487, 0.0337, 0.0208,  ..., 0.7677, 0.4751, 0.0328],\n",
       "         ...,\n",
       "         [0.7473, 0.0938, 0.4703,  ..., 0.8276, 0.7052, 0.0970],\n",
       "         [0.0000, 0.0000, 0.1383,  ..., 0.5049, 0.5820, 0.2939],\n",
       "         [0.0274, 1.5578, 0.0000,  ..., 0.6135, 0.9990, 0.2173]]),\n",
       " 'deux jeunes hommes blancs')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = training_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9460, 0.0000, 0.0000,  ..., 0.9983, 0.9990, 0.1519],\n",
       "        [0.0000, 0.0000, 0.3983,  ..., 0.4634, 0.7727, 0.1531],\n",
       "        [2.3487, 0.0337, 0.0208,  ..., 0.7677, 0.4751, 0.0328],\n",
       "        ...,\n",
       "        [0.7473, 0.0938, 0.4703,  ..., 0.8276, 0.7052, 0.0970],\n",
       "        [0.0000, 0.0000, 0.1383,  ..., 0.5049, 0.5820, 0.2939],\n",
       "        [0.0274, 1.5578, 0.0000,  ..., 0.6135, 0.9990, 0.2173]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2053])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1519)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A[0][-3] - A[0][-5])*(A[0][-2] - A[0][-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deux jeunes hommes blancs'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2053])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[1.1333e-01, 2.3880e+00, 8.1123e-01,  ..., 9.9900e-01, 5.7636e-01,\n",
       "           5.1638e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.3661e-01, 9.9833e-01,\n",
       "           9.5590e-03],\n",
       "          [9.6640e-04, 3.0147e-01, 1.2200e+00,  ..., 8.3006e-01, 8.5222e-01,\n",
       "           1.6638e-01],\n",
       "          ...,\n",
       "          [2.0308e-01, 1.5471e-03, 0.0000e+00,  ..., 7.2942e-01, 4.9238e-01,\n",
       "           2.1457e-02],\n",
       "          [0.0000e+00, 1.6355e-01, 8.3413e-02,  ..., 9.9900e-01, 9.9833e-01,\n",
       "           1.1927e-01],\n",
       "          [0.0000e+00, 4.9662e-02, 2.4938e-02,  ..., 2.7541e-01, 1.6554e-01,\n",
       "           1.7283e-03]]), \"un groupe d' hommes\"),\n",
       " tensor([0.1720, 0.1081, 0.4280, 0.3213]),\n",
       " ('1018148011', '568', array(500), array(333)))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 14527 triples in the validation set\n",
    "\n",
    "validation_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2756"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2053])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0.0000, 0.0000, 0.2207,  ..., 0.8460, 0.4874, 0.2967],\n",
       "          [0.0000, 0.0532, 0.0260,  ..., 0.4820, 0.5275, 0.0117],\n",
       "          [0.0020, 0.0000, 0.0000,  ..., 0.7766, 0.9983, 0.4192],\n",
       "          ...,\n",
       "          [0.0022, 0.0000, 0.0347,  ..., 0.7141, 0.9983, 0.1812],\n",
       "          [0.0439, 0.0399, 0.0406,  ..., 0.8497, 0.7945, 0.6751],\n",
       "          [0.0152, 0.7325, 0.0020,  ..., 0.3951, 0.9826, 0.1539]]),\n",
       "  'un homme'),\n",
       " tensor([0.1100, 0.0911, 0.7980, 1.0000]),\n",
       " ('1007129816', '203', array(500), array(461)))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-2dca2111cf56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_generator' is not defined"
     ]
    }
   ],
   "source": [
    "len(training_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6462.921875"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "413627/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate IoU score between two boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(box_a, box_b):  # Tackle with N (like 100) box pairs at the same time\n",
    "    #print(box_a.type())\n",
    "    #print(box_b.type())\n",
    "    inter_xmin=torch.max(box_a[:,:,0], box_b[:,:,0])\n",
    "    inter_xmax=torch.min(box_a[:,:,2], box_b[:,:,2])\n",
    "    inter_ymin=torch.max(box_a[:,:,1], box_b[:,:,1])\n",
    "    inter_ymax=torch.min(box_a[:,:,3], box_b[:,:,3])\n",
    "    inter = torch.max((inter_xmax-inter_xmin).float(), torch.tensor(0).float().to(box_a.device)) * torch.max((inter_ymax-inter_ymin).float(), torch.tensor(0).float().to(box_a.device))\n",
    "    return inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 6., 0.]])\n"
     ]
    }
   ],
   "source": [
    "b1 = torch.tensor([[1,5,4,8],[1,1,3,3],[3,6,6,9],[2,3,5,5],[1,2,3,4]]).to(device)\n",
    "b2 = torch.tensor([[3,2,7,6],[5,5,8,8],[1,3,4,7],[1,2,6,6],[4,1,6,3]]).to(device)\n",
    "b1 = b1.unsqueeze(0)\n",
    "b2 = b2.unsqueeze(0)\n",
    "print(intersect(b1,b2)) # intersection expected: 1, 0, 1, 6, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/amdegroot/ssd.pytorch/blob/master/layers/box_utils.py#L48\n",
    "def IoU(box_a, box_b):  # Tackle with N (like 100) box pairs at the same time\n",
    "    # The shape of each input: (batch_size, box_number_in_each_image, 4)\n",
    "    box_a = box_a.float() \n",
    "    box_b = box_b.float()\n",
    "    #print(\"box_a shape\", box_a.size())\n",
    "    #print(\"box_b shape\", box_b.size())\n",
    "    inter = intersect(box_a, box_b)\n",
    "    area_a = (box_a[:,:,2] - box_a[:,:,0]) * (box_a[:,:,3] - box_a[:,:,1])\n",
    "    area_b = (box_b[:,:,2] - box_b[:,:,0]) * (box_b[:,:,3] - box_b[:,:,1])\n",
    "    union = area_a + area_b - inter\n",
    "    return inter.float() / union.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0417, 0.0000, 0.0500, 0.3000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(IoU(b1,b2))  # Expected answer: tensor([[0.0417, 0.0000, 0.0500, 0.3000, 0.0000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate softlable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.1969e-04, 4.4159e-02, 7.1317e-01, 9.4961e-01],\n",
       "        [0.0000e+00, 6.2040e-02, 4.7278e-01, 9.3002e-01],\n",
       "        [0.0000e+00, 5.4799e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [0.0000e+00, 1.2673e-01, 3.8553e-01, 5.9441e-01],\n",
       "        [2.3631e-01, 4.3101e-02, 7.0622e-01, 7.7726e-01],\n",
       "        [1.2156e-01, 2.3790e-01, 7.8092e-01, 8.9407e-01],\n",
       "        [2.0145e-01, 6.4568e-02, 6.4798e-01, 4.8737e-01],\n",
       "        [2.2413e-01, 7.5099e-02, 9.8721e-01, 5.4597e-01],\n",
       "        [9.2835e-02, 5.8494e-01, 6.3375e-01, 9.1759e-01],\n",
       "        [0.0000e+00, 1.5378e-01, 5.7126e-01, 5.7386e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 3.2736e-01, 2.6507e-01],\n",
       "        [7.6301e-01, 5.2890e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [0.0000e+00, 2.8935e-01, 6.5871e-01, 7.9631e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 9.8721e-01, 5.5247e-01],\n",
       "        [0.0000e+00, 3.1430e-02, 5.3487e-01, 4.0054e-01],\n",
       "        [1.0286e-01, 7.0030e-01, 6.0901e-01, 9.4653e-01],\n",
       "        [0.0000e+00, 3.1606e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [2.8571e-01, 3.0191e-01, 9.2748e-01, 8.2741e-01],\n",
       "        [1.8692e-01, 2.1457e-02, 6.2255e-01, 3.2091e-01],\n",
       "        [1.8927e-01, 5.9635e-01, 7.1666e-01, 9.3147e-01],\n",
       "        [0.0000e+00, 4.3508e-01, 4.1748e-01, 8.9088e-01],\n",
       "        [2.4769e-01, 2.8113e-02, 7.0878e-01, 4.1865e-01],\n",
       "        [2.3829e-01, 5.3514e-01, 7.1191e-01, 9.9219e-01],\n",
       "        [5.7845e-01, 8.1643e-02, 9.6448e-01, 4.9791e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 9.8721e-01, 9.9219e-01],\n",
       "        [5.5306e-01, 5.0825e-01, 9.8689e-01, 8.6039e-01],\n",
       "        [2.4730e-01, 2.0546e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [6.4011e-02, 7.7240e-01, 8.7594e-01, 9.8459e-01],\n",
       "        [0.0000e+00, 4.2569e-01, 7.7512e-01, 8.9017e-01],\n",
       "        [0.0000e+00, 2.4889e-01, 4.3156e-01, 8.2636e-01],\n",
       "        [7.5640e-01, 6.7741e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [1.8134e-01, 0.0000e+00, 9.1528e-01, 9.2247e-01],\n",
       "        [4.5635e-01, 4.2226e-01, 9.1520e-01, 8.2980e-01],\n",
       "        [2.3263e-01, 7.0514e-01, 7.2496e-01, 9.4018e-01],\n",
       "        [0.0000e+00, 6.3679e-01, 3.7500e-01, 9.5324e-01],\n",
       "        [0.0000e+00, 5.0653e-01, 6.3688e-01, 9.0755e-01],\n",
       "        [3.8588e-01, 7.2146e-01, 8.2199e-01, 9.4836e-01],\n",
       "        [3.5674e-01, 2.3547e-02, 9.0210e-01, 4.3336e-01],\n",
       "        [5.2044e-01, 0.0000e+00, 9.8721e-01, 2.8523e-01],\n",
       "        [0.0000e+00, 1.4431e-01, 5.4513e-01, 7.6854e-01],\n",
       "        [1.3114e-01, 0.0000e+00, 6.8220e-01, 8.5043e-01],\n",
       "        [6.7596e-01, 2.9110e-01, 9.8721e-01, 6.1554e-01],\n",
       "        [4.9492e-01, 2.2061e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [3.5400e-01, 0.0000e+00, 9.8721e-01, 6.7541e-01],\n",
       "        [1.2276e-01, 5.4238e-01, 6.1982e-01, 9.9219e-01],\n",
       "        [3.5196e-01, 5.7573e-01, 8.1557e-01, 9.9219e-01],\n",
       "        [6.3958e-02, 3.2747e-01, 7.0388e-01, 9.2481e-01],\n",
       "        [1.4900e-01, 3.4526e-01, 9.8040e-01, 8.0226e-01],\n",
       "        [2.0029e-01, 2.2022e-01, 9.8721e-01, 6.7394e-01],\n",
       "        [1.4822e-01, 4.6208e-01, 8.1937e-01, 9.4934e-01],\n",
       "        [0.0000e+00, 3.6772e-01, 5.6276e-01, 8.9484e-01],\n",
       "        [3.3409e-01, 1.6261e-01, 9.3600e-01, 7.1989e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 5.9332e-01, 2.0722e-01],\n",
       "        [5.7535e-01, 1.3839e-01, 9.3351e-01, 5.6518e-01],\n",
       "        [5.3224e-01, 0.0000e+00, 9.7960e-01, 4.4478e-01],\n",
       "        [0.0000e+00, 7.2192e-01, 3.4358e-01, 9.9219e-01],\n",
       "        [4.4696e-03, 6.1001e-01, 5.1093e-01, 9.4482e-01],\n",
       "        [4.4643e-01, 2.1135e-01, 9.7103e-01, 6.2006e-01],\n",
       "        [4.9696e-01, 5.9199e-01, 9.0680e-01, 9.9219e-01],\n",
       "        [3.5569e-01, 7.7980e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [1.2720e-01, 1.4510e-01, 6.9124e-01, 9.9219e-01],\n",
       "        [1.2856e-01, 6.6631e-01, 9.5309e-01, 9.7798e-01],\n",
       "        [4.4829e-01, 1.0288e-01, 9.8721e-01, 5.4615e-01],\n",
       "        [3.5697e-02, 0.0000e+00, 7.3871e-01, 2.4398e-01],\n",
       "        [2.9026e-01, 4.3782e-01, 8.7896e-01, 9.1976e-01],\n",
       "        [1.2975e-01, 1.0383e-01, 6.6438e-01, 6.8246e-01],\n",
       "        [4.0085e-01, 5.8874e-02, 9.0423e-01, 5.6509e-01],\n",
       "        [6.4148e-02, 1.2967e-01, 7.2236e-01, 5.8078e-01],\n",
       "        [3.2651e-01, 4.3326e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [7.0356e-01, 3.7553e-01, 9.8721e-01, 6.8219e-01],\n",
       "        [2.0979e-01, 8.0762e-02, 7.2516e-01, 5.9902e-01],\n",
       "        [3.6509e-01, 4.9976e-01, 9.8721e-01, 9.0808e-01],\n",
       "        [6.9799e-01, 6.2035e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [2.1758e-01, 0.0000e+00, 9.8721e-01, 2.6993e-01],\n",
       "        [5.7332e-01, 6.6664e-01, 9.5603e-01, 9.6725e-01],\n",
       "        [4.2628e-01, 2.6929e-01, 9.7533e-01, 7.2622e-01],\n",
       "        [6.5415e-01, 1.5063e-01, 9.8721e-01, 5.4922e-01],\n",
       "        [3.3032e-01, 3.9002e-01, 9.8721e-01, 7.3455e-01],\n",
       "        [0.0000e+00, 7.1810e-02, 9.8721e-01, 7.4424e-01],\n",
       "        [0.0000e+00, 2.0707e-02, 4.5095e-01, 3.0905e-01],\n",
       "        [6.6964e-01, 0.0000e+00, 9.8721e-01, 2.7266e-01],\n",
       "        [3.4030e-01, 6.5340e-01, 8.3316e-01, 9.4057e-01],\n",
       "        [0.0000e+00, 6.0929e-02, 4.4758e-01, 5.1297e-01],\n",
       "        [0.0000e+00, 6.5308e-01, 7.2621e-01, 9.4296e-01],\n",
       "        [1.0009e-01, 1.1553e-01, 8.5618e-01, 5.3433e-01],\n",
       "        [3.7055e-01, 5.4748e-02, 7.8511e-01, 6.6733e-01],\n",
       "        [3.8355e-01, 6.5255e-01, 9.8721e-01, 9.7966e-01],\n",
       "        [6.9475e-01, 4.9185e-01, 9.8721e-01, 8.6091e-01],\n",
       "        [6.1298e-01, 2.9687e-01, 9.8721e-01, 7.2223e-01],\n",
       "        [5.6698e-01, 3.7723e-01, 9.8721e-01, 6.6512e-01],\n",
       "        [3.9297e-01, 0.0000e+00, 9.0628e-01, 3.1733e-01],\n",
       "        [0.0000e+00, 6.9906e-01, 4.9604e-01, 9.8193e-01],\n",
       "        [5.4105e-01, 2.8813e-01, 9.8721e-01, 5.8926e-01],\n",
       "        [3.7176e-02, 6.0062e-02, 4.2541e-01, 3.9426e-01],\n",
       "        [6.6256e-01, 3.9180e-02, 9.8721e-01, 4.3597e-01],\n",
       "        [6.9949e-01, 7.4227e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [6.7554e-01, 3.9544e-01, 9.8721e-01, 7.9000e-01],\n",
       "        [4.0546e-01, 5.2122e-01, 8.8524e-01, 9.7012e-01],\n",
       "        [4.3293e-02, 1.4038e-01, 5.6647e-01, 9.9219e-01],\n",
       "        [5.4658e-01, 0.0000e+00, 9.8721e-01, 7.4209e-01]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[374573][0][0][:,-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f89a061b16e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m374573\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mIoU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRPN_TOPN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-79961d211c99>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m'Generates one sample of data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Select sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mimageID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_triple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"imgId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mentityID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_triple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"entityId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2007\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "i = 374573\n",
    "IoU(training_set[i][0][0][:,-5:-1].unsqueeze(0), training_set[i][1].repeat((1,cfg.RPN_TOPN,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softlabel_wrapper(threshold, epsilon):\n",
    "    def get_softlable(X, gt_bbox): # gt_bbox is expected as a triple in format (x1, y1, x2, y2). All the four boundaries are between 0 and 1. Batch is not considered here\n",
    "        # X is expected in shape (batch_size, N, 2053). We use the 4 columns with indexes 2047-2051. It should be noted that the last column in X is the area so we should not use it. \n",
    "        # gt_bbox is expected in format tensor with shape (batch_size, 4)\n",
    "        #print(\"gt_bbox\", gt_bbox.size())\n",
    "        gt_bbox = gt_bbox.unsqueeze(1)\n",
    "        #print(\"gt_bbox after repeat\", gt_bbox.repeat((1,cfg.RPN_TOPN,1)).size())\n",
    "        iou = IoU(X[:,:,-5:-1], gt_bbox.repeat((1,cfg.RPN_TOPN,1)))   #.double()\n",
    "        iou_with_threshold = iou*(iou>threshold).float()\n",
    "        #print(\"iou_with_threshold\", iou_with_threshold.size())  # size is (64, 100)\n",
    "        #return F.softmax(iou_with_threshold, dim=1)\n",
    "        denominator = iou_with_threshold.sum(dim=1).unsqueeze(1) + epsilon\n",
    "        #print(\"iou_with_threshold denominator\", denominator.size())  # size is (64, 1)\n",
    "        iou_with_threshold_l1_norm = iou_with_threshold / denominator\n",
    "        #assert not torch.isinf(iou_with_threshold_l1_norm).any()\n",
    "        #assert not torch.isnan(iou_with_threshold_l1_norm).any()\n",
    "        return iou_with_threshold_l1_norm\n",
    "    return get_softlable\n",
    "get_softlable = get_softlabel_wrapper(cfg.SOFTLABEL_THRESHOLD, torch.tensor(cfg.epsilon).to(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_pass_threshold(X, gt_bbox, threshold): # For statistical use only\n",
    "    iou = IoU(X[:,:,-5:-1], gt_bbox.repeat((1,cfg.RPN_TOPN,1)))   \n",
    "    return iou>threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 , counter= 1\n",
      "i= 100 , counter= 95\n",
      "i= 200 , counter= 186\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-080bf2440821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mthre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou_pass_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-34f2c18de2fa>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Convert numpy array to torch tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_triple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"entity_content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# count how many images in training set has at least one proposal with IoU > 0.5 against the ground truth bounding box\n",
    "if True:   # Modify here to do the statistics below\n",
    "    device = torch.device('cpu')\n",
    "    counter = 0\n",
    "    thre = 0.5\n",
    "    for i in range(len(training_set)):\n",
    "        iou = iou_pass_threshold(training_set[i][0][0].unsqueeze(0),training_set[i][1], thre)\n",
    "        if iou.sum() > 0:\n",
    "            counter += 1\n",
    "        if i%100 == 0:\n",
    "            print(\"i=\", i, \", counter=\", counter)\n",
    "    print(\"Finally,\", counter, \"examples pass the threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9374734042553191"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Otani's features\n",
    "387739/413600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6110275889644142"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My features\n",
    "152818.0/250100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-f0e2b4350ccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m374573\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_softlable_0_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_softlabel_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_softlable_0_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-0baf1f6b1cbf>\u001b[0m in \u001b[0;36mget_softlable\u001b[0;34m(X, gt_bbox)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mgt_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_bbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print(\"gt_bbox after repeat\", gt_bbox.repeat((1,cfg.RPN_TOPN,1)).size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIoU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_bbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRPN_TOPN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#.double()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# print(iou)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0miou_with_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-662fb35eddc4>\u001b[0m in \u001b[0;36mIoU\u001b[0;34m(box_a, box_b)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(\"box_a shape\", box_a.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(\"box_b shape\", box_b.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0marea_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0marea_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-1ad12fe02001>\u001b[0m in \u001b[0;36mintersect\u001b[0;34m(box_a, box_b)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minter_ymin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minter_ymax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_xmax\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minter_xmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_ymax\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minter_ymin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "i = 374573\n",
    "get_softlable_0_5 = get_softlabel_wrapper(0.5)\n",
    "get_softlable_0_5(training_set[i][0][0].unsqueeze(0),training_set[i][1].unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_wrapper(cfg, loggers_dct=None):\n",
    "    # loggers_dct are to log the training process\n",
    "    def my_loss(predict, target):  # predict is expected to be (s,t), target their ground truth value\n",
    "        s, t = predict\n",
    "        gt_s, gt_t = target\n",
    "        #print(\"s\", s.size())   # --> s torch.Size([64, 100])\n",
    "        #print(\"gt_s\", gt_s.size())   # --> gt_s torch.Size([64, 100])\n",
    "        #print(\"t\", t.size())   # --> t torch.Size([64, 100, 4])\n",
    "        #print(\"gt_t\", gt_t.size())   # --> gt_t torch.Size([64, 4])\n",
    "        s = torch.add(s, torch.tensor(cfg.epsilon))  # In order to avoid 0 in the denominator\n",
    "        try:\n",
    "#             assert not torch.isnan(s).any()\n",
    "#             assert not torch.isinf(s).any()\n",
    "#             assert not torch.isnan(t).any()\n",
    "#             assert not torch.isinf(t).any()\n",
    "#             assert not torch.isnan(gt_s).any()\n",
    "#             assert not torch.isinf(gt_s).any()\n",
    "#             assert not torch.isnan(gt_t).any()\n",
    "#             assert not torch.isinf(gt_t).any()\n",
    "            loss_ranking = F.kl_div(torch.log(s), gt_s, reduction='batchmean') \n",
    "            assert not torch.isnan(loss_ranking).any()\n",
    "            assert not torch.isinf(loss_ranking).any()\n",
    "            if loggers_dct != None:\n",
    "                loggers_dct['logger'].add_scalar(\"ranking_loss\", loss_ranking, my_loss.counter)\n",
    "            if cfg.regression_loss:\n",
    "                N = t.size()[1]\n",
    "                #print('gt_t after repeat', gt_t.unsqueeze(1).repeat(1,N,1).size())\n",
    "\n",
    "    #             proposal_chosen = torch.argmax(s, dim=1)\n",
    "    #             batch_size = s.size()[0]\n",
    "    #             t_chosen = t[torch.arange(batch_size),proposal_chosen,:]  # t_chosen shape is expected to be (batch_size, 4)\n",
    "    #             #print(\"t_chosen\", t_chosen.size())\n",
    "    #             loss_regression = F.smooth_l1_loss(t_chosen, gt_t, reduction='mean')\n",
    "\n",
    "                loss_regression = F.smooth_l1_loss(t, gt_t.unsqueeze(1).repeat(1,N,1), reduction='mean')\n",
    "\n",
    "                #print(\"loss_regression\", loss_regression)\n",
    "#                 assert not torch.isnan(loss_regression).any()\n",
    "#                 assert not torch.isinf(loss_regression).any()\n",
    "                if loggers_dct != None:\n",
    "                    loggers_dct['logger'].add_scalar(\"regression_loss\", cfg.GAMMA*loss_regression, my_loss.counter)\n",
    "            my_loss.counter += 1 \n",
    "            \n",
    "        except AssertionError as e:\n",
    "            torch.set_printoptions(profile='full')\n",
    "            print('s\\n', s)\n",
    "            print('t\\n', t)\n",
    "            print('gt_s\\n', gt_s)\n",
    "            print('gt_t\\n', gt_t)\n",
    "            with open(\"debug.log\", 'w') as log:\n",
    "                log.write('s\\n')\n",
    "                log.write(str(s))\n",
    "                log.write('gt_s\\n')\n",
    "                log.write(str(gt_s))\n",
    "            torch.set_printoptions(profile='default')\n",
    "            raise e\n",
    "        \n",
    "        if cfg.regression_loss:\n",
    "            #return delta*loss_ranking + loss_regression\n",
    "            return loss_ranking + cfg.GAMMA*loss_regression\n",
    "        else:\n",
    "            return loss_ranking \n",
    "    my_loss.counter = 0\n",
    "    return my_loss\n",
    "loss_func = loss_wrapper(cfg)  # This function doesn't contain loggers. It is used for testing. \n",
    "# Before training, another loss_func should be created with loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deux jeunes hommes blancs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stemmer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-a707b72818f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_corpus_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-a707b72818f6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_corpus_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stemmer' is not defined"
     ]
    }
   ],
   "source": [
    "# For testing\n",
    "print(training_set[0][0][1])\n",
    "print([stemmer.stem(w) for w in word_tokenize(training_set[0][0][1])])\n",
    "print(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(training_set[0][0][1])]))\n",
    "qs = [training_set[i][0][1] for i in range(5)]\n",
    "print([torch.tensor(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)])) for q in qs])\n",
    "print(nn.utils.rnn.pad_sequence([torch.tensor(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)])) for q in qs], batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence_right_alignment(sequences, batch_first=False, padding_value=0):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        sequences (list[Tensor]): list of variable length sequences.\n",
    "        batch_first (bool, optional): output will be in ``B x T x *`` if True, or in\n",
    "            ``T x B x *`` otherwise\n",
    "        padding_value (float, optional): value for padded elements. Default: 0.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # assuming trailing dimensions and type of all the Tensors\n",
    "    # in sequences are same and fetching those from sequences[0]\n",
    "    max_size = sequences[0].size()\n",
    "    trailing_dims = max_size[1:]\n",
    "    max_len = max([s.size(0) for s in sequences])\n",
    "    if batch_first:\n",
    "        out_dims = (len(sequences), max_len) + trailing_dims\n",
    "    else:\n",
    "        out_dims = (max_len, len(sequences)) + trailing_dims\n",
    "\n",
    "    out_tensor = sequences[0].data.new(*out_dims).fill_(padding_value)\n",
    "    for i, tensor in enumerate(sequences):\n",
    "        length = tensor.size(0)\n",
    "        # use index notation to prevent duplicate references to the tensor\n",
    "        if batch_first:\n",
    "            out_tensor[i, -length:, ...] = tensor  # Modification 1/2\n",
    "        else:\n",
    "            out_tensor[-length:, i, ...] = tensor  # Modification 2/2\n",
    "\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two young guys\n",
      "['two', 'young', 'guy']\n",
      "[3, 4, 65]\n",
      "[tensor([ 3,  4, 65]), tensor([-1,  5]), tensor([  8, 442]), tensor([  3,   4,   9,  11, 558]), tensor([5030,  979])]\n"
     ]
    }
   ],
   "source": [
    "# For testing\n",
    "print(training_set[0][0][1])\n",
    "print([stemmer.stem(w) for w in word_tokenize(training_set[0][0][1])])\n",
    "print(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(training_set[0][0][1])]))\n",
    "qs = [training_set[i][0][1] for i in range(5)]\n",
    "print([torch.tensor(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)])) for q in qs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    3,    4,   65],\n",
      "        [   0,    0,    0,   -1,    5],\n",
      "        [   0,    0,    0,    8,  442],\n",
      "        [   3,    4,    9,   11,  558],\n",
      "        [   0,    0,    0, 5030,  979]])\n"
     ]
    }
   ],
   "source": [
    "print(pad_sequence_right_alignment([torch.tensor(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)])) for q in qs], batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,    3,    0],\n",
      "        [   0,    0,    0,    4,    0],\n",
      "        [   3,    0,    0,    9,    0],\n",
      "        [   4,   -1,    8,   11, 5030],\n",
      "        [  65,    5,  442,  558,  979]])\n"
     ]
    }
   ],
   "source": [
    "print(pad_sequence_right_alignment([torch.tensor(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)])) for q in qs], batch_first=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is -1 above because we don't do stemming anymore when building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_sentence_to_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-b214437dbf06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqs_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentence_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-b214437dbf06>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqs_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentence_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_sentence_to_indices' is not defined"
     ]
    }
   ],
   "source": [
    "qs = [training_set[i][0][1] for i in range(5)]\n",
    "qs_tensor = [torch.tensor(tokenized_sentence_to_indices([w.lower() for w in word_tokenize(q)])) for q in qs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qs_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-d112860a5d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqs_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'qs_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pad_packed_sequence(qs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-40262981612b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglove_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdoc2idx_glove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdoc2idx_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc2idx_glove_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'glove' is not defined"
     ]
    }
   ],
   "source": [
    "# To convert a tokenized document to a list of list of index of each word\n",
    "def doc2idx_glove_wrapper(glove_object):\n",
    "    def doc2idx_glove(doc): # doc is a list of list of word(string)\n",
    "        return [[glove_object.stoi[word] for word in line] for line in doc]\n",
    "    return doc2idx_glove\n",
    "doc2idx_glove = doc2idx_glove_wrapper(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 2926, 2995, 13, 3827], [7, 5450, 4525, 2120]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [[\"a\", \"dog\", \"sitting\", \"on\", \"bed\"],\n",
    "        [\"a\", \"cat\", \"eating\", \"fish\"]]\n",
    "doc2idx_glove(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert a tokenized sentence to a list of index of each word\n",
    "def snt2idx_glove_wrapper(glove_object):\n",
    "    def snt2idx_glove(snt): # snt is a list of list of word(string)\n",
    "        return [glove_object.stoi[word] for word in snt]\n",
    "        #due to torchtext.\n",
    "    return snt2idx_glove\n",
    "snt2idx_glove = snt2idx_glove_wrapper(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2926, 2995, 13, 3827]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [\"a\", \"dog\", \"sitting\", \"on\", \"bed\"]\n",
    "snt2idx_glove(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.use_pretrained_word_embedding == None:\n",
    "    tokenized_sentence_to_indices = training_corpus_dct.doc2idx\n",
    "elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "    tokenized_sentence_to_indices = snt2idx_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPN(torch.nn.Module):\n",
    "    def __init__(self, cfg, vocab_size=None, embedding_weights=None):\n",
    "        super(DDPN, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        if type(embedding_weights) == type(None):\n",
    "            #print(\"type(embedding_weights) equals to type(None)\")\n",
    "            assert isinstance(vocab_size, int), \"Error: you are using non-pretraind embedding, and vocab_size is not an integer, but {}.\".format(vocab_size)\n",
    "            self.embedding = nn.Embedding(vocab_size, self.cfg.WORD_EMB_SIZE)  \n",
    "            self.embedding.requires_grad = True\n",
    "        else:\n",
    "            #print(\"type(embedding_weights) doesn't equal to type(None)\")\n",
    "            self.embedding = nn.Embedding(embedding_weights.size()[0], embedding_weights.size()[1])\n",
    "            self.embedding.load_state_dict({'weight': embedding_weights})\n",
    "            self.embedding.requires_grad = False\n",
    "        self.lstm = nn.LSTM(self.cfg.WORD_EMB_SIZE, self.cfg.RNN_DIM)  # This lstm is batch_first=false\n",
    "        self.fc1 = nn.Linear(self.cfg.VISUAL_FEATURES+self.cfg.SPATIAL_FEATURES+self.cfg.RNN_DIM, 512)\n",
    "        # Pytorch's Linear layer automatically exerts on the last dimension of the tensor, so we don't need to take care of N=100 manually. \n",
    "        self.fc_rank = nn.Linear(512,1)\n",
    "        if cfg.regression_loss:\n",
    "            self.fc_regression = nn.Linear(512,4)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(cfg.dropout_rate)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        if cfg.transfer_learning:\n",
    "            #self.frozen_layers = []\n",
    "            #self.frozen_layers = [self.embedding, self.lstm, self.fc1, self.fc_rank]\n",
    "            self.frozen_layers = [self.lstm, self.fc1, self.fc_rank]\n",
    "            #self.frozen_layers = [self.fc1, self.fc_rank]\n",
    "            #self.frozen_layers = [self.fc_rank]\n",
    "            for frozen_layer in self.frozen_layers:\n",
    "                for param in frozen_layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        \n",
    "    def forward(self, Xs, queries, seq_lengths):\n",
    "        \n",
    "        # one piece of query here should be a 1d tensor of indices (index of each word in the corpus dictionary) \n",
    "        # queries is a batch of query\n",
    "        # seq_lengths is the length of each query\n",
    "        \n",
    "        batch_size = Xs.size()[0]\n",
    "        \n",
    "        emb = self.embedding(queries) # emb size is (time_sequence, batch_size, 300)\n",
    "        # self.tanh = ...\n",
    "        emb_packed = torch.nn.utils.rnn.pack_padded_sequence(emb, lengths=seq_lengths, batch_first=False, enforce_sorted=False)\n",
    "        qs = self.lstm(emb_packed)[0] # [0] is to choose the output h_t sequence\n",
    "        # qs.size() is (time_sequence, batch_size, 1024)\n",
    "        qs_unpacked, qs_len = torch.nn.utils.rnn.pad_packed_sequence(qs, batch_first=False)\n",
    "        qs_unpacked_batch_first = qs_unpacked.permute(1,0,2)\n",
    "        q = qs_unpacked_batch_first[torch.arange(batch_size),qs_len-1] # to choose the output feature of last word\n",
    "        # self.slice = ...\n",
    "        #print(\"q0\", q0.type(), q0.size())  # The shape is (64, 1024)\n",
    "        \n",
    "        q_tiled = q.unsqueeze(1).repeat((1,self.cfg.RPN_TOPN,1)) #.double()\n",
    "        #print('q_tiled', q_tiled.type(), q_tiled.size())\n",
    "        #print('Xs', Xs.type(), Xs.size())\n",
    "        x_concat = torch.cat((Xs, q_tiled), dim=2)  # x_concat's shape is expected as (batch_size, 100, 2053+1024)\n",
    "        x1_linear = self.fc1(x_concat) \n",
    "        x1 = F.relu(x1_linear)\n",
    "        x1 = x1.permute(0,2,1)\n",
    "        x1 = self.batchnorm(x1)\n",
    "        x1 = x1.permute(0,2,1)\n",
    "        x1_dropped = self.dropout(x1)\n",
    "        # x1's shape is expected as (batch_size, 100, 512)\n",
    "        s0 = self.fc_rank(x1_dropped).squeeze()  # s's shape is expected to be (batch_size, 100)\n",
    "        s = self.softmax(s0)\n",
    "        if cfg.regression_loss:\n",
    "            t = self.fc_regression(x1_dropped)\n",
    "            return (s, t)\n",
    "        else:\n",
    "            return (s, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tutorial on working with non-equal-length sequence when use LSTM in Pytorch\n",
    "https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-aae283226d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cfg.use_pretrained_word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(queries):  \n",
    "    # queries is a tuple of strings. The length of queries is the batch size. \n",
    "    if cfg.STEMMING:\n",
    "        indices = [tokenized_sentence_to_indices([stemmer.stem(w) for w in word_tokenize(q, language=\"french\")]) for q in queries]\n",
    "    else:\n",
    "        indices = [tokenized_sentence_to_indices([w.lower() for w in word_tokenize(q, language=\"french\")]) for q in queries]\n",
    "\n",
    "    if cfg.use_pretrained_word_embedding == None:\n",
    "        # Gensim assign -1 to unknown word in the dictionary. \n",
    "        # Pytorch embedding, however, don't support negative index. \n",
    "        # So we kept 1 for unknown word when building Gensim dictionary, and convert -1 to 1 now\n",
    "        indices = [[idx if idx!=-1 else 1 for idx in row] for row in indices]\n",
    "    elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "        # Torchtext's GloVe raise KeyError when encountering a token not found\n",
    "        raise Exception(\"Part not implemented.\")  # Need modification somewhere else\n",
    "    else:\n",
    "        raise Exception(\"Illegal value for the parameter cfg.use_pretrained_word_embedding.\")\n",
    "        \n",
    "        \n",
    "#     # Word order shuffle test:\n",
    "#     for row in indices:\n",
    "#         random.shuffle(row) \n",
    "    \n",
    "    \n",
    "    \n",
    "    seq_lengths = [len(row) for row in indices]\n",
    "    \n",
    "    Qs_before_padding = [torch.tensor(row) for row in indices]\n",
    "    \n",
    "    if cfg.use_pretrained_word_embedding == None:\n",
    "        padding_value = 0\n",
    "    elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "        padding_value = 1  # 1 is '.', since in GloVe there is no empty word token\n",
    "    \n",
    "    Qs = nn.utils.rnn.pad_sequence(Qs_before_padding, batch_first=False, padding_value=padding_value)\n",
    "    # Qs = pad_sequence_right_alignment(Qs_before_padding, batch_first=False, padding_value=padding_value)\n",
    "    \n",
    "    return Qs, seq_lengths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IoU_scores_wrapper(cfg):\n",
    "    def calculate_IoU_scores(Xs, pred, gt_bboxes):\n",
    "        s, t = pred\n",
    "        proposal_chosen = torch.argmax(s, dim=1)\n",
    "        batch_size = Xs.size()[0]\n",
    "        gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "        bboxes_chosen_original = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "        ious_original = IoU(bboxes_chosen_original, gt_bboxes).squeeze()\n",
    "        if cfg.regression_loss:\n",
    "            bboxes_chosen_refined = t[torch.arange(batch_size),proposal_chosen,:].unsqueeze(1)\n",
    "            ious_refined = IoU(bboxes_chosen_refined, gt_bboxes).squeeze()\n",
    "            return ious_original, ious_refined\n",
    "        return ious_original\n",
    "    return calculate_IoU_scores\n",
    "calculate_IoU_scores = calculate_IoU_scores_wrapper(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-pretrained embedding is used.\n"
     ]
    }
   ],
   "source": [
    "en_vocab = len(training_corpus_dct_en.token2id)\n",
    "fr_vocab = len(training_corpus_dct.token2id)\n",
    "\n",
    "\n",
    "if cfg.use_pretrained_word_embedding == None:\n",
    "    print(\"Non-pretrained embedding is used.\")\n",
    "    model = DDPN(cfg, vocab_size=len(training_corpus_dct.token2id))\n",
    "elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "    print(\"Glove embedding is used.\")\n",
    "    model = DDPN(cfg, embedding_weights=glove.vectors)\n",
    "else:\n",
    "    raise Exception(\"Embedding configuration not recognized\")\n",
    "    \n",
    "mapping_method_name = 'training_from_scratch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and map the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14384\n",
      "3112\n"
     ]
    }
   ],
   "source": [
    "en_vocab = len(training_corpus_dct_en.token2id)\n",
    "fr_vocab = len(training_corpus_dct.token2id)\n",
    "print(en_vocab)\n",
    "print(fr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DDPN:\n\tMissing key(s) in state_dict: \"embedding.weight\", \"lstm.weight_ih_l0\", \"lstm.weight_hh_l0\", \"lstm.bias_ih_l0\", \"lstm.bias_hh_l0\", \"fc1.weight\", \"fc1.bias\", \"fc_rank.weight\", \"fc_rank.bias\", \"batchnorm.weight\", \"batchnorm.bias\", \"batchnorm.running_mean\", \"batchnorm.running_var\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"model_state_dict\", \"optimizer_state_dict\", \"loss\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-59faaba08dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0men_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_pretrained_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DDPN:\n\tMissing key(s) in state_dict: \"embedding.weight\", \"lstm.weight_ih_l0\", \"lstm.weight_hh_l0\", \"lstm.bias_ih_l0\", \"lstm.bias_hh_l0\", \"fc1.weight\", \"fc1.bias\", \"fc_rank.weight\", \"fc_rank.bias\", \"batchnorm.weight\", \"batchnorm.bias\", \"batchnorm.running_mean\", \"batchnorm.running_var\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"model_state_dict\", \"optimizer_state_dict\", \"loss\". "
     ]
    }
   ],
   "source": [
    "model = DDPN(cfg, vocab_size=fr_vocab)\n",
    "\n",
    "model_en = DDPN(cfg, vocab_size=en_vocab)\n",
    "\n",
    "model_en.load_state_dict(torch.load(english_pretrained_model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[-1.3595, -0.6513,  2.1616,  ...,  0.8357, -1.5402, -0.3802],\n",
       "                      [ 0.0176,  0.5985,  1.0572,  ...,  0.8117,  0.7600,  0.1525],\n",
       "                      [-1.4310, -0.8208, -0.1493,  ...,  1.6667,  0.3925, -0.1387],\n",
       "                      ...,\n",
       "                      [-1.2302, -0.3652,  0.6891,  ..., -0.0472, -1.2129, -0.1886],\n",
       "                      [ 1.6078,  0.8081, -1.5679,  ...,  0.2433,  0.0604, -1.9498],\n",
       "                      [-0.5467, -0.7315, -0.5455,  ..., -0.1423,  1.1181,  0.1505]])),\n",
       "             ('lstm.weight_ih_l0',\n",
       "              tensor([[ 0.0853, -0.0833,  0.1183,  ..., -0.1000,  0.0568, -0.1339],\n",
       "                      [ 0.0024,  0.1039,  0.0174,  ..., -0.0104, -0.0737, -0.2190],\n",
       "                      [ 0.0786,  0.0711, -0.0738,  ..., -0.1413, -0.1097,  0.0262],\n",
       "                      ...,\n",
       "                      [-0.0287, -0.1493, -0.0651,  ..., -0.1109,  0.0185,  0.0355],\n",
       "                      [-0.0039,  0.0497, -0.0874,  ...,  0.2767,  0.2946, -0.0249],\n",
       "                      [-0.0701, -0.0918,  0.0208,  ...,  0.0556,  0.0070,  0.2107]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-0.1128,  0.0071,  0.0659,  ...,  0.0710,  0.1208, -0.0230],\n",
       "                      [ 0.1511,  0.1486, -0.0011,  ..., -0.0510,  0.0154,  0.1128],\n",
       "                      [-0.0177, -0.0751, -0.0630,  ..., -0.0530, -0.0803,  0.0173],\n",
       "                      ...,\n",
       "                      [-0.0919,  0.1003,  0.0979,  ...,  0.0456,  0.0110,  0.0232],\n",
       "                      [ 0.0613, -0.1331,  0.1599,  ..., -0.0971,  0.0814,  0.0241],\n",
       "                      [ 0.0272,  0.3311,  0.1051,  ..., -0.1327,  0.0803, -0.0977]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([-0.0231, -0.1082, -0.1312,  ..., -0.1933, -0.2480, -0.2443])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([-0.0078, -0.0917, -0.1264,  ..., -0.2223, -0.2028, -0.2484])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0168, -0.0216,  0.0127,  ...,  0.0080, -0.0034, -0.0054],\n",
       "                      [-0.0108, -0.0315, -0.0357,  ..., -0.1420,  0.0207,  0.0884],\n",
       "                      [-0.0348, -0.0275, -0.0118,  ..., -0.0893, -0.1060,  0.0546],\n",
       "                      ...,\n",
       "                      [-0.0118, -0.0332, -0.0289,  ..., -0.0879, -0.0024,  0.1927],\n",
       "                      [-0.0127, -0.0211, -0.0096,  ..., -0.1079, -0.0757,  0.0948],\n",
       "                      [-0.0230,  0.0119, -0.0226,  ..., -0.1315,  0.0038,  0.0909]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0522, -0.8491, -0.8050, -0.9052, -0.6854, -0.8034, -0.9282, -0.8416,\n",
       "                      -0.7137, -0.8011, -0.6062, -0.8014, -0.7608, -0.7913, -0.7198, -0.7600,\n",
       "                      -0.7157, -0.6570, -0.7018, -0.7787, -0.5001, -0.6519, -0.6003, -0.7672,\n",
       "                      -0.7739, -0.6940, -0.7735, -0.7440, -0.8754, -0.6366, -0.7314, -0.6086,\n",
       "                      -0.8598, -0.7685, -0.6313, -0.0123, -0.4367, -0.7331, -0.7776, -0.8665,\n",
       "                      -0.7401, -0.7944, -0.6084, -0.7813, -0.8245, -0.7576, -0.5732, -0.8005,\n",
       "                      -0.4625, -0.7702, -0.7982, -0.7568, -0.8450, -0.4856, -0.7800,  0.0242,\n",
       "                      -0.5521, -0.5928, -0.6961, -0.7492, -0.8607, -0.7492, -0.6457, -0.7793,\n",
       "                      -0.7336, -0.8088, -0.6592, -0.7320, -0.7150, -0.7417, -0.6065, -0.8184,\n",
       "                      -0.5995, -0.7724, -0.7022, -0.8082, -0.6508, -0.6291, -0.7543, -0.7736,\n",
       "                      -0.8117, -0.6894, -0.7833, -0.7371, -0.1330, -0.7418,  0.1003, -0.6991,\n",
       "                      -0.7694, -0.7769, -0.7055, -0.7164, -0.6963, -0.8483, -0.7719, -0.7865,\n",
       "                      -0.6577, -0.6572, -0.8103, -0.6873, -0.7708, -0.7500, -0.7114, -0.9904,\n",
       "                      -0.6858, -0.7763, -0.7405, -0.7939, -0.7812, -0.7632, -0.8357,  0.0064,\n",
       "                      -0.7566, -0.7844, -0.7826, -0.5539, -0.7834, -0.6163, -0.7186, -0.7139,\n",
       "                      -0.8381, -0.8435, -0.6358, -0.6645, -0.7445, -0.7527, -0.6268, -0.7182,\n",
       "                      -0.8158, -0.7977, -0.7629, -0.7606, -0.5308, -0.6932, -0.7165, -0.6715,\n",
       "                      -0.6929, -0.1588, -0.6704, -0.6992, -0.6940, -0.7877, -0.6202, -0.8697,\n",
       "                      -0.6231, -0.7906, -0.7524, -0.6347, -0.4447, -0.7210, -0.4930, -0.7335,\n",
       "                      -0.8357, -0.6313, -0.8153, -0.7963, -0.6347, -0.7984, -0.7425, -0.7045,\n",
       "                      -0.7875, -0.6461, -0.5935, -0.6958, -0.8697, -0.7588, -0.6507,  0.1459,\n",
       "                      -0.8574, -0.6590, -0.6743, -0.7020, -0.8638, -0.7496, -0.5727, -0.9357,\n",
       "                      -0.6712, -0.6363, -0.7526, -0.6848, -0.8291, -0.6435, -0.6456, -0.7695,\n",
       "                      -0.8652, -0.8403, -0.7993, -0.7045, -0.7553, -0.7245, -0.5867, -0.5780,\n",
       "                      -0.6398, -0.1012, -0.7435, -0.7500, -0.8412, -0.7332, -0.7796, -0.8388,\n",
       "                      -0.7359, -0.6863, -0.6757, -0.8044, -0.7125, -0.7852, -0.5312, -0.8536,\n",
       "                      -0.6929, -0.7816, -0.7471, -0.7236, -0.7681, -0.7529, -0.8032, -0.8147,\n",
       "                      -0.7352, -0.7076, -0.7022, -0.7148, -0.7921, -0.7945, -0.6749,  0.1405,\n",
       "                      -0.8199, -0.7211, -0.6436, -0.6579, -0.5783, -0.6675, -0.8102, -0.7893,\n",
       "                      -0.9462, -0.5776, -0.0377, -0.8316, -0.7930, -0.7938, -0.6074, -0.6415,\n",
       "                      -0.7256, -0.8270, -0.4422, -0.6638, -0.6945, -0.7070, -0.7916, -0.7802,\n",
       "                      -0.8085, -0.8861, -0.6952, -0.7163, -0.5582, -0.7082, -0.7919, -0.7814,\n",
       "                      -0.5799, -0.8190, -0.7410, -0.7492, -0.7281, -0.7724, -0.7578, -0.6426,\n",
       "                      -0.6658, -0.8818, -0.6559, -0.7232, -0.8127, -0.7772, -0.7438, -0.5793,\n",
       "                      -0.6172, -0.5156, -0.9325, -0.8947, -0.6010, -0.7347, -0.7404, -0.8592,\n",
       "                      -0.7655, -0.8782, -0.7564,  0.2368, -0.7074, -0.7886, -0.6927, -0.7668,\n",
       "                      -0.6119, -0.7600, -0.6012, -0.7360, -0.7552, -0.6163,  0.0169, -0.7875,\n",
       "                      -0.7007, -0.8401, -0.6779, -0.8226, -0.7403, -0.7431, -0.7408, -0.7976,\n",
       "                      -0.6079, -0.9048, -0.7227, -0.6401, -0.6798, -0.8027, -0.8204, -0.7307,\n",
       "                      -0.8775, -0.7210, -0.8327, -0.7036, -0.6927, -0.6920, -0.8180, -0.5885,\n",
       "                      -0.7275, -0.6924, -0.7834, -0.6938, -0.6861, -0.8264, -0.7025, -0.7380,\n",
       "                      -0.7240, -0.7710, -0.7800, -0.7499, -0.6452, -0.8161, -0.8033, -0.7812,\n",
       "                      -0.7360, -0.8446, -0.6798, -0.6831, -0.8595, -0.2063, -0.7356, -0.7306,\n",
       "                      -0.8053, -0.8053, -0.6831, -0.6433, -0.6890, -0.7676, -0.7610, -0.8412,\n",
       "                      -0.8083, -0.8317, -0.7162, -0.8203, -0.7799, -0.7007, -0.4411, -0.8112,\n",
       "                      -0.5702, -0.7098, -0.9333, -0.7504, -0.9151, -0.0179, -0.8080, -0.6515,\n",
       "                      -0.7613, -0.6160, -0.5183, -0.8099, -0.2842, -0.7171, -0.8175, -0.7544,\n",
       "                      -0.6756, -0.6866, -0.8396, -0.6721, -0.7540, -0.7058, -0.8029, -0.8766,\n",
       "                      -0.6507, -0.5821, -0.7713, -0.8111, -0.7411, -0.6670, -0.7803, -0.8589,\n",
       "                      -0.7800,  0.0103, -0.7478, -0.8291, -0.7775, -0.7200, -0.7395, -0.7634,\n",
       "                      -0.7170, -0.6361, -0.7726, -0.7158, -0.6174, -0.8835, -0.7060, -0.7879,\n",
       "                      -0.8196, -0.5615, -0.7471, -0.3239, -0.8700, -0.7060, -0.7344, -0.6734,\n",
       "                      -0.8057, -0.5647, -0.4585, -0.7170, -0.6839, -0.7231, -0.8049, -0.8505,\n",
       "                      -0.5710, -0.6554, -0.8563, -0.6291, -0.5989, -0.7694, -0.8001, -0.7257,\n",
       "                      -0.1657, -0.7972,  0.1371, -0.6864, -0.6476, -0.7960, -0.7473, -0.8126,\n",
       "                      -0.1688, -0.7956, -0.7525, -0.6837, -0.6721, -0.8151, -0.8192, -0.7034,\n",
       "                      -0.8212, -0.8529, -0.8109, -0.7415, -0.8087, -0.7194, -0.7262, -0.7224,\n",
       "                      -0.8354, -0.7352, -0.6740, -0.6547, -0.4961, -0.8124, -0.8072, -0.6920,\n",
       "                      -0.6135, -0.7382, -0.6511, -0.8125, -0.7892, -0.4195, -0.8979, -0.7640,\n",
       "                      -0.7934, -0.7303, -0.7391, -0.7136, -0.6972, -0.6236, -0.2068, -0.7243,\n",
       "                      -0.8134, -0.7294, -0.6047, -0.6488, -0.6497, -0.7991, -0.7247, -0.6651,\n",
       "                      -0.7417, -0.7937, -0.7099, -0.7221, -0.7040, -0.7698, -0.2280, -0.8653,\n",
       "                      -0.7911, -0.6735, -0.8641, -0.7838, -0.6288, -0.8011, -0.7483, -0.7537,\n",
       "                      -0.7481, -0.6560, -0.7570, -0.6757, -0.7059, -0.8806, -0.7311, -0.8281])),\n",
       "             ('fc_rank.weight',\n",
       "              tensor([[ 5.1509e-03,  5.3527e-03,  4.5635e-04,  1.3469e-03, -1.9905e-02,\n",
       "                       -1.0536e-03,  1.2105e-03, -7.5411e-04,  2.1385e-03, -5.9177e-03,\n",
       "                       -2.4476e-03,  9.7069e-03,  3.0663e-03,  6.3931e-04,  3.5765e-03,\n",
       "                       -4.8726e-03, -1.1828e-03, -3.4574e-03, -3.7725e-04,  1.0358e-03,\n",
       "                       -1.2128e-02,  3.4262e-03, -5.4626e-04,  3.3927e-03, -4.6671e-04,\n",
       "                       -2.1270e-03,  1.8159e-03, -1.0562e-02, -1.5116e-03,  1.1154e-03,\n",
       "                        2.0135e-03, -5.5850e-03,  1.2317e-02, -3.4253e-04, -3.4226e-03,\n",
       "                       -6.1293e-04,  1.7395e-02, -4.2100e-03, -2.7900e-03,  1.1965e-02,\n",
       "                        6.4356e-04,  1.0911e-03,  5.7412e-03, -1.8148e-03, -6.0681e-03,\n",
       "                        3.7751e-04,  4.5795e-03, -8.9540e-03, -7.0566e-03,  1.6275e-03,\n",
       "                        3.3641e-03, -3.4924e-03,  2.7459e-03,  5.7599e-03,  6.8563e-03,\n",
       "                        1.3514e-02, -1.8172e-03,  9.3641e-03,  3.0919e-04,  4.1440e-03,\n",
       "                        5.3767e-03, -2.9846e-03,  3.2558e-03, -2.6752e-03,  1.3731e-02,\n",
       "                       -1.4518e-03, -1.6084e-03,  1.2155e-03, -3.7937e-03,  4.0825e-03,\n",
       "                       -1.2928e-02,  1.7419e-04, -2.7942e-03, -1.2007e-03,  5.0313e-03,\n",
       "                        4.3683e-04,  1.4339e-03, -9.9499e-03, -6.1881e-03,  2.5984e-03,\n",
       "                        3.0328e-03,  1.9467e-03,  5.0426e-03,  2.9025e-03, -2.9823e-02,\n",
       "                       -2.8892e-03,  1.3019e-02,  1.9663e-03,  4.4732e-03, -6.4568e-03,\n",
       "                        3.1491e-03,  2.9899e-03, -1.0562e-04, -7.6530e-04,  3.7968e-03,\n",
       "                       -5.3910e-03, -1.1179e-02, -9.0014e-04,  1.7241e-03,  2.9585e-03,\n",
       "                       -7.4985e-04, -1.2580e-03,  1.3382e-03,  4.6969e-03, -6.5115e-03,\n",
       "                       -1.3999e-03, -2.6749e-03, -1.0580e-03, -6.4777e-03,  3.8123e-03,\n",
       "                        4.7253e-04, -4.4034e-03,  2.3062e-03,  3.9111e-04, -1.8664e-03,\n",
       "                       -6.3513e-03,  2.3184e-03, -1.2748e-02, -5.0992e-03,  5.1753e-03,\n",
       "                       -6.5393e-04, -5.8973e-03, -5.4398e-03, -4.9229e-03, -1.1496e-03,\n",
       "                        4.7645e-04, -7.2287e-04,  1.3863e-03, -6.9763e-03, -7.4350e-05,\n",
       "                       -5.5366e-03,  1.2588e-02, -1.2610e-02,  8.1051e-04,  2.1316e-03,\n",
       "                        2.4638e-03,  2.7725e-02,  2.6123e-02, -4.9172e-03, -1.7250e-04,\n",
       "                       -3.0756e-03,  1.0648e-03,  1.1143e-02,  2.4508e-03, -2.6515e-03,\n",
       "                        2.6380e-04,  1.6101e-02, -2.0320e-03, -6.7051e-03,  1.8826e-04,\n",
       "                        5.6927e-03,  3.2353e-03,  3.3999e-03, -4.7279e-03,  9.2765e-04,\n",
       "                       -1.9483e-05,  6.0555e-04,  4.5490e-03,  2.4910e-03,  3.2704e-04,\n",
       "                        1.2612e-03, -9.2230e-04,  4.2387e-03,  4.7854e-03,  5.8439e-03,\n",
       "                       -1.9831e-03, -5.4389e-03, -1.9317e-02, -2.7265e-03, -1.4443e-03,\n",
       "                        5.0852e-03,  2.4367e-03,  3.0302e-03, -4.1350e-04,  9.3279e-03,\n",
       "                       -1.1106e-04,  1.5260e-03,  2.1253e-03, -7.0821e-03, -4.4566e-04,\n",
       "                       -2.2039e-03, -7.7292e-04,  3.9742e-03,  2.9665e-03,  3.2540e-03,\n",
       "                       -1.9281e-03, -7.6297e-03, -6.9646e-03,  1.5231e-05,  4.7618e-03,\n",
       "                       -1.3742e-02,  6.3799e-03, -4.3693e-03, -3.0495e-02,  1.6248e-03,\n",
       "                       -2.3925e-03,  1.7159e-03, -1.0495e-02,  7.5656e-04,  2.9730e-03,\n",
       "                       -5.7541e-03, -8.0301e-04,  2.3103e-03,  2.6327e-03,  2.3934e-03,\n",
       "                        2.4238e-04,  8.9056e-03,  7.0696e-03, -6.6560e-03,  2.7180e-03,\n",
       "                       -3.2487e-03,  1.4825e-04, -4.1075e-03,  4.6682e-03,  4.9370e-04,\n",
       "                        3.0143e-03,  7.0934e-04,  3.2927e-03,  1.2862e-03, -4.4449e-04,\n",
       "                       -1.2484e-03,  3.4247e-03,  5.4897e-03, -6.8124e-03,  4.4922e-03,\n",
       "                       -8.9891e-03,  8.1445e-03,  4.9470e-03,  6.8518e-03, -6.6442e-03,\n",
       "                        1.4927e-03,  5.6580e-03,  5.5933e-03, -5.4783e-04,  6.3613e-03,\n",
       "                       -1.1143e-03, -1.2758e-03, -6.0917e-04,  3.3784e-03,  3.0397e-03,\n",
       "                       -3.7120e-03, -3.2079e-03, -1.5449e-02, -2.1920e-03,  7.0176e-04,\n",
       "                        2.7288e-03,  2.3807e-03,  5.5738e-03,  2.0234e-03,  6.6531e-03,\n",
       "                       -5.8415e-03, -1.5766e-02, -9.0943e-03, -6.1474e-03, -3.6185e-03,\n",
       "                        7.9284e-03,  5.6962e-04,  2.0064e-03,  4.9350e-03,  1.4223e-03,\n",
       "                        2.4007e-03,  2.1030e-03, -3.7933e-03,  4.9258e-03,  3.5906e-03,\n",
       "                        2.4432e-03,  1.2514e-03,  5.6955e-03,  3.4894e-03,  4.3053e-03,\n",
       "                        2.7868e-03, -8.4828e-04, -7.6563e-03, -5.1928e-03,  7.6538e-04,\n",
       "                       -2.6362e-04,  8.0181e-03,  8.9878e-03,  3.9016e-03,  2.5711e-03,\n",
       "                       -1.3728e-03,  9.7359e-03,  2.1298e-03, -4.6960e-02,  3.1884e-03,\n",
       "                        6.4060e-03,  3.0596e-03,  6.8234e-04,  3.7822e-03, -1.2753e-03,\n",
       "                       -3.8215e-04, -1.1492e-03,  2.1680e-03,  7.5949e-03, -1.1106e-03,\n",
       "                        3.5569e-03,  7.8369e-03,  8.2035e-03,  2.1834e-03, -8.2893e-04,\n",
       "                       -3.4548e-03,  7.9871e-03,  7.4203e-03,  2.2738e-03,  5.6030e-03,\n",
       "                       -1.8358e-03, -9.2854e-04, -1.3962e-04, -4.1996e-03, -6.0783e-04,\n",
       "                        7.2158e-03,  1.9460e-03, -1.0930e-03, -1.8411e-04, -5.5879e-05,\n",
       "                        3.6668e-04, -4.6385e-03,  8.3762e-03,  2.1266e-03,  1.2671e-03,\n",
       "                       -3.3332e-03, -4.3879e-03, -2.3435e-03,  5.9489e-03, -3.9327e-03,\n",
       "                       -8.4251e-04,  6.6346e-03, -2.3812e-03, -2.5256e-03,  5.6035e-03,\n",
       "                       -1.9586e-03, -3.1728e-03, -2.8034e-03, -9.5185e-04,  5.7851e-03,\n",
       "                        2.9846e-03,  6.0379e-03,  7.2703e-03, -1.7584e-03,  2.6096e-03,\n",
       "                       -3.7418e-03, -2.2086e-02,  3.9150e-03, -1.6616e-03, -5.5669e-03,\n",
       "                        9.3712e-03, -6.0401e-03, -1.4045e-02,  4.3223e-03, -8.4124e-03,\n",
       "                       -7.5224e-03, -4.1490e-03, -8.0023e-04, -7.2291e-04,  5.9454e-03,\n",
       "                        8.3097e-04, -2.7120e-03,  1.5092e-03,  2.4222e-02,  1.4104e-03,\n",
       "                        4.0356e-03, -7.5720e-03,  4.9301e-03, -2.7086e-03, -1.1861e-03,\n",
       "                       -1.3620e-02,  3.3576e-03, -1.1090e-02,  2.4748e-03,  9.4635e-04,\n",
       "                        2.8380e-02, -7.2980e-03, -1.6748e-02, -3.3741e-03,  4.9372e-04,\n",
       "                        3.1755e-03,  2.2367e-03, -2.5333e-03,  4.3058e-03,  2.2720e-03,\n",
       "                        2.2005e-03, -8.6757e-03, -5.7265e-03,  1.4489e-03,  8.0993e-03,\n",
       "                       -1.4471e-03, -1.1457e-04,  1.6136e-03, -1.8389e-03,  8.2227e-03,\n",
       "                        5.3749e-03, -1.0408e-03,  9.9654e-04, -2.5684e-04,  7.6622e-03,\n",
       "                        2.8012e-03,  6.6243e-03,  4.9823e-03,  4.0383e-03, -2.3599e-03,\n",
       "                        2.3810e-04, -4.5007e-03, -1.0321e-03,  1.9207e-04,  2.3372e-03,\n",
       "                        5.9381e-03, -3.0398e-03,  3.9953e-03,  1.3197e-03, -8.0390e-03,\n",
       "                        6.0387e-04, -8.8545e-03, -1.8910e-04,  1.1861e-03, -3.6189e-03,\n",
       "                       -8.9414e-04,  3.7207e-04, -7.8352e-03, -8.5385e-03,  2.5326e-03,\n",
       "                       -6.5131e-03,  6.5072e-04,  1.0948e-03, -3.8551e-03, -7.8956e-03,\n",
       "                       -2.9058e-03, -2.3399e-03, -5.9482e-03,  4.9820e-03, -1.5129e-03,\n",
       "                       -1.3970e-03,  1.8878e-03,  2.6037e-02,  2.1239e-03,  1.2373e-02,\n",
       "                       -3.1199e-03,  2.4383e-03,  4.5437e-03, -5.2326e-03,  9.6224e-04,\n",
       "                        1.9585e-02,  5.8169e-03, -6.5474e-03, -2.6314e-03, -8.9744e-04,\n",
       "                        3.9168e-03,  1.9776e-03,  5.2697e-04,  4.1797e-03, -2.9715e-03,\n",
       "                        4.2285e-03, -8.8435e-04,  3.8017e-04,  6.2078e-03,  1.3738e-04,\n",
       "                       -6.6137e-03, -2.4081e-03,  4.1236e-03, -1.9971e-03,  1.6556e-03,\n",
       "                       -4.0215e-05,  6.2783e-04, -5.4000e-03, -2.5218e-03, -2.2268e-03,\n",
       "                        2.3740e-03, -3.9283e-03,  4.4026e-03,  4.6312e-04,  1.2193e-02,\n",
       "                       -3.9014e-03, -5.0284e-04,  7.9820e-05,  3.9291e-03,  1.4045e-03,\n",
       "                       -1.1841e-02, -6.7879e-03, -1.2934e-03, -8.9156e-03, -5.9948e-03,\n",
       "                        5.4834e-03, -1.0759e-05,  1.1635e-02, -4.8803e-03,  1.9988e-04,\n",
       "                        1.1743e-02,  1.0016e-03, -8.4472e-03,  3.5292e-03, -4.5690e-03,\n",
       "                        1.5077e-03, -2.4041e-03,  5.3630e-03,  1.9356e-03,  1.9336e-02,\n",
       "                        1.5122e-03, -3.5098e-03,  5.2232e-03, -5.0219e-03,  9.6389e-03,\n",
       "                       -7.2707e-03, -2.6708e-03,  6.6903e-03, -1.8230e-03, -5.7928e-03,\n",
       "                       -4.9578e-03,  4.0080e-03, -3.1227e-03,  1.0250e-02, -3.5601e-03,\n",
       "                        7.3428e-03,  1.7555e-03]])),\n",
       "             ('fc_rank.bias', tensor([-4.5970])),\n",
       "             ('fc_regression.weight',\n",
       "              tensor([[-0.0071, -0.0004,  0.0024,  ...,  0.0009,  0.0063,  0.0054],\n",
       "                      [ 0.0557,  0.0009,  0.0003,  ...,  0.0077, -0.0014, -0.0040],\n",
       "                      [-0.0146,  0.0055,  0.0051,  ...,  0.0014, -0.0030,  0.0037],\n",
       "                      [ 0.0051,  0.0010,  0.0022,  ...,  0.0002, -0.0093,  0.0069]])),\n",
       "             ('fc_regression.bias',\n",
       "              tensor([-0.0032, -0.0207,  0.0066,  0.0740]))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weights = model_en.state_dict()[\"embedding.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14384, 300])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('embedding.weight', tensor([[-1.3595, -0.6513,  2.1616,  ...,  0.8357, -1.5402, -0.3802],\n",
       "        [ 0.0176,  0.5985,  1.0572,  ...,  0.8117,  0.7600,  0.1525],\n",
       "        [-1.4310, -0.8208, -0.1493,  ...,  1.6667,  0.3925, -0.1387],\n",
       "        ...,\n",
       "        [-1.2302, -0.3652,  0.6891,  ..., -0.0472, -1.2129, -0.1886],\n",
       "        [ 1.6078,  0.8081, -1.5679,  ...,  0.2433,  0.0604, -1.9498],\n",
       "        [-0.5467, -0.7315, -0.5455,  ..., -0.1423,  1.1181,  0.1505]])), ('lstm.weight_ih_l0', tensor([[ 0.0853, -0.0833,  0.1183,  ..., -0.1000,  0.0568, -0.1339],\n",
       "        [ 0.0024,  0.1039,  0.0174,  ..., -0.0104, -0.0737, -0.2190],\n",
       "        [ 0.0786,  0.0711, -0.0738,  ..., -0.1413, -0.1097,  0.0262],\n",
       "        ...,\n",
       "        [-0.0287, -0.1493, -0.0651,  ..., -0.1109,  0.0185,  0.0355],\n",
       "        [-0.0039,  0.0497, -0.0874,  ...,  0.2767,  0.2946, -0.0249],\n",
       "        [-0.0701, -0.0918,  0.0208,  ...,  0.0556,  0.0070,  0.2107]])), ('lstm.weight_hh_l0', tensor([[-0.1128,  0.0071,  0.0659,  ...,  0.0710,  0.1208, -0.0230],\n",
       "        [ 0.1511,  0.1486, -0.0011,  ..., -0.0510,  0.0154,  0.1128],\n",
       "        [-0.0177, -0.0751, -0.0630,  ..., -0.0530, -0.0803,  0.0173],\n",
       "        ...,\n",
       "        [-0.0919,  0.1003,  0.0979,  ...,  0.0456,  0.0110,  0.0232],\n",
       "        [ 0.0613, -0.1331,  0.1599,  ..., -0.0971,  0.0814,  0.0241],\n",
       "        [ 0.0272,  0.3311,  0.1051,  ..., -0.1327,  0.0803, -0.0977]])), ('lstm.bias_ih_l0', tensor([-0.0231, -0.1082, -0.1312,  ..., -0.1933, -0.2480, -0.2443])), ('lstm.bias_hh_l0', tensor([-0.0078, -0.0917, -0.1264,  ..., -0.2223, -0.2028, -0.2484])), ('fc1.weight', tensor([[-0.0168, -0.0216,  0.0127,  ...,  0.0080, -0.0034, -0.0054],\n",
       "        [-0.0108, -0.0315, -0.0357,  ..., -0.1420,  0.0207,  0.0884],\n",
       "        [-0.0348, -0.0275, -0.0118,  ..., -0.0893, -0.1060,  0.0546],\n",
       "        ...,\n",
       "        [-0.0118, -0.0332, -0.0289,  ..., -0.0879, -0.0024,  0.1927],\n",
       "        [-0.0127, -0.0211, -0.0096,  ..., -0.1079, -0.0757,  0.0948],\n",
       "        [-0.0230,  0.0119, -0.0226,  ..., -0.1315,  0.0038,  0.0909]])), ('fc1.bias', tensor([ 0.0522, -0.8491, -0.8050, -0.9052, -0.6854, -0.8034, -0.9282, -0.8416,\n",
       "        -0.7137, -0.8011, -0.6062, -0.8014, -0.7608, -0.7913, -0.7198, -0.7600,\n",
       "        -0.7157, -0.6570, -0.7018, -0.7787, -0.5001, -0.6519, -0.6003, -0.7672,\n",
       "        -0.7739, -0.6940, -0.7735, -0.7440, -0.8754, -0.6366, -0.7314, -0.6086,\n",
       "        -0.8598, -0.7685, -0.6313, -0.0123, -0.4367, -0.7331, -0.7776, -0.8665,\n",
       "        -0.7401, -0.7944, -0.6084, -0.7813, -0.8245, -0.7576, -0.5732, -0.8005,\n",
       "        -0.4625, -0.7702, -0.7982, -0.7568, -0.8450, -0.4856, -0.7800,  0.0242,\n",
       "        -0.5521, -0.5928, -0.6961, -0.7492, -0.8607, -0.7492, -0.6457, -0.7793,\n",
       "        -0.7336, -0.8088, -0.6592, -0.7320, -0.7150, -0.7417, -0.6065, -0.8184,\n",
       "        -0.5995, -0.7724, -0.7022, -0.8082, -0.6508, -0.6291, -0.7543, -0.7736,\n",
       "        -0.8117, -0.6894, -0.7833, -0.7371, -0.1330, -0.7418,  0.1003, -0.6991,\n",
       "        -0.7694, -0.7769, -0.7055, -0.7164, -0.6963, -0.8483, -0.7719, -0.7865,\n",
       "        -0.6577, -0.6572, -0.8103, -0.6873, -0.7708, -0.7500, -0.7114, -0.9904,\n",
       "        -0.6858, -0.7763, -0.7405, -0.7939, -0.7812, -0.7632, -0.8357,  0.0064,\n",
       "        -0.7566, -0.7844, -0.7826, -0.5539, -0.7834, -0.6163, -0.7186, -0.7139,\n",
       "        -0.8381, -0.8435, -0.6358, -0.6645, -0.7445, -0.7527, -0.6268, -0.7182,\n",
       "        -0.8158, -0.7977, -0.7629, -0.7606, -0.5308, -0.6932, -0.7165, -0.6715,\n",
       "        -0.6929, -0.1588, -0.6704, -0.6992, -0.6940, -0.7877, -0.6202, -0.8697,\n",
       "        -0.6231, -0.7906, -0.7524, -0.6347, -0.4447, -0.7210, -0.4930, -0.7335,\n",
       "        -0.8357, -0.6313, -0.8153, -0.7963, -0.6347, -0.7984, -0.7425, -0.7045,\n",
       "        -0.7875, -0.6461, -0.5935, -0.6958, -0.8697, -0.7588, -0.6507,  0.1459,\n",
       "        -0.8574, -0.6590, -0.6743, -0.7020, -0.8638, -0.7496, -0.5727, -0.9357,\n",
       "        -0.6712, -0.6363, -0.7526, -0.6848, -0.8291, -0.6435, -0.6456, -0.7695,\n",
       "        -0.8652, -0.8403, -0.7993, -0.7045, -0.7553, -0.7245, -0.5867, -0.5780,\n",
       "        -0.6398, -0.1012, -0.7435, -0.7500, -0.8412, -0.7332, -0.7796, -0.8388,\n",
       "        -0.7359, -0.6863, -0.6757, -0.8044, -0.7125, -0.7852, -0.5312, -0.8536,\n",
       "        -0.6929, -0.7816, -0.7471, -0.7236, -0.7681, -0.7529, -0.8032, -0.8147,\n",
       "        -0.7352, -0.7076, -0.7022, -0.7148, -0.7921, -0.7945, -0.6749,  0.1405,\n",
       "        -0.8199, -0.7211, -0.6436, -0.6579, -0.5783, -0.6675, -0.8102, -0.7893,\n",
       "        -0.9462, -0.5776, -0.0377, -0.8316, -0.7930, -0.7938, -0.6074, -0.6415,\n",
       "        -0.7256, -0.8270, -0.4422, -0.6638, -0.6945, -0.7070, -0.7916, -0.7802,\n",
       "        -0.8085, -0.8861, -0.6952, -0.7163, -0.5582, -0.7082, -0.7919, -0.7814,\n",
       "        -0.5799, -0.8190, -0.7410, -0.7492, -0.7281, -0.7724, -0.7578, -0.6426,\n",
       "        -0.6658, -0.8818, -0.6559, -0.7232, -0.8127, -0.7772, -0.7438, -0.5793,\n",
       "        -0.6172, -0.5156, -0.9325, -0.8947, -0.6010, -0.7347, -0.7404, -0.8592,\n",
       "        -0.7655, -0.8782, -0.7564,  0.2368, -0.7074, -0.7886, -0.6927, -0.7668,\n",
       "        -0.6119, -0.7600, -0.6012, -0.7360, -0.7552, -0.6163,  0.0169, -0.7875,\n",
       "        -0.7007, -0.8401, -0.6779, -0.8226, -0.7403, -0.7431, -0.7408, -0.7976,\n",
       "        -0.6079, -0.9048, -0.7227, -0.6401, -0.6798, -0.8027, -0.8204, -0.7307,\n",
       "        -0.8775, -0.7210, -0.8327, -0.7036, -0.6927, -0.6920, -0.8180, -0.5885,\n",
       "        -0.7275, -0.6924, -0.7834, -0.6938, -0.6861, -0.8264, -0.7025, -0.7380,\n",
       "        -0.7240, -0.7710, -0.7800, -0.7499, -0.6452, -0.8161, -0.8033, -0.7812,\n",
       "        -0.7360, -0.8446, -0.6798, -0.6831, -0.8595, -0.2063, -0.7356, -0.7306,\n",
       "        -0.8053, -0.8053, -0.6831, -0.6433, -0.6890, -0.7676, -0.7610, -0.8412,\n",
       "        -0.8083, -0.8317, -0.7162, -0.8203, -0.7799, -0.7007, -0.4411, -0.8112,\n",
       "        -0.5702, -0.7098, -0.9333, -0.7504, -0.9151, -0.0179, -0.8080, -0.6515,\n",
       "        -0.7613, -0.6160, -0.5183, -0.8099, -0.2842, -0.7171, -0.8175, -0.7544,\n",
       "        -0.6756, -0.6866, -0.8396, -0.6721, -0.7540, -0.7058, -0.8029, -0.8766,\n",
       "        -0.6507, -0.5821, -0.7713, -0.8111, -0.7411, -0.6670, -0.7803, -0.8589,\n",
       "        -0.7800,  0.0103, -0.7478, -0.8291, -0.7775, -0.7200, -0.7395, -0.7634,\n",
       "        -0.7170, -0.6361, -0.7726, -0.7158, -0.6174, -0.8835, -0.7060, -0.7879,\n",
       "        -0.8196, -0.5615, -0.7471, -0.3239, -0.8700, -0.7060, -0.7344, -0.6734,\n",
       "        -0.8057, -0.5647, -0.4585, -0.7170, -0.6839, -0.7231, -0.8049, -0.8505,\n",
       "        -0.5710, -0.6554, -0.8563, -0.6291, -0.5989, -0.7694, -0.8001, -0.7257,\n",
       "        -0.1657, -0.7972,  0.1371, -0.6864, -0.6476, -0.7960, -0.7473, -0.8126,\n",
       "        -0.1688, -0.7956, -0.7525, -0.6837, -0.6721, -0.8151, -0.8192, -0.7034,\n",
       "        -0.8212, -0.8529, -0.8109, -0.7415, -0.8087, -0.7194, -0.7262, -0.7224,\n",
       "        -0.8354, -0.7352, -0.6740, -0.6547, -0.4961, -0.8124, -0.8072, -0.6920,\n",
       "        -0.6135, -0.7382, -0.6511, -0.8125, -0.7892, -0.4195, -0.8979, -0.7640,\n",
       "        -0.7934, -0.7303, -0.7391, -0.7136, -0.6972, -0.6236, -0.2068, -0.7243,\n",
       "        -0.8134, -0.7294, -0.6047, -0.6488, -0.6497, -0.7991, -0.7247, -0.6651,\n",
       "        -0.7417, -0.7937, -0.7099, -0.7221, -0.7040, -0.7698, -0.2280, -0.8653,\n",
       "        -0.7911, -0.6735, -0.8641, -0.7838, -0.6288, -0.8011, -0.7483, -0.7537,\n",
       "        -0.7481, -0.6560, -0.7570, -0.6757, -0.7059, -0.8806, -0.7311, -0.8281])), ('fc_rank.weight', tensor([[ 5.1509e-03,  5.3527e-03,  4.5635e-04,  1.3469e-03, -1.9905e-02,\n",
       "         -1.0536e-03,  1.2105e-03, -7.5411e-04,  2.1385e-03, -5.9177e-03,\n",
       "         -2.4476e-03,  9.7069e-03,  3.0663e-03,  6.3931e-04,  3.5765e-03,\n",
       "         -4.8726e-03, -1.1828e-03, -3.4574e-03, -3.7725e-04,  1.0358e-03,\n",
       "         -1.2128e-02,  3.4262e-03, -5.4626e-04,  3.3927e-03, -4.6671e-04,\n",
       "         -2.1270e-03,  1.8159e-03, -1.0562e-02, -1.5116e-03,  1.1154e-03,\n",
       "          2.0135e-03, -5.5850e-03,  1.2317e-02, -3.4253e-04, -3.4226e-03,\n",
       "         -6.1293e-04,  1.7395e-02, -4.2100e-03, -2.7900e-03,  1.1965e-02,\n",
       "          6.4356e-04,  1.0911e-03,  5.7412e-03, -1.8148e-03, -6.0681e-03,\n",
       "          3.7751e-04,  4.5795e-03, -8.9540e-03, -7.0566e-03,  1.6275e-03,\n",
       "          3.3641e-03, -3.4924e-03,  2.7459e-03,  5.7599e-03,  6.8563e-03,\n",
       "          1.3514e-02, -1.8172e-03,  9.3641e-03,  3.0919e-04,  4.1440e-03,\n",
       "          5.3767e-03, -2.9846e-03,  3.2558e-03, -2.6752e-03,  1.3731e-02,\n",
       "         -1.4518e-03, -1.6084e-03,  1.2155e-03, -3.7937e-03,  4.0825e-03,\n",
       "         -1.2928e-02,  1.7419e-04, -2.7942e-03, -1.2007e-03,  5.0313e-03,\n",
       "          4.3683e-04,  1.4339e-03, -9.9499e-03, -6.1881e-03,  2.5984e-03,\n",
       "          3.0328e-03,  1.9467e-03,  5.0426e-03,  2.9025e-03, -2.9823e-02,\n",
       "         -2.8892e-03,  1.3019e-02,  1.9663e-03,  4.4732e-03, -6.4568e-03,\n",
       "          3.1491e-03,  2.9899e-03, -1.0562e-04, -7.6530e-04,  3.7968e-03,\n",
       "         -5.3910e-03, -1.1179e-02, -9.0014e-04,  1.7241e-03,  2.9585e-03,\n",
       "         -7.4985e-04, -1.2580e-03,  1.3382e-03,  4.6969e-03, -6.5115e-03,\n",
       "         -1.3999e-03, -2.6749e-03, -1.0580e-03, -6.4777e-03,  3.8123e-03,\n",
       "          4.7253e-04, -4.4034e-03,  2.3062e-03,  3.9111e-04, -1.8664e-03,\n",
       "         -6.3513e-03,  2.3184e-03, -1.2748e-02, -5.0992e-03,  5.1753e-03,\n",
       "         -6.5393e-04, -5.8973e-03, -5.4398e-03, -4.9229e-03, -1.1496e-03,\n",
       "          4.7645e-04, -7.2287e-04,  1.3863e-03, -6.9763e-03, -7.4350e-05,\n",
       "         -5.5366e-03,  1.2588e-02, -1.2610e-02,  8.1051e-04,  2.1316e-03,\n",
       "          2.4638e-03,  2.7725e-02,  2.6123e-02, -4.9172e-03, -1.7250e-04,\n",
       "         -3.0756e-03,  1.0648e-03,  1.1143e-02,  2.4508e-03, -2.6515e-03,\n",
       "          2.6380e-04,  1.6101e-02, -2.0320e-03, -6.7051e-03,  1.8826e-04,\n",
       "          5.6927e-03,  3.2353e-03,  3.3999e-03, -4.7279e-03,  9.2765e-04,\n",
       "         -1.9483e-05,  6.0555e-04,  4.5490e-03,  2.4910e-03,  3.2704e-04,\n",
       "          1.2612e-03, -9.2230e-04,  4.2387e-03,  4.7854e-03,  5.8439e-03,\n",
       "         -1.9831e-03, -5.4389e-03, -1.9317e-02, -2.7265e-03, -1.4443e-03,\n",
       "          5.0852e-03,  2.4367e-03,  3.0302e-03, -4.1350e-04,  9.3279e-03,\n",
       "         -1.1106e-04,  1.5260e-03,  2.1253e-03, -7.0821e-03, -4.4566e-04,\n",
       "         -2.2039e-03, -7.7292e-04,  3.9742e-03,  2.9665e-03,  3.2540e-03,\n",
       "         -1.9281e-03, -7.6297e-03, -6.9646e-03,  1.5231e-05,  4.7618e-03,\n",
       "         -1.3742e-02,  6.3799e-03, -4.3693e-03, -3.0495e-02,  1.6248e-03,\n",
       "         -2.3925e-03,  1.7159e-03, -1.0495e-02,  7.5656e-04,  2.9730e-03,\n",
       "         -5.7541e-03, -8.0301e-04,  2.3103e-03,  2.6327e-03,  2.3934e-03,\n",
       "          2.4238e-04,  8.9056e-03,  7.0696e-03, -6.6560e-03,  2.7180e-03,\n",
       "         -3.2487e-03,  1.4825e-04, -4.1075e-03,  4.6682e-03,  4.9370e-04,\n",
       "          3.0143e-03,  7.0934e-04,  3.2927e-03,  1.2862e-03, -4.4449e-04,\n",
       "         -1.2484e-03,  3.4247e-03,  5.4897e-03, -6.8124e-03,  4.4922e-03,\n",
       "         -8.9891e-03,  8.1445e-03,  4.9470e-03,  6.8518e-03, -6.6442e-03,\n",
       "          1.4927e-03,  5.6580e-03,  5.5933e-03, -5.4783e-04,  6.3613e-03,\n",
       "         -1.1143e-03, -1.2758e-03, -6.0917e-04,  3.3784e-03,  3.0397e-03,\n",
       "         -3.7120e-03, -3.2079e-03, -1.5449e-02, -2.1920e-03,  7.0176e-04,\n",
       "          2.7288e-03,  2.3807e-03,  5.5738e-03,  2.0234e-03,  6.6531e-03,\n",
       "         -5.8415e-03, -1.5766e-02, -9.0943e-03, -6.1474e-03, -3.6185e-03,\n",
       "          7.9284e-03,  5.6962e-04,  2.0064e-03,  4.9350e-03,  1.4223e-03,\n",
       "          2.4007e-03,  2.1030e-03, -3.7933e-03,  4.9258e-03,  3.5906e-03,\n",
       "          2.4432e-03,  1.2514e-03,  5.6955e-03,  3.4894e-03,  4.3053e-03,\n",
       "          2.7868e-03, -8.4828e-04, -7.6563e-03, -5.1928e-03,  7.6538e-04,\n",
       "         -2.6362e-04,  8.0181e-03,  8.9878e-03,  3.9016e-03,  2.5711e-03,\n",
       "         -1.3728e-03,  9.7359e-03,  2.1298e-03, -4.6960e-02,  3.1884e-03,\n",
       "          6.4060e-03,  3.0596e-03,  6.8234e-04,  3.7822e-03, -1.2753e-03,\n",
       "         -3.8215e-04, -1.1492e-03,  2.1680e-03,  7.5949e-03, -1.1106e-03,\n",
       "          3.5569e-03,  7.8369e-03,  8.2035e-03,  2.1834e-03, -8.2893e-04,\n",
       "         -3.4548e-03,  7.9871e-03,  7.4203e-03,  2.2738e-03,  5.6030e-03,\n",
       "         -1.8358e-03, -9.2854e-04, -1.3962e-04, -4.1996e-03, -6.0783e-04,\n",
       "          7.2158e-03,  1.9460e-03, -1.0930e-03, -1.8411e-04, -5.5879e-05,\n",
       "          3.6668e-04, -4.6385e-03,  8.3762e-03,  2.1266e-03,  1.2671e-03,\n",
       "         -3.3332e-03, -4.3879e-03, -2.3435e-03,  5.9489e-03, -3.9327e-03,\n",
       "         -8.4251e-04,  6.6346e-03, -2.3812e-03, -2.5256e-03,  5.6035e-03,\n",
       "         -1.9586e-03, -3.1728e-03, -2.8034e-03, -9.5185e-04,  5.7851e-03,\n",
       "          2.9846e-03,  6.0379e-03,  7.2703e-03, -1.7584e-03,  2.6096e-03,\n",
       "         -3.7418e-03, -2.2086e-02,  3.9150e-03, -1.6616e-03, -5.5669e-03,\n",
       "          9.3712e-03, -6.0401e-03, -1.4045e-02,  4.3223e-03, -8.4124e-03,\n",
       "         -7.5224e-03, -4.1490e-03, -8.0023e-04, -7.2291e-04,  5.9454e-03,\n",
       "          8.3097e-04, -2.7120e-03,  1.5092e-03,  2.4222e-02,  1.4104e-03,\n",
       "          4.0356e-03, -7.5720e-03,  4.9301e-03, -2.7086e-03, -1.1861e-03,\n",
       "         -1.3620e-02,  3.3576e-03, -1.1090e-02,  2.4748e-03,  9.4635e-04,\n",
       "          2.8380e-02, -7.2980e-03, -1.6748e-02, -3.3741e-03,  4.9372e-04,\n",
       "          3.1755e-03,  2.2367e-03, -2.5333e-03,  4.3058e-03,  2.2720e-03,\n",
       "          2.2005e-03, -8.6757e-03, -5.7265e-03,  1.4489e-03,  8.0993e-03,\n",
       "         -1.4471e-03, -1.1457e-04,  1.6136e-03, -1.8389e-03,  8.2227e-03,\n",
       "          5.3749e-03, -1.0408e-03,  9.9654e-04, -2.5684e-04,  7.6622e-03,\n",
       "          2.8012e-03,  6.6243e-03,  4.9823e-03,  4.0383e-03, -2.3599e-03,\n",
       "          2.3810e-04, -4.5007e-03, -1.0321e-03,  1.9207e-04,  2.3372e-03,\n",
       "          5.9381e-03, -3.0398e-03,  3.9953e-03,  1.3197e-03, -8.0390e-03,\n",
       "          6.0387e-04, -8.8545e-03, -1.8910e-04,  1.1861e-03, -3.6189e-03,\n",
       "         -8.9414e-04,  3.7207e-04, -7.8352e-03, -8.5385e-03,  2.5326e-03,\n",
       "         -6.5131e-03,  6.5072e-04,  1.0948e-03, -3.8551e-03, -7.8956e-03,\n",
       "         -2.9058e-03, -2.3399e-03, -5.9482e-03,  4.9820e-03, -1.5129e-03,\n",
       "         -1.3970e-03,  1.8878e-03,  2.6037e-02,  2.1239e-03,  1.2373e-02,\n",
       "         -3.1199e-03,  2.4383e-03,  4.5437e-03, -5.2326e-03,  9.6224e-04,\n",
       "          1.9585e-02,  5.8169e-03, -6.5474e-03, -2.6314e-03, -8.9744e-04,\n",
       "          3.9168e-03,  1.9776e-03,  5.2697e-04,  4.1797e-03, -2.9715e-03,\n",
       "          4.2285e-03, -8.8435e-04,  3.8017e-04,  6.2078e-03,  1.3738e-04,\n",
       "         -6.6137e-03, -2.4081e-03,  4.1236e-03, -1.9971e-03,  1.6556e-03,\n",
       "         -4.0215e-05,  6.2783e-04, -5.4000e-03, -2.5218e-03, -2.2268e-03,\n",
       "          2.3740e-03, -3.9283e-03,  4.4026e-03,  4.6312e-04,  1.2193e-02,\n",
       "         -3.9014e-03, -5.0284e-04,  7.9820e-05,  3.9291e-03,  1.4045e-03,\n",
       "         -1.1841e-02, -6.7879e-03, -1.2934e-03, -8.9156e-03, -5.9948e-03,\n",
       "          5.4834e-03, -1.0759e-05,  1.1635e-02, -4.8803e-03,  1.9988e-04,\n",
       "          1.1743e-02,  1.0016e-03, -8.4472e-03,  3.5292e-03, -4.5690e-03,\n",
       "          1.5077e-03, -2.4041e-03,  5.3630e-03,  1.9356e-03,  1.9336e-02,\n",
       "          1.5122e-03, -3.5098e-03,  5.2232e-03, -5.0219e-03,  9.6389e-03,\n",
       "         -7.2707e-03, -2.6708e-03,  6.6903e-03, -1.8230e-03, -5.7928e-03,\n",
       "         -4.9578e-03,  4.0080e-03, -3.1227e-03,  1.0250e-02, -3.5601e-03,\n",
       "          7.3428e-03,  1.7555e-03]])), ('fc_rank.bias', tensor([-4.5970])), ('fc_regression.weight', tensor([[-0.0071, -0.0004,  0.0024,  ...,  0.0009,  0.0063,  0.0054],\n",
       "        [ 0.0557,  0.0009,  0.0003,  ...,  0.0077, -0.0014, -0.0040],\n",
       "        [-0.0146,  0.0055,  0.0051,  ...,  0.0014, -0.0030,  0.0037],\n",
       "        [ 0.0051,  0.0010,  0.0022,  ...,  0.0002, -0.0093,  0.0069]])), ('fc_regression.bias', tensor([-0.0032, -0.0207,  0.0066,  0.0740]))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.state_dict().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_dict = model_en.state_dict()\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k != \"embedding.weight\"}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "# 3. load the new state dict\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[ 0.6745, -3.4088,  1.9979,  ..., -0.0156,  0.0784, -0.3459],\n",
       "                      [ 1.0027,  0.0932,  0.0216,  ...,  0.0527,  0.3173,  0.7685],\n",
       "                      [-0.4296,  0.1829,  1.8594,  ..., -0.3114, -2.5064,  0.2881],\n",
       "                      ...,\n",
       "                      [-0.7272, -0.4035, -1.5756,  ...,  0.4721, -0.9802, -0.4710],\n",
       "                      [ 0.0076,  1.9663, -2.5632,  ..., -0.6804, -1.2699, -1.0845],\n",
       "                      [-0.4288, -1.0715, -0.5323,  ...,  1.8674,  0.6794,  1.4025]])),\n",
       "             ('lstm.weight_ih_l0',\n",
       "              tensor([[ 0.0853, -0.0833,  0.1183,  ..., -0.1000,  0.0568, -0.1339],\n",
       "                      [ 0.0024,  0.1039,  0.0174,  ..., -0.0104, -0.0737, -0.2190],\n",
       "                      [ 0.0786,  0.0711, -0.0738,  ..., -0.1413, -0.1097,  0.0262],\n",
       "                      ...,\n",
       "                      [-0.0287, -0.1493, -0.0651,  ..., -0.1109,  0.0185,  0.0355],\n",
       "                      [-0.0039,  0.0497, -0.0874,  ...,  0.2767,  0.2946, -0.0249],\n",
       "                      [-0.0701, -0.0918,  0.0208,  ...,  0.0556,  0.0070,  0.2107]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-0.1128,  0.0071,  0.0659,  ...,  0.0710,  0.1208, -0.0230],\n",
       "                      [ 0.1511,  0.1486, -0.0011,  ..., -0.0510,  0.0154,  0.1128],\n",
       "                      [-0.0177, -0.0751, -0.0630,  ..., -0.0530, -0.0803,  0.0173],\n",
       "                      ...,\n",
       "                      [-0.0919,  0.1003,  0.0979,  ...,  0.0456,  0.0110,  0.0232],\n",
       "                      [ 0.0613, -0.1331,  0.1599,  ..., -0.0971,  0.0814,  0.0241],\n",
       "                      [ 0.0272,  0.3311,  0.1051,  ..., -0.1327,  0.0803, -0.0977]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([-0.0231, -0.1082, -0.1312,  ..., -0.1933, -0.2480, -0.2443])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([-0.0078, -0.0917, -0.1264,  ..., -0.2223, -0.2028, -0.2484])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0168, -0.0216,  0.0127,  ...,  0.0080, -0.0034, -0.0054],\n",
       "                      [-0.0108, -0.0315, -0.0357,  ..., -0.1420,  0.0207,  0.0884],\n",
       "                      [-0.0348, -0.0275, -0.0118,  ..., -0.0893, -0.1060,  0.0546],\n",
       "                      ...,\n",
       "                      [-0.0118, -0.0332, -0.0289,  ..., -0.0879, -0.0024,  0.1927],\n",
       "                      [-0.0127, -0.0211, -0.0096,  ..., -0.1079, -0.0757,  0.0948],\n",
       "                      [-0.0230,  0.0119, -0.0226,  ..., -0.1315,  0.0038,  0.0909]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0522, -0.8491, -0.8050, -0.9052, -0.6854, -0.8034, -0.9282, -0.8416,\n",
       "                      -0.7137, -0.8011, -0.6062, -0.8014, -0.7608, -0.7913, -0.7198, -0.7600,\n",
       "                      -0.7157, -0.6570, -0.7018, -0.7787, -0.5001, -0.6519, -0.6003, -0.7672,\n",
       "                      -0.7739, -0.6940, -0.7735, -0.7440, -0.8754, -0.6366, -0.7314, -0.6086,\n",
       "                      -0.8598, -0.7685, -0.6313, -0.0123, -0.4367, -0.7331, -0.7776, -0.8665,\n",
       "                      -0.7401, -0.7944, -0.6084, -0.7813, -0.8245, -0.7576, -0.5732, -0.8005,\n",
       "                      -0.4625, -0.7702, -0.7982, -0.7568, -0.8450, -0.4856, -0.7800,  0.0242,\n",
       "                      -0.5521, -0.5928, -0.6961, -0.7492, -0.8607, -0.7492, -0.6457, -0.7793,\n",
       "                      -0.7336, -0.8088, -0.6592, -0.7320, -0.7150, -0.7417, -0.6065, -0.8184,\n",
       "                      -0.5995, -0.7724, -0.7022, -0.8082, -0.6508, -0.6291, -0.7543, -0.7736,\n",
       "                      -0.8117, -0.6894, -0.7833, -0.7371, -0.1330, -0.7418,  0.1003, -0.6991,\n",
       "                      -0.7694, -0.7769, -0.7055, -0.7164, -0.6963, -0.8483, -0.7719, -0.7865,\n",
       "                      -0.6577, -0.6572, -0.8103, -0.6873, -0.7708, -0.7500, -0.7114, -0.9904,\n",
       "                      -0.6858, -0.7763, -0.7405, -0.7939, -0.7812, -0.7632, -0.8357,  0.0064,\n",
       "                      -0.7566, -0.7844, -0.7826, -0.5539, -0.7834, -0.6163, -0.7186, -0.7139,\n",
       "                      -0.8381, -0.8435, -0.6358, -0.6645, -0.7445, -0.7527, -0.6268, -0.7182,\n",
       "                      -0.8158, -0.7977, -0.7629, -0.7606, -0.5308, -0.6932, -0.7165, -0.6715,\n",
       "                      -0.6929, -0.1588, -0.6704, -0.6992, -0.6940, -0.7877, -0.6202, -0.8697,\n",
       "                      -0.6231, -0.7906, -0.7524, -0.6347, -0.4447, -0.7210, -0.4930, -0.7335,\n",
       "                      -0.8357, -0.6313, -0.8153, -0.7963, -0.6347, -0.7984, -0.7425, -0.7045,\n",
       "                      -0.7875, -0.6461, -0.5935, -0.6958, -0.8697, -0.7588, -0.6507,  0.1459,\n",
       "                      -0.8574, -0.6590, -0.6743, -0.7020, -0.8638, -0.7496, -0.5727, -0.9357,\n",
       "                      -0.6712, -0.6363, -0.7526, -0.6848, -0.8291, -0.6435, -0.6456, -0.7695,\n",
       "                      -0.8652, -0.8403, -0.7993, -0.7045, -0.7553, -0.7245, -0.5867, -0.5780,\n",
       "                      -0.6398, -0.1012, -0.7435, -0.7500, -0.8412, -0.7332, -0.7796, -0.8388,\n",
       "                      -0.7359, -0.6863, -0.6757, -0.8044, -0.7125, -0.7852, -0.5312, -0.8536,\n",
       "                      -0.6929, -0.7816, -0.7471, -0.7236, -0.7681, -0.7529, -0.8032, -0.8147,\n",
       "                      -0.7352, -0.7076, -0.7022, -0.7148, -0.7921, -0.7945, -0.6749,  0.1405,\n",
       "                      -0.8199, -0.7211, -0.6436, -0.6579, -0.5783, -0.6675, -0.8102, -0.7893,\n",
       "                      -0.9462, -0.5776, -0.0377, -0.8316, -0.7930, -0.7938, -0.6074, -0.6415,\n",
       "                      -0.7256, -0.8270, -0.4422, -0.6638, -0.6945, -0.7070, -0.7916, -0.7802,\n",
       "                      -0.8085, -0.8861, -0.6952, -0.7163, -0.5582, -0.7082, -0.7919, -0.7814,\n",
       "                      -0.5799, -0.8190, -0.7410, -0.7492, -0.7281, -0.7724, -0.7578, -0.6426,\n",
       "                      -0.6658, -0.8818, -0.6559, -0.7232, -0.8127, -0.7772, -0.7438, -0.5793,\n",
       "                      -0.6172, -0.5156, -0.9325, -0.8947, -0.6010, -0.7347, -0.7404, -0.8592,\n",
       "                      -0.7655, -0.8782, -0.7564,  0.2368, -0.7074, -0.7886, -0.6927, -0.7668,\n",
       "                      -0.6119, -0.7600, -0.6012, -0.7360, -0.7552, -0.6163,  0.0169, -0.7875,\n",
       "                      -0.7007, -0.8401, -0.6779, -0.8226, -0.7403, -0.7431, -0.7408, -0.7976,\n",
       "                      -0.6079, -0.9048, -0.7227, -0.6401, -0.6798, -0.8027, -0.8204, -0.7307,\n",
       "                      -0.8775, -0.7210, -0.8327, -0.7036, -0.6927, -0.6920, -0.8180, -0.5885,\n",
       "                      -0.7275, -0.6924, -0.7834, -0.6938, -0.6861, -0.8264, -0.7025, -0.7380,\n",
       "                      -0.7240, -0.7710, -0.7800, -0.7499, -0.6452, -0.8161, -0.8033, -0.7812,\n",
       "                      -0.7360, -0.8446, -0.6798, -0.6831, -0.8595, -0.2063, -0.7356, -0.7306,\n",
       "                      -0.8053, -0.8053, -0.6831, -0.6433, -0.6890, -0.7676, -0.7610, -0.8412,\n",
       "                      -0.8083, -0.8317, -0.7162, -0.8203, -0.7799, -0.7007, -0.4411, -0.8112,\n",
       "                      -0.5702, -0.7098, -0.9333, -0.7504, -0.9151, -0.0179, -0.8080, -0.6515,\n",
       "                      -0.7613, -0.6160, -0.5183, -0.8099, -0.2842, -0.7171, -0.8175, -0.7544,\n",
       "                      -0.6756, -0.6866, -0.8396, -0.6721, -0.7540, -0.7058, -0.8029, -0.8766,\n",
       "                      -0.6507, -0.5821, -0.7713, -0.8111, -0.7411, -0.6670, -0.7803, -0.8589,\n",
       "                      -0.7800,  0.0103, -0.7478, -0.8291, -0.7775, -0.7200, -0.7395, -0.7634,\n",
       "                      -0.7170, -0.6361, -0.7726, -0.7158, -0.6174, -0.8835, -0.7060, -0.7879,\n",
       "                      -0.8196, -0.5615, -0.7471, -0.3239, -0.8700, -0.7060, -0.7344, -0.6734,\n",
       "                      -0.8057, -0.5647, -0.4585, -0.7170, -0.6839, -0.7231, -0.8049, -0.8505,\n",
       "                      -0.5710, -0.6554, -0.8563, -0.6291, -0.5989, -0.7694, -0.8001, -0.7257,\n",
       "                      -0.1657, -0.7972,  0.1371, -0.6864, -0.6476, -0.7960, -0.7473, -0.8126,\n",
       "                      -0.1688, -0.7956, -0.7525, -0.6837, -0.6721, -0.8151, -0.8192, -0.7034,\n",
       "                      -0.8212, -0.8529, -0.8109, -0.7415, -0.8087, -0.7194, -0.7262, -0.7224,\n",
       "                      -0.8354, -0.7352, -0.6740, -0.6547, -0.4961, -0.8124, -0.8072, -0.6920,\n",
       "                      -0.6135, -0.7382, -0.6511, -0.8125, -0.7892, -0.4195, -0.8979, -0.7640,\n",
       "                      -0.7934, -0.7303, -0.7391, -0.7136, -0.6972, -0.6236, -0.2068, -0.7243,\n",
       "                      -0.8134, -0.7294, -0.6047, -0.6488, -0.6497, -0.7991, -0.7247, -0.6651,\n",
       "                      -0.7417, -0.7937, -0.7099, -0.7221, -0.7040, -0.7698, -0.2280, -0.8653,\n",
       "                      -0.7911, -0.6735, -0.8641, -0.7838, -0.6288, -0.8011, -0.7483, -0.7537,\n",
       "                      -0.7481, -0.6560, -0.7570, -0.6757, -0.7059, -0.8806, -0.7311, -0.8281])),\n",
       "             ('fc_rank.weight',\n",
       "              tensor([[ 5.1509e-03,  5.3527e-03,  4.5635e-04,  1.3469e-03, -1.9905e-02,\n",
       "                       -1.0536e-03,  1.2105e-03, -7.5411e-04,  2.1385e-03, -5.9177e-03,\n",
       "                       -2.4476e-03,  9.7069e-03,  3.0663e-03,  6.3931e-04,  3.5765e-03,\n",
       "                       -4.8726e-03, -1.1828e-03, -3.4574e-03, -3.7725e-04,  1.0358e-03,\n",
       "                       -1.2128e-02,  3.4262e-03, -5.4626e-04,  3.3927e-03, -4.6671e-04,\n",
       "                       -2.1270e-03,  1.8159e-03, -1.0562e-02, -1.5116e-03,  1.1154e-03,\n",
       "                        2.0135e-03, -5.5850e-03,  1.2317e-02, -3.4253e-04, -3.4226e-03,\n",
       "                       -6.1293e-04,  1.7395e-02, -4.2100e-03, -2.7900e-03,  1.1965e-02,\n",
       "                        6.4356e-04,  1.0911e-03,  5.7412e-03, -1.8148e-03, -6.0681e-03,\n",
       "                        3.7751e-04,  4.5795e-03, -8.9540e-03, -7.0566e-03,  1.6275e-03,\n",
       "                        3.3641e-03, -3.4924e-03,  2.7459e-03,  5.7599e-03,  6.8563e-03,\n",
       "                        1.3514e-02, -1.8172e-03,  9.3641e-03,  3.0919e-04,  4.1440e-03,\n",
       "                        5.3767e-03, -2.9846e-03,  3.2558e-03, -2.6752e-03,  1.3731e-02,\n",
       "                       -1.4518e-03, -1.6084e-03,  1.2155e-03, -3.7937e-03,  4.0825e-03,\n",
       "                       -1.2928e-02,  1.7419e-04, -2.7942e-03, -1.2007e-03,  5.0313e-03,\n",
       "                        4.3683e-04,  1.4339e-03, -9.9499e-03, -6.1881e-03,  2.5984e-03,\n",
       "                        3.0328e-03,  1.9467e-03,  5.0426e-03,  2.9025e-03, -2.9823e-02,\n",
       "                       -2.8892e-03,  1.3019e-02,  1.9663e-03,  4.4732e-03, -6.4568e-03,\n",
       "                        3.1491e-03,  2.9899e-03, -1.0562e-04, -7.6530e-04,  3.7968e-03,\n",
       "                       -5.3910e-03, -1.1179e-02, -9.0014e-04,  1.7241e-03,  2.9585e-03,\n",
       "                       -7.4985e-04, -1.2580e-03,  1.3382e-03,  4.6969e-03, -6.5115e-03,\n",
       "                       -1.3999e-03, -2.6749e-03, -1.0580e-03, -6.4777e-03,  3.8123e-03,\n",
       "                        4.7253e-04, -4.4034e-03,  2.3062e-03,  3.9111e-04, -1.8664e-03,\n",
       "                       -6.3513e-03,  2.3184e-03, -1.2748e-02, -5.0992e-03,  5.1753e-03,\n",
       "                       -6.5393e-04, -5.8973e-03, -5.4398e-03, -4.9229e-03, -1.1496e-03,\n",
       "                        4.7645e-04, -7.2287e-04,  1.3863e-03, -6.9763e-03, -7.4350e-05,\n",
       "                       -5.5366e-03,  1.2588e-02, -1.2610e-02,  8.1051e-04,  2.1316e-03,\n",
       "                        2.4638e-03,  2.7725e-02,  2.6123e-02, -4.9172e-03, -1.7250e-04,\n",
       "                       -3.0756e-03,  1.0648e-03,  1.1143e-02,  2.4508e-03, -2.6515e-03,\n",
       "                        2.6380e-04,  1.6101e-02, -2.0320e-03, -6.7051e-03,  1.8826e-04,\n",
       "                        5.6927e-03,  3.2353e-03,  3.3999e-03, -4.7279e-03,  9.2765e-04,\n",
       "                       -1.9483e-05,  6.0555e-04,  4.5490e-03,  2.4910e-03,  3.2704e-04,\n",
       "                        1.2612e-03, -9.2230e-04,  4.2387e-03,  4.7854e-03,  5.8439e-03,\n",
       "                       -1.9831e-03, -5.4389e-03, -1.9317e-02, -2.7265e-03, -1.4443e-03,\n",
       "                        5.0852e-03,  2.4367e-03,  3.0302e-03, -4.1350e-04,  9.3279e-03,\n",
       "                       -1.1106e-04,  1.5260e-03,  2.1253e-03, -7.0821e-03, -4.4566e-04,\n",
       "                       -2.2039e-03, -7.7292e-04,  3.9742e-03,  2.9665e-03,  3.2540e-03,\n",
       "                       -1.9281e-03, -7.6297e-03, -6.9646e-03,  1.5231e-05,  4.7618e-03,\n",
       "                       -1.3742e-02,  6.3799e-03, -4.3693e-03, -3.0495e-02,  1.6248e-03,\n",
       "                       -2.3925e-03,  1.7159e-03, -1.0495e-02,  7.5656e-04,  2.9730e-03,\n",
       "                       -5.7541e-03, -8.0301e-04,  2.3103e-03,  2.6327e-03,  2.3934e-03,\n",
       "                        2.4238e-04,  8.9056e-03,  7.0696e-03, -6.6560e-03,  2.7180e-03,\n",
       "                       -3.2487e-03,  1.4825e-04, -4.1075e-03,  4.6682e-03,  4.9370e-04,\n",
       "                        3.0143e-03,  7.0934e-04,  3.2927e-03,  1.2862e-03, -4.4449e-04,\n",
       "                       -1.2484e-03,  3.4247e-03,  5.4897e-03, -6.8124e-03,  4.4922e-03,\n",
       "                       -8.9891e-03,  8.1445e-03,  4.9470e-03,  6.8518e-03, -6.6442e-03,\n",
       "                        1.4927e-03,  5.6580e-03,  5.5933e-03, -5.4783e-04,  6.3613e-03,\n",
       "                       -1.1143e-03, -1.2758e-03, -6.0917e-04,  3.3784e-03,  3.0397e-03,\n",
       "                       -3.7120e-03, -3.2079e-03, -1.5449e-02, -2.1920e-03,  7.0176e-04,\n",
       "                        2.7288e-03,  2.3807e-03,  5.5738e-03,  2.0234e-03,  6.6531e-03,\n",
       "                       -5.8415e-03, -1.5766e-02, -9.0943e-03, -6.1474e-03, -3.6185e-03,\n",
       "                        7.9284e-03,  5.6962e-04,  2.0064e-03,  4.9350e-03,  1.4223e-03,\n",
       "                        2.4007e-03,  2.1030e-03, -3.7933e-03,  4.9258e-03,  3.5906e-03,\n",
       "                        2.4432e-03,  1.2514e-03,  5.6955e-03,  3.4894e-03,  4.3053e-03,\n",
       "                        2.7868e-03, -8.4828e-04, -7.6563e-03, -5.1928e-03,  7.6538e-04,\n",
       "                       -2.6362e-04,  8.0181e-03,  8.9878e-03,  3.9016e-03,  2.5711e-03,\n",
       "                       -1.3728e-03,  9.7359e-03,  2.1298e-03, -4.6960e-02,  3.1884e-03,\n",
       "                        6.4060e-03,  3.0596e-03,  6.8234e-04,  3.7822e-03, -1.2753e-03,\n",
       "                       -3.8215e-04, -1.1492e-03,  2.1680e-03,  7.5949e-03, -1.1106e-03,\n",
       "                        3.5569e-03,  7.8369e-03,  8.2035e-03,  2.1834e-03, -8.2893e-04,\n",
       "                       -3.4548e-03,  7.9871e-03,  7.4203e-03,  2.2738e-03,  5.6030e-03,\n",
       "                       -1.8358e-03, -9.2854e-04, -1.3962e-04, -4.1996e-03, -6.0783e-04,\n",
       "                        7.2158e-03,  1.9460e-03, -1.0930e-03, -1.8411e-04, -5.5879e-05,\n",
       "                        3.6668e-04, -4.6385e-03,  8.3762e-03,  2.1266e-03,  1.2671e-03,\n",
       "                       -3.3332e-03, -4.3879e-03, -2.3435e-03,  5.9489e-03, -3.9327e-03,\n",
       "                       -8.4251e-04,  6.6346e-03, -2.3812e-03, -2.5256e-03,  5.6035e-03,\n",
       "                       -1.9586e-03, -3.1728e-03, -2.8034e-03, -9.5185e-04,  5.7851e-03,\n",
       "                        2.9846e-03,  6.0379e-03,  7.2703e-03, -1.7584e-03,  2.6096e-03,\n",
       "                       -3.7418e-03, -2.2086e-02,  3.9150e-03, -1.6616e-03, -5.5669e-03,\n",
       "                        9.3712e-03, -6.0401e-03, -1.4045e-02,  4.3223e-03, -8.4124e-03,\n",
       "                       -7.5224e-03, -4.1490e-03, -8.0023e-04, -7.2291e-04,  5.9454e-03,\n",
       "                        8.3097e-04, -2.7120e-03,  1.5092e-03,  2.4222e-02,  1.4104e-03,\n",
       "                        4.0356e-03, -7.5720e-03,  4.9301e-03, -2.7086e-03, -1.1861e-03,\n",
       "                       -1.3620e-02,  3.3576e-03, -1.1090e-02,  2.4748e-03,  9.4635e-04,\n",
       "                        2.8380e-02, -7.2980e-03, -1.6748e-02, -3.3741e-03,  4.9372e-04,\n",
       "                        3.1755e-03,  2.2367e-03, -2.5333e-03,  4.3058e-03,  2.2720e-03,\n",
       "                        2.2005e-03, -8.6757e-03, -5.7265e-03,  1.4489e-03,  8.0993e-03,\n",
       "                       -1.4471e-03, -1.1457e-04,  1.6136e-03, -1.8389e-03,  8.2227e-03,\n",
       "                        5.3749e-03, -1.0408e-03,  9.9654e-04, -2.5684e-04,  7.6622e-03,\n",
       "                        2.8012e-03,  6.6243e-03,  4.9823e-03,  4.0383e-03, -2.3599e-03,\n",
       "                        2.3810e-04, -4.5007e-03, -1.0321e-03,  1.9207e-04,  2.3372e-03,\n",
       "                        5.9381e-03, -3.0398e-03,  3.9953e-03,  1.3197e-03, -8.0390e-03,\n",
       "                        6.0387e-04, -8.8545e-03, -1.8910e-04,  1.1861e-03, -3.6189e-03,\n",
       "                       -8.9414e-04,  3.7207e-04, -7.8352e-03, -8.5385e-03,  2.5326e-03,\n",
       "                       -6.5131e-03,  6.5072e-04,  1.0948e-03, -3.8551e-03, -7.8956e-03,\n",
       "                       -2.9058e-03, -2.3399e-03, -5.9482e-03,  4.9820e-03, -1.5129e-03,\n",
       "                       -1.3970e-03,  1.8878e-03,  2.6037e-02,  2.1239e-03,  1.2373e-02,\n",
       "                       -3.1199e-03,  2.4383e-03,  4.5437e-03, -5.2326e-03,  9.6224e-04,\n",
       "                        1.9585e-02,  5.8169e-03, -6.5474e-03, -2.6314e-03, -8.9744e-04,\n",
       "                        3.9168e-03,  1.9776e-03,  5.2697e-04,  4.1797e-03, -2.9715e-03,\n",
       "                        4.2285e-03, -8.8435e-04,  3.8017e-04,  6.2078e-03,  1.3738e-04,\n",
       "                       -6.6137e-03, -2.4081e-03,  4.1236e-03, -1.9971e-03,  1.6556e-03,\n",
       "                       -4.0215e-05,  6.2783e-04, -5.4000e-03, -2.5218e-03, -2.2268e-03,\n",
       "                        2.3740e-03, -3.9283e-03,  4.4026e-03,  4.6312e-04,  1.2193e-02,\n",
       "                       -3.9014e-03, -5.0284e-04,  7.9820e-05,  3.9291e-03,  1.4045e-03,\n",
       "                       -1.1841e-02, -6.7879e-03, -1.2934e-03, -8.9156e-03, -5.9948e-03,\n",
       "                        5.4834e-03, -1.0759e-05,  1.1635e-02, -4.8803e-03,  1.9988e-04,\n",
       "                        1.1743e-02,  1.0016e-03, -8.4472e-03,  3.5292e-03, -4.5690e-03,\n",
       "                        1.5077e-03, -2.4041e-03,  5.3630e-03,  1.9356e-03,  1.9336e-02,\n",
       "                        1.5122e-03, -3.5098e-03,  5.2232e-03, -5.0219e-03,  9.6389e-03,\n",
       "                       -7.2707e-03, -2.6708e-03,  6.6903e-03, -1.8230e-03, -5.7928e-03,\n",
       "                       -4.9578e-03,  4.0080e-03, -3.1227e-03,  1.0250e-02, -3.5601e-03,\n",
       "                        7.3428e-03,  1.7555e-03]])),\n",
       "             ('fc_rank.bias', tensor([-4.5970])),\n",
       "             ('fc_regression.weight',\n",
       "              tensor([[-0.0071, -0.0004,  0.0024,  ...,  0.0009,  0.0063,  0.0054],\n",
       "                      [ 0.0557,  0.0009,  0.0003,  ...,  0.0077, -0.0014, -0.0040],\n",
       "                      [-0.0146,  0.0055,  0.0051,  ...,  0.0014, -0.0030,  0.0037],\n",
       "                      [ 0.0051,  0.0010,  0.0022,  ...,  0.0002, -0.0093,  0.0069]])),\n",
       "             ('fc_regression.bias',\n",
       "              tensor([-0.0032, -0.0207,  0.0066,  0.0740]))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14384, 300])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_en = model_en.state_dict()[\"embedding.weight\"]\n",
    "emb_en.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1278, 300])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()[\"embedding.weight\"].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init model: put things above together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_for_transfer(training_corpus_dct, training_corpus_dct_en, english_pretrained_model_path, cfg):\n",
    "    en_vocab = len(training_corpus_dct_en.token2id)\n",
    "    fr_vocab = len(training_corpus_dct.token2id)\n",
    "\n",
    "    model = DDPN(cfg, vocab_size=fr_vocab)\n",
    "    model_en = DDPN(cfg, vocab_size=en_vocab)\n",
    "\n",
    "    #model_en.load_state_dict(torch.load(english_pretrained_model_path, map_location=device))\n",
    "    checkpoint = torch.load(english_pretrained_model_path, map_location=device)\n",
    "\n",
    "    if not cfg.regression_loss:  # In case of the pretrained model has regression loss while transfering model doesn't\n",
    "        try:\n",
    "            checkpoint['model_state_dict'].pop(\"fc_regression.weight\")\n",
    "            checkpoint['model_state_dict'].pop(\"fc_regression.bias\")\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    model_en.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    \n",
    "\n",
    "    pretrained_dict = model_en.state_dict()\n",
    "    model_dict = model.state_dict()\n",
    "\n",
    "    # 1. filter out unnecessary keys\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k != \"embedding.weight\"}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict) \n",
    "    # 3. load the new state dict\n",
    "    #model.load_state_dict(model_dict)\n",
    "    \n",
    "    return model, model_en, model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_en, model_dict = prepare_model_for_transfer(training_corpus_dct, \n",
    "                                                        training_corpus_dct_en, \n",
    "                                                        english_pretrained_model_path, \n",
    "                                                        cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/dongwenjian/SSDBACKUP/Internship/DDPN_transfer/pretrained-models/2019-08-17_19-26-48_L1-gt-softlabel_drop0.5_checkpoint_4_69.30.tar'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_pretrained_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test: only the word embedding will be transfered. All other layers will be trained from scratch. \n",
    "def prepare_model_for_transfer_no_transfer_learning(training_corpus_dct, training_corpus_dct_en, english_pretrained_model_path, cfg):\n",
    "    en_vocab = len(training_corpus_dct_en.token2id)\n",
    "    fr_vocab = len(training_corpus_dct.token2id)\n",
    "\n",
    "    model = DDPN(cfg, vocab_size=fr_vocab)\n",
    "    model_en = DDPN(cfg, vocab_size=en_vocab)\n",
    "\n",
    "    #model_en.load_state_dict(torch.load(english_pretrained_model_path, map_location=device))\n",
    "    checkpoint = torch.load(english_pretrained_model_path, map_location=device)\n",
    "\n",
    "    if not cfg.regression_loss:  # In case of the pretrained model has regression loss while transfering model doesn't\n",
    "        try:\n",
    "            checkpoint['model_state_dict'].pop(\"fc_regression.weight\")\n",
    "            checkpoint['model_state_dict'].pop(\"fc_regression.bias\")\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    model_en.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    \n",
    "\n",
    "    model_dict = model.state_dict()\n",
    "\n",
    "    \n",
    "    \n",
    "    return model, model_en, model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_en, model_dict = prepare_model_for_transfer_no_transfer_learning(training_corpus_dct, \n",
    "                                                        training_corpus_dct_en, \n",
    "                                                        english_pretrained_model_path, \n",
    "                                                        cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xavier initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[-1.1616,  0.2428, -0.4151,  ...,  1.2138,  0.6308,  0.9409],\n",
       "                      [-0.6414, -1.0994,  0.3357,  ..., -0.4051, -0.0729,  1.0998],\n",
       "                      [ 1.1675,  0.6098, -0.0414,  ..., -0.2666, -1.5640,  1.0458],\n",
       "                      ...,\n",
       "                      [-0.9786, -1.1147,  0.6099,  ..., -0.7170,  0.1602,  0.4780],\n",
       "                      [ 0.0235, -0.5968, -2.1768,  ..., -0.0141,  1.1254, -2.6534],\n",
       "                      [-0.1067,  0.0974, -0.5876,  ...,  0.1812,  1.6167, -0.5884]])),\n",
       "             ('lstm.weight_ih_l0',\n",
       "              tensor([[-8.2271e-02, -2.6502e-02,  1.3620e-01,  ...,  1.7146e-01,\n",
       "                        1.5154e-01, -8.0110e-02],\n",
       "                      [-1.4765e-01,  7.7709e-02, -4.5470e-02,  ..., -1.7563e-01,\n",
       "                       -5.4936e-02,  1.5066e-01],\n",
       "                      [ 1.1844e-01,  5.8075e-03,  1.9253e-04,  ...,  9.0586e-02,\n",
       "                       -1.2200e-01,  2.1301e-02],\n",
       "                      ...,\n",
       "                      [ 3.5888e-01, -8.1858e-02, -6.5284e-02,  ..., -4.0579e-02,\n",
       "                        2.4097e-02,  2.1075e-01],\n",
       "                      [ 1.1874e-01,  2.2968e-01,  1.1914e-01,  ..., -1.8865e-03,\n",
       "                       -2.9639e-01, -2.0719e-01],\n",
       "                      [ 1.2594e-01, -1.1320e-01,  1.0662e-01,  ...,  7.6919e-02,\n",
       "                       -1.1031e-01, -9.1731e-02]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[ 0.2194,  0.1908, -0.0803,  ...,  0.1767,  0.0452, -0.0051],\n",
       "                      [-0.1178, -0.1192,  0.1934,  ...,  0.0464, -0.2070, -0.3033],\n",
       "                      [ 0.0826, -0.0236, -0.0321,  ..., -0.0195, -0.1177,  0.0623],\n",
       "                      ...,\n",
       "                      [ 0.1186, -0.0156,  0.1487,  ...,  0.0937,  0.0233, -0.1020],\n",
       "                      [ 0.0175, -0.0755, -0.0923,  ..., -0.0776, -0.0231,  0.0331],\n",
       "                      [ 0.0695,  0.0480,  0.1871,  ...,  0.0549, -0.2409,  0.2596]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([0.2554, 0.1750, 0.0706,  ..., 0.1238, 0.2089, 0.0962])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([0.2048, 0.2110, 0.0321,  ..., 0.0843, 0.1780, 0.0777])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-1.3531e-02, -1.1848e-01,  1.2078e-02,  ...,  2.8935e-01,\n",
       "                        5.2006e-01,  1.3240e-01],\n",
       "                      [ 5.1532e-02, -5.1827e-02, -8.8378e-02,  ...,  7.9595e-04,\n",
       "                        2.6064e-01,  2.3051e-01],\n",
       "                      [-3.1399e-04,  4.0559e-02, -1.6089e-01,  ...,  2.8618e-01,\n",
       "                       -4.5120e-01,  1.2146e-01],\n",
       "                      ...,\n",
       "                      [ 1.7859e-02, -1.3444e-01, -4.4722e-02,  ..., -2.1683e-02,\n",
       "                       -1.5643e-01,  1.1762e-01],\n",
       "                      [ 4.5331e-03,  3.3103e-02, -4.3278e-02,  ...,  7.6261e-02,\n",
       "                        5.4129e-02,  1.4174e-01],\n",
       "                      [ 2.8152e-02,  3.0245e-02,  5.5006e-02,  ...,  2.0770e-02,\n",
       "                        2.2741e-02, -4.4565e-02]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-1.5350e-01, -1.3668e-01, -1.7624e-01, -1.8935e-01,  4.4374e-02,\n",
       "                       5.8577e-02, -1.6065e-01, -1.3972e-01, -1.4403e-01, -1.8469e-01,\n",
       "                      -1.7393e-01,  2.5929e-03, -2.1059e-01, -2.6876e-03, -5.4330e-02,\n",
       "                      -5.5322e-02,  7.5502e-03, -1.1710e-01, -7.7378e-02, -7.4364e-02,\n",
       "                      -8.0652e-02, -6.1286e-02,  1.8424e-02,  2.5973e-02, -1.6902e-01,\n",
       "                      -3.1871e-02, -7.2310e-02, -1.6188e-01,  8.7697e-03, -1.5675e-01,\n",
       "                      -3.2950e-02, -2.2285e-02, -3.0631e-02, -1.5788e-01, -1.6293e-01,\n",
       "                      -1.7604e-01, -1.5516e-01, -5.1527e-02, -2.7132e-02, -1.3193e-02,\n",
       "                       1.6449e-02, -1.9822e-01, -1.5373e-01, -2.0102e-01, -1.9324e-01,\n",
       "                      -1.4015e-01, -2.2384e-01, -1.5826e-01, -1.2310e-01, -1.3940e-01,\n",
       "                      -5.6517e-01, -3.9108e-02, -1.6601e-01, -1.8011e-01,  2.5789e-03,\n",
       "                      -2.7699e-01, -1.5704e-01,  4.3695e-02, -2.4958e-01, -1.5977e-01,\n",
       "                      -1.6518e-01, -1.5995e-02, -1.2427e-02, -2.7229e-01, -4.4743e-02,\n",
       "                       4.5488e-02, -2.2504e-02, -1.4278e-01, -2.2279e-01, -3.7095e-03,\n",
       "                       8.9180e-03, -1.6039e-01, -1.7843e-02, -1.4495e-01, -3.2041e-02,\n",
       "                      -2.2840e-01, -2.2018e-01, -6.4286e-02, -2.3452e-01, -4.5656e-02,\n",
       "                      -5.4573e-02, -7.9613e-02, -8.2687e-02, -1.7561e-01, -1.7136e-01,\n",
       "                      -1.6650e-01, -1.5505e-01, -1.3681e-01, -1.1172e-01, -1.7471e-01,\n",
       "                      -1.8406e-01, -1.6769e-01, -1.9988e-01, -1.6463e-01, -1.5199e-01,\n",
       "                      -1.5894e-01, -1.2147e-01, -1.9045e-01, -1.8264e-01, -2.2107e-02,\n",
       "                      -1.9796e-01, -1.8601e-01, -2.0958e-01, -2.4878e-01, -2.8161e-02,\n",
       "                      -2.9271e-02, -6.4088e-02, -6.6982e-02,  4.3636e-03, -1.1936e-01,\n",
       "                      -1.5312e-01, -1.8285e-01, -7.2093e-02, -1.9254e-01, -1.5900e-01,\n",
       "                      -4.1352e-02, -2.0361e-01,  9.8274e-03, -2.5661e-02, -1.8314e-01,\n",
       "                       4.2460e-03, -4.7761e-01, -2.1031e-01, -5.3291e-02, -1.5485e-01,\n",
       "                      -1.5944e-01, -1.3236e-02, -5.8721e-02, -2.6642e-01, -1.4322e-01,\n",
       "                      -1.8556e-01, -2.2713e-01, -2.2515e-01, -3.5318e-02, -2.0136e-01,\n",
       "                      -8.6484e-02, -4.5261e-02, -1.7719e-01, -1.5194e-01, -8.1825e-02,\n",
       "                       6.1066e-02, -1.6875e-02, -1.0634e-01, -1.6235e-01, -3.1741e-02,\n",
       "                      -1.3256e-01, -1.8511e-01, -1.4524e-01, -2.1996e-01, -1.7203e-01,\n",
       "                      -1.5576e-01, -1.9460e-01, -2.1659e-01, -3.3081e-02, -1.4922e-01,\n",
       "                      -1.2643e-01, -1.8405e-02, -5.0146e-02, -1.3206e-01, -1.5229e-01,\n",
       "                      -2.0343e-01, -1.0132e-02, -5.0761e-02, -1.9917e-01,  3.0647e-03,\n",
       "                      -1.5031e-01, -2.4015e-01, -2.1951e-01, -2.9014e-02, -1.7570e-01,\n",
       "                      -1.6064e-01, -3.5808e-02, -1.5673e-01, -7.4531e-03, -1.2216e-01,\n",
       "                      -9.9012e-03, -4.6705e-02, -5.3088e-02, -9.4061e-02, -1.6952e-01,\n",
       "                      -6.8211e-02, -3.2472e-02, -1.7722e-01, -2.1944e-02, -3.5439e-01,\n",
       "                      -2.0666e-01, -1.8383e-01, -3.0936e-02,  3.3983e-02, -1.3386e-01,\n",
       "                       1.6573e-02, -4.3322e-02, -3.9792e-02, -2.1269e-01, -1.3534e-01,\n",
       "                      -2.2193e-01, -1.4627e-01, -1.5101e-01,  1.0130e-02,  8.6656e-02,\n",
       "                      -6.9502e-03, -3.1144e-02, -8.6167e-02, -3.1939e-02, -5.6254e-02,\n",
       "                      -4.6560e-02, -1.3873e-01, -1.6216e-01, -3.0098e-01, -2.1927e-01,\n",
       "                      -2.8719e-02, -2.0693e-01, -1.7085e-01, -2.0240e-01, -1.2623e-01,\n",
       "                      -8.2035e-02, -3.2232e-02, -2.6725e-01, -5.1466e-02, -4.8037e-02,\n",
       "                       1.2979e-02, -5.1403e-02, -5.1205e-01, -2.6405e-02, -1.6406e-01,\n",
       "                      -2.7590e-02, -3.1509e-02, -1.7123e-01, -1.5869e-01, -5.7678e-03,\n",
       "                      -4.2869e-02, -9.8121e-02, -9.5176e-02, -3.0344e-02, -1.8964e-02,\n",
       "                       2.4364e-02, -2.3356e-01, -3.2238e-02,  2.8267e-02, -1.9834e-01,\n",
       "                      -1.4597e-01, -1.4741e-01, -1.8411e-01, -1.2850e-02, -8.1743e-02,\n",
       "                      -4.0142e-02, -2.7927e-02, -2.9763e-02, -6.7642e-02, -6.5575e-02,\n",
       "                      -3.9042e-02, -2.2050e-01, -2.0642e-01, -2.7809e-02, -6.0581e-02,\n",
       "                      -1.0567e-01, -3.4514e-02, -9.3806e-03, -2.2648e-02, -2.5527e-01,\n",
       "                      -1.6970e-01, -1.5409e-01, -1.7265e-01, -1.9450e-01, -5.4704e-03,\n",
       "                      -1.4139e-01, -1.3742e-02, -1.3672e-02, -8.5522e-03, -2.2822e-01,\n",
       "                      -3.4118e-02, -7.3435e-02, -6.1664e-02, -1.7495e-01,  5.8636e-03,\n",
       "                      -2.1599e-02, -6.0500e-02, -1.5697e-01, -3.2492e-02, -3.1032e-02,\n",
       "                      -2.0304e-02, -1.8507e-01, -9.3517e-02, -1.7981e-01, -3.4291e-02,\n",
       "                      -1.8027e-01, -2.4442e-02,  1.0088e-01, -1.0068e-02, -2.0641e-01,\n",
       "                      -2.5418e-01, -3.0785e-01, -2.1228e-01, -3.8926e-02, -2.6811e-02,\n",
       "                      -3.2785e-02, -1.9086e-01, -1.3167e-02, -2.0831e-01, -1.5578e-01,\n",
       "                      -2.3053e-01, -1.5561e-01,  5.4110e-02,  8.7048e-02, -1.2492e-01,\n",
       "                      -2.1152e-01, -5.4741e-02, -5.1655e-02, -3.4360e-02, -2.4845e-01,\n",
       "                      -1.7250e-01,  1.1089e-02, -1.5379e-02, -2.1278e-01,  4.4422e-02,\n",
       "                      -1.8561e-01, -1.8226e-01, -2.8930e-02, -1.8159e-02, -4.2032e-02,\n",
       "                      -4.0426e-02, -5.9784e-02, -4.8985e-02, -1.0157e-01, -8.8918e-02,\n",
       "                      -2.4865e-01, -1.1871e-01,  1.3418e-01, -3.9417e-02, -2.3168e-02,\n",
       "                      -1.3263e-02, -4.1198e-02, -5.0836e-02, -5.2208e-02, -1.5311e-01,\n",
       "                      -2.5401e-02, -3.3811e-02, -1.0450e-01, -1.7397e-01, -2.4919e-01,\n",
       "                      -1.7290e-01, -1.2624e-01, -1.5359e-01, -1.9513e-01, -2.2641e-02,\n",
       "                      -5.3485e-02,  1.7105e-03, -5.2798e-02, -1.8175e-01,  2.8607e-02,\n",
       "                      -3.6188e-02, -1.5625e-04, -1.5248e-01, -1.2854e-01, -1.3349e-01,\n",
       "                      -7.5856e-02, -1.9724e-01,  6.9651e-04, -1.5492e-01,  3.0098e-03,\n",
       "                      -3.7499e-01, -1.5018e-01, -5.9444e-02, -1.4709e-01,  1.8810e-01,\n",
       "                      -1.8158e-01, -1.4275e-01, -1.3449e-01, -5.9478e-03, -2.0086e-01,\n",
       "                       2.8648e-03, -7.2425e-02, -1.9158e-01, -1.5488e-02, -2.2436e-02,\n",
       "                      -2.0338e-01, -2.0696e-01, -1.7018e-01, -5.4065e-02, -2.9895e-01,\n",
       "                      -1.7175e-01, -7.4188e-02,  3.2183e-03, -6.7791e-02, -1.1235e-01,\n",
       "                      -5.4820e-02, -2.2053e-01, -1.0354e-02, -1.8138e-01,  1.1004e-01,\n",
       "                      -1.3764e-01, -6.2183e-02, -1.6856e-01,  1.7962e-02, -6.8705e-02,\n",
       "                      -1.1972e-01, -1.4574e-01, -1.8620e-01, -1.0653e-02, -9.8637e-02,\n",
       "                      -4.1593e-02, -2.0689e-01, -2.7483e-02, -1.2393e-02, -6.3546e-02,\n",
       "                       5.5911e-03, -3.1846e-02, -1.4407e-01, -1.4196e-01, -3.5980e-02,\n",
       "                      -1.9061e-01, -2.2665e-02, -4.0746e-02, -2.2764e-01, -2.8095e-02,\n",
       "                      -1.4707e-01, -2.0443e-01, -1.9375e-01, -1.1269e-01, -3.1755e-02,\n",
       "                      -1.5742e-01, -2.2417e-01, -2.8592e-01, -1.1976e-04, -1.4684e-01,\n",
       "                      -2.0838e-01, -4.5753e-02, -2.7247e-01, -1.3865e-01, -8.3999e-03,\n",
       "                       3.2023e-02,  1.3440e-03,  1.8518e-02, -2.2927e-01, -1.9137e-01,\n",
       "                      -1.8418e-01, -9.2459e-03, -1.8355e-01, -7.4203e-03, -2.0658e-01,\n",
       "                      -1.3940e-01, -1.8775e-01, -1.7530e-01, -2.3366e-01, -8.8494e-02,\n",
       "                      -1.6830e-01, -2.4919e-01, -1.7980e-02, -2.0212e-01, -2.4615e-01,\n",
       "                      -1.1547e-01,  1.2699e-02, -1.6425e-01, -1.6780e-01, -2.3221e-02,\n",
       "                      -1.5806e-01,  6.9017e-02, -3.1158e-02, -3.0639e-02, -1.3762e-01,\n",
       "                      -9.1835e-02, -1.2012e-02, -1.3026e-01, -1.7594e-01, -8.3937e-02,\n",
       "                      -1.9191e-01, -1.6504e-01, -5.9432e-02, -7.9799e-02, -1.4081e-01,\n",
       "                      -2.0532e-01, -2.0691e-01, -1.6140e-01, -4.4731e-02, -2.7867e-02,\n",
       "                      -4.5116e-02, -1.8817e-01, -1.6116e-01, -2.3826e-01, -1.7587e-01,\n",
       "                       2.4856e-02, -1.4798e-01, -7.4049e-02,  9.3399e-03, -4.2828e-02,\n",
       "                      -1.8180e-01, -7.6563e-02, -1.8730e-01, -1.8554e-01, -2.1853e-02,\n",
       "                      -1.1266e-02, -1.4883e-01, -2.0201e-01, -4.0968e-02, -2.1379e-01,\n",
       "                      -2.2988e-02, -2.8720e-01, -2.4289e-01, -2.0050e-01, -5.8358e-02,\n",
       "                      -2.0255e-01, -8.8338e-02, -2.0509e-01, -1.5321e-01,  2.9711e-02,\n",
       "                      -8.7013e-02, -9.5652e-02, -1.5350e-01, -7.1536e-02, -1.4427e-01,\n",
       "                      -1.1756e-01, -7.8393e-02])),\n",
       "             ('fc_rank.weight',\n",
       "              tensor([[-1.5208e-01, -1.2868e-01, -1.2694e-01, -2.0865e-01,  2.0146e-02,\n",
       "                        4.5054e-02, -8.9351e-02, -2.7685e-01, -3.3974e-01, -2.0719e-01,\n",
       "                       -1.9640e-01,  2.4794e-02, -8.2954e-02,  4.3773e-02,  3.7726e-02,\n",
       "                        3.5356e-02,  7.1335e-02,  5.9520e-03,  4.0732e-02,  3.0064e-02,\n",
       "                        5.2796e-02,  2.5857e-02,  3.6663e-02,  7.3622e-02, -1.1180e-01,\n",
       "                       -1.1886e-02, -1.3018e-02, -1.7937e-01,  2.3277e-02, -2.1247e-01,\n",
       "                        4.7353e-02,  2.7146e-02,  2.8973e-02, -2.3658e-01, -2.3460e-01,\n",
       "                       -8.2271e-02, -6.4900e-02,  2.2642e-02,  3.4282e-02,  3.2043e-02,\n",
       "                        6.8746e-02, -1.4857e-01, -8.8111e-02, -1.6172e-01, -1.0359e-01,\n",
       "                       -4.5988e-02, -2.4441e-01, -1.4208e-01, -1.2382e-01, -1.3146e-01,\n",
       "                       -6.6572e-02,  3.3345e-02, -1.2595e-01, -3.2612e-01,  2.6722e-02,\n",
       "                       -1.9288e-01, -1.3401e-01,  2.1255e-02, -7.1126e-02, -2.4116e-01,\n",
       "                       -1.0553e-01,  5.1093e-02,  4.6723e-02,  9.9119e-02,  4.9564e-02,\n",
       "                       -2.4711e-02,  7.9027e-02, -8.5705e-02, -1.6387e-01,  7.4999e-02,\n",
       "                        2.2310e-02, -2.3483e-01,  3.3992e-02, -2.3541e-01,  5.7652e-02,\n",
       "                       -1.8926e-01, -1.9915e-01,  7.8645e-02, -1.6032e-01,  1.0105e-01,\n",
       "                        2.9346e-02, -3.9634e-02, -3.2042e-02, -1.2542e-01, -1.0847e-01,\n",
       "                       -2.2022e-01, -1.5397e-01, -8.1227e-02, -1.9959e-01, -1.0632e-01,\n",
       "                       -2.6796e-01, -1.1496e-01, -2.1565e-01, -1.0740e-01, -1.2342e-01,\n",
       "                       -2.0005e-01, -1.0741e-01, -9.4138e-02, -1.4109e-01,  4.9374e-02,\n",
       "                       -1.6934e-01, -1.4880e-01, -8.7474e-02, -2.2259e-01,  8.1771e-02,\n",
       "                        8.1696e-02,  4.0891e-02,  1.6494e-02,  5.3239e-02,  9.1929e-02,\n",
       "                       -9.2365e-02, -1.1329e-01,  4.4711e-02, -1.3983e-01, -1.4055e-01,\n",
       "                        9.5304e-02, -2.1961e-01,  9.7075e-02,  2.8914e-02, -1.2448e-01,\n",
       "                        6.6557e-02, -5.1312e-02, -1.3754e-01, -2.5299e-02, -9.4424e-02,\n",
       "                       -1.4267e-01,  3.5721e-02,  6.4956e-02, -2.3894e-01, -1.5421e-01,\n",
       "                       -2.3274e-01, -9.5475e-02, -1.7021e-01,  7.6872e-02, -1.0042e-01,\n",
       "                       -1.2267e-02, -2.2467e-02, -8.5053e-02, -2.5716e-01,  4.5514e-02,\n",
       "                        4.0077e-02,  3.0949e-02, -2.9603e-02, -1.3064e-01,  2.9492e-02,\n",
       "                       -2.2494e-02, -1.5302e-01, -1.1826e-01, -1.7578e-01, -9.8167e-02,\n",
       "                       -1.2080e-01, -1.2620e-01, -1.6158e-01,  2.3466e-02, -1.2691e-01,\n",
       "                       -7.4451e-02,  4.3622e-02,  5.0082e-02, -1.1148e-01, -2.4260e-01,\n",
       "                       -2.0755e-01,  7.0735e-02,  5.8547e-02, -2.7467e-01,  3.8522e-02,\n",
       "                       -6.8225e-02, -1.7048e-01, -2.1353e-01,  2.5356e-02, -2.2801e-01,\n",
       "                       -1.2522e-01,  8.8101e-02, -1.4638e-01,  2.9732e-02, -1.9030e-01,\n",
       "                        3.0427e-02,  8.8934e-02,  2.7320e-02,  1.6905e-02, -1.8989e-01,\n",
       "                        8.9647e-02,  4.4736e-02, -1.5400e-01,  4.7738e-02, -1.1691e-01,\n",
       "                       -1.3761e-01, -1.1143e-01,  7.0106e-02,  2.3611e-02, -2.0160e-01,\n",
       "                        3.5193e-02,  6.7442e-02,  4.8292e-02, -2.8591e-01, -6.9320e-02,\n",
       "                       -1.4438e-01, -2.4814e-01, -1.2509e-01,  3.3882e-02,  2.8817e-02,\n",
       "                        6.7288e-02,  4.6658e-02,  3.6718e-02,  3.5568e-02,  6.2967e-02,\n",
       "                       -1.8624e-02, -1.7235e-01,  3.3234e-02, -1.1540e-01, -2.2245e-01,\n",
       "                       -1.9563e-02,  3.9947e-03, -1.6430e-01, -1.7416e-01, -1.3395e-01,\n",
       "                        1.7810e-02,  3.9895e-02, -7.2726e-02,  3.5841e-02, -1.0694e-01,\n",
       "                        2.6977e-02,  4.1634e-02, -3.9792e-02,  2.7762e-02, -1.7236e-01,\n",
       "                        2.0697e-02,  2.0406e-02, -2.4252e-01, -1.6120e-01,  2.8556e-02,\n",
       "                        4.2524e-02, -9.0027e-03, -8.1547e-02,  8.1307e-02,  3.4940e-02,\n",
       "                        3.0390e-02, -1.0768e-01,  7.1774e-02,  1.8775e-02, -3.3696e-01,\n",
       "                       -1.3146e-01, -1.1817e-01, -2.1932e-01,  3.0707e-02,  6.7114e-02,\n",
       "                        4.3179e-02,  5.4870e-02,  3.0639e-02,  9.8481e-02,  8.9549e-02,\n",
       "                        4.3228e-02, -1.5279e-01, -1.3944e-01,  6.1598e-02,  7.4892e-02,\n",
       "                       -3.1648e-03,  4.8037e-02,  1.9952e-02,  4.3174e-02, -1.0681e-01,\n",
       "                       -8.1895e-02, -1.3289e-01, -3.0153e-01, -2.1601e-01,  2.8928e-02,\n",
       "                       -1.4275e-01,  3.3117e-02,  5.5026e-02,  2.6431e-02, -2.6049e-01,\n",
       "                        6.7457e-02,  4.5570e-02,  4.4486e-02, -1.2683e-01,  4.1059e-02,\n",
       "                        3.0023e-02,  5.8264e-02, -1.5234e-01,  2.7388e-02,  4.3815e-02,\n",
       "                        3.1406e-02, -9.2281e-02, -2.2308e-01, -1.7225e-01,  2.9619e-02,\n",
       "                       -2.1001e-01,  6.8453e-02, -4.9835e-02,  4.3026e-02, -1.6010e-01,\n",
       "                       -2.0607e-01, -1.4118e-01, -1.0595e-01,  4.4938e-02,  3.3273e-02,\n",
       "                        2.8077e-02, -5.0768e-02,  2.5923e-02, -1.9086e-01, -9.3134e-02,\n",
       "                       -1.1686e-01, -8.5738e-02, -5.0609e-02, -2.9115e-02, -9.1895e-02,\n",
       "                       -1.9225e-01,  6.2381e-02,  2.3264e-02,  4.5427e-02, -1.8628e-01,\n",
       "                       -9.1672e-02,  6.9610e-02,  4.1153e-02, -2.3402e-01,  4.7168e-02,\n",
       "                       -2.1703e-01, -2.0093e-01,  7.7296e-02,  3.8840e-02,  8.6140e-02,\n",
       "                        1.0935e-01,  8.9288e-02,  2.4340e-02, -1.5484e-01,  2.4417e-02,\n",
       "                       -1.7633e-01, -1.3133e-01, -2.4266e-02,  3.4828e-02,  2.2803e-02,\n",
       "                        2.4183e-02,  4.8287e-02,  5.2536e-02,  5.5118e-02, -1.5961e-01,\n",
       "                        3.6868e-02,  4.9110e-02, -1.5932e-01, -1.3982e-01, -1.8676e-01,\n",
       "                       -1.2430e-01, -1.9457e-01, -1.2587e-01, -8.1594e-02,  2.0079e-02,\n",
       "                        2.6806e-02,  3.5257e-02,  3.2891e-02, -1.3492e-01,  4.1991e-02,\n",
       "                        4.3881e-02,  2.4941e-02, -1.3177e-01, -2.3523e-01, -1.2903e-01,\n",
       "                        9.6773e-02, -1.4856e-01,  4.6607e-02, -1.5919e-01,  3.9956e-02,\n",
       "                       -7.9878e-02, -7.5418e-02,  9.2321e-02, -3.0985e-01, -5.8488e-02,\n",
       "                       -1.9788e-01, -1.8814e-01, -1.2486e-01,  6.8098e-02, -2.0914e-01,\n",
       "                        2.1637e-02,  1.9711e-02, -1.4146e-01,  2.2644e-02,  5.7708e-02,\n",
       "                       -9.7300e-02, -1.9301e-01, -9.9693e-02,  7.4168e-02, -1.1762e-01,\n",
       "                       -2.1645e-01,  5.2838e-02,  3.4707e-02,  5.7000e-02,  1.3878e-02,\n",
       "                       -4.4107e-03, -1.2236e-01,  4.6629e-02, -1.5330e-01, -3.1437e-02,\n",
       "                       -7.7253e-02,  3.2450e-02, -2.6349e-01,  1.2272e-02,  6.0353e-02,\n",
       "                       -9.9611e-02, -1.3175e-01, -1.1538e-01,  3.8518e-02, -1.8551e-01,\n",
       "                        5.4468e-02, -2.2894e-01,  6.1848e-02,  4.5322e-02,  6.0674e-02,\n",
       "                        2.3442e-02,  2.8300e-02, -2.3593e-01, -8.1880e-02,  3.0983e-02,\n",
       "                       -1.6309e-01,  2.2222e-02,  2.4968e-02, -2.8224e-01,  5.2124e-02,\n",
       "                       -1.6697e-01, -2.1075e-01, -1.4358e-01,  9.5067e-02,  5.5622e-02,\n",
       "                        1.4193e-02, -2.0105e-01, -1.2986e-01, -5.4396e-02, -2.3543e-01,\n",
       "                       -2.6100e-01,  2.6640e-02, -1.5277e-01, -2.6336e-01,  8.7545e-02,\n",
       "                        4.4974e-02,  2.5254e-02, -2.4448e-02, -1.0341e-01, -1.1355e-01,\n",
       "                       -2.1825e-02,  5.1576e-02, -1.3973e-01,  3.8885e-02, -1.5379e-01,\n",
       "                       -9.5970e-02, -1.6143e-01, -1.8640e-01,  5.5858e-02,  1.3923e-03,\n",
       "                       -1.1799e-01, -1.1804e-01,  5.1171e-02, -2.0445e-01, -1.2722e-01,\n",
       "                       -1.5386e-01,  2.5063e-02, -1.2947e-01, -1.8790e-01,  7.5192e-02,\n",
       "                       -1.5336e-01, -1.2133e-02,  1.9151e-02,  3.3896e-02, -1.7296e-01,\n",
       "                        7.3719e-02,  3.6452e-02, -1.3188e-01, -1.4005e-01,  4.8869e-02,\n",
       "                       -2.0547e-01, -2.9499e-01,  3.1174e-02,  3.8645e-02, -1.0237e-01,\n",
       "                       -1.2100e-01, -2.0373e-01, -2.2154e-01,  5.5259e-02,  4.5460e-02,\n",
       "                        4.1666e-02, -2.1433e-01, -3.0357e-01, -1.6585e-01, -2.1654e-01,\n",
       "                        4.7398e-02, -1.5108e-01, -2.4493e-04,  7.9401e-02,  2.9549e-02,\n",
       "                       -1.9420e-01,  3.5547e-02, -1.2779e-01, -1.5447e-01,  2.4059e-02,\n",
       "                        2.4143e-02, -1.2213e-01, -1.1906e-01,  8.7930e-02, -2.6791e-01,\n",
       "                        3.1829e-02, -4.1606e-02, -1.1495e-01, -2.2182e-01,  2.8038e-02,\n",
       "                       -2.6073e-01,  5.4091e-02, -1.0543e-01, -1.0658e-01,  2.0930e-02,\n",
       "                        3.0828e-02,  6.5904e-02, -1.4169e-01,  1.9053e-02, -1.8390e-01,\n",
       "                       -7.4741e-02, -9.6680e-02]])),\n",
       "             ('fc_rank.bias', tensor([-1.7595])),\n",
       "             ('batchnorm.weight',\n",
       "              tensor([ 0.8168,  0.7923,  0.9404,  0.3899,  0.4678,  0.3453,  0.9203,  0.3772,\n",
       "                       0.3389,  0.5303,  0.4620,  0.5162,  0.9382,  0.2493,  0.3042,  0.4079,\n",
       "                       0.1623,  0.1539,  0.2864,  0.6242,  0.1963,  0.4865,  0.3155,  0.1397,\n",
       "                       0.9179,  0.5414,  0.1242,  0.4616,  0.4130,  0.4243,  0.2885,  0.3167,\n",
       "                       0.4605,  0.4202,  0.2408,  0.6651,  0.7905,  0.5623,  0.2982,  0.3446,\n",
       "                       0.1105,  0.7479,  0.8682,  0.5556,  0.7572,  0.3141,  0.2846,  0.6796,\n",
       "                       0.5893,  0.7064,  0.1918,  0.5753,  0.9771,  0.2916,  0.5634,  0.5332,\n",
       "                       0.6675,  0.5159,  0.1955,  0.2674,  0.9298,  0.2515,  0.5807, -0.1264,\n",
       "                       0.2201,  0.5488,  0.1212,  0.9238,  0.7276,  0.2218,  0.4274,  0.3744,\n",
       "                       0.6300,  0.3908,  0.2659,  0.2779,  0.3983,  0.1367,  0.6607,  0.1495,\n",
       "                       0.6268,  0.3161,  0.1398,  0.8620,  0.7585,  0.3282,  0.4007,  0.8001,\n",
       "                       0.4382,  0.6340,  0.2759,  0.8397,  0.5027,  0.7547,  0.8325,  0.3762,\n",
       "                       0.9285,  0.7051,  0.6101,  0.5961,  0.4922,  0.4596,  0.8662,  0.3046,\n",
       "                       0.1813,  0.0991,  0.6119,  0.5448,  0.2687,  0.1432,  0.7802,  0.8019,\n",
       "                       0.1844,  0.5603,  0.6236,  0.1491,  0.3248,  0.1345,  0.5407,  0.7678,\n",
       "                       0.1685,  0.2817,  0.6698,  0.1289,  1.0075,  0.5749,  0.1602,  0.1608,\n",
       "                       0.2429,  0.6092,  0.3676,  0.4443,  0.4897,  0.1180,  0.8837,  0.6543,\n",
       "                       0.3612,  0.6677,  0.3812,  0.2619,  0.3442,  0.4030,  0.9517,  0.6234,\n",
       "                       0.2690,  0.5359,  0.4906,  0.6071,  0.4568,  0.8536,  0.9212,  0.8736,\n",
       "                       0.6380,  0.5048,  0.6445, -0.1056,  0.3901,  0.6814,  0.6487,  0.3952,\n",
       "                       0.2294,  0.1584,  0.4528,  0.3355,  0.3099,  0.7033,  0.3358,  0.3388,\n",
       "                       0.6912,  0.2406,  0.8687,  0.1473,  0.4919,  0.5383,  0.3903,  0.4168,\n",
       "                       0.1796,  0.5859,  0.0425,  0.4888,  0.1580,  0.2875,  0.6793,  0.2691,\n",
       "                       0.2659,  0.5003,  0.7726,  0.1190,  0.6173,  0.3773,  0.4012,  0.1875,\n",
       "                       0.2541,  0.2884,  0.9245,  0.6297,  0.3606,  0.8425,  0.4137,  0.3626,\n",
       "                       0.1203,  0.2424,  0.2254,  0.5305,  0.2980,  0.1511,  0.5632,  0.1503,\n",
       "                       0.4107,  0.4641,  0.5370,  0.6518,  0.4582,  0.4163,  0.6925,  0.5986,\n",
       "                       0.3415,  0.5374,  0.4262, -0.1162,  0.4720,  0.2253,  0.4061,  0.7935,\n",
       "                       0.7095,  0.4408,  0.5359,  0.4608,  0.4995,  0.5933,  0.2033,  0.6592,\n",
       "                       0.6727,  0.1147,  0.3838,  0.4611,  0.9341,  0.1869,  0.4966,  0.2897,\n",
       "                       0.7229,  0.6207,  0.3106,  0.2624,  0.1875,  0.3410,  0.3191,  0.4409,\n",
       "                       0.1010,  0.1182,  0.5431,  0.7041,  0.5495,  0.2069,  0.2176,  0.4156,\n",
       "                       0.2583,  0.4905,  0.3907,  0.9280,  0.8183,  0.9067,  0.3495,  0.5546,\n",
       "                       0.4695,  0.5380,  0.4786,  0.1852,  0.4358,  0.2699,  0.2147,  0.3340,\n",
       "                       0.3801,  0.7586,  0.2748,  0.5229,  0.4004,  0.6488,  0.4371,  0.3639,\n",
       "                       0.4389,  0.7055,  0.4323,  0.6183,  0.3943,  0.4830,  0.1769,  0.8612,\n",
       "                       0.4115,  0.8281,  0.2543,  0.2181,  0.8166,  0.3794,  0.3271,  0.4313,\n",
       "                       0.6806,  0.3615,  0.3136,  0.1266,  0.9415,  0.8785,  0.2569,  0.6283,\n",
       "                      -0.0967,  0.5050,  0.0934,  0.5497,  0.2641,  0.3548,  0.8930,  0.1581,\n",
       "                       0.4506,  0.3348,  0.2334,  0.3883,  0.3986,  0.1911,  0.2914,  0.1505,\n",
       "                       0.1121,  0.1430,  0.3840,  0.6905,  0.5521,  0.4033,  0.8734,  0.5298,\n",
       "                       0.3951,  0.5606,  0.4968,  0.1513,  0.1593,  0.2326,  0.5355,  0.4118,\n",
       "                       0.2050,  0.5021,  0.7496,  0.4554,  0.7116,  0.3840,  0.5712,  0.8105,\n",
       "                       0.4798,  0.5724,  0.3153,  0.3573,  0.5978,  0.2898,  0.5425,  0.4674,\n",
       "                       0.5852,  0.3597,  0.7430,  0.1172,  0.5711,  0.6218,  0.5875,  0.3621,\n",
       "                       0.2432,  0.1736,  0.1911,  0.3423,  0.7056,  0.4190,  0.3579,  0.7598,\n",
       "                       0.1492,  0.4656,  0.5281,  0.5067,  0.8619,  0.5099,  0.2289,  0.9135,\n",
       "                       0.4191,  0.7457,  0.2091,  0.1497,  0.3207,  0.3710,  0.4056,  0.1901,\n",
       "                       0.6615,  0.4596,  0.7493,  0.3265,  0.5105,  0.8986,  0.6356,  0.4228,\n",
       "                       0.2852,  0.5374,  0.1497,  0.6240,  0.8404,  0.7795,  0.3178,  0.6767,\n",
       "                       0.3145,  0.2563,  0.2547,  0.2651,  0.2758,  0.6044,  0.6183,  0.3001,\n",
       "                       0.8136,  0.3693,  0.5310,  0.6231,  0.6538,  0.3296,  0.4199,  0.5787,\n",
       "                       0.2893,  0.4625, -0.1301,  0.2378,  0.1080,  0.5874,  0.7949,  0.3305,\n",
       "                       0.3376,  0.3224,  0.3862,  0.3554,  0.4449,  0.1115,  0.1899,  0.6128,\n",
       "                       0.7763,  0.8584,  0.8034,  0.1270,  0.2687,  0.9776,  0.6373,  0.6802,\n",
       "                       0.7951,  0.5646,  0.4275,  0.1553,  0.1440,  0.8372,  0.9002,  0.1760,\n",
       "                       0.6108,  1.0235,  0.5798,  0.6071,  0.5374,  0.3698,  0.1175,  0.4592,\n",
       "                       0.6939,  0.5353,  0.5397,  0.3402,  0.1116,  0.2772,  0.8564,  0.6200,\n",
       "                       0.7735,  0.4042,  0.3311,  0.5959,  0.2634,  0.8933,  0.9568,  0.3155,\n",
       "                       0.4204,  0.2503,  0.3246,  0.3712,  0.4209,  0.2790,  0.5483,  0.3782,\n",
       "                       0.2802,  0.7500,  0.0038,  0.1448,  0.5764,  0.4364,  0.2906,  0.4889,\n",
       "                       0.7878,  0.6922,  0.4501,  0.6059,  0.7445,  0.1225,  0.2569,  0.4639,\n",
       "                       0.3048,  0.9519,  0.3279,  0.6113,  0.4191,  0.2329,  0.8241,  0.7849,\n",
       "                       0.6045,  0.6049,  0.1276,  0.4497,  0.4803,  0.4816,  0.1762,  0.1198])),\n",
       "             ('batchnorm.bias',\n",
       "              tensor([ 2.6856e-01,  3.0927e-01,  3.2250e-01,  1.1019e-01, -1.2865e-01,\n",
       "                      -4.1813e-02,  2.7891e-01,  1.5833e-01,  1.5513e-01,  1.8758e-01,\n",
       "                       2.0373e-01, -8.3961e-02,  2.5908e-01, -1.7115e-01, -4.8813e-02,\n",
       "                      -6.6992e-03, -3.2541e-02, -1.4751e-02, -1.4862e-02,  8.8922e-03,\n",
       "                      -5.9220e-02, -1.1261e-02, -1.3434e-01, -3.9400e-02,  2.5839e-01,\n",
       "                       1.2153e-02,  1.1271e-02,  1.1080e-01, -7.3989e-02,  1.2600e-01,\n",
       "                       1.2830e-02, -1.9629e-01, -4.2003e-02,  1.8175e-01,  7.9238e-02,\n",
       "                       3.7723e-01,  3.3950e-01, -6.4135e-02, -3.6043e-02, -9.1971e-02,\n",
       "                      -7.5431e-02,  3.7648e-01,  2.7384e-01,  2.4744e-01,  3.2404e-01,\n",
       "                       1.0960e-01,  1.0474e-01,  2.5330e-01,  1.8056e-01,  2.7958e-01,\n",
       "                       1.1892e-01, -4.1158e-02,  2.3688e-01,  1.3002e-01, -1.8295e-01,\n",
       "                       2.1726e-01,  1.5953e-01, -1.1882e-01,  7.6568e-02,  1.0179e-01,\n",
       "                       3.3147e-01, -7.6678e-02,  1.4673e-02, -5.5458e-02, -3.4776e-02,\n",
       "                      -3.6249e-03, -7.6332e-02,  2.2592e-01,  2.4480e-01, -2.3469e-02,\n",
       "                      -1.2282e-01,  1.0296e-01,  3.8868e-03,  1.5022e-01, -3.9363e-02,\n",
       "                       1.7745e-01,  1.7610e-01, -2.6606e-02,  2.9011e-01, -2.5475e-02,\n",
       "                       2.2888e-02,  4.8586e-02, -2.8927e-02,  3.3516e-01,  2.7126e-01,\n",
       "                       1.3339e-01,  1.3026e-01,  2.6928e-01,  2.1458e-01,  2.3329e-01,\n",
       "                       8.1707e-02,  3.3450e-01,  2.9782e-01,  2.5948e-01,  2.6186e-01,\n",
       "                       1.0350e-01,  2.7041e-01,  2.4757e-01,  3.5106e-01,  4.0868e-02,\n",
       "                       1.2223e-01,  3.1261e-01,  2.2016e-01,  9.5057e-02, -2.6980e-02,\n",
       "                      -1.1355e-01,  2.3386e-02, -2.6223e-01, -3.4427e-02, -5.2728e-02,\n",
       "                       2.8072e-01,  3.8476e-01, -3.5631e-02,  1.6585e-01,  2.1074e-01,\n",
       "                      -1.4789e-02,  1.0896e-01, -2.4367e-02, -2.2483e-02,  2.4665e-01,\n",
       "                      -2.6148e-03,  1.6652e-01,  1.9605e-01,  2.4655e-02,  2.8898e-01,\n",
       "                       1.6165e-01, -8.6826e-04, -3.3464e-02,  1.0962e-01,  2.4673e-01,\n",
       "                       9.9782e-02,  1.7955e-01,  1.8059e-01, -2.9436e-02,  2.2231e-01,\n",
       "                      -3.6969e-03, -1.4544e-02,  1.6376e-01,  1.3515e-01, -3.4833e-02,\n",
       "                      -6.7995e-02, -7.0709e-02,  8.3033e-03,  1.6333e-01, -4.2957e-02,\n",
       "                      -2.3182e-02,  1.2953e-01,  1.8421e-01,  1.6423e-01,  3.1929e-01,\n",
       "                       2.7842e-01,  3.7805e-01,  2.4979e-01, -1.6211e-01,  2.0418e-01,\n",
       "                       1.8417e-02, -6.0821e-02,  7.1757e-02,  2.0924e-01,  1.3949e-01,\n",
       "                       1.4362e-01, -3.9171e-02,  2.1138e-02,  1.0059e-01, -8.5277e-02,\n",
       "                       2.7807e-01,  1.3901e-01,  8.9149e-02,  3.6990e-02,  1.6069e-01,\n",
       "                       2.3005e-01, -2.4260e-02,  1.3854e-01, -7.1315e-02,  1.8563e-01,\n",
       "                      -9.9192e-02,  5.7674e-03, -3.0967e-03,  1.8600e-02,  1.5516e-01,\n",
       "                      -2.7339e-03, -3.7177e-02,  2.4737e-01, -6.9517e-02,  1.1231e-01,\n",
       "                       1.6077e-01,  4.5138e-01, -3.9878e-02, -7.1359e-02,  1.1811e-01,\n",
       "                      -1.3496e-01, -2.4464e-02, -4.1597e-02,  1.7177e-01,  2.9220e-01,\n",
       "                       2.0332e-01,  1.7914e-01,  2.9110e-01, -6.4403e-02, -1.9955e-01,\n",
       "                      -3.5049e-02, -6.5520e-02, -2.4045e-02,  1.6338e-02, -8.5266e-03,\n",
       "                      -1.8719e-02,  1.6202e-01, -3.4113e-02,  1.4754e-01,  2.4754e-01,\n",
       "                       2.8194e-03,  1.6135e-03,  1.7448e-01,  1.6581e-01,  2.8435e-01,\n",
       "                      -1.3789e-01, -4.1109e-02,  2.1754e-01,  1.4732e-02,  7.5918e-03,\n",
       "                      -3.5728e-02, -1.1399e-01,  1.7685e-01,  6.0791e-02,  2.7922e-01,\n",
       "                      -1.3443e-01, -1.4034e-01,  1.4061e-01,  1.3298e-01,  2.6069e-02,\n",
       "                      -2.5982e-02,  1.3333e-02,  2.0343e-01, -2.4682e-02, -4.3866e-02,\n",
       "                      -9.9521e-02,  2.0304e-01, -2.5830e-02, -1.3490e-01,  1.4140e-01,\n",
       "                       2.2295e-01,  2.8664e-01,  7.4618e-02, -7.3100e-02, -7.5497e-02,\n",
       "                      -7.1344e-02,  7.6933e-03, -8.4373e-02, -1.4548e-02, -4.4191e-03,\n",
       "                       2.7140e-02,  2.9379e-01,  2.4027e-01, -1.4002e-02,  3.0464e-03,\n",
       "                       6.8616e-03, -1.8378e-02, -3.0047e-01, -1.3232e-02,  4.0095e-01,\n",
       "                       3.5408e-01,  4.3403e-01,  1.7050e-01,  2.1555e-01, -1.0473e-01,\n",
       "                       1.9448e-01, -7.8460e-03, -8.7963e-02, -2.0444e-01,  7.6497e-02,\n",
       "                      -8.7418e-02,  6.1583e-03,  3.8794e-02,  4.5999e-01, -1.3545e-01,\n",
       "                      -5.5704e-02, -4.9838e-03,  1.8145e-01, -5.1178e-02, -2.7029e-02,\n",
       "                      -7.4478e-03,  2.9989e-01,  1.2574e-01,  2.0003e-01, -7.6309e-02,\n",
       "                       1.7387e-01, -4.6775e-02,  2.5688e-02,  1.0909e-02,  2.5152e-01,\n",
       "                       1.0467e-01,  1.3540e-01,  3.0997e-01, -2.5951e-02, -8.4452e-02,\n",
       "                      -6.2370e-02,  2.8588e-01, -6.8832e-02,  9.6593e-02,  5.5573e-02,\n",
       "                       3.3050e-01,  2.6257e-01,  6.0510e-02, -1.8038e-02, -1.0077e-02,\n",
       "                       1.6790e-01, -7.1435e-02, -2.9266e-02, -2.5735e-02,  1.4998e-01,\n",
       "                       3.0129e-01, -1.7990e-02, -1.8004e-02,  1.5658e-01, -7.9340e-02,\n",
       "                       1.4055e-01,  9.3265e-02, -2.4881e-02, -1.1337e-01, -3.6162e-02,\n",
       "                      -2.8333e-02, -1.7541e-02, -2.0531e-01,  2.4553e-01, -8.1918e-02,\n",
       "                       1.4006e-01,  2.6177e-01,  1.1245e-02, -6.6041e-02,  1.7554e-02,\n",
       "                      -1.1356e-01, -7.9010e-03, -4.2250e-02, -4.5378e-02,  2.0531e-01,\n",
       "                      -2.2297e-02, -2.3714e-02,  1.7299e-01,  3.1834e-01,  2.4103e-01,\n",
       "                       4.1730e-01,  1.9381e-01,  1.1455e-01,  2.0352e-01, -1.2525e-01,\n",
       "                      -7.1242e-02, -6.3358e-02, -1.2270e-01,  1.9830e-01, -1.0049e-01,\n",
       "                       2.5949e-02,  4.1722e-02,  1.6740e-01,  1.8773e-01,  3.1792e-01,\n",
       "                      -1.9210e-02,  1.3510e-01,  3.3930e-02,  2.0267e-01, -2.4989e-02,\n",
       "                       1.1014e-01,  4.6547e-02,  4.6709e-03,  1.4427e-01, -7.7965e-03,\n",
       "                       1.0023e-01,  1.6399e-01,  2.3031e-01, -6.1112e-02,  1.1622e-01,\n",
       "                      -8.1313e-02, -4.4910e-02,  3.3849e-01, -1.5949e-02,  5.7958e-03,\n",
       "                       3.2546e-01,  1.0420e-01,  2.1561e-01, -3.8243e-02,  5.1317e-02,\n",
       "                       1.1605e-01, -2.1470e-02, -4.5477e-02, -9.4693e-02, -2.1820e-02,\n",
       "                      -1.0552e-02,  2.0561e-01, -1.3027e-02,  1.6626e-01,  2.8202e-02,\n",
       "                       1.2352e-01, -8.8986e-02,  1.0768e-01, -3.2983e-01, -8.2187e-02,\n",
       "                       2.7285e-01,  3.1788e-01,  2.9308e-01, -1.1922e-01,  2.3179e-01,\n",
       "                       1.1787e-02,  1.5627e-01, -5.4614e-03, -6.3809e-02, -2.8136e-02,\n",
       "                      -1.7824e-01, -6.7102e-02,  1.8550e-01,  2.2655e-01, -1.0233e-01,\n",
       "                       1.3963e-01, -9.6534e-03, -8.0557e-02,  9.9271e-02, -3.4456e-03,\n",
       "                       3.1160e-01,  6.2674e-02,  2.6852e-01, -2.5312e-02, -9.3132e-03,\n",
       "                      -1.6575e-02,  1.6351e-01,  3.0982e-01,  6.4524e-02,  2.2990e-01,\n",
       "                       1.9243e-01, -1.6074e-01,  9.3028e-02,  1.6068e-01, -8.9357e-02,\n",
       "                      -1.6876e-01, -6.4591e-02,  6.7283e-03,  2.3316e-01,  3.5723e-01,\n",
       "                      -2.2927e-02, -4.8483e-02,  3.5769e-01,  6.0529e-03,  3.2630e-01,\n",
       "                       2.7239e-01,  3.0888e-01,  1.2189e-01, -9.4757e-03,  3.6190e-03,\n",
       "                       3.6985e-01,  2.3060e-01, -8.0466e-02,  1.7366e-01,  2.4625e-01,\n",
       "                       1.6220e-01, -1.0220e-01,  1.7258e-01,  1.5241e-01, -1.0690e-01,\n",
       "                       1.8189e-01,  5.9309e-03, -9.9538e-02, -1.2347e-02,  1.4488e-01,\n",
       "                      -2.2883e-02, -1.1215e-01,  3.6971e-01,  3.4377e-01,  3.7454e-02,\n",
       "                       1.0293e-01,  1.4580e-01,  2.7452e-02, -6.5214e-02,  2.8402e-01,\n",
       "                       4.2789e-01,  7.3494e-02,  2.2136e-01, -3.2487e-02,  2.4683e-03,\n",
       "                      -1.2009e-02,  1.9547e-01,  1.5785e-01,  1.3010e-01,  2.1159e-01,\n",
       "                      -9.8648e-02,  1.8942e-01, -1.2731e-04, -3.9489e-02, -5.6775e-03,\n",
       "                       1.4659e-01, -5.9194e-02,  2.3659e-01,  2.5243e-01, -1.7155e-02,\n",
       "                      -4.6603e-02,  1.6346e-01,  1.9457e-01, -5.8816e-02,  9.1039e-02,\n",
       "                      -8.6085e-02,  8.8464e-02,  3.3208e-01,  1.2057e-01, -1.6693e-04,\n",
       "                       1.3743e-01, -1.7904e-02,  2.2657e-01,  3.3055e-01, -2.1172e-01,\n",
       "                       1.7273e-02, -8.2132e-02,  2.3530e-01, -1.5380e-01,  2.4048e-01,\n",
       "                       1.0204e-01,  4.4816e-02])),\n",
       "             ('batchnorm.running_mean',\n",
       "              tensor([2.0628e+00, 2.5637e+00, 2.3246e+00, 1.8503e+00, 4.8040e-01, 6.7406e-01,\n",
       "                      2.4180e+00, 3.0123e+00, 3.7543e+00, 2.1828e+00, 3.8467e+00, 1.9526e-01,\n",
       "                      1.4846e+00, 8.1235e-01, 6.8736e-02, 6.6111e-02, 2.4329e-01, 7.7975e-04,\n",
       "                      2.9077e-02, 1.7110e-01, 2.6616e-01, 4.3634e-02, 9.1123e-01, 4.1325e-01,\n",
       "                      1.7360e+00, 9.5780e-04, 1.2112e-03, 8.7910e-01, 2.3157e-01, 1.6506e+00,\n",
       "                      1.2572e-01, 2.8136e-01, 4.1132e-01, 3.5591e+00, 3.0962e+00, 9.2111e+00,\n",
       "                      5.0820e+00, 4.0282e-01, 2.7502e-01, 2.5751e-01, 1.5932e+00, 4.6581e+00,\n",
       "                      2.5862e+00, 4.1882e+00, 4.2120e+00, 7.4607e+01, 2.0331e+00, 3.1065e+00,\n",
       "                      1.8000e+00, 3.5824e+00, 4.0402e+01, 3.5387e-01, 1.3411e+00, 3.6185e+00,\n",
       "                      6.9030e-01, 2.3912e+00, 1.1213e+00, 6.6742e-01, 7.1362e+01, 3.3832e+00,\n",
       "                      2.6569e+00, 4.8315e-01, 1.1611e-01, 7.1224e+01, 1.7807e-01, 1.6793e-03,\n",
       "                      2.8794e-01, 1.0287e+00, 1.8738e+00, 1.6759e-01, 2.5086e-01, 2.4726e+00,\n",
       "                      5.6351e-02, 2.1412e+00, 1.3173e-01, 9.9576e+00, 4.1195e+00, 1.2916e-01,\n",
       "                      3.2761e+00, 3.7310e-01, 2.5039e-01, 6.7297e+01, 6.4034e-05, 2.5913e+00,\n",
       "                      3.5124e+00, 3.0474e+00, 2.4695e+00, 2.2359e+00, 3.8031e+00, 3.3639e+00,\n",
       "                      2.0860e+00, 3.3569e+00, 4.9924e+00, 2.2085e+00, 1.5587e+00, 1.9553e+00,\n",
       "                      1.4497e+00, 3.0942e+00, 6.7476e+00, 1.6306e-01, 1.4959e+00, 1.2471e+01,\n",
       "                      1.3447e+00, 2.7539e+00, 2.6331e-01, 7.1102e-01, 1.9942e-01, 2.3889e-01,\n",
       "                      2.3108e-01, 4.3062e-01, 2.9124e+00, 4.4902e+00, 1.0426e-01, 1.4707e+00,\n",
       "                      2.5765e+00, 2.5627e-01, 2.1121e+00, 1.8559e-01, 2.5636e-01, 2.3793e+00,\n",
       "                      9.1452e-02, 3.2326e+01, 2.0832e+00, 9.7098e-07, 1.8612e+00, 1.4914e+00,\n",
       "                      2.6122e-02, 1.5232e-01, 5.7460e+00, 2.5902e+00, 1.3607e+00, 5.8833e+00,\n",
       "                      3.2453e+00, 1.2730e-01, 1.4598e+00, 8.1279e-04, 8.1209e-06, 2.0569e+00,\n",
       "                      2.9130e+00, 9.2444e-02, 1.2047e+00, 3.2979e-01, 1.9067e-05, 1.6454e+00,\n",
       "                      2.3249e-01, 1.2919e-03, 1.3334e+00, 1.9417e+00, 2.5654e+00, 3.0954e+00,\n",
       "                      1.8990e+00, 3.8534e+00, 3.2478e+00, 3.5269e-01, 1.9395e+00, 1.4101e-01,\n",
       "                      6.1685e-01, 1.8239e-01, 2.5636e+00, 2.8004e+00, 9.8554e+00, 3.2321e-01,\n",
       "                      1.2183e-01, 2.4435e+00, 2.2246e-01, 5.0379e+00, 3.4763e+00, 1.3456e+00,\n",
       "                      5.6006e-01, 1.2180e+01, 1.3724e+00, 2.0319e-01, 1.5208e+00, 3.8710e-01,\n",
       "                      4.5964e+00, 1.7966e-01, 8.2714e-02, 1.3660e-01, 6.0271e-04, 1.6573e+00,\n",
       "                      1.9636e-01, 2.2347e-02, 2.2404e+00, 4.3780e-01, 8.0942e+00, 2.0315e+00,\n",
       "                      7.0842e+00, 2.3253e-01, 1.2126e+00, 2.0677e+00, 3.0953e-01, 1.0603e-01,\n",
       "                      2.8023e-01, 7.9868e+00, 2.4101e+00, 1.7214e+00, 5.1571e+00, 2.3296e+00,\n",
       "                      6.0562e-01, 1.8350e+00, 5.4419e-01, 5.4966e-01, 2.1502e-01, 5.9613e-02,\n",
       "                      1.0996e-01, 1.4730e-05, 1.0127e+00, 4.5947e-04, 2.8322e+00, 5.7921e+00,\n",
       "                      9.9293e-06, 3.6899e-06, 2.1099e+00, 3.0023e+00, 2.6983e+00, 3.0595e-01,\n",
       "                      2.1936e-01, 8.1442e+00, 4.7869e-02, 1.6848e-01, 3.8933e-01, 3.4186e-01,\n",
       "                      3.0601e+01, 1.5377e-01, 2.8089e+00, 2.5275e-01, 3.3907e-01, 1.6856e+00,\n",
       "                      1.5012e+00, 8.2052e-01, 1.4036e-01, 7.8416e-07, 1.7388e+00, 1.1288e-01,\n",
       "                      9.6383e-02, 5.3894e-01, 5.8255e-01, 2.2413e-01, 5.4274e-01, 4.7514e+00,\n",
       "                      1.7570e+00, 4.3019e+00, 1.8803e+00, 3.0232e-01, 2.7694e-01, 3.3001e-01,\n",
       "                      3.6493e-01, 3.8705e-01, 6.8601e-02, 1.0845e-01, 4.6052e-01, 3.1232e+00,\n",
       "                      4.7747e+00, 3.7595e-01, 1.6458e-01, 6.7933e-07, 3.6180e-01, 1.0282e+00,\n",
       "                      8.6166e-02, 2.8846e+00, 4.3098e+00, 4.4268e+00, 5.1736e+00, 1.9862e+00,\n",
       "                      4.1829e-01, 2.7061e+00, 2.7110e-01, 6.5361e-01, 1.2022e+00, 1.9120e+00,\n",
       "                      2.1908e-01, 1.0016e-02, 6.0055e-01, 7.8229e+00, 5.7316e-01, 7.4197e-01,\n",
       "                      1.2172e-01, 1.8311e+00, 2.5432e-01, 1.4368e-01, 1.0455e-01, 3.9295e+00,\n",
       "                      1.7169e+00, 2.6518e+00, 2.9128e-01, 2.5847e+00, 2.7254e-01, 1.9479e-04,\n",
       "                      5.2495e-01, 1.8594e+00, 3.7320e+00, 1.1284e+01, 3.4778e+00, 1.0999e-01,\n",
       "                      1.2091e-01, 2.0449e-01, 5.5340e+00, 1.8558e-01, 2.2543e+00, 5.6634e+01,\n",
       "                      1.8257e+00, 2.6289e+00, 7.1747e+01, 5.4560e-05, 1.4120e-04, 2.5426e+00,\n",
       "                      6.8328e-01, 5.7318e-02, 2.0835e-01, 3.5858e+00, 2.1664e+00, 6.9220e-02,\n",
       "                      1.1820e-01, 4.0302e+00, 1.0770e+00, 2.4050e+00, 1.4250e+00, 1.4983e-01,\n",
       "                      1.3444e-01, 2.2161e-01, 1.4820e-01, 6.4679e-02, 2.0956e-01, 2.4641e+00,\n",
       "                      9.1096e-02, 2.6495e+00, 1.5644e+00, 9.2486e-05, 1.8971e-01, 1.0431e-01,\n",
       "                      5.0264e-01, 1.0471e-01, 1.1207e-01, 2.4483e-01, 2.5092e+00, 3.2428e-01,\n",
       "                      6.8825e-02, 2.5590e+00, 2.8250e+00, 4.4063e+00, 6.4675e+00, 7.1799e+00,\n",
       "                      1.2118e+00, 1.5103e+00, 2.8946e-01, 1.8845e-01, 5.5972e-01, 2.1121e-01,\n",
       "                      2.8345e+00, 1.0390e+00, 3.7267e-01, 2.0151e-01, 1.6420e+00, 4.9613e+00,\n",
       "                      4.0635e+00, 8.2755e-02, 8.7671e-01, 1.5314e-01, 1.9971e+00, 1.5123e-01,\n",
       "                      1.7338e+01, 6.3991e+01, 8.2055e-02, 3.9496e+00, 1.2717e-03, 1.7258e+00,\n",
       "                      3.5285e+00, 1.9070e+00, 4.5942e-01, 1.2675e+00, 7.0841e-01, 9.9200e-02,\n",
       "                      2.8165e+00, 1.4895e-01, 1.0856e-01, 3.3423e+00, 1.2078e+00, 1.2373e+00,\n",
       "                      2.9214e-01, 1.4789e+01, 1.9312e+00, 2.8028e-01, 3.9173e-01, 2.4701e-01,\n",
       "                      3.2142e-04, 6.3783e-05, 1.3011e+00, 3.1368e-01, 2.1420e+00, 1.4875e-03,\n",
       "                      7.0244e-01, 1.4409e-01, 2.9654e+00, 7.2730e-01, 4.3725e-01, 3.4217e+00,\n",
       "                      2.6429e+00, 2.5926e+00, 6.5382e-01, 2.4738e+00, 3.5947e-02, 8.2733e+00,\n",
       "                      1.2497e-01, 3.7313e-01, 3.1706e-01, 9.6717e-01, 2.5038e-01, 7.3847e+00,\n",
       "                      1.6571e+00, 5.1909e-01, 1.3709e+00, 2.2771e-01, 6.2359e-01, 2.2515e+00,\n",
       "                      3.3616e-01, 6.1238e+00, 1.3238e+00, 8.7232e+00, 9.0593e+01, 1.8728e-01,\n",
       "                      2.7570e-05, 1.7974e+00, 2.8355e+00, 1.6167e+00, 1.0878e+01, 8.6799e+00,\n",
       "                      4.3070e-01, 2.0520e+00, 2.5063e+00, 5.3185e-01, 1.1652e+00, 3.3852e-01,\n",
       "                      3.7205e-06, 1.2956e+00, 4.5365e+00, 4.4449e-07, 2.5244e-01, 2.4430e+00,\n",
       "                      1.7599e-01, 4.4261e+00, 1.8810e+00, 6.0510e+00, 2.4763e+00, 6.1698e-04,\n",
       "                      7.6396e-05, 3.3812e+00, 9.7611e-01, 2.7461e-01, 1.0421e+00, 1.0774e+00,\n",
       "                      1.9754e+00, 4.9959e-01, 1.9676e+00, 3.0547e+00, 3.7281e-01, 2.9642e+00,\n",
       "                      1.8673e+01, 4.3903e-01, 8.7182e-02, 3.6143e+00, 1.1699e-01, 5.3439e-01,\n",
       "                      3.9241e+00, 5.7152e+00, 7.7126e-02, 1.8708e+00, 4.2618e+00, 1.9737e-01,\n",
       "                      4.4442e-01, 1.9007e+00, 3.2023e+00, 2.0387e+00, 6.1368e+00, 1.3879e-01,\n",
       "                      3.1535e-01, 3.3940e-01, 3.9688e+00, 8.3413e+00, 1.2427e+00, 8.2305e+00,\n",
       "                      3.3410e-01, 1.3218e+00, 1.1052e-03, 3.7568e-01, 1.8371e-01, 1.9929e+00,\n",
       "                      3.1345e-01, 5.6100e+00, 1.3506e+00, 3.9796e-01, 3.2257e-01, 2.2738e+00,\n",
       "                      1.5892e+00, 2.4894e-01, 3.2121e+00, 2.6926e-01, 5.3698e+01, 2.3228e+00,\n",
       "                      2.4749e+00, 1.4464e-01, 2.0010e+00, 1.4463e-01, 1.5080e+00, 3.6959e+00,\n",
       "                      5.5271e-01, 1.9713e-02, 3.7062e-01, 7.3036e+00, 3.3163e-01, 4.7515e+00,\n",
       "                      7.2474e+01, 7.9814e+01])),\n",
       "             ('batchnorm.running_var',\n",
       "              tensor([3.5456e+01, 3.4688e+01, 4.4976e+01, 2.9879e+01, 4.6702e+00, 6.9521e+00,\n",
       "                      3.7243e+01, 4.6709e+01, 5.8808e+01, 3.3780e+01, 5.7459e+01, 1.7717e+00,\n",
       "                      2.2298e+01, 6.9972e+00, 5.3253e-01, 5.5253e-01, 2.1208e+00, 5.2887e-03,\n",
       "                      3.0103e-01, 1.6686e+00, 2.3601e+00, 3.9969e-01, 8.4175e+00, 4.1109e+00,\n",
       "                      2.7206e+01, 4.6210e-03, 8.9952e-03, 1.1838e+01, 2.4068e+00, 2.4930e+01,\n",
       "                      1.2342e+00, 1.9298e+00, 4.0157e+00, 5.9794e+01, 5.3878e+01, 1.5482e+02,\n",
       "                      6.5154e+01, 3.6841e+00, 2.8988e+00, 2.4730e+00, 1.9887e+01, 8.4197e+01,\n",
       "                      3.7108e+01, 5.9503e+01, 6.8953e+01, 4.5149e+02, 3.0451e+01, 5.0945e+01,\n",
       "                      2.7639e+01, 4.8185e+01, 4.2525e+02, 3.2454e+00, 2.6228e+01, 5.1962e+01,\n",
       "                      7.0992e+00, 3.1161e+01, 1.6948e+01, 5.8380e+00, 5.3705e+02, 5.5542e+01,\n",
       "                      3.9819e+01, 4.6868e+00, 9.6128e-01, 4.8095e+02, 1.7153e+00, 1.0439e-02,\n",
       "                      2.4519e+00, 1.4287e+01, 2.6130e+01, 1.1697e+00, 2.2539e+00, 4.4052e+01,\n",
       "                      4.1832e-01, 3.1627e+01, 1.2854e+00, 1.4546e+02, 6.0389e+01, 1.1422e+00,\n",
       "                      5.3123e+01, 3.3833e+00, 2.3614e+00, 4.7174e+02, 2.4746e-04, 3.6430e+01,\n",
       "                      6.1572e+01, 4.4990e+01, 3.2878e+01, 2.5795e+01, 5.8808e+01, 4.6109e+01,\n",
       "                      3.6696e+01, 5.8204e+01, 7.4639e+01, 2.8386e+01, 2.6350e+01, 3.0850e+01,\n",
       "                      1.8447e+01, 4.1959e+01, 1.1205e+02, 1.3964e+00, 2.0684e+01, 2.1794e+02,\n",
       "                      2.5300e+01, 4.5613e+01, 2.6884e+00, 7.1934e+00, 2.0578e+00, 2.0490e+00,\n",
       "                      1.9511e+00, 4.2560e+00, 3.9549e+01, 7.4003e+01, 1.1439e+00, 2.0018e+01,\n",
       "                      4.0479e+01, 2.4120e+00, 3.1890e+01, 1.8216e+00, 2.3723e+00, 4.2134e+01,\n",
       "                      8.0602e-01, 4.0921e+02, 3.4245e+01, 4.2097e-06, 3.0785e+01, 2.3072e+01,\n",
       "                      2.8868e-01, 1.5495e+00, 8.9963e+01, 3.6298e+01, 2.0290e+01, 8.1291e+01,\n",
       "                      4.4442e+01, 1.0957e+00, 1.9500e+01, 2.9422e-03, 1.6284e-05, 3.2935e+01,\n",
       "                      4.5701e+01, 7.8281e-01, 1.2535e+01, 3.1144e+00, 3.0446e-05, 2.6886e+01,\n",
       "                      2.2824e+00, 7.6351e-03, 2.0171e+01, 2.7021e+01, 3.6969e+01, 4.6365e+01,\n",
       "                      2.9408e+01, 6.3218e+01, 5.0193e+01, 3.5165e+00, 3.3551e+01, 1.7490e+00,\n",
       "                      5.5491e+00, 1.9241e+00, 4.1998e+01, 4.2981e+01, 1.3909e+02, 3.3418e+00,\n",
       "                      1.0750e+00, 4.7164e+01, 1.6881e+00, 8.2677e+01, 5.1802e+01, 2.0733e+01,\n",
       "                      4.8585e+00, 1.9436e+02, 2.3412e+01, 1.5145e+00, 2.4962e+01, 3.7320e+00,\n",
       "                      6.8598e+01, 1.8223e+00, 8.5162e-01, 1.1004e+00, 3.4016e-03, 2.5641e+01,\n",
       "                      1.8215e+00, 1.6295e-01, 3.4133e+01, 3.9829e+00, 1.2081e+02, 3.1512e+01,\n",
       "                      1.1300e+02, 1.9125e+00, 1.3236e+01, 3.9971e+01, 2.5985e+00, 9.3784e-01,\n",
       "                      2.0440e+00, 1.2347e+02, 3.4702e+01, 2.4033e+01, 7.6841e+01, 3.0921e+01,\n",
       "                      6.0887e+00, 2.1994e+01, 7.2919e+00, 4.7345e+00, 2.2195e+00, 5.9581e-01,\n",
       "                      1.0886e+00, 3.7514e-05, 1.3307e+01, 1.3043e-03, 3.7470e+01, 1.0910e+02,\n",
       "                      1.7003e-05, 8.0490e-06, 2.8339e+01, 4.1850e+01, 3.6220e+01, 2.4263e+00,\n",
       "                      2.1984e+00, 1.2689e+02, 4.0481e-01, 1.4805e+00, 3.9411e+00, 2.5872e+00,\n",
       "                      3.9754e+02, 1.2610e+00, 4.6723e+01, 2.0815e+00, 2.8205e+00, 2.4460e+01,\n",
       "                      2.6747e+01, 9.3159e+00, 1.3750e+00, 1.5944e-06, 2.6327e+01, 9.4743e-01,\n",
       "                      8.1037e-01, 4.5655e+00, 6.9705e+00, 1.7491e+00, 5.8605e+00, 8.8186e+01,\n",
       "                      2.9837e+01, 6.2743e+01, 3.1369e+01, 3.2387e+00, 1.9633e+00, 2.9595e+00,\n",
       "                      3.4697e+00, 3.1111e+00, 6.6108e-01, 1.1902e+00, 3.9808e+00, 4.3593e+01,\n",
       "                      8.0911e+01, 3.8911e+00, 1.3830e+00, 9.9508e-07, 3.4323e+00, 9.6678e+00,\n",
       "                      7.5829e-01, 3.3587e+01, 6.7272e+01, 6.6616e+01, 9.6047e+01, 2.6703e+01,\n",
       "                      3.5882e+00, 3.7865e+01, 2.3576e+00, 5.2890e+00, 1.3433e+01, 2.7918e+01,\n",
       "                      1.7271e+00, 1.3163e-01, 6.5618e+00, 1.4751e+02, 4.5318e+00, 6.9087e+00,\n",
       "                      1.1398e+00, 2.9122e+01, 1.9734e+00, 1.1269e+00, 1.1127e+00, 5.6775e+01,\n",
       "                      2.8362e+01, 4.7315e+01, 2.9229e+00, 3.8366e+01, 2.2450e+00, 4.6362e-04,\n",
       "                      5.0637e+00, 3.0928e+01, 5.1524e+01, 1.3175e+02, 5.8758e+01, 9.3782e-01,\n",
       "                      8.3053e-01, 1.9858e+00, 8.2277e+01, 1.6741e+00, 3.0137e+01, 3.6726e+02,\n",
       "                      1.9347e+01, 4.0593e+01, 3.4296e+02, 1.9135e-04, 1.0092e-03, 3.9709e+01,\n",
       "                      6.9797e+00, 4.2765e-01, 2.0956e+00, 4.3057e+01, 2.9406e+01, 6.6294e-01,\n",
       "                      1.0404e+00, 6.8784e+01, 1.1090e+01, 3.0403e+01, 2.1685e+01, 1.1768e+00,\n",
       "                      1.0386e+00, 2.3842e+00, 1.3069e+00, 6.1806e-01, 1.6528e+00, 4.0510e+01,\n",
       "                      8.5315e-01, 3.3824e+01, 2.4833e+01, 5.0912e-04, 1.5050e+00, 9.5129e-01,\n",
       "                      5.2234e+00, 1.0575e+00, 1.0162e+00, 2.0834e+00, 3.3042e+01, 2.8842e+00,\n",
       "                      5.7266e-01, 4.2490e+01, 4.0467e+01, 5.7624e+01, 9.5725e+01, 1.3837e+02,\n",
       "                      2.1010e+01, 1.8372e+01, 2.2832e+00, 1.5350e+00, 5.8484e+00, 1.5038e+00,\n",
       "                      5.0624e+01, 1.0247e+01, 3.4975e+00, 2.7042e+00, 2.3442e+01, 7.1830e+01,\n",
       "                      6.3268e+01, 9.1860e-01, 1.3927e+01, 1.8180e+00, 2.9662e+01, 1.1170e+00,\n",
       "                      2.4607e+02, 3.7610e+02, 6.8556e-01, 6.6374e+01, 8.7031e-03, 2.8661e+01,\n",
       "                      5.6562e+01, 2.8392e+01, 3.9527e+00, 1.9222e+01, 7.6643e+00, 8.8752e-01,\n",
       "                      4.3709e+01, 1.2845e+00, 1.1080e+00, 6.2072e+01, 1.6924e+01, 1.6184e+01,\n",
       "                      2.6957e+00, 1.8048e+02, 2.5888e+01, 2.3017e+00, 4.0822e+00, 1.8325e+00,\n",
       "                      9.8343e-04, 1.7331e-04, 1.6124e+01, 2.9780e+00, 3.4423e+01, 8.8640e-03,\n",
       "                      9.8025e+00, 1.2619e+00, 4.6226e+01, 6.4386e+00, 4.0392e+00, 4.8737e+01,\n",
       "                      4.2809e+01, 3.7219e+01, 6.4133e+00, 3.8637e+01, 2.8318e-01, 1.5341e+02,\n",
       "                      1.0455e+00, 2.6290e+00, 2.7220e+00, 1.0846e+01, 2.0161e+00, 1.0771e+02,\n",
       "                      2.3197e+01, 4.2418e+00, 1.9333e+01, 2.1474e+00, 5.7397e+00, 3.9218e+01,\n",
       "                      2.9328e+00, 1.1349e+02, 1.7509e+01, 1.5061e+02, 6.3843e+02, 1.8213e+00,\n",
       "                      5.3097e-05, 3.5608e+01, 3.8173e+01, 1.9672e+01, 2.1946e+02, 1.6869e+02,\n",
       "                      3.7290e+00, 3.0561e+01, 3.7801e+01, 4.5118e+00, 1.0779e+01, 3.5641e+00,\n",
       "                      1.0641e-05, 1.8253e+01, 8.6807e+01, 1.0812e-07, 2.2032e+00, 3.5257e+01,\n",
       "                      1.4043e+00, 7.7483e+01, 2.8120e+01, 1.0844e+02, 4.3601e+01, 1.5856e-03,\n",
       "                      4.1834e-04, 4.5832e+01, 1.1617e+01, 2.4267e+00, 1.4865e+01, 1.7744e+01,\n",
       "                      3.3810e+01, 4.4653e+00, 2.5576e+01, 4.7194e+01, 3.1021e+00, 3.6419e+01,\n",
       "                      8.4340e+01, 4.6497e+00, 7.4946e-01, 5.0382e+01, 1.0919e+00, 5.4124e+00,\n",
       "                      6.3985e+01, 9.2649e+01, 6.1129e-01, 3.7042e+01, 6.6117e+01, 2.0667e+00,\n",
       "                      3.8539e+00, 2.9391e+01, 4.5860e+01, 3.3993e+01, 1.0921e+02, 1.0489e+00,\n",
       "                      3.4397e+00, 3.5741e+00, 5.7012e+01, 1.6041e+02, 2.0429e+01, 1.7063e+02,\n",
       "                      3.4431e+00, 1.9653e+01, 4.8048e-03, 4.1398e+00, 1.6027e+00, 4.1432e+01,\n",
       "                      2.9050e+00, 7.8762e+01, 1.9030e+01, 3.7577e+00, 3.4421e+00, 4.1576e+01,\n",
       "                      3.2072e+01, 1.9279e+00, 5.3391e+01, 2.3532e+00, 4.0379e+02, 3.9288e+01,\n",
       "                      3.3979e+01, 1.0046e+00, 2.9031e+01, 1.4817e+00, 2.4392e+01, 6.7462e+01,\n",
       "                      5.2469e+00, 1.6996e-01, 3.0576e+00, 1.3001e+02, 3.2939e+00, 7.0346e+01,\n",
       "                      3.4982e+02, 5.1226e+02])),\n",
       "             ('batchnorm.num_batches_tracked', tensor(32315))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_dict)\n",
    "torch.nn.init.xavier_uniform_(model.embedding.weight.data)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0137,  0.0019,  0.0307,  ..., -0.0425,  0.0308,  0.0305],\n",
       "        [ 0.0210, -0.0083,  0.0317,  ..., -0.0345,  0.0143,  0.0375],\n",
       "        [-0.0428,  0.0051,  0.0241,  ..., -0.0057, -0.0407,  0.0364],\n",
       "        ...,\n",
       "        [ 0.0201, -0.0392,  0.0253,  ...,  0.0052,  0.0080, -0.0015],\n",
       "        [ 0.0375, -0.0435,  0.0449,  ..., -0.0219, -0.0353,  0.0058],\n",
       "        [-0.0247, -0.0070, -0.0193,  ...,  0.0166,  0.0384, -0.0159]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[ 0.0365,  0.0239, -0.0009,  ..., -0.0264, -0.0320, -0.0142],\n",
       "                      [ 0.0267,  0.0163,  0.0086,  ..., -0.0311,  0.0353,  0.0044],\n",
       "                      [ 0.0208, -0.0450,  0.0369,  ..., -0.0236, -0.0407,  0.0076],\n",
       "                      ...,\n",
       "                      [-0.0466,  0.0329, -0.0261,  ..., -0.0070, -0.0250,  0.0095],\n",
       "                      [-0.0158, -0.0414, -0.0326,  ...,  0.0020,  0.0365,  0.0198],\n",
       "                      [-0.0169, -0.0099,  0.0369,  ..., -0.0127, -0.0237, -0.0141]])),\n",
       "             ('lstm.weight_ih_l0',\n",
       "              tensor([[-0.0512,  0.0411,  0.0453,  ..., -0.0619,  0.1240, -0.0714],\n",
       "                      [ 0.1037,  0.0532, -0.1620,  ..., -0.0452,  0.0265, -0.1414],\n",
       "                      [ 0.0513, -0.0808, -0.0294,  ..., -0.1921, -0.0320, -0.0887],\n",
       "                      ...,\n",
       "                      [ 0.0155, -0.0932,  0.0118,  ...,  0.1192, -0.0158,  0.0475],\n",
       "                      [-0.1830, -0.0217,  0.1311,  ...,  0.0062, -0.0633, -0.0942],\n",
       "                      [ 0.0346,  0.0523,  0.0663,  ..., -0.1833,  0.1532, -0.1337]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-0.0297, -0.0894,  0.0724,  ...,  0.0756, -0.0841, -0.0651],\n",
       "                      [ 0.0949,  0.0570,  0.0391,  ...,  0.0820, -0.2257,  0.1743],\n",
       "                      [ 0.0880,  0.0672,  0.0773,  ..., -0.0064, -0.0006, -0.0990],\n",
       "                      ...,\n",
       "                      [ 0.0939,  0.0442,  0.1249,  ..., -0.1698, -0.0206, -0.0310],\n",
       "                      [ 0.0597, -0.0308, -0.0672,  ..., -0.0822, -0.0718,  0.2376],\n",
       "                      [-0.0992, -0.0623, -0.1139,  ..., -0.0358, -0.2093,  0.0688]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([ 0.0408,  0.0678, -0.0664,  ..., -0.0339, -0.0782, -0.0694])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([ 0.0225,  0.0794, -0.0518,  ..., -0.0231, -0.0311, -0.0304])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0953, -0.0443, -0.0284,  ..., -0.0365,  0.1162, -0.1964],\n",
       "                      [-0.0228, -0.0413, -0.0138,  ..., -0.0266,  0.0698, -0.0554],\n",
       "                      [-0.0591, -0.0014,  0.1901,  ...,  0.0229,  0.0583, -0.0190],\n",
       "                      ...,\n",
       "                      [-0.1423, -0.0622,  0.0036,  ...,  0.0337,  0.0640,  0.0023],\n",
       "                      [ 0.0262,  0.0120, -0.0229,  ...,  0.0229, -0.0123, -0.0972],\n",
       "                      [ 0.1148, -0.1269,  0.0256,  ..., -0.0292,  0.0070,  0.0229]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.2484, -0.0970, -0.3423, -0.1425, -0.0345, -0.1170, -0.0793, -0.1452,\n",
       "                      -0.1512, -0.1889, -0.1858, -0.0890, -0.1203, -0.2160, -0.0831, -0.0773,\n",
       "                      -0.1259, -0.0817, -0.0892, -0.0505, -0.1092, -0.1113, -0.0572, -0.1263,\n",
       "                      -0.0324, -0.1002, -0.2795, -0.0713, -0.0928,  0.0477,  0.1634, -0.2789,\n",
       "                      -0.1511, -0.2138,  0.0365, -0.0080, -0.0226, -0.0119, -0.1665,  0.0693,\n",
       "                      -0.0568, -0.1237, -0.0020, -0.0415, -0.1750, -0.0965,  0.0060,  0.0256,\n",
       "                      -0.3199, -0.0015, -0.1191, -0.0705, -0.1525, -0.1055, -0.0538,  0.0221,\n",
       "                      -0.1279, -0.1503, -0.2341, -0.1607, -0.0987, -0.0675, -0.0670, -0.0674,\n",
       "                      -0.0878, -0.0367, -0.0933, -0.0618, -0.1887,  0.0374,  0.1311, -0.0879,\n",
       "                      -0.1431, -0.1836, -0.0868, -0.2619, -0.0726, -0.1418, -0.0660,  0.1069,\n",
       "                      -0.1201, -0.3026, -0.1191, -0.1333, -0.0423, -0.0857, -0.0533, -0.1359,\n",
       "                      -0.3286, -0.0488, -0.1006, -0.1125, -0.0367, -0.0062,  0.0507, -0.0310,\n",
       "                      -0.1554, -0.1436, -0.3174, -0.1187, -0.1732, -0.0149, -0.1000, -0.0576,\n",
       "                      -0.1265, -0.1010, -0.2488, -0.0416, -0.1480, -0.0954, -0.2913, -0.0754,\n",
       "                       0.0045,  0.0761, -0.2004, -0.1671, -0.0967, -0.2461, -0.0082,  0.0063,\n",
       "                      -0.3405, -0.1369, -0.0779, -0.1020, -0.1527, -0.0517, -0.1426, -0.0491,\n",
       "                      -0.0908, -0.0446, -0.2342, -0.2448, -0.2127,  0.0234, -0.1448, -0.0181,\n",
       "                      -0.1198, -0.0907, -0.1005, -0.0689, -0.2744, -0.0075, -0.1203,  0.0409,\n",
       "                      -0.0413, -0.0975, -0.0450, -0.0369, -0.1226,  0.0274, -0.1511, -0.0939,\n",
       "                      -0.0756,  0.0271, -0.2213, -0.0060, -0.0914, -0.2429, -0.0565, -0.0336,\n",
       "                      -0.0470, -0.0754,  0.0139, -0.0263, -0.2339,  0.0281, -0.1889, -0.0597,\n",
       "                      -0.1443, -0.0958, -0.1081, -0.1155, -0.0687, -0.2397, -0.2810, -0.1703,\n",
       "                      -0.3088, -0.0209, -0.0433, -0.1131, -0.1108,  0.0012, -0.1430, -0.3027,\n",
       "                      -0.0775, -0.1417, -0.0737, -0.0520,  0.0315, -0.0803,  0.0176, -0.0442,\n",
       "                      -0.0682, -0.2553, -0.2531, -0.0829, -0.0276, -0.1194,  0.0148, -0.1857,\n",
       "                      -0.2666, -0.0480, -0.3621, -0.0882, -0.0147, -0.2551, -0.1500, -0.0486,\n",
       "                      -0.0958, -0.2242, -0.0874, -0.1455, -0.0014, -0.1377, -0.0013, -0.0246,\n",
       "                       0.2377, -0.2160, -0.2806, -0.0783, -0.1260,  0.1047,  0.2421, -0.1700,\n",
       "                      -0.0120,  0.0226, -0.1255, -0.2882, -0.0632, -0.0293, -0.2397, -0.1857,\n",
       "                       0.0224, -0.1979, -0.0061, -0.1260, -0.1362, -0.2702, -0.1277, -0.0307,\n",
       "                      -0.2202, -0.2860, -0.1557, -0.1722, -0.0349, -0.2120, -0.1252, -0.0451,\n",
       "                      -0.1193, -0.0682, -0.0755, -0.1498, -0.1026,  0.1231, -0.3420, -0.1876,\n",
       "                      -0.0162, -0.1027, -0.2171, -0.0790, -0.0745, -0.0747,  0.1085, -0.0739,\n",
       "                       0.0362,  0.0561, -0.0499,  0.0055, -0.1140,  0.2535, -0.1606, -0.1627,\n",
       "                      -0.0299, -0.0327, -0.0453, -0.0930, -0.0546, -0.0200, -0.2515, -0.0330,\n",
       "                      -0.1211, -0.0787, -0.0583, -0.1175, -0.1368, -0.0603, -0.0491, -0.0694,\n",
       "                      -0.1056, -0.0662,  0.0213, -0.2204, -0.0873,  0.0238, -0.0764, -0.0799,\n",
       "                      -0.1676, -0.0415, -0.0106, -0.0792, -0.1058, -0.0663,  0.1037, -0.0379,\n",
       "                      -0.0671, -0.1743, -0.0089, -0.0895, -0.0622, -0.1913, -0.1542, -0.0547,\n",
       "                      -0.1398,  0.0375, -0.0173, -0.0947, -0.1023, -0.0469, -0.0676,  0.0261,\n",
       "                       0.0015, -0.0356, -0.0581, -0.0300,  0.1233, -0.2323, -0.1710, -0.0892,\n",
       "                      -0.1420, -0.2856, -0.1858, -0.0680, -0.3979, -0.1120, -0.2476, -0.0695,\n",
       "                      -0.1465, -0.0687,  0.0099, -0.3368, -0.0628, -0.1007, -0.2731, -0.0506,\n",
       "                      -0.1419, -0.2824, -0.0762, -0.1287, -0.1148, -0.1658, -0.2742, -0.0079,\n",
       "                      -0.0982, -0.1938, -0.0781, -0.0931, -0.0940, -0.0476, -0.0594, -0.0852,\n",
       "                      -0.1904, -0.1952, -0.0398, -0.1903, -0.0518, -0.1465, -0.0720, -0.1644,\n",
       "                      -0.1233,  0.0828, -0.0626,  0.0088, -0.1160, -0.1365, -0.1067, -0.1408,\n",
       "                      -0.0781, -0.0869, -0.1108, -0.0044, -0.0680, -0.1224, -0.1012, -0.1385,\n",
       "                      -0.0934, -0.0280, -0.0769, -0.0303, -0.1447, -0.0291, -0.3379, -0.0655,\n",
       "                       0.0324, -0.1183, -0.1015, -0.1378, -0.0602, -0.1535, -0.0171, -0.0748,\n",
       "                      -0.1413, -0.1016, -0.1443, -0.0103, -0.0836, -0.1499, -0.0805, -0.1613,\n",
       "                      -0.0703, -0.0675, -0.1676, -0.0512, -0.1919, -0.0482, -0.0772, -0.0868,\n",
       "                      -0.1924, -0.3188, -0.1288, -0.1800, -0.1121, -0.1103,  0.0187, -0.0468,\n",
       "                      -0.1961, -0.0253, -0.0850,  0.0127, -0.1388, -0.1273, -0.1702, -0.0613,\n",
       "                      -0.1057, -0.1727, -0.1199, -0.0943, -0.1004, -0.2355,  0.0095, -0.1892,\n",
       "                      -0.0262, -0.3431, -0.1430, -0.0174, -0.0024, -0.0570, -0.3087, -0.1618,\n",
       "                      -0.0646,  0.0543, -0.2149, -0.1254, -0.1496, -0.1177, -0.1112,  0.2071,\n",
       "                      -0.0872, -0.1202, -0.1041, -0.2916, -0.1008, -0.1391, -0.1152, -0.0894,\n",
       "                      -0.0748,  0.0305, -0.0790, -0.1105,  0.0512, -0.1052, -0.2471, -0.0740,\n",
       "                      -0.1538, -0.0587,  0.0167, -0.2293, -0.1868, -0.0080, -0.0805, -0.0708,\n",
       "                      -0.2237, -0.3088, -0.1573, -0.3384, -0.0912, -0.3074, -0.0679, -0.0962,\n",
       "                      -0.1764, -0.1506, -0.1647, -0.0822, -0.1009, -0.0146, -0.0346, -0.1623,\n",
       "                      -0.1035, -0.2110,  0.0452, -0.1346, -0.0522, -0.1299, -0.0176, -0.0034,\n",
       "                      -0.0821, -0.2333, -0.0388, -0.0289, -0.1493, -0.1191, -0.1187, -0.3156])),\n",
       "             ('fc_rank.weight',\n",
       "              tensor([[-2.0015e-02,  1.8432e-03,  2.6302e-02, -1.0846e-04,  9.6639e-03,\n",
       "                        1.8415e-03,  2.5366e-02,  2.0318e-02, -3.5270e-02,  1.9251e-02,\n",
       "                       -3.7442e-02,  1.9477e-03, -2.1483e-02,  4.3168e-02, -9.2513e-04,\n",
       "                        1.1174e-03, -4.3654e-03,  1.6537e-02,  2.5312e-03,  7.8040e-03,\n",
       "                        5.5865e-03,  3.9724e-02, -1.9484e-02, -3.2410e-03, -2.0331e-02,\n",
       "                        4.4651e-03,  4.2267e-02, -1.8659e-02,  1.5759e-04, -1.3901e-02,\n",
       "                       -3.4262e-02,  1.9079e-02, -5.4943e-03,  2.8920e-02, -3.1611e-02,\n",
       "                       -3.3291e-02, -1.3631e-02, -4.3907e-03,  3.0536e-02, -2.4107e-02,\n",
       "                       -5.4155e-04, -1.6163e-02, -3.8707e-03, -3.7142e-02,  2.6015e-04,\n",
       "                       -7.9374e-04,  1.7172e-02, -2.6525e-02,  3.3726e-02, -1.5000e-02,\n",
       "                        2.0157e-02,  3.9586e-02,  3.6072e-02,  1.7111e-03, -1.2621e-02,\n",
       "                       -1.6629e-02,  3.4693e-03, -6.9095e-03,  1.5063e-02,  4.3120e-02,\n",
       "                       -3.7831e-03,  2.8720e-02, -3.1454e-02,  1.4446e-02,  4.0606e-02,\n",
       "                       -1.4240e-02,  3.5776e-02, -4.9682e-03,  2.4400e-02, -1.4586e-02,\n",
       "                       -1.6060e-02, -7.3309e-03,  2.3040e-02,  2.5882e-02,  4.3900e-04,\n",
       "                        2.2453e-02, -2.5961e-02,  3.5732e-03, -6.3213e-04, -3.2615e-02,\n",
       "                        6.3731e-03,  2.6511e-02, -4.2581e-03,  3.2412e-03, -7.8336e-03,\n",
       "                        3.2110e-02, -1.4035e-02,  1.9353e-02,  9.3562e-03, -3.0518e-02,\n",
       "                        2.4024e-04, -1.5850e-02, -1.6887e-02, -1.4649e-02, -2.3472e-02,\n",
       "                        1.4748e-02, -3.4253e-02,  3.4860e-02,  3.9760e-02, -3.9902e-19,\n",
       "                       -4.5550e-03, -2.4021e-02,  9.7061e-03, -5.9025e-03,  1.4399e-02,\n",
       "                        1.2305e-03,  1.2943e-02, -1.2550e-02, -1.7975e-04, -4.4746e-03,\n",
       "                        1.9416e-02,  7.3313e-03, -2.8342e-02, -2.0048e-02,  3.5668e-02,\n",
       "                        1.9995e-02, -2.4513e-04,  3.5320e-02, -1.3957e-02, -3.9937e-02,\n",
       "                        4.9905e-02,  1.0634e-03,  1.9388e-02, -7.1028e-03, -3.2986e-02,\n",
       "                        2.0933e-03,  4.6417e-02, -2.2558e-03,  1.9535e-03, -3.5629e-02,\n",
       "                        1.2378e-02,  3.2455e-02,  3.8755e-02, -2.6068e-02, -3.9376e-02,\n",
       "                        2.5665e-02, -2.5791e-12,  1.2627e-02, -9.7862e-04, -2.6121e-02,\n",
       "                        1.8275e-02, -3.0625e-02,  2.2641e-02, -1.5852e-02,  1.0344e-07,\n",
       "                        3.6454e-02, -1.1462e-03, -1.6360e-03, -3.4674e-03, -1.5700e-02,\n",
       "                        2.4613e-03, -4.7912e-03,  3.9881e-03, -3.7809e-02,  1.6141e-02,\n",
       "                       -2.5208e-02, -2.0658e-03,  2.4098e-02, -1.8354e-02, -2.5929e-02,\n",
       "                        3.8527e-02, -5.2064e-04,  4.4614e-03, -1.4570e-02,  1.5495e-02,\n",
       "                        1.8937e-02,  2.0168e-02, -3.5464e-02,  1.9827e-02,  1.3151e-03,\n",
       "                        1.8037e-03,  2.0248e-03, -2.0585e-02,  2.5886e-02,  2.8745e-02,\n",
       "                       -3.5857e-04,  3.2200e-02, -1.1621e-02,  4.2407e-04, -2.6062e-04,\n",
       "                       -3.3759e-02, -2.0581e-02,  2.2962e-03,  1.9214e-02, -3.5401e-03,\n",
       "                        1.7598e-02, -3.3474e-03,  9.0367e-04, -3.1085e-02,  1.5818e-02,\n",
       "                       -1.1139e-02,  5.5686e-08, -3.3008e-02,  2.6647e-02,  3.0271e-02,\n",
       "                       -3.0178e-02, -4.8683e-03, -3.5159e-02, -2.1412e-02,  4.1068e-02,\n",
       "                        2.9590e-02, -1.9880e-02,  2.5388e-02, -1.7612e-02, -2.3402e-02,\n",
       "                        3.6272e-02, -1.9602e-03,  1.7546e-02, -3.4833e-03,  2.8683e-02,\n",
       "                        3.2068e-02,  2.5628e-03, -1.3859e-03,  4.0897e-02, -3.0240e-02,\n",
       "                       -1.1162e-02, -3.4474e-02, -7.0414e-03,  2.1806e-02,  3.2538e-02,\n",
       "                        3.4616e-10, -2.2336e-02, -3.2187e-02, -2.1285e-03, -2.2984e-03,\n",
       "                       -1.5420e-02,  2.1471e-03,  3.5955e-02, -4.3249e-02,  7.1731e-04,\n",
       "                        3.1948e-02,  6.8761e-03, -1.0037e-02, -1.1015e-03, -3.1168e-02,\n",
       "                        3.2575e-02,  3.8796e-03,  4.4245e-02,  3.3295e-02,  1.8369e-02,\n",
       "                        4.1243e-02,  1.3003e-02, -1.7556e-02,  2.3606e-02, -1.6011e-02,\n",
       "                        4.4324e-02,  9.4069e-04,  2.0673e-02,  2.8225e-02, -2.9648e-02,\n",
       "                       -3.3123e-03,  3.5530e-02,  3.0239e-04, -2.4929e-02,  4.0934e-02,\n",
       "                        1.3614e-02, -6.1306e-03,  6.1356e-16,  1.6512e-02, -3.4607e-02,\n",
       "                        1.1435e-03,  3.9694e-03, -2.2371e-02, -1.3119e-02, -3.8633e-02,\n",
       "                       -2.8210e-02, -1.3493e-03, -2.4615e-02, -6.8108e-03, -2.6455e-02,\n",
       "                        2.0126e-02, -1.3577e-02,  8.2126e-03,  1.1185e-02, -8.9898e-03,\n",
       "                       -3.2259e-02, -3.0694e-02,  3.5637e-03,  3.8881e-02,  1.7342e-03,\n",
       "                       -2.9371e-02, -1.7702e-02,  2.1632e-03, -8.9268e-03, -2.1027e-04,\n",
       "                       -1.9188e-02,  6.3729e-03, -3.3621e-02,  3.4051e-03, -7.2467e-05,\n",
       "                       -2.3776e-02,  3.0356e-02, -2.4272e-02, -3.2595e-02, -2.9812e-04,\n",
       "                        3.3714e-02,  3.3796e-02,  5.2652e-03, -1.2162e-02,  2.8071e-03,\n",
       "                        5.2706e-03,  3.9817e-04, -2.1216e-02,  7.3666e-04,  2.0860e-03,\n",
       "                        1.8295e-02, -3.5730e-02,  9.7953e-03, -1.6939e-03, -2.5586e-02,\n",
       "                       -2.9627e-02, -1.7634e-02, -1.7692e-02, -2.6633e-02, -3.3500e-02,\n",
       "                       -4.2243e-20,  3.2715e-02, -1.7421e-02,  3.4241e-02, -2.5882e-02,\n",
       "                       -1.6606e-02, -7.2485e-03,  6.4745e-03,  4.7639e-03, -3.1269e-02,\n",
       "                        1.2646e-03, -4.9929e-03,  3.3329e-02, -5.2055e-03,  2.4012e-02,\n",
       "                        3.2940e-02,  8.1706e-03,  4.6059e-02,  1.1995e-02,  1.9049e-02,\n",
       "                        3.1852e-03,  2.4748e-02, -3.8098e-02, -1.9398e-02,  3.9679e-02,\n",
       "                       -3.7179e-03, -3.2224e-03,  3.6296e-02,  9.5988e-03,  2.9679e-02,\n",
       "                        2.7464e-02,  5.7881e-03,  2.4336e-02,  4.2414e-02,  1.2166e-02,\n",
       "                        2.9114e-02, -1.8104e-02, -6.4564e-03, -4.4368e-02,  3.8481e-02,\n",
       "                        4.5094e-03,  2.2196e-03, -2.3948e-02,  5.8125e-04, -2.3675e-03,\n",
       "                        3.8728e-02,  2.1118e-02,  1.7571e-03,  1.7816e-02, -3.6297e-02,\n",
       "                        9.6137e-03, -7.8903e-04,  3.5850e-02, -9.6457e-03, -2.8663e-02,\n",
       "                       -2.8325e-02, -2.7903e-02,  4.3883e-03,  6.3760e-04, -1.2989e-21,\n",
       "                        2.3416e-03,  4.8175e-03, -7.2374e-06, -2.3319e-04, -3.7952e-02,\n",
       "                        4.4198e-23, -1.2660e-02,  3.2243e-02, -1.5444e-02, -2.0811e-04,\n",
       "                       -7.8683e-03, -2.9705e-02, -3.3393e-03,  3.9887e-03, -2.3858e-02,\n",
       "                        4.2822e-02, -3.1511e-02, -2.9862e-02, -2.8330e-02,  2.3886e-02,\n",
       "                       -2.8437e-03,  1.7968e-02,  6.2271e-03, -3.4559e-02,  2.2321e-02,\n",
       "                       -8.0348e-03,  7.9191e-03,  4.8791e-03, -1.9848e-02,  1.3583e-04,\n",
       "                        1.4565e-02,  3.0079e-02,  1.8923e-17,  2.9419e-03, -3.7500e-03,\n",
       "                        3.6784e-02, -1.6348e-02,  2.9025e-02,  1.6867e-03,  3.7324e-04,\n",
       "                       -2.9645e-03,  3.3094e-02,  4.0738e-02,  3.6252e-02, -3.5757e-02,\n",
       "                       -1.6114e-02,  1.1784e-02, -5.8706e-03, -1.6298e-02, -3.5936e-02,\n",
       "                        1.6599e-03,  2.0033e-02,  3.2733e-02, -2.6463e-02,  1.7747e-02,\n",
       "                       -5.5692e-03, -2.1873e-02,  4.5575e-03, -9.7574e-05,  3.1071e-02,\n",
       "                        2.4572e-03, -1.9243e-02,  3.9315e-02, -2.0953e-02, -2.5718e-03,\n",
       "                       -3.0735e-02,  4.6396e-02, -2.9111e-03,  2.4174e-02, -2.2369e-02,\n",
       "                       -2.0285e-02,  3.8740e-02,  2.5452e-02, -3.0551e-02, -2.5050e-02,\n",
       "                        3.6906e-02,  1.8708e-03, -1.0826e-02, -4.0078e-02, -1.6674e-03,\n",
       "                       -2.5414e-02, -3.0117e-02, -5.8480e-04,  1.0952e-02,  1.8164e-02,\n",
       "                       -1.7891e-02,  2.8777e-03,  6.5272e-04, -8.9961e-03, -1.1011e-06,\n",
       "                       -3.7967e-02, -2.4466e-03, -2.9851e-03, -2.1299e-02,  2.5492e-02,\n",
       "                        3.5516e-02,  3.4720e-04,  2.4937e-02,  2.8691e-18, -5.0126e-03,\n",
       "                        3.8441e-02,  1.4758e-02, -1.6606e-02, -1.5617e-02, -1.8634e-03,\n",
       "                       -1.2191e-02,  3.8211e-02,  3.2916e-03,  2.8376e-02, -2.6124e-02,\n",
       "                        1.5724e-02,  1.2779e-10, -3.7347e-03,  2.3775e-02, -1.6062e-02,\n",
       "                       -1.3981e-04,  7.2862e-04, -3.6227e-03,  1.0661e-02, -5.7883e-03,\n",
       "                        7.3168e-04,  3.4703e-02,  4.6457e-02, -3.7531e-02,  7.9994e-04,\n",
       "                        2.0075e-02,  2.0390e-02, -1.7667e-02, -2.5597e-02, -3.2396e-02,\n",
       "                        2.9568e-02, -4.3597e-03, -3.8132e-02,  1.4470e-02, -4.4075e-02,\n",
       "                       -9.9847e-03,  2.1937e-02]])),\n",
       "             ('fc_rank.bias', tensor([-4.6522])),\n",
       "             ('batchnorm.weight',\n",
       "              tensor([ 0.0580,  0.6417,  0.1053,  0.0669,  0.0247,  0.5738,  0.0746,  0.1314,\n",
       "                       0.0539,  0.1331,  0.0517,  0.6082,  0.0514,  0.0576, -0.0304,  0.0092,\n",
       "                       0.1522,  0.0895,  0.4464,  0.1982,  0.0090,  0.0573,  0.0390,  0.0669,\n",
       "                       0.1019,  0.0627,  0.0513,  0.8267,  0.4456,  0.1425,  0.0451,  0.1530,\n",
       "                       0.3552,  0.0914,  0.0516,  0.0611,  0.0454,  0.4073,  0.0844,  0.0371,\n",
       "                       0.7048,  0.0679,  0.0353, -0.0439,  0.0510,  0.2788,  0.0958,  0.0774,\n",
       "                       0.0876,  0.1322,  0.1300, -0.0759,  0.0598,  0.2556, -0.0315,  0.1177,\n",
       "                       0.5484,  0.0662,  0.1746,  0.0619,  0.0951,  0.0612,  0.0708,  0.0919,\n",
       "                       0.0569,  0.0627,  0.0511,  0.3739,  0.1304,  0.1429,  0.1090,  0.1777,\n",
       "                       0.1137,  0.1070,  0.0485,  0.1224,  0.0829, -0.0098,  0.5145,  0.0594,\n",
       "                       0.0279,  0.0453,  0.4685,  0.2026,  0.1836,  0.0853,  0.1480,  0.1128,\n",
       "                       0.2345,  0.0655,  0.0414,  0.0688,  0.1273,  0.1289,  0.0688,  0.3289,\n",
       "                       0.0653,  0.0666,  0.0694,  0.5819,  0.1474,  0.0922,  0.6983,  0.8988,\n",
       "                       0.2289,  0.7163,  0.2284,  0.0392,  0.6593,  0.5719,  0.1270,  0.5095,\n",
       "                       0.0729,  0.1063,  0.0613,  0.1593,  0.0056,  0.0625,  0.1536,  0.0494,\n",
       "                       0.0530,  0.4780,  0.1224,  0.3906,  0.0624,  0.3029,  0.0550,  0.6807,\n",
       "                       0.3894,  0.0506,  0.2342,  0.0908,  0.0613,  0.0658,  0.0476,  0.0712,\n",
       "                       0.2992,  0.1660,  0.2164,  0.0891,  0.1528,  0.0677,  0.1234,  0.1280,\n",
       "                       0.5975,  0.0646,  0.0029, -0.0462,  0.1962,  0.1336,  0.0227,  0.6378,\n",
       "                       0.3962, -0.0460,  0.1817,  0.0760,  0.1423,  0.1126, -0.0336,  0.0878,\n",
       "                       0.0457,  0.0570,  0.1704,  0.1502,  0.1811,  0.0984,  0.1386,  0.0505,\n",
       "                       0.1485,  0.1670,  0.1564,  0.7420,  0.0983,  0.1018,  0.1042,  0.0756,\n",
       "                       0.0727,  0.8130,  0.2809,  0.8033,  0.0538,  0.0691,  0.2735,  0.1591,\n",
       "                       0.3336,  0.1349,  0.8925,  0.0895,  0.0479,  0.0318,  0.1562,  0.7143,\n",
       "                       0.0557,  0.1018,  0.0785,  0.0659,  0.1124,  0.0640,  0.0378,  0.0648,\n",
       "                       0.0865,  0.0938,  0.0927,  0.1293,  0.0797,  0.0680,  0.0872, -0.0423,\n",
       "                       0.3560,  0.0988,  0.0645,  0.6075,  0.2136,  0.0588,  0.0676,  0.0833,\n",
       "                       0.0518, -0.0225,  0.1476,  0.0578,  0.7737,  0.0799,  0.0511,  0.0109,\n",
       "                       0.1299,  0.1240,  0.7321,  0.0841, -0.0486,  0.5149,  0.0900,  0.6660,\n",
       "                       0.1599,  0.4891,  0.0701,  0.0653,  0.0537,  0.0683,  0.0599, -0.0441,\n",
       "                       0.0626,  0.1764,  0.0860,  0.1185,  0.1342, -0.0549,  0.8432,  0.1255,\n",
       "                       0.1097,  0.0363,  0.1003,  0.0601,  0.1040,  0.0653,  0.0728,  0.2229,\n",
       "                       0.0228, -0.0024,  0.1695,  0.0521,  0.0768,  0.4639,  0.0756,  0.6964,\n",
       "                       0.0591,  0.0686, -0.0246,  0.0768,  0.3140,  0.0623,  0.1694,  0.0621,\n",
       "                       0.4386,  0.1884, -0.0181,  0.0659,  0.0742,  0.4199,  0.0731,  0.0513,\n",
       "                       0.0622,  0.1181,  0.3390,  0.2543,  0.2128,  0.0664,  0.3180,  0.0575,\n",
       "                       0.6098,  0.7625,  0.0788,  0.0770,  0.0715,  0.0563,  0.6845,  0.0680,\n",
       "                       0.0772,  0.0286,  0.1525,  0.0639,  0.0212,  0.1773,  0.0905,  0.0602,\n",
       "                       0.0292,  0.1565,  0.0483,  0.0356,  0.2356,  0.0899,  0.0720,  0.4702,\n",
       "                       0.0497,  0.0659,  0.0489,  0.5335,  0.0846,  0.1353,  0.0473,  0.0807,\n",
       "                       0.1171,  0.4957,  0.6054, -0.0088,  0.0547,  0.2337,  0.8549,  0.0728,\n",
       "                       0.2629,  0.1176,  0.0817,  0.1721,  0.0616,  0.1957,  0.1470,  0.2344,\n",
       "                       0.1272,  0.0580,  0.0969,  0.0713,  0.4817,  0.6636,  0.0664,  0.7100,\n",
       "                       0.0623,  0.0939,  0.0972,  0.1392,  0.0479,  0.2200,  0.1031,  0.0736,\n",
       "                       0.0979,  0.0534,  0.0516,  0.2558,  0.1015,  0.0879,  0.0362,  0.0605,\n",
       "                       0.0577,  0.1409,  0.6654,  0.1349,  0.0655,  0.5209,  0.5386,  0.0698,\n",
       "                       0.0876,  0.0506,  0.0691,  0.0549,  0.5807, -0.0275,  0.8512,  0.1182,\n",
       "                       0.2065,  0.0704, -0.0188,  0.0484,  0.6966,  0.0979,  0.0690,  0.5532,\n",
       "                       0.3631,  0.2517,  0.0582,  0.7908,  0.8614,  0.2188,  0.0596,  0.0666,\n",
       "                       0.0603,  0.0737,  0.1128,  0.7022,  0.1586,  0.6990,  0.0664,  0.0873,\n",
       "                       0.0652,  0.4353,  0.6855,  0.0961,  0.7642,  0.1738,  0.0667,  0.5226,\n",
       "                       0.7869,  0.0780,  0.0793,  0.1110,  0.0903,  0.5870,  0.1286,  0.0146,\n",
       "                       0.0858,  0.0590,  0.0902,  0.0467,  0.0834,  0.2000,  0.0644,  0.1224,\n",
       "                       0.0732,  0.3336, -0.0419, -0.0384,  0.0733,  0.7687,  0.3395,  0.0850,\n",
       "                       0.4680,  0.4628,  0.0807,  0.2351,  0.1020,  0.0731,  0.0872,  0.4469,\n",
       "                       0.0632,  0.0604,  0.8270,  0.0701,  0.0857,  0.1128,  0.0613,  0.1085,\n",
       "                       0.0674,  0.0592,  0.0745,  0.4086,  0.0567,  0.0603,  0.6014,  0.0589,\n",
       "                       0.0716,  0.6299,  0.1505,  0.1195,  0.1142,  0.2214,  0.0414,  0.1432,\n",
       "                       0.0153,  0.0513,  0.3617,  0.2474,  0.0943,  0.1014,  0.0750,  0.6004,\n",
       "                       0.1228,  0.7779,  0.5752,  0.0808,  0.2095,  0.0539,  0.1335,  0.3982,\n",
       "                       0.0533,  0.0693,  0.2059,  0.0531,  0.0795,  0.1371,  0.6534,  0.5317,\n",
       "                       0.1084,  0.0475,  0.1067,  0.6424,  0.2577,  0.7509,  0.2337,  0.5041,\n",
       "                       0.0865,  0.0564,  0.0487,  0.2695,  0.4468,  0.1252,  0.1129,  0.0708,\n",
       "                       0.0635,  0.0876,  0.5506,  0.0511,  0.1953,  0.0598,  0.0910,  0.1329])),\n",
       "             ('batchnorm.bias',\n",
       "              tensor([-1.8195e-03, -1.8838e-03, -2.8090e-03, -7.5463e-04, -1.0393e-03,\n",
       "                       5.5506e-03, -3.5568e-03, -4.6174e-03,  6.4714e-04, -2.3292e-03,\n",
       "                      -9.0015e-04, -6.3063e-03,  3.3629e-03, -4.3136e-03,  4.5117e-04,\n",
       "                      -2.5416e-03,  3.3134e-04, -4.0933e-03,  2.0095e-03, -1.1725e-02,\n",
       "                      -8.0679e-03, -4.7196e-03, -1.2185e-03,  1.8469e-03, -1.0136e-03,\n",
       "                      -4.3244e-03, -4.2357e-03,  2.4652e-04,  1.0937e-03,  9.5436e-04,\n",
       "                       3.1627e-03, -2.7453e-03,  4.3532e-03, -2.6108e-03,  6.7849e-04,\n",
       "                      -2.2530e-03,  9.8014e-04, -7.5062e-04, -1.3159e-03,  5.1973e-04,\n",
       "                       1.2511e-03,  5.5726e-04, -3.4345e-04,  1.7597e-03, -1.8906e-03,\n",
       "                       4.9969e-03, -8.2922e-03,  1.9174e-03, -2.5659e-03, -1.0296e-03,\n",
       "                      -3.2080e-03,  2.2814e-03, -4.0150e-03,  3.5236e-03, -6.6973e-04,\n",
       "                       6.5135e-04,  1.3022e-02, -1.3997e-03, -5.3503e-03, -1.4648e-03,\n",
       "                       4.3773e-03, -2.1894e-03, -1.0640e-03,  1.6603e-04, -5.0279e-03,\n",
       "                       4.1285e-04, -2.5183e-03, -3.1683e-03, -4.5054e-03,  5.2206e-03,\n",
       "                       1.4422e-03, -9.8114e-04, -4.2690e-03, -4.1812e-04, -2.5804e-03,\n",
       "                      -4.1913e-03,  1.2863e-03,  4.9785e-03, -5.4067e-03,  6.0544e-04,\n",
       "                       1.6883e-03, -4.3585e-04,  4.2382e-03,  8.8185e-03, -1.2975e-04,\n",
       "                      -7.2790e-04, -1.5941e-03, -2.6520e-03, -1.8961e-02, -2.2863e-03,\n",
       "                      -5.8330e-04, -2.2689e-03, -2.2802e-03, -3.6544e-03,  1.1412e-03,\n",
       "                       2.3883e-03, -9.9573e-04, -6.1800e-04, -2.2603e-03, -1.4275e-19,\n",
       "                       3.2284e-03,  1.7344e-03,  3.5567e-03,  4.3547e-04, -2.1680e-03,\n",
       "                       2.5830e-03, -3.6560e-03, -3.0619e-03, -6.3225e-03, -1.2093e-03,\n",
       "                      -8.3755e-03, -5.2877e-03,  2.0346e-04,  1.8560e-03, -7.7315e-04,\n",
       "                      -5.3240e-03, -2.5875e-03, -2.7925e-03,  2.6176e-03, -1.4528e-03,\n",
       "                      -1.6650e-03, -3.1840e-03, -3.8352e-03, -3.6299e-03, -3.1147e-04,\n",
       "                       7.1700e-03,  4.8760e-04, -2.2541e-03,  2.6562e-03,  8.4822e-04,\n",
       "                      -7.8830e-03, -2.9809e-03, -6.9444e-04, -2.1933e-03, -1.7519e-03,\n",
       "                      -1.9826e-03, -2.6144e-12, -5.6256e-03, -7.3377e-04, -2.6569e-03,\n",
       "                      -3.2721e-03, -9.4056e-04, -1.9142e-03,  2.4879e-04,  8.9927e-04,\n",
       "                      -1.4331e-03,  4.6977e-03,  6.2851e-03, -4.4109e-03, -8.1759e-04,\n",
       "                       2.2311e-03, -4.8004e-03, -4.5358e-03,  1.9352e-03, -4.2971e-03,\n",
       "                       1.7314e-04,  9.5479e-04, -5.4920e-04,  8.6889e-04, -1.9721e-03,\n",
       "                      -1.7253e-04,  4.7741e-03,  3.3243e-03, -9.7999e-04, -8.1366e-03,\n",
       "                      -4.6799e-03, -2.2941e-03,  5.3504e-04, -5.2995e-03,  1.7154e-04,\n",
       "                      -8.3053e-03, -7.2611e-03, -7.7659e-04, -4.2749e-03,  5.8694e-04,\n",
       "                      -5.9901e-04,  3.9655e-04,  2.4273e-03, -2.5358e-03, -2.6050e-04,\n",
       "                      -8.0380e-04,  3.0945e-03, -3.1765e-04, -3.1462e-03,  5.4686e-03,\n",
       "                      -6.1032e-03,  5.4809e-03,  1.9961e-03,  2.4554e-03, -3.9139e-04,\n",
       "                      -2.0546e-03, -5.6256e-08, -4.2915e-04, -9.2118e-04, -4.6704e-03,\n",
       "                      -1.3030e-03, -1.1264e-02, -9.7847e-04,  5.2211e-04,  1.2934e-04,\n",
       "                      -5.1106e-03, -8.0921e-04, -2.9447e-03, -6.4069e-04,  1.1083e-03,\n",
       "                      -2.7143e-03,  7.1255e-03,  9.2282e-04,  3.9142e-03, -2.8913e-03,\n",
       "                      -2.2338e-03, -2.8680e-03, -1.8880e-03, -1.1601e-03,  2.2353e-05,\n",
       "                      -4.4011e-04,  9.1612e-04, -1.0708e-03, -3.4011e-03, -4.3979e-03,\n",
       "                      -3.4620e-10,  8.5111e-04,  3.1073e-03, -1.5483e-03, -5.9683e-03,\n",
       "                       2.4002e-03,  3.9048e-03, -8.3581e-04,  2.5189e-03, -2.7430e-03,\n",
       "                      -2.8961e-03,  2.8218e-03,  4.6227e-03,  3.8869e-04,  1.6410e-03,\n",
       "                      -4.1903e-03,  7.7847e-03, -7.8609e-04, -4.6323e-03,  1.3404e-03,\n",
       "                      -1.3206e-03, -7.9464e-03, -1.6435e-03, -7.1192e-04, -1.9865e-03,\n",
       "                      -6.8963e-04, -1.7741e-03, -2.4760e-03, -2.2196e-03,  9.2947e-04,\n",
       "                       6.6811e-03, -2.7047e-03, -1.3449e-04,  1.0968e-03, -6.0757e-04,\n",
       "                      -5.5624e-03,  1.9240e-03,  1.2084e-15, -7.6989e-03,  5.2953e-04,\n",
       "                      -9.1523e-04, -8.5625e-04,  9.7105e-04,  7.6597e-05, -1.5525e-03,\n",
       "                       2.8585e-03, -6.5714e-03,  9.6428e-04,  3.8026e-03,  1.8713e-04,\n",
       "                      -4.9426e-04,  4.6456e-03,  2.8010e-03, -1.7252e-03,  1.5974e-03,\n",
       "                      -9.3569e-06,  1.4592e-04, -7.9116e-04, -2.8049e-03,  2.1577e-04,\n",
       "                      -5.3665e-04, -2.9005e-04, -1.1694e-03,  1.7493e-03,  6.6435e-03,\n",
       "                      -3.1856e-03, -6.8061e-03,  1.4740e-03,  3.8426e-03,  5.1856e-04,\n",
       "                       1.4340e-03, -1.7359e-04,  1.6627e-03,  6.3251e-04,  1.1619e-02,\n",
       "                      -2.7679e-03, -2.2526e-03, -6.6816e-03, -3.8366e-03, -7.2269e-03,\n",
       "                       4.6487e-03,  3.0929e-03, -5.1326e-04, -3.8228e-03, -2.6373e-03,\n",
       "                      -1.6086e-03, -7.7879e-05, -1.0696e-03,  6.6408e-03, -2.0298e-03,\n",
       "                      -3.6229e-04, -1.1198e-03, -8.4992e-04,  4.1576e-04, -4.1936e-04,\n",
       "                      -2.1572e-20, -2.2018e-03, -1.5650e-03, -1.3482e-03,  2.4700e-04,\n",
       "                      -2.9881e-04, -1.5738e-03,  2.9762e-03,  5.5825e-03,  3.3420e-03,\n",
       "                      -2.3338e-03,  4.1516e-03, -2.6168e-03, -6.1249e-04, -2.0151e-03,\n",
       "                       7.8745e-04, -1.1289e-02, -6.4478e-04, -8.8859e-03, -6.7448e-03,\n",
       "                       5.2551e-03, -1.6691e-03, -1.5412e-03, -9.3816e-04, -1.8227e-03,\n",
       "                      -1.0782e-03,  1.6193e-03,  4.7713e-04, -1.8553e-03, -2.0606e-03,\n",
       "                      -3.5134e-03,  4.4449e-04, -2.5096e-03, -1.0288e-03, -1.0231e-02,\n",
       "                      -3.0835e-03, -1.4250e-03,  5.7764e-03,  4.3151e-04, -1.1788e-03,\n",
       "                       1.9940e-03, -3.8920e-03, -3.0566e-03, -1.1189e-03, -4.4654e-03,\n",
       "                      -3.6451e-03,  4.8841e-05,  8.7019e-03, -4.6222e-03,  2.4392e-04,\n",
       "                      -8.2011e-04,  1.3529e-04, -2.9530e-03, -7.5157e-04,  4.3037e-03,\n",
       "                      -1.3814e-03,  1.1846e-03, -1.8460e-03, -6.6780e-03, -1.2998e-21,\n",
       "                       2.2690e-03, -1.0833e-02, -8.1738e-05,  1.3884e-03, -2.0729e-04,\n",
       "                       4.4453e-23, -1.9758e-04, -2.1159e-03, -6.1175e-05, -3.1398e-03,\n",
       "                      -2.3344e-04, -7.3144e-04, -4.2998e-03, -2.0373e-03,  3.3786e-05,\n",
       "                      -1.7235e-03, -1.4626e-03, -9.3986e-04, -1.4841e-03, -3.9179e-04,\n",
       "                       3.4992e-04, -2.2410e-03, -6.6747e-03,  1.5669e-03, -1.4330e-03,\n",
       "                      -1.0658e-03, -3.6468e-03,  2.5309e-04, -2.3989e-03,  1.3513e-04,\n",
       "                      -6.4654e-03, -3.5738e-03, -2.1465e-18, -3.2855e-03,  7.5407e-04,\n",
       "                      -2.5509e-03,  4.0112e-04, -2.3553e-03, -5.7129e-03,  1.8348e-03,\n",
       "                       2.8336e-03, -4.4287e-03, -1.9368e-03, -2.5843e-03,  3.7003e-04,\n",
       "                      -2.1397e-03, -1.0287e-02, -1.1881e-03,  1.8464e-03, -1.7563e-03,\n",
       "                       9.0541e-03,  2.4071e-03, -1.5411e-03,  3.2280e-04, -1.2775e-03,\n",
       "                      -5.1650e-03,  1.6394e-04, -8.4188e-03, -1.8269e-03, -1.4064e-03,\n",
       "                      -7.5576e-03, -1.4059e-03, -3.6199e-03,  2.2436e-03, -2.1446e-03,\n",
       "                       3.6300e-03, -1.0332e-03, -3.3106e-04, -3.4523e-03,  1.6734e-03,\n",
       "                      -1.9937e-03, -2.1995e-03, -2.4140e-03,  8.4180e-04,  6.1199e-04,\n",
       "                      -1.3193e-03,  7.0333e-03,  5.8094e-04, -1.0536e-04, -6.3984e-04,\n",
       "                       3.0741e-03, -1.7647e-03,  3.0909e-03, -1.0127e-02, -6.4918e-03,\n",
       "                       1.8559e-03,  3.7946e-03,  1.5711e-03,  1.5054e-03, -1.2483e-06,\n",
       "                       1.8196e-03,  1.7646e-03,  6.0758e-03,  9.5896e-04, -4.5090e-03,\n",
       "                      -1.3512e-03,  5.9659e-04, -3.2478e-03, -2.8745e-18,  1.6373e-03,\n",
       "                      -3.5088e-03, -8.3302e-03,  1.3097e-03, -1.5660e-03,  2.6439e-03,\n",
       "                       3.3852e-03, -2.2086e-03, -2.3379e-03,  1.6691e-03, -1.8636e-03,\n",
       "                      -9.8770e-03, -1.2479e-10, -3.0738e-03, -3.8583e-03,  1.6179e-03,\n",
       "                      -2.6826e-04, -6.2093e-03, -3.1663e-03, -6.9150e-04, -5.9368e-03,\n",
       "                      -7.0396e-03, -3.3376e-03, -9.1868e-04, -9.4449e-04,  3.9203e-03,\n",
       "                      -1.5120e-03, -6.0026e-03, -3.4925e-04,  6.5179e-04, -2.3615e-04,\n",
       "                      -2.7707e-03, -1.7929e-03, -6.6388e-04, -7.7983e-03,  2.7694e-04,\n",
       "                       2.0329e-04, -5.0138e-03])),\n",
       "             ('batchnorm.running_mean',\n",
       "              tensor([3.2211e-05, 5.6052e-45, 5.3300e-02, 5.6052e-45, 3.9206e-05, 5.6052e-45,\n",
       "                      4.5151e-01, 8.7379e-02, 1.7585e-01, 1.4060e-02, 1.0505e-02, 1.0855e-16,\n",
       "                      2.0522e-06, 2.7587e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45, 3.0961e+00,\n",
       "                      5.6052e-45, 4.5233e+00, 7.3423e-05, 5.5184e-01, 1.2662e-04, 5.6052e-45,\n",
       "                      4.9924e-01, 4.0045e-06, 1.8564e-01, 5.6052e-45, 1.0495e-11, 1.7964e+00,\n",
       "                      1.5009e+01, 3.6504e-02, 2.5918e-40, 5.1519e-02, 4.5959e-02, 1.2429e-01,\n",
       "                      3.5063e-13, 5.6052e-45, 3.2889e-02, 4.4593e-04, 5.6052e-45, 3.1850e-04,\n",
       "                      5.7795e-10, 4.5348e+00, 5.6052e-45, 4.3224e-39, 3.3186e+00, 5.0192e-01,\n",
       "                      2.9646e-02, 3.4109e-01, 1.5534e-01, 1.6120e-30, 2.9170e-01, 5.6052e-45,\n",
       "                      6.7341e-05, 9.5224e-01, 5.6052e-45, 8.6420e-10, 2.5882e-02, 5.1756e-02,\n",
       "                      5.6052e-45, 1.1389e+00, 5.4623e-02, 9.3623e-02, 6.2883e-01, 5.5201e-06,\n",
       "                      8.3785e-01, 5.6052e-45, 6.3745e-02, 1.6414e+00, 5.8875e+00, 5.6052e-45,\n",
       "                      1.2493e-01, 1.9763e-02, 5.6052e-45, 7.8611e-02, 1.0542e-01, 5.7089e-11,\n",
       "                      5.6052e-45, 8.5827e-01, 2.4314e-05, 1.3527e-01, 5.6052e-45, 9.2838e-40,\n",
       "                      1.5610e-04, 9.4185e-02, 5.9519e-01, 8.2232e-02, 2.1361e-01, 2.5380e-02,\n",
       "                      5.6052e-45, 4.8823e-24, 1.0096e-01, 5.6634e-01, 8.1874e+00, 5.6052e-45,\n",
       "                      1.3910e-02, 4.2392e-02, 1.3182e-01, 5.6052e-45, 5.6052e-45, 4.1442e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6580e-07, 4.7518e-02, 2.1751e-06,\n",
       "                      5.6052e-45, 2.0818e-11, 2.0501e-01, 5.6052e-45, 1.2325e+00, 1.7790e+00,\n",
       "                      1.1284e-02, 3.4818e-02, 5.6052e-45, 9.8489e-03, 1.2409e+00, 1.2099e-01,\n",
       "                      6.3305e-02, 5.6052e-45, 4.7582e-01, 5.6052e-45, 2.9632e-02, 5.6052e-45,\n",
       "                      4.7591e-03, 1.7056e-08, 5.6052e-45, 4.5095e-02, 4.4399e-02, 1.5502e-02,\n",
       "                      2.9904e-02, 2.4082e+00, 1.3498e-02, 1.8450e+00, 5.6052e-45, 3.3550e-02,\n",
       "                      5.6052e-45, 2.3840e-02, 4.9016e-02, 6.2547e-01, 4.8076e-02, 1.0468e+00,\n",
       "                      5.6052e-45, 2.1013e-01, 2.4910e-28, 5.6052e-45, 5.6052e-45, 5.9467e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 4.4529e+00, 7.4962e-02, 8.6637e-01,\n",
       "                      5.6052e-45, 4.2045e-02, 3.8316e-05, 1.1434e-01, 2.9699e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 3.6524e-01, 2.1508e-02, 2.1763e+00, 2.5127e-02, 6.4232e-02,\n",
       "                      1.5189e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45, 1.0104e-01, 2.6403e-02,\n",
       "                      4.4229e-02, 1.8419e-29, 2.5149e-02, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      7.9807e-02, 1.6394e+01, 6.3971e-09, 5.1197e-02, 1.1103e-11, 4.8322e-02,\n",
       "                      5.6052e-45, 5.6052e-45, 6.6920e-01, 3.1601e-04, 6.6018e-01, 5.6052e-45,\n",
       "                      3.7462e-02, 2.4354e-02, 4.9765e-01, 1.1179e-01, 5.6052e-45, 1.8871e-02,\n",
       "                      2.4216e-04, 2.1947e-02, 1.1235e-01, 2.6845e-02, 3.7592e-02, 3.1924e-02,\n",
       "                      7.8426e-01, 1.1129e-02, 5.6052e-45, 7.5600e-05, 1.2955e-05, 3.4879e-02,\n",
       "                      4.7153e-01, 5.6052e-45, 1.1596e-29, 2.0001e-02, 4.1703e-01, 8.3706e-05,\n",
       "                      5.1441e+00, 5.6266e-06, 5.4189e-02, 5.5419e-01, 5.6052e-45, 4.5507e+00,\n",
       "                      1.1977e+01, 1.8124e-21, 5.6052e-45, 1.2080e+00, 5.6052e-45, 5.0839e-02,\n",
       "                      5.6648e-01, 5.6052e-45, 3.2098e-02, 5.6052e-45, 6.3499e-37, 5.6052e-45,\n",
       "                      3.2651e-01, 3.0585e-01, 5.6052e-45, 4.7201e-02, 4.7506e-01, 8.3733e-07,\n",
       "                      6.0203e-02, 2.7763e-01, 1.2976e-15, 1.8847e-01, 2.0586e-01, 3.6740e-02,\n",
       "                      5.6052e-45, 3.2210e-02, 3.1402e-02, 2.7027e+00, 2.0565e-27, 3.6131e-01,\n",
       "                      5.6052e-45, 7.2691e+00, 7.3023e-02, 3.1251e-02, 5.6052e-45, 5.6052e-45,\n",
       "                      1.8206e-01, 1.4706e-02, 5.6052e-45, 5.6052e-45, 5.5270e+00, 5.6052e-45,\n",
       "                      4.8211e-02, 1.3022e+00, 4.6762e-28, 8.5609e-01, 5.6052e-45, 1.3089e+01,\n",
       "                      4.3258e-02, 1.4717e-12, 2.3705e-28, 5.6052e-45, 2.1481e-04, 5.7682e-02,\n",
       "                      4.2887e-02, 5.6052e-45, 4.7047e-02, 5.6052e-45, 5.1723e-02, 2.3481e-01,\n",
       "                      5.6052e-45, 5.8951e-05, 5.6052e-45, 5.1686e-07, 5.6052e-45, 1.5148e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 1.9772e+00, 2.2611e-02, 6.0425e-02, 4.8770e-02,\n",
       "                      5.6052e-45, 5.4228e-01, 4.6846e-02, 5.6052e-45, 3.8368e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.3805e+00, 5.6052e-45, 5.6052e-45, 3.1923e-02,\n",
       "                      1.0867e-01, 3.3537e-11, 5.6052e-45, 5.2999e-02, 4.4572e-02, 5.6052e-45,\n",
       "                      8.8712e-12, 2.4745e+00, 1.1466e-01, 5.6052e-45, 4.8497e-01, 5.5271e-01,\n",
       "                      1.2647e+00, 4.3407e-01, 9.7563e-02, 5.6052e-45, 5.6052e-45, 1.0447e-03,\n",
       "                      5.9325e+00, 5.6052e-45, 5.6052e-45, 7.6632e-02, 5.6052e-45, 2.9223e-02,\n",
       "                      6.3880e-02, 5.6413e+00, 6.6653e-02, 4.0558e-01, 6.6353e-02, 4.6569e-21,\n",
       "                      2.3751e-02, 4.8884e-02, 8.9846e-01, 4.5011e-02, 6.2448e-28, 5.6052e-45,\n",
       "                      3.2421e-03, 5.6052e-45, 3.6121e-02, 2.5027e-02, 5.6052e-45, 3.4332e-02,\n",
       "                      2.4108e-01, 1.2664e-01, 4.9993e-02, 1.4979e-01, 5.6052e-45, 2.5578e-02,\n",
       "                      9.5001e-02, 5.6052e-45, 2.6195e-05, 1.4619e-01, 5.6052e-45, 3.6376e-28,\n",
       "                      3.3623e-01, 1.9979e-02, 5.6052e-45, 4.4094e-02, 6.1168e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 1.1265e-01, 1.2014e-11, 1.3828e+01, 6.1871e-02, 2.5299e-02,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 3.1909e-02, 5.6052e-45, 3.6376e-05, 7.8692e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.8724e-02, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      3.7861e-02, 1.4130e-01, 5.0929e-02, 4.8342e-02, 2.6020e-02, 5.6052e-45,\n",
       "                      7.8850e-02, 3.1000e-28, 2.7152e-02, 5.1514e-02, 2.2370e-10, 1.2450e-38,\n",
       "                      5.6052e-45, 1.3464e-01, 5.6052e-45, 1.5394e-01, 4.8593e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.1093e-01, 4.4436e-01, 1.3525e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.2256e-22, 5.5711e-02, 2.5688e-02, 3.8738e-03, 2.2136e-02,\n",
       "                      1.2690e-05, 3.9418e-02, 5.6833e-28, 2.0778e-01, 2.6375e-02, 1.8933e-39,\n",
       "                      8.1854e-06, 4.3775e+00, 1.7432e-02, 5.6052e-45, 7.5361e-39, 2.1043e-01,\n",
       "                      5.6052e-45, 1.1146e-38, 1.4225e-01, 5.6052e-45, 1.3228e-01, 6.6211e-02,\n",
       "                      1.6326e+00, 5.6052e-45, 9.4454e-01, 3.1635e-02, 5.6052e-45, 4.0909e+00,\n",
       "                      8.6794e-01, 1.0765e-01, 3.4152e-02, 9.0450e-02, 1.6655e-02, 7.8827e+00,\n",
       "                      3.0162e-02, 5.6052e-45, 6.6550e-27, 1.5280e-02, 4.4874e-14, 1.2084e+01,\n",
       "                      5.1285e-02, 5.6052e-45, 2.4135e-01, 2.5116e-01, 6.2627e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 2.0958e-17, 5.6052e-45, 8.3218e-02, 4.2238e-06, 5.6052e-45,\n",
       "                      7.1840e-01, 5.6127e-01, 2.5887e-02, 5.6052e-45, 2.4725e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 3.2416e-02, 6.4210e-02, 1.5288e-13, 3.2610e-01, 5.6052e-45,\n",
       "                      4.4032e-07, 4.0128e-02, 5.6052e-45, 6.7327e-01, 6.3849e-02, 1.5304e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 2.5789e-02, 6.3811e-04, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 2.0992e-11, 5.6052e-45, 6.9159e-02, 3.7846e-02,\n",
       "                      3.6520e-02, 5.6052e-45, 5.6052e-45, 1.8496e-01, 5.0906e-01, 1.9104e+00,\n",
       "                      8.8357e-02, 4.1406e-02, 5.6052e-45, 7.7524e-02, 3.8921e-02, 1.3101e-02,\n",
       "                      6.5994e-07, 6.1717e-02])),\n",
       "             ('batchnorm.running_var',\n",
       "              tensor([2.8534e-05, 5.6052e-45, 3.1291e-01, 5.6052e-45, 1.3180e-04, 5.6052e-45,\n",
       "                      3.1774e+00, 5.1336e-01, 1.3210e+00, 7.9538e-02, 5.9436e-02, 4.7444e-17,\n",
       "                      8.5697e-06, 2.0554e+00, 5.6052e-45, 5.6052e-45, 5.6052e-45, 2.3637e+01,\n",
       "                      5.6052e-45, 4.2685e+01, 5.1885e-04, 4.6889e+00, 2.5139e-04, 5.6052e-45,\n",
       "                      3.2315e+00, 9.3859e-06, 1.4858e+00, 5.6052e-45, 9.2634e-12, 1.1517e+01,\n",
       "                      1.1194e+02, 2.4848e-01, 2.1391e-40, 2.8521e-01, 2.2678e-01, 7.3005e-01,\n",
       "                      1.9893e-12, 5.6052e-45, 1.8221e-01, 8.4606e-04, 5.6052e-45, 6.3332e-04,\n",
       "                      3.3111e-10, 4.5585e+01, 5.6052e-45, 4.1426e-39, 4.1579e+01, 2.3937e+00,\n",
       "                      1.4053e-01, 1.7137e+00, 9.6609e-01, 1.5993e-30, 2.2200e+00, 5.6052e-45,\n",
       "                      3.9321e-04, 5.4693e+00, 5.6052e-45, 1.3681e-08, 1.4900e-01, 2.8671e-01,\n",
       "                      5.6052e-45, 9.1419e+00, 2.3104e-01, 6.1865e-01, 5.5467e+00, 9.7955e-06,\n",
       "                      6.9150e+00, 5.6052e-45, 3.8627e-01, 1.0929e+01, 3.5723e+01, 5.6052e-45,\n",
       "                      6.8585e-01, 9.5252e-02, 5.6052e-45, 3.4145e-01, 4.4504e-01, 1.3140e-10,\n",
       "                      5.6052e-45, 4.2689e+00, 6.0926e-05, 7.3357e-01, 5.6052e-45, 1.5479e-40,\n",
       "                      1.4806e-04, 5.0665e-01, 3.1883e+00, 3.9208e-01, 1.5661e+00, 1.4754e-01,\n",
       "                      5.6052e-45, 4.3723e-23, 5.1124e-01, 3.0463e+00, 5.1757e+01, 5.6052e-45,\n",
       "                      7.6496e-02, 1.9808e-01, 9.0947e-01, 5.6052e-45, 5.6052e-45, 2.3077e+00,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 1.7092e-06, 3.3416e-01, 9.3153e-06,\n",
       "                      5.6052e-45, 3.6449e-11, 1.4412e+00, 5.6052e-45, 8.2004e+00, 1.1009e+01,\n",
       "                      6.5778e-02, 1.8589e-01, 5.6052e-45, 8.6292e-02, 7.2417e+00, 6.8456e-01,\n",
       "                      4.8658e-01, 5.6052e-45, 2.8507e+00, 5.6052e-45, 1.5224e-01, 5.6052e-45,\n",
       "                      4.9186e-02, 1.8020e-08, 5.6052e-45, 2.9937e-01, 2.2093e-01, 8.3692e-02,\n",
       "                      1.6926e-01, 1.6884e+01, 8.9263e-02, 1.7116e+01, 5.6052e-45, 1.6227e-01,\n",
       "                      5.6052e-45, 1.1581e-01, 2.0298e-01, 3.7076e+00, 2.8149e-01, 7.0466e+00,\n",
       "                      5.6052e-45, 1.4075e+00, 1.5497e-28, 5.6052e-45, 5.6052e-45, 3.0157e+00,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.8520e+01, 4.6144e-01, 4.9689e+00,\n",
       "                      5.6052e-45, 2.1622e-01, 6.5977e-05, 5.4834e-01, 1.7180e+00, 5.6052e-45,\n",
       "                      5.6052e-45, 2.2683e+00, 9.0879e-02, 2.0862e+01, 1.4426e-01, 4.0787e-01,\n",
       "                      7.7020e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.3073e-01, 1.7329e-01,\n",
       "                      2.2264e-01, 1.9079e-29, 1.9623e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      4.9743e-01, 1.2669e+02, 4.0565e-08, 3.5746e-01, 1.0368e-11, 2.3827e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 2.8638e+00, 3.0471e-03, 3.5071e+00, 5.6052e-45,\n",
       "                      2.1762e-01, 1.4094e-01, 4.1792e+00, 6.3451e-01, 5.6052e-45, 9.9053e-02,\n",
       "                      5.0573e-04, 1.2919e-01, 6.9798e-01, 1.3660e-01, 3.1685e-01, 1.4087e-01,\n",
       "                      4.8720e+00, 9.6167e-02, 5.6052e-45, 1.5723e-04, 5.8777e-05, 2.2782e-01,\n",
       "                      3.7036e+00, 5.6052e-45, 4.8870e-30, 8.4423e-02, 2.6621e+00, 2.5487e-04,\n",
       "                      4.3121e+01, 1.1257e-05, 3.6340e-01, 4.3134e+00, 5.6052e-45, 2.8209e+01,\n",
       "                      8.0954e+01, 4.4059e-22, 5.6052e-45, 7.1036e+00, 5.6052e-45, 3.7277e-01,\n",
       "                      4.9073e+00, 5.6052e-45, 2.0798e-01, 5.6052e-45, 1.1009e-36, 5.6052e-45,\n",
       "                      1.7495e+00, 2.8527e+00, 5.6052e-45, 2.6696e-01, 3.7668e+00, 9.2899e-07,\n",
       "                      3.8827e-01, 2.3922e+00, 2.7043e-15, 1.0922e+00, 1.0776e+00, 1.9606e-01,\n",
       "                      5.6052e-45, 1.4064e-01, 1.8115e-01, 7.1792e+00, 1.4903e-27, 4.0449e+00,\n",
       "                      5.6052e-45, 5.9102e+01, 4.8725e-01, 1.3780e-01, 5.6052e-45, 5.6052e-45,\n",
       "                      9.6272e-01, 1.0381e-01, 5.6052e-45, 5.6052e-45, 4.4634e+01, 5.6052e-45,\n",
       "                      2.6712e-01, 8.0564e+00, 5.4543e-28, 5.2527e+00, 5.6052e-45, 8.9158e+01,\n",
       "                      2.1716e-01, 1.3276e-12, 1.4034e-28, 5.6052e-45, 7.8540e-04, 2.5277e-01,\n",
       "                      2.8299e-01, 5.6052e-45, 2.6961e-01, 5.6052e-45, 2.6564e-01, 1.4034e+00,\n",
       "                      5.6052e-45, 1.9267e-04, 5.6052e-45, 6.0370e-07, 5.6052e-45, 8.8335e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 1.3859e+01, 1.6462e-01, 3.5435e-01, 2.5807e-01,\n",
       "                      5.6052e-45, 3.8674e+00, 2.6405e-01, 5.6052e-45, 1.9853e+00, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 7.4056e+00, 5.6052e-45, 5.6052e-45, 1.9965e-01,\n",
       "                      6.8956e-01, 8.0746e-11, 5.6052e-45, 2.1985e-01, 2.8354e-01, 5.6052e-45,\n",
       "                      2.4106e-11, 1.8410e+01, 9.4397e-01, 5.6052e-45, 3.6944e+00, 3.3474e+00,\n",
       "                      1.1589e+01, 2.9441e+00, 5.3544e-01, 5.6052e-45, 5.6052e-45, 4.6153e-03,\n",
       "                      4.5649e+01, 5.6052e-45, 5.6052e-45, 3.6570e-01, 5.6052e-45, 1.2720e-01,\n",
       "                      4.2688e-01, 5.0448e+01, 4.1129e-01, 3.4746e+00, 3.9449e-01, 1.0299e-20,\n",
       "                      1.3387e-01, 2.4582e-01, 5.5301e+00, 3.3614e-01, 9.7396e-28, 5.6052e-45,\n",
       "                      2.9873e-02, 5.6052e-45, 2.4052e-01, 2.1368e-01, 5.6052e-45, 1.5769e-01,\n",
       "                      1.5211e+00, 5.9584e-01, 2.5166e-01, 6.5549e-01, 5.6052e-45, 1.4049e-01,\n",
       "                      6.5774e-01, 5.6052e-45, 6.5360e-05, 8.1513e-01, 5.6052e-45, 3.3048e-28,\n",
       "                      2.9290e+00, 9.7488e-02, 5.6052e-45, 2.2622e-01, 3.8270e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 7.4297e-01, 4.8802e-12, 9.2236e+01, 3.5912e-01, 1.2881e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 2.0848e-01, 5.6052e-45, 4.1148e-05, 4.9279e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.2777e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      2.8828e-01, 7.9913e-01, 3.1760e-01, 2.1687e-01, 1.4687e-01, 5.6052e-45,\n",
       "                      3.5505e-01, 2.4002e-28, 1.6100e-01, 2.9796e-01, 9.1675e-10, 3.4369e-38,\n",
       "                      5.6052e-45, 6.1168e-01, 5.6052e-45, 9.7859e-01, 3.7303e+00, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 6.8292e-01, 3.0755e+00, 9.7755e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 6.9986e-22, 3.0300e-01, 1.6659e-01, 3.8257e-02, 1.5880e-01,\n",
       "                      4.5371e-06, 1.9666e-01, 8.0670e-28, 1.0744e+00, 1.3058e-01, 6.4380e-40,\n",
       "                      4.0752e-07, 2.3089e+01, 7.8448e-02, 5.6052e-45, 1.2592e-38, 1.1780e+00,\n",
       "                      5.6052e-45, 2.7544e-38, 8.6012e-01, 5.6052e-45, 8.7330e-01, 3.7217e-01,\n",
       "                      1.2853e+01, 5.6052e-45, 6.0468e+00, 2.1921e-01, 5.6052e-45, 3.7250e+01,\n",
       "                      6.0316e+00, 6.0223e-01, 2.2649e-01, 5.3216e-01, 8.7062e-02, 7.5514e+01,\n",
       "                      1.7818e-01, 5.6052e-45, 1.0489e-26, 8.0094e-02, 7.5148e-14, 8.4594e+01,\n",
       "                      2.7736e-01, 5.6052e-45, 1.7774e+00, 2.1512e+00, 3.3427e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 1.1104e-17, 5.6052e-45, 3.9417e-01, 6.2484e-06, 5.6052e-45,\n",
       "                      4.2114e+00, 4.8074e+00, 1.2927e-01, 5.6052e-45, 1.3594e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 2.2698e-01, 3.3126e-01, 3.3822e-13, 1.7253e+00, 5.6052e-45,\n",
       "                      9.0017e-07, 2.6023e-01, 5.6052e-45, 3.4991e+00, 3.8097e-01, 1.1273e+00,\n",
       "                      5.6052e-45, 5.6052e-45, 1.3167e-01, 2.4766e-03, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 3.7061e-11, 5.6052e-45, 4.4467e-01, 1.9664e-01,\n",
       "                      2.6126e-01, 5.6052e-45, 5.6052e-45, 1.0565e+00, 2.8277e+00, 1.2307e+01,\n",
       "                      5.1082e-01, 2.1219e-01, 5.6052e-45, 4.8630e-01, 1.8863e-01, 5.5108e-02,\n",
       "                      5.7147e-07, 3.0761e-01])),\n",
       "             ('batchnorm.num_batches_tracked', tensor(64630))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_with_random_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, cfg):\n",
    "    fr_vocab = len(training_corpus_dct.token2id)\n",
    "    en_vocab = len(training_corpus_dct_en.token2id)\n",
    "    \n",
    "    emb_en = model_en.state_dict()[\"embedding.weight\"]\n",
    "    emb_fr = torch.zeros((fr_vocab, cfg.WORD_EMB_SIZE))\n",
    "    \n",
    "    for i in range(fr_vocab):\n",
    "        emb_fr[i,:] = emb_en[random.randint(0, en_vocab-1),:]\n",
    "\n",
    "    model_dict.update({\"embedding.weight\":emb_fr}) \n",
    "    model.load_state_dict(model_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_with_random_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, cfg)\n",
    "mapping_method_name = 'random-mapping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[ 1.7271, -1.2524,  0.3662,  ...,  0.2888, -0.0980,  0.7038],\n",
       "                      [ 1.2250,  1.0468,  0.7116,  ...,  1.3039,  1.7643,  0.6113],\n",
       "                      [-0.5549,  0.2516,  0.0771,  ...,  0.0116, -0.2818,  0.0639],\n",
       "                      ...,\n",
       "                      [-0.4953,  1.1682, -1.4139,  ..., -1.2872,  0.4483, -0.2479],\n",
       "                      [-2.0895, -0.8601,  0.9913,  ..., -0.1803,  0.4244,  1.5329],\n",
       "                      [ 0.1732, -0.0028, -1.6158,  ...,  0.7078, -1.5452,  0.4110]])),\n",
       "             ('lstm.weight_ih_l0',\n",
       "              tensor([[-0.0512,  0.0411,  0.0453,  ..., -0.0619,  0.1240, -0.0714],\n",
       "                      [ 0.1037,  0.0532, -0.1620,  ..., -0.0452,  0.0265, -0.1414],\n",
       "                      [ 0.0513, -0.0808, -0.0294,  ..., -0.1921, -0.0320, -0.0887],\n",
       "                      ...,\n",
       "                      [ 0.0155, -0.0932,  0.0118,  ...,  0.1192, -0.0158,  0.0475],\n",
       "                      [-0.1830, -0.0217,  0.1311,  ...,  0.0062, -0.0633, -0.0942],\n",
       "                      [ 0.0346,  0.0523,  0.0663,  ..., -0.1833,  0.1532, -0.1337]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-0.0297, -0.0894,  0.0724,  ...,  0.0756, -0.0841, -0.0651],\n",
       "                      [ 0.0949,  0.0570,  0.0391,  ...,  0.0820, -0.2257,  0.1743],\n",
       "                      [ 0.0880,  0.0672,  0.0773,  ..., -0.0064, -0.0006, -0.0990],\n",
       "                      ...,\n",
       "                      [ 0.0939,  0.0442,  0.1249,  ..., -0.1698, -0.0206, -0.0310],\n",
       "                      [ 0.0597, -0.0308, -0.0672,  ..., -0.0822, -0.0718,  0.2376],\n",
       "                      [-0.0992, -0.0623, -0.1139,  ..., -0.0358, -0.2093,  0.0688]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([ 0.0408,  0.0678, -0.0664,  ..., -0.0339, -0.0782, -0.0694])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([ 0.0225,  0.0794, -0.0518,  ..., -0.0231, -0.0311, -0.0304])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0953, -0.0443, -0.0284,  ..., -0.0365,  0.1162, -0.1964],\n",
       "                      [-0.0228, -0.0413, -0.0138,  ..., -0.0266,  0.0698, -0.0554],\n",
       "                      [-0.0591, -0.0014,  0.1901,  ...,  0.0229,  0.0583, -0.0190],\n",
       "                      ...,\n",
       "                      [-0.1423, -0.0622,  0.0036,  ...,  0.0337,  0.0640,  0.0023],\n",
       "                      [ 0.0262,  0.0120, -0.0229,  ...,  0.0229, -0.0123, -0.0972],\n",
       "                      [ 0.1148, -0.1269,  0.0256,  ..., -0.0292,  0.0070,  0.0229]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.2484, -0.0970, -0.3423, -0.1425, -0.0345, -0.1170, -0.0793, -0.1452,\n",
       "                      -0.1512, -0.1889, -0.1858, -0.0890, -0.1203, -0.2160, -0.0831, -0.0773,\n",
       "                      -0.1259, -0.0817, -0.0892, -0.0505, -0.1092, -0.1113, -0.0572, -0.1263,\n",
       "                      -0.0324, -0.1002, -0.2795, -0.0713, -0.0928,  0.0477,  0.1634, -0.2789,\n",
       "                      -0.1511, -0.2138,  0.0365, -0.0080, -0.0226, -0.0119, -0.1665,  0.0693,\n",
       "                      -0.0568, -0.1237, -0.0020, -0.0415, -0.1750, -0.0965,  0.0060,  0.0256,\n",
       "                      -0.3199, -0.0015, -0.1191, -0.0705, -0.1525, -0.1055, -0.0538,  0.0221,\n",
       "                      -0.1279, -0.1503, -0.2341, -0.1607, -0.0987, -0.0675, -0.0670, -0.0674,\n",
       "                      -0.0878, -0.0367, -0.0933, -0.0618, -0.1887,  0.0374,  0.1311, -0.0879,\n",
       "                      -0.1431, -0.1836, -0.0868, -0.2619, -0.0726, -0.1418, -0.0660,  0.1069,\n",
       "                      -0.1201, -0.3026, -0.1191, -0.1333, -0.0423, -0.0857, -0.0533, -0.1359,\n",
       "                      -0.3286, -0.0488, -0.1006, -0.1125, -0.0367, -0.0062,  0.0507, -0.0310,\n",
       "                      -0.1554, -0.1436, -0.3174, -0.1187, -0.1732, -0.0149, -0.1000, -0.0576,\n",
       "                      -0.1265, -0.1010, -0.2488, -0.0416, -0.1480, -0.0954, -0.2913, -0.0754,\n",
       "                       0.0045,  0.0761, -0.2004, -0.1671, -0.0967, -0.2461, -0.0082,  0.0063,\n",
       "                      -0.3405, -0.1369, -0.0779, -0.1020, -0.1527, -0.0517, -0.1426, -0.0491,\n",
       "                      -0.0908, -0.0446, -0.2342, -0.2448, -0.2127,  0.0234, -0.1448, -0.0181,\n",
       "                      -0.1198, -0.0907, -0.1005, -0.0689, -0.2744, -0.0075, -0.1203,  0.0409,\n",
       "                      -0.0413, -0.0975, -0.0450, -0.0369, -0.1226,  0.0274, -0.1511, -0.0939,\n",
       "                      -0.0756,  0.0271, -0.2213, -0.0060, -0.0914, -0.2429, -0.0565, -0.0336,\n",
       "                      -0.0470, -0.0754,  0.0139, -0.0263, -0.2339,  0.0281, -0.1889, -0.0597,\n",
       "                      -0.1443, -0.0958, -0.1081, -0.1155, -0.0687, -0.2397, -0.2810, -0.1703,\n",
       "                      -0.3088, -0.0209, -0.0433, -0.1131, -0.1108,  0.0012, -0.1430, -0.3027,\n",
       "                      -0.0775, -0.1417, -0.0737, -0.0520,  0.0315, -0.0803,  0.0176, -0.0442,\n",
       "                      -0.0682, -0.2553, -0.2531, -0.0829, -0.0276, -0.1194,  0.0148, -0.1857,\n",
       "                      -0.2666, -0.0480, -0.3621, -0.0882, -0.0147, -0.2551, -0.1500, -0.0486,\n",
       "                      -0.0958, -0.2242, -0.0874, -0.1455, -0.0014, -0.1377, -0.0013, -0.0246,\n",
       "                       0.2377, -0.2160, -0.2806, -0.0783, -0.1260,  0.1047,  0.2421, -0.1700,\n",
       "                      -0.0120,  0.0226, -0.1255, -0.2882, -0.0632, -0.0293, -0.2397, -0.1857,\n",
       "                       0.0224, -0.1979, -0.0061, -0.1260, -0.1362, -0.2702, -0.1277, -0.0307,\n",
       "                      -0.2202, -0.2860, -0.1557, -0.1722, -0.0349, -0.2120, -0.1252, -0.0451,\n",
       "                      -0.1193, -0.0682, -0.0755, -0.1498, -0.1026,  0.1231, -0.3420, -0.1876,\n",
       "                      -0.0162, -0.1027, -0.2171, -0.0790, -0.0745, -0.0747,  0.1085, -0.0739,\n",
       "                       0.0362,  0.0561, -0.0499,  0.0055, -0.1140,  0.2535, -0.1606, -0.1627,\n",
       "                      -0.0299, -0.0327, -0.0453, -0.0930, -0.0546, -0.0200, -0.2515, -0.0330,\n",
       "                      -0.1211, -0.0787, -0.0583, -0.1175, -0.1368, -0.0603, -0.0491, -0.0694,\n",
       "                      -0.1056, -0.0662,  0.0213, -0.2204, -0.0873,  0.0238, -0.0764, -0.0799,\n",
       "                      -0.1676, -0.0415, -0.0106, -0.0792, -0.1058, -0.0663,  0.1037, -0.0379,\n",
       "                      -0.0671, -0.1743, -0.0089, -0.0895, -0.0622, -0.1913, -0.1542, -0.0547,\n",
       "                      -0.1398,  0.0375, -0.0173, -0.0947, -0.1023, -0.0469, -0.0676,  0.0261,\n",
       "                       0.0015, -0.0356, -0.0581, -0.0300,  0.1233, -0.2323, -0.1710, -0.0892,\n",
       "                      -0.1420, -0.2856, -0.1858, -0.0680, -0.3979, -0.1120, -0.2476, -0.0695,\n",
       "                      -0.1465, -0.0687,  0.0099, -0.3368, -0.0628, -0.1007, -0.2731, -0.0506,\n",
       "                      -0.1419, -0.2824, -0.0762, -0.1287, -0.1148, -0.1658, -0.2742, -0.0079,\n",
       "                      -0.0982, -0.1938, -0.0781, -0.0931, -0.0940, -0.0476, -0.0594, -0.0852,\n",
       "                      -0.1904, -0.1952, -0.0398, -0.1903, -0.0518, -0.1465, -0.0720, -0.1644,\n",
       "                      -0.1233,  0.0828, -0.0626,  0.0088, -0.1160, -0.1365, -0.1067, -0.1408,\n",
       "                      -0.0781, -0.0869, -0.1108, -0.0044, -0.0680, -0.1224, -0.1012, -0.1385,\n",
       "                      -0.0934, -0.0280, -0.0769, -0.0303, -0.1447, -0.0291, -0.3379, -0.0655,\n",
       "                       0.0324, -0.1183, -0.1015, -0.1378, -0.0602, -0.1535, -0.0171, -0.0748,\n",
       "                      -0.1413, -0.1016, -0.1443, -0.0103, -0.0836, -0.1499, -0.0805, -0.1613,\n",
       "                      -0.0703, -0.0675, -0.1676, -0.0512, -0.1919, -0.0482, -0.0772, -0.0868,\n",
       "                      -0.1924, -0.3188, -0.1288, -0.1800, -0.1121, -0.1103,  0.0187, -0.0468,\n",
       "                      -0.1961, -0.0253, -0.0850,  0.0127, -0.1388, -0.1273, -0.1702, -0.0613,\n",
       "                      -0.1057, -0.1727, -0.1199, -0.0943, -0.1004, -0.2355,  0.0095, -0.1892,\n",
       "                      -0.0262, -0.3431, -0.1430, -0.0174, -0.0024, -0.0570, -0.3087, -0.1618,\n",
       "                      -0.0646,  0.0543, -0.2149, -0.1254, -0.1496, -0.1177, -0.1112,  0.2071,\n",
       "                      -0.0872, -0.1202, -0.1041, -0.2916, -0.1008, -0.1391, -0.1152, -0.0894,\n",
       "                      -0.0748,  0.0305, -0.0790, -0.1105,  0.0512, -0.1052, -0.2471, -0.0740,\n",
       "                      -0.1538, -0.0587,  0.0167, -0.2293, -0.1868, -0.0080, -0.0805, -0.0708,\n",
       "                      -0.2237, -0.3088, -0.1573, -0.3384, -0.0912, -0.3074, -0.0679, -0.0962,\n",
       "                      -0.1764, -0.1506, -0.1647, -0.0822, -0.1009, -0.0146, -0.0346, -0.1623,\n",
       "                      -0.1035, -0.2110,  0.0452, -0.1346, -0.0522, -0.1299, -0.0176, -0.0034,\n",
       "                      -0.0821, -0.2333, -0.0388, -0.0289, -0.1493, -0.1191, -0.1187, -0.3156])),\n",
       "             ('fc_rank.weight',\n",
       "              tensor([[-2.0015e-02,  1.8432e-03,  2.6302e-02, -1.0846e-04,  9.6639e-03,\n",
       "                        1.8415e-03,  2.5366e-02,  2.0318e-02, -3.5270e-02,  1.9251e-02,\n",
       "                       -3.7442e-02,  1.9477e-03, -2.1483e-02,  4.3168e-02, -9.2513e-04,\n",
       "                        1.1174e-03, -4.3654e-03,  1.6537e-02,  2.5312e-03,  7.8040e-03,\n",
       "                        5.5865e-03,  3.9724e-02, -1.9484e-02, -3.2410e-03, -2.0331e-02,\n",
       "                        4.4651e-03,  4.2267e-02, -1.8659e-02,  1.5759e-04, -1.3901e-02,\n",
       "                       -3.4262e-02,  1.9079e-02, -5.4943e-03,  2.8920e-02, -3.1611e-02,\n",
       "                       -3.3291e-02, -1.3631e-02, -4.3907e-03,  3.0536e-02, -2.4107e-02,\n",
       "                       -5.4155e-04, -1.6163e-02, -3.8707e-03, -3.7142e-02,  2.6015e-04,\n",
       "                       -7.9374e-04,  1.7172e-02, -2.6525e-02,  3.3726e-02, -1.5000e-02,\n",
       "                        2.0157e-02,  3.9586e-02,  3.6072e-02,  1.7111e-03, -1.2621e-02,\n",
       "                       -1.6629e-02,  3.4693e-03, -6.9095e-03,  1.5063e-02,  4.3120e-02,\n",
       "                       -3.7831e-03,  2.8720e-02, -3.1454e-02,  1.4446e-02,  4.0606e-02,\n",
       "                       -1.4240e-02,  3.5776e-02, -4.9682e-03,  2.4400e-02, -1.4586e-02,\n",
       "                       -1.6060e-02, -7.3309e-03,  2.3040e-02,  2.5882e-02,  4.3900e-04,\n",
       "                        2.2453e-02, -2.5961e-02,  3.5732e-03, -6.3213e-04, -3.2615e-02,\n",
       "                        6.3731e-03,  2.6511e-02, -4.2581e-03,  3.2412e-03, -7.8336e-03,\n",
       "                        3.2110e-02, -1.4035e-02,  1.9353e-02,  9.3562e-03, -3.0518e-02,\n",
       "                        2.4024e-04, -1.5850e-02, -1.6887e-02, -1.4649e-02, -2.3472e-02,\n",
       "                        1.4748e-02, -3.4253e-02,  3.4860e-02,  3.9760e-02, -3.9902e-19,\n",
       "                       -4.5550e-03, -2.4021e-02,  9.7061e-03, -5.9025e-03,  1.4399e-02,\n",
       "                        1.2305e-03,  1.2943e-02, -1.2550e-02, -1.7975e-04, -4.4746e-03,\n",
       "                        1.9416e-02,  7.3313e-03, -2.8342e-02, -2.0048e-02,  3.5668e-02,\n",
       "                        1.9995e-02, -2.4513e-04,  3.5320e-02, -1.3957e-02, -3.9937e-02,\n",
       "                        4.9905e-02,  1.0634e-03,  1.9388e-02, -7.1028e-03, -3.2986e-02,\n",
       "                        2.0933e-03,  4.6417e-02, -2.2558e-03,  1.9535e-03, -3.5629e-02,\n",
       "                        1.2378e-02,  3.2455e-02,  3.8755e-02, -2.6068e-02, -3.9376e-02,\n",
       "                        2.5665e-02, -2.5791e-12,  1.2627e-02, -9.7862e-04, -2.6121e-02,\n",
       "                        1.8275e-02, -3.0625e-02,  2.2641e-02, -1.5852e-02,  1.0344e-07,\n",
       "                        3.6454e-02, -1.1462e-03, -1.6360e-03, -3.4674e-03, -1.5700e-02,\n",
       "                        2.4613e-03, -4.7912e-03,  3.9881e-03, -3.7809e-02,  1.6141e-02,\n",
       "                       -2.5208e-02, -2.0658e-03,  2.4098e-02, -1.8354e-02, -2.5929e-02,\n",
       "                        3.8527e-02, -5.2064e-04,  4.4614e-03, -1.4570e-02,  1.5495e-02,\n",
       "                        1.8937e-02,  2.0168e-02, -3.5464e-02,  1.9827e-02,  1.3151e-03,\n",
       "                        1.8037e-03,  2.0248e-03, -2.0585e-02,  2.5886e-02,  2.8745e-02,\n",
       "                       -3.5857e-04,  3.2200e-02, -1.1621e-02,  4.2407e-04, -2.6062e-04,\n",
       "                       -3.3759e-02, -2.0581e-02,  2.2962e-03,  1.9214e-02, -3.5401e-03,\n",
       "                        1.7598e-02, -3.3474e-03,  9.0367e-04, -3.1085e-02,  1.5818e-02,\n",
       "                       -1.1139e-02,  5.5686e-08, -3.3008e-02,  2.6647e-02,  3.0271e-02,\n",
       "                       -3.0178e-02, -4.8683e-03, -3.5159e-02, -2.1412e-02,  4.1068e-02,\n",
       "                        2.9590e-02, -1.9880e-02,  2.5388e-02, -1.7612e-02, -2.3402e-02,\n",
       "                        3.6272e-02, -1.9602e-03,  1.7546e-02, -3.4833e-03,  2.8683e-02,\n",
       "                        3.2068e-02,  2.5628e-03, -1.3859e-03,  4.0897e-02, -3.0240e-02,\n",
       "                       -1.1162e-02, -3.4474e-02, -7.0414e-03,  2.1806e-02,  3.2538e-02,\n",
       "                        3.4616e-10, -2.2336e-02, -3.2187e-02, -2.1285e-03, -2.2984e-03,\n",
       "                       -1.5420e-02,  2.1471e-03,  3.5955e-02, -4.3249e-02,  7.1731e-04,\n",
       "                        3.1948e-02,  6.8761e-03, -1.0037e-02, -1.1015e-03, -3.1168e-02,\n",
       "                        3.2575e-02,  3.8796e-03,  4.4245e-02,  3.3295e-02,  1.8369e-02,\n",
       "                        4.1243e-02,  1.3003e-02, -1.7556e-02,  2.3606e-02, -1.6011e-02,\n",
       "                        4.4324e-02,  9.4069e-04,  2.0673e-02,  2.8225e-02, -2.9648e-02,\n",
       "                       -3.3123e-03,  3.5530e-02,  3.0239e-04, -2.4929e-02,  4.0934e-02,\n",
       "                        1.3614e-02, -6.1306e-03,  6.1356e-16,  1.6512e-02, -3.4607e-02,\n",
       "                        1.1435e-03,  3.9694e-03, -2.2371e-02, -1.3119e-02, -3.8633e-02,\n",
       "                       -2.8210e-02, -1.3493e-03, -2.4615e-02, -6.8108e-03, -2.6455e-02,\n",
       "                        2.0126e-02, -1.3577e-02,  8.2126e-03,  1.1185e-02, -8.9898e-03,\n",
       "                       -3.2259e-02, -3.0694e-02,  3.5637e-03,  3.8881e-02,  1.7342e-03,\n",
       "                       -2.9371e-02, -1.7702e-02,  2.1632e-03, -8.9268e-03, -2.1027e-04,\n",
       "                       -1.9188e-02,  6.3729e-03, -3.3621e-02,  3.4051e-03, -7.2467e-05,\n",
       "                       -2.3776e-02,  3.0356e-02, -2.4272e-02, -3.2595e-02, -2.9812e-04,\n",
       "                        3.3714e-02,  3.3796e-02,  5.2652e-03, -1.2162e-02,  2.8071e-03,\n",
       "                        5.2706e-03,  3.9817e-04, -2.1216e-02,  7.3666e-04,  2.0860e-03,\n",
       "                        1.8295e-02, -3.5730e-02,  9.7953e-03, -1.6939e-03, -2.5586e-02,\n",
       "                       -2.9627e-02, -1.7634e-02, -1.7692e-02, -2.6633e-02, -3.3500e-02,\n",
       "                       -4.2243e-20,  3.2715e-02, -1.7421e-02,  3.4241e-02, -2.5882e-02,\n",
       "                       -1.6606e-02, -7.2485e-03,  6.4745e-03,  4.7639e-03, -3.1269e-02,\n",
       "                        1.2646e-03, -4.9929e-03,  3.3329e-02, -5.2055e-03,  2.4012e-02,\n",
       "                        3.2940e-02,  8.1706e-03,  4.6059e-02,  1.1995e-02,  1.9049e-02,\n",
       "                        3.1852e-03,  2.4748e-02, -3.8098e-02, -1.9398e-02,  3.9679e-02,\n",
       "                       -3.7179e-03, -3.2224e-03,  3.6296e-02,  9.5988e-03,  2.9679e-02,\n",
       "                        2.7464e-02,  5.7881e-03,  2.4336e-02,  4.2414e-02,  1.2166e-02,\n",
       "                        2.9114e-02, -1.8104e-02, -6.4564e-03, -4.4368e-02,  3.8481e-02,\n",
       "                        4.5094e-03,  2.2196e-03, -2.3948e-02,  5.8125e-04, -2.3675e-03,\n",
       "                        3.8728e-02,  2.1118e-02,  1.7571e-03,  1.7816e-02, -3.6297e-02,\n",
       "                        9.6137e-03, -7.8903e-04,  3.5850e-02, -9.6457e-03, -2.8663e-02,\n",
       "                       -2.8325e-02, -2.7903e-02,  4.3883e-03,  6.3760e-04, -1.2989e-21,\n",
       "                        2.3416e-03,  4.8175e-03, -7.2374e-06, -2.3319e-04, -3.7952e-02,\n",
       "                        4.4198e-23, -1.2660e-02,  3.2243e-02, -1.5444e-02, -2.0811e-04,\n",
       "                       -7.8683e-03, -2.9705e-02, -3.3393e-03,  3.9887e-03, -2.3858e-02,\n",
       "                        4.2822e-02, -3.1511e-02, -2.9862e-02, -2.8330e-02,  2.3886e-02,\n",
       "                       -2.8437e-03,  1.7968e-02,  6.2271e-03, -3.4559e-02,  2.2321e-02,\n",
       "                       -8.0348e-03,  7.9191e-03,  4.8791e-03, -1.9848e-02,  1.3583e-04,\n",
       "                        1.4565e-02,  3.0079e-02,  1.8923e-17,  2.9419e-03, -3.7500e-03,\n",
       "                        3.6784e-02, -1.6348e-02,  2.9025e-02,  1.6867e-03,  3.7324e-04,\n",
       "                       -2.9645e-03,  3.3094e-02,  4.0738e-02,  3.6252e-02, -3.5757e-02,\n",
       "                       -1.6114e-02,  1.1784e-02, -5.8706e-03, -1.6298e-02, -3.5936e-02,\n",
       "                        1.6599e-03,  2.0033e-02,  3.2733e-02, -2.6463e-02,  1.7747e-02,\n",
       "                       -5.5692e-03, -2.1873e-02,  4.5575e-03, -9.7574e-05,  3.1071e-02,\n",
       "                        2.4572e-03, -1.9243e-02,  3.9315e-02, -2.0953e-02, -2.5718e-03,\n",
       "                       -3.0735e-02,  4.6396e-02, -2.9111e-03,  2.4174e-02, -2.2369e-02,\n",
       "                       -2.0285e-02,  3.8740e-02,  2.5452e-02, -3.0551e-02, -2.5050e-02,\n",
       "                        3.6906e-02,  1.8708e-03, -1.0826e-02, -4.0078e-02, -1.6674e-03,\n",
       "                       -2.5414e-02, -3.0117e-02, -5.8480e-04,  1.0952e-02,  1.8164e-02,\n",
       "                       -1.7891e-02,  2.8777e-03,  6.5272e-04, -8.9961e-03, -1.1011e-06,\n",
       "                       -3.7967e-02, -2.4466e-03, -2.9851e-03, -2.1299e-02,  2.5492e-02,\n",
       "                        3.5516e-02,  3.4720e-04,  2.4937e-02,  2.8691e-18, -5.0126e-03,\n",
       "                        3.8441e-02,  1.4758e-02, -1.6606e-02, -1.5617e-02, -1.8634e-03,\n",
       "                       -1.2191e-02,  3.8211e-02,  3.2916e-03,  2.8376e-02, -2.6124e-02,\n",
       "                        1.5724e-02,  1.2779e-10, -3.7347e-03,  2.3775e-02, -1.6062e-02,\n",
       "                       -1.3981e-04,  7.2862e-04, -3.6227e-03,  1.0661e-02, -5.7883e-03,\n",
       "                        7.3168e-04,  3.4703e-02,  4.6457e-02, -3.7531e-02,  7.9994e-04,\n",
       "                        2.0075e-02,  2.0390e-02, -1.7667e-02, -2.5597e-02, -3.2396e-02,\n",
       "                        2.9568e-02, -4.3597e-03, -3.8132e-02,  1.4470e-02, -4.4075e-02,\n",
       "                       -9.9847e-03,  2.1937e-02]])),\n",
       "             ('fc_rank.bias', tensor([-4.6522])),\n",
       "             ('batchnorm.weight',\n",
       "              tensor([ 0.0580,  0.6417,  0.1053,  0.0669,  0.0247,  0.5738,  0.0746,  0.1314,\n",
       "                       0.0539,  0.1331,  0.0517,  0.6082,  0.0514,  0.0576, -0.0304,  0.0092,\n",
       "                       0.1522,  0.0895,  0.4464,  0.1982,  0.0090,  0.0573,  0.0390,  0.0669,\n",
       "                       0.1019,  0.0627,  0.0513,  0.8267,  0.4456,  0.1425,  0.0451,  0.1530,\n",
       "                       0.3552,  0.0914,  0.0516,  0.0611,  0.0454,  0.4073,  0.0844,  0.0371,\n",
       "                       0.7048,  0.0679,  0.0353, -0.0439,  0.0510,  0.2788,  0.0958,  0.0774,\n",
       "                       0.0876,  0.1322,  0.1300, -0.0759,  0.0598,  0.2556, -0.0315,  0.1177,\n",
       "                       0.5484,  0.0662,  0.1746,  0.0619,  0.0951,  0.0612,  0.0708,  0.0919,\n",
       "                       0.0569,  0.0627,  0.0511,  0.3739,  0.1304,  0.1429,  0.1090,  0.1777,\n",
       "                       0.1137,  0.1070,  0.0485,  0.1224,  0.0829, -0.0098,  0.5145,  0.0594,\n",
       "                       0.0279,  0.0453,  0.4685,  0.2026,  0.1836,  0.0853,  0.1480,  0.1128,\n",
       "                       0.2345,  0.0655,  0.0414,  0.0688,  0.1273,  0.1289,  0.0688,  0.3289,\n",
       "                       0.0653,  0.0666,  0.0694,  0.5819,  0.1474,  0.0922,  0.6983,  0.8988,\n",
       "                       0.2289,  0.7163,  0.2284,  0.0392,  0.6593,  0.5719,  0.1270,  0.5095,\n",
       "                       0.0729,  0.1063,  0.0613,  0.1593,  0.0056,  0.0625,  0.1536,  0.0494,\n",
       "                       0.0530,  0.4780,  0.1224,  0.3906,  0.0624,  0.3029,  0.0550,  0.6807,\n",
       "                       0.3894,  0.0506,  0.2342,  0.0908,  0.0613,  0.0658,  0.0476,  0.0712,\n",
       "                       0.2992,  0.1660,  0.2164,  0.0891,  0.1528,  0.0677,  0.1234,  0.1280,\n",
       "                       0.5975,  0.0646,  0.0029, -0.0462,  0.1962,  0.1336,  0.0227,  0.6378,\n",
       "                       0.3962, -0.0460,  0.1817,  0.0760,  0.1423,  0.1126, -0.0336,  0.0878,\n",
       "                       0.0457,  0.0570,  0.1704,  0.1502,  0.1811,  0.0984,  0.1386,  0.0505,\n",
       "                       0.1485,  0.1670,  0.1564,  0.7420,  0.0983,  0.1018,  0.1042,  0.0756,\n",
       "                       0.0727,  0.8130,  0.2809,  0.8033,  0.0538,  0.0691,  0.2735,  0.1591,\n",
       "                       0.3336,  0.1349,  0.8925,  0.0895,  0.0479,  0.0318,  0.1562,  0.7143,\n",
       "                       0.0557,  0.1018,  0.0785,  0.0659,  0.1124,  0.0640,  0.0378,  0.0648,\n",
       "                       0.0865,  0.0938,  0.0927,  0.1293,  0.0797,  0.0680,  0.0872, -0.0423,\n",
       "                       0.3560,  0.0988,  0.0645,  0.6075,  0.2136,  0.0588,  0.0676,  0.0833,\n",
       "                       0.0518, -0.0225,  0.1476,  0.0578,  0.7737,  0.0799,  0.0511,  0.0109,\n",
       "                       0.1299,  0.1240,  0.7321,  0.0841, -0.0486,  0.5149,  0.0900,  0.6660,\n",
       "                       0.1599,  0.4891,  0.0701,  0.0653,  0.0537,  0.0683,  0.0599, -0.0441,\n",
       "                       0.0626,  0.1764,  0.0860,  0.1185,  0.1342, -0.0549,  0.8432,  0.1255,\n",
       "                       0.1097,  0.0363,  0.1003,  0.0601,  0.1040,  0.0653,  0.0728,  0.2229,\n",
       "                       0.0228, -0.0024,  0.1695,  0.0521,  0.0768,  0.4639,  0.0756,  0.6964,\n",
       "                       0.0591,  0.0686, -0.0246,  0.0768,  0.3140,  0.0623,  0.1694,  0.0621,\n",
       "                       0.4386,  0.1884, -0.0181,  0.0659,  0.0742,  0.4199,  0.0731,  0.0513,\n",
       "                       0.0622,  0.1181,  0.3390,  0.2543,  0.2128,  0.0664,  0.3180,  0.0575,\n",
       "                       0.6098,  0.7625,  0.0788,  0.0770,  0.0715,  0.0563,  0.6845,  0.0680,\n",
       "                       0.0772,  0.0286,  0.1525,  0.0639,  0.0212,  0.1773,  0.0905,  0.0602,\n",
       "                       0.0292,  0.1565,  0.0483,  0.0356,  0.2356,  0.0899,  0.0720,  0.4702,\n",
       "                       0.0497,  0.0659,  0.0489,  0.5335,  0.0846,  0.1353,  0.0473,  0.0807,\n",
       "                       0.1171,  0.4957,  0.6054, -0.0088,  0.0547,  0.2337,  0.8549,  0.0728,\n",
       "                       0.2629,  0.1176,  0.0817,  0.1721,  0.0616,  0.1957,  0.1470,  0.2344,\n",
       "                       0.1272,  0.0580,  0.0969,  0.0713,  0.4817,  0.6636,  0.0664,  0.7100,\n",
       "                       0.0623,  0.0939,  0.0972,  0.1392,  0.0479,  0.2200,  0.1031,  0.0736,\n",
       "                       0.0979,  0.0534,  0.0516,  0.2558,  0.1015,  0.0879,  0.0362,  0.0605,\n",
       "                       0.0577,  0.1409,  0.6654,  0.1349,  0.0655,  0.5209,  0.5386,  0.0698,\n",
       "                       0.0876,  0.0506,  0.0691,  0.0549,  0.5807, -0.0275,  0.8512,  0.1182,\n",
       "                       0.2065,  0.0704, -0.0188,  0.0484,  0.6966,  0.0979,  0.0690,  0.5532,\n",
       "                       0.3631,  0.2517,  0.0582,  0.7908,  0.8614,  0.2188,  0.0596,  0.0666,\n",
       "                       0.0603,  0.0737,  0.1128,  0.7022,  0.1586,  0.6990,  0.0664,  0.0873,\n",
       "                       0.0652,  0.4353,  0.6855,  0.0961,  0.7642,  0.1738,  0.0667,  0.5226,\n",
       "                       0.7869,  0.0780,  0.0793,  0.1110,  0.0903,  0.5870,  0.1286,  0.0146,\n",
       "                       0.0858,  0.0590,  0.0902,  0.0467,  0.0834,  0.2000,  0.0644,  0.1224,\n",
       "                       0.0732,  0.3336, -0.0419, -0.0384,  0.0733,  0.7687,  0.3395,  0.0850,\n",
       "                       0.4680,  0.4628,  0.0807,  0.2351,  0.1020,  0.0731,  0.0872,  0.4469,\n",
       "                       0.0632,  0.0604,  0.8270,  0.0701,  0.0857,  0.1128,  0.0613,  0.1085,\n",
       "                       0.0674,  0.0592,  0.0745,  0.4086,  0.0567,  0.0603,  0.6014,  0.0589,\n",
       "                       0.0716,  0.6299,  0.1505,  0.1195,  0.1142,  0.2214,  0.0414,  0.1432,\n",
       "                       0.0153,  0.0513,  0.3617,  0.2474,  0.0943,  0.1014,  0.0750,  0.6004,\n",
       "                       0.1228,  0.7779,  0.5752,  0.0808,  0.2095,  0.0539,  0.1335,  0.3982,\n",
       "                       0.0533,  0.0693,  0.2059,  0.0531,  0.0795,  0.1371,  0.6534,  0.5317,\n",
       "                       0.1084,  0.0475,  0.1067,  0.6424,  0.2577,  0.7509,  0.2337,  0.5041,\n",
       "                       0.0865,  0.0564,  0.0487,  0.2695,  0.4468,  0.1252,  0.1129,  0.0708,\n",
       "                       0.0635,  0.0876,  0.5506,  0.0511,  0.1953,  0.0598,  0.0910,  0.1329])),\n",
       "             ('batchnorm.bias',\n",
       "              tensor([-1.8195e-03, -1.8838e-03, -2.8090e-03, -7.5463e-04, -1.0393e-03,\n",
       "                       5.5506e-03, -3.5568e-03, -4.6174e-03,  6.4714e-04, -2.3292e-03,\n",
       "                      -9.0015e-04, -6.3063e-03,  3.3629e-03, -4.3136e-03,  4.5117e-04,\n",
       "                      -2.5416e-03,  3.3134e-04, -4.0933e-03,  2.0095e-03, -1.1725e-02,\n",
       "                      -8.0679e-03, -4.7196e-03, -1.2185e-03,  1.8469e-03, -1.0136e-03,\n",
       "                      -4.3244e-03, -4.2357e-03,  2.4652e-04,  1.0937e-03,  9.5436e-04,\n",
       "                       3.1627e-03, -2.7453e-03,  4.3532e-03, -2.6108e-03,  6.7849e-04,\n",
       "                      -2.2530e-03,  9.8014e-04, -7.5062e-04, -1.3159e-03,  5.1973e-04,\n",
       "                       1.2511e-03,  5.5726e-04, -3.4345e-04,  1.7597e-03, -1.8906e-03,\n",
       "                       4.9969e-03, -8.2922e-03,  1.9174e-03, -2.5659e-03, -1.0296e-03,\n",
       "                      -3.2080e-03,  2.2814e-03, -4.0150e-03,  3.5236e-03, -6.6973e-04,\n",
       "                       6.5135e-04,  1.3022e-02, -1.3997e-03, -5.3503e-03, -1.4648e-03,\n",
       "                       4.3773e-03, -2.1894e-03, -1.0640e-03,  1.6603e-04, -5.0279e-03,\n",
       "                       4.1285e-04, -2.5183e-03, -3.1683e-03, -4.5054e-03,  5.2206e-03,\n",
       "                       1.4422e-03, -9.8114e-04, -4.2690e-03, -4.1812e-04, -2.5804e-03,\n",
       "                      -4.1913e-03,  1.2863e-03,  4.9785e-03, -5.4067e-03,  6.0544e-04,\n",
       "                       1.6883e-03, -4.3585e-04,  4.2382e-03,  8.8185e-03, -1.2975e-04,\n",
       "                      -7.2790e-04, -1.5941e-03, -2.6520e-03, -1.8961e-02, -2.2863e-03,\n",
       "                      -5.8330e-04, -2.2689e-03, -2.2802e-03, -3.6544e-03,  1.1412e-03,\n",
       "                       2.3883e-03, -9.9573e-04, -6.1800e-04, -2.2603e-03, -1.4275e-19,\n",
       "                       3.2284e-03,  1.7344e-03,  3.5567e-03,  4.3547e-04, -2.1680e-03,\n",
       "                       2.5830e-03, -3.6560e-03, -3.0619e-03, -6.3225e-03, -1.2093e-03,\n",
       "                      -8.3755e-03, -5.2877e-03,  2.0346e-04,  1.8560e-03, -7.7315e-04,\n",
       "                      -5.3240e-03, -2.5875e-03, -2.7925e-03,  2.6176e-03, -1.4528e-03,\n",
       "                      -1.6650e-03, -3.1840e-03, -3.8352e-03, -3.6299e-03, -3.1147e-04,\n",
       "                       7.1700e-03,  4.8760e-04, -2.2541e-03,  2.6562e-03,  8.4822e-04,\n",
       "                      -7.8830e-03, -2.9809e-03, -6.9444e-04, -2.1933e-03, -1.7519e-03,\n",
       "                      -1.9826e-03, -2.6144e-12, -5.6256e-03, -7.3377e-04, -2.6569e-03,\n",
       "                      -3.2721e-03, -9.4056e-04, -1.9142e-03,  2.4879e-04,  8.9927e-04,\n",
       "                      -1.4331e-03,  4.6977e-03,  6.2851e-03, -4.4109e-03, -8.1759e-04,\n",
       "                       2.2311e-03, -4.8004e-03, -4.5358e-03,  1.9352e-03, -4.2971e-03,\n",
       "                       1.7314e-04,  9.5479e-04, -5.4920e-04,  8.6889e-04, -1.9721e-03,\n",
       "                      -1.7253e-04,  4.7741e-03,  3.3243e-03, -9.7999e-04, -8.1366e-03,\n",
       "                      -4.6799e-03, -2.2941e-03,  5.3504e-04, -5.2995e-03,  1.7154e-04,\n",
       "                      -8.3053e-03, -7.2611e-03, -7.7659e-04, -4.2749e-03,  5.8694e-04,\n",
       "                      -5.9901e-04,  3.9655e-04,  2.4273e-03, -2.5358e-03, -2.6050e-04,\n",
       "                      -8.0380e-04,  3.0945e-03, -3.1765e-04, -3.1462e-03,  5.4686e-03,\n",
       "                      -6.1032e-03,  5.4809e-03,  1.9961e-03,  2.4554e-03, -3.9139e-04,\n",
       "                      -2.0546e-03, -5.6256e-08, -4.2915e-04, -9.2118e-04, -4.6704e-03,\n",
       "                      -1.3030e-03, -1.1264e-02, -9.7847e-04,  5.2211e-04,  1.2934e-04,\n",
       "                      -5.1106e-03, -8.0921e-04, -2.9447e-03, -6.4069e-04,  1.1083e-03,\n",
       "                      -2.7143e-03,  7.1255e-03,  9.2282e-04,  3.9142e-03, -2.8913e-03,\n",
       "                      -2.2338e-03, -2.8680e-03, -1.8880e-03, -1.1601e-03,  2.2353e-05,\n",
       "                      -4.4011e-04,  9.1612e-04, -1.0708e-03, -3.4011e-03, -4.3979e-03,\n",
       "                      -3.4620e-10,  8.5111e-04,  3.1073e-03, -1.5483e-03, -5.9683e-03,\n",
       "                       2.4002e-03,  3.9048e-03, -8.3581e-04,  2.5189e-03, -2.7430e-03,\n",
       "                      -2.8961e-03,  2.8218e-03,  4.6227e-03,  3.8869e-04,  1.6410e-03,\n",
       "                      -4.1903e-03,  7.7847e-03, -7.8609e-04, -4.6323e-03,  1.3404e-03,\n",
       "                      -1.3206e-03, -7.9464e-03, -1.6435e-03, -7.1192e-04, -1.9865e-03,\n",
       "                      -6.8963e-04, -1.7741e-03, -2.4760e-03, -2.2196e-03,  9.2947e-04,\n",
       "                       6.6811e-03, -2.7047e-03, -1.3449e-04,  1.0968e-03, -6.0757e-04,\n",
       "                      -5.5624e-03,  1.9240e-03,  1.2084e-15, -7.6989e-03,  5.2953e-04,\n",
       "                      -9.1523e-04, -8.5625e-04,  9.7105e-04,  7.6597e-05, -1.5525e-03,\n",
       "                       2.8585e-03, -6.5714e-03,  9.6428e-04,  3.8026e-03,  1.8713e-04,\n",
       "                      -4.9426e-04,  4.6456e-03,  2.8010e-03, -1.7252e-03,  1.5974e-03,\n",
       "                      -9.3569e-06,  1.4592e-04, -7.9116e-04, -2.8049e-03,  2.1577e-04,\n",
       "                      -5.3665e-04, -2.9005e-04, -1.1694e-03,  1.7493e-03,  6.6435e-03,\n",
       "                      -3.1856e-03, -6.8061e-03,  1.4740e-03,  3.8426e-03,  5.1856e-04,\n",
       "                       1.4340e-03, -1.7359e-04,  1.6627e-03,  6.3251e-04,  1.1619e-02,\n",
       "                      -2.7679e-03, -2.2526e-03, -6.6816e-03, -3.8366e-03, -7.2269e-03,\n",
       "                       4.6487e-03,  3.0929e-03, -5.1326e-04, -3.8228e-03, -2.6373e-03,\n",
       "                      -1.6086e-03, -7.7879e-05, -1.0696e-03,  6.6408e-03, -2.0298e-03,\n",
       "                      -3.6229e-04, -1.1198e-03, -8.4992e-04,  4.1576e-04, -4.1936e-04,\n",
       "                      -2.1572e-20, -2.2018e-03, -1.5650e-03, -1.3482e-03,  2.4700e-04,\n",
       "                      -2.9881e-04, -1.5738e-03,  2.9762e-03,  5.5825e-03,  3.3420e-03,\n",
       "                      -2.3338e-03,  4.1516e-03, -2.6168e-03, -6.1249e-04, -2.0151e-03,\n",
       "                       7.8745e-04, -1.1289e-02, -6.4478e-04, -8.8859e-03, -6.7448e-03,\n",
       "                       5.2551e-03, -1.6691e-03, -1.5412e-03, -9.3816e-04, -1.8227e-03,\n",
       "                      -1.0782e-03,  1.6193e-03,  4.7713e-04, -1.8553e-03, -2.0606e-03,\n",
       "                      -3.5134e-03,  4.4449e-04, -2.5096e-03, -1.0288e-03, -1.0231e-02,\n",
       "                      -3.0835e-03, -1.4250e-03,  5.7764e-03,  4.3151e-04, -1.1788e-03,\n",
       "                       1.9940e-03, -3.8920e-03, -3.0566e-03, -1.1189e-03, -4.4654e-03,\n",
       "                      -3.6451e-03,  4.8841e-05,  8.7019e-03, -4.6222e-03,  2.4392e-04,\n",
       "                      -8.2011e-04,  1.3529e-04, -2.9530e-03, -7.5157e-04,  4.3037e-03,\n",
       "                      -1.3814e-03,  1.1846e-03, -1.8460e-03, -6.6780e-03, -1.2998e-21,\n",
       "                       2.2690e-03, -1.0833e-02, -8.1738e-05,  1.3884e-03, -2.0729e-04,\n",
       "                       4.4453e-23, -1.9758e-04, -2.1159e-03, -6.1175e-05, -3.1398e-03,\n",
       "                      -2.3344e-04, -7.3144e-04, -4.2998e-03, -2.0373e-03,  3.3786e-05,\n",
       "                      -1.7235e-03, -1.4626e-03, -9.3986e-04, -1.4841e-03, -3.9179e-04,\n",
       "                       3.4992e-04, -2.2410e-03, -6.6747e-03,  1.5669e-03, -1.4330e-03,\n",
       "                      -1.0658e-03, -3.6468e-03,  2.5309e-04, -2.3989e-03,  1.3513e-04,\n",
       "                      -6.4654e-03, -3.5738e-03, -2.1465e-18, -3.2855e-03,  7.5407e-04,\n",
       "                      -2.5509e-03,  4.0112e-04, -2.3553e-03, -5.7129e-03,  1.8348e-03,\n",
       "                       2.8336e-03, -4.4287e-03, -1.9368e-03, -2.5843e-03,  3.7003e-04,\n",
       "                      -2.1397e-03, -1.0287e-02, -1.1881e-03,  1.8464e-03, -1.7563e-03,\n",
       "                       9.0541e-03,  2.4071e-03, -1.5411e-03,  3.2280e-04, -1.2775e-03,\n",
       "                      -5.1650e-03,  1.6394e-04, -8.4188e-03, -1.8269e-03, -1.4064e-03,\n",
       "                      -7.5576e-03, -1.4059e-03, -3.6199e-03,  2.2436e-03, -2.1446e-03,\n",
       "                       3.6300e-03, -1.0332e-03, -3.3106e-04, -3.4523e-03,  1.6734e-03,\n",
       "                      -1.9937e-03, -2.1995e-03, -2.4140e-03,  8.4180e-04,  6.1199e-04,\n",
       "                      -1.3193e-03,  7.0333e-03,  5.8094e-04, -1.0536e-04, -6.3984e-04,\n",
       "                       3.0741e-03, -1.7647e-03,  3.0909e-03, -1.0127e-02, -6.4918e-03,\n",
       "                       1.8559e-03,  3.7946e-03,  1.5711e-03,  1.5054e-03, -1.2483e-06,\n",
       "                       1.8196e-03,  1.7646e-03,  6.0758e-03,  9.5896e-04, -4.5090e-03,\n",
       "                      -1.3512e-03,  5.9659e-04, -3.2478e-03, -2.8745e-18,  1.6373e-03,\n",
       "                      -3.5088e-03, -8.3302e-03,  1.3097e-03, -1.5660e-03,  2.6439e-03,\n",
       "                       3.3852e-03, -2.2086e-03, -2.3379e-03,  1.6691e-03, -1.8636e-03,\n",
       "                      -9.8770e-03, -1.2479e-10, -3.0738e-03, -3.8583e-03,  1.6179e-03,\n",
       "                      -2.6826e-04, -6.2093e-03, -3.1663e-03, -6.9150e-04, -5.9368e-03,\n",
       "                      -7.0396e-03, -3.3376e-03, -9.1868e-04, -9.4449e-04,  3.9203e-03,\n",
       "                      -1.5120e-03, -6.0026e-03, -3.4925e-04,  6.5179e-04, -2.3615e-04,\n",
       "                      -2.7707e-03, -1.7929e-03, -6.6388e-04, -7.7983e-03,  2.7694e-04,\n",
       "                       2.0329e-04, -5.0138e-03])),\n",
       "             ('batchnorm.running_mean',\n",
       "              tensor([3.2211e-05, 5.6052e-45, 5.3300e-02, 5.6052e-45, 3.9206e-05, 5.6052e-45,\n",
       "                      4.5151e-01, 8.7379e-02, 1.7585e-01, 1.4060e-02, 1.0505e-02, 1.0855e-16,\n",
       "                      2.0522e-06, 2.7587e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45, 3.0961e+00,\n",
       "                      5.6052e-45, 4.5233e+00, 7.3423e-05, 5.5184e-01, 1.2662e-04, 5.6052e-45,\n",
       "                      4.9924e-01, 4.0045e-06, 1.8564e-01, 5.6052e-45, 1.0495e-11, 1.7964e+00,\n",
       "                      1.5009e+01, 3.6504e-02, 2.5918e-40, 5.1519e-02, 4.5959e-02, 1.2429e-01,\n",
       "                      3.5063e-13, 5.6052e-45, 3.2889e-02, 4.4593e-04, 5.6052e-45, 3.1850e-04,\n",
       "                      5.7795e-10, 4.5348e+00, 5.6052e-45, 4.3224e-39, 3.3186e+00, 5.0192e-01,\n",
       "                      2.9646e-02, 3.4109e-01, 1.5534e-01, 1.6120e-30, 2.9170e-01, 5.6052e-45,\n",
       "                      6.7341e-05, 9.5224e-01, 5.6052e-45, 8.6420e-10, 2.5882e-02, 5.1756e-02,\n",
       "                      5.6052e-45, 1.1389e+00, 5.4623e-02, 9.3623e-02, 6.2883e-01, 5.5201e-06,\n",
       "                      8.3785e-01, 5.6052e-45, 6.3745e-02, 1.6414e+00, 5.8875e+00, 5.6052e-45,\n",
       "                      1.2493e-01, 1.9763e-02, 5.6052e-45, 7.8611e-02, 1.0542e-01, 5.7089e-11,\n",
       "                      5.6052e-45, 8.5827e-01, 2.4314e-05, 1.3527e-01, 5.6052e-45, 9.2838e-40,\n",
       "                      1.5610e-04, 9.4185e-02, 5.9519e-01, 8.2232e-02, 2.1361e-01, 2.5380e-02,\n",
       "                      5.6052e-45, 4.8823e-24, 1.0096e-01, 5.6634e-01, 8.1874e+00, 5.6052e-45,\n",
       "                      1.3910e-02, 4.2392e-02, 1.3182e-01, 5.6052e-45, 5.6052e-45, 4.1442e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6580e-07, 4.7518e-02, 2.1751e-06,\n",
       "                      5.6052e-45, 2.0818e-11, 2.0501e-01, 5.6052e-45, 1.2325e+00, 1.7790e+00,\n",
       "                      1.1284e-02, 3.4818e-02, 5.6052e-45, 9.8489e-03, 1.2409e+00, 1.2099e-01,\n",
       "                      6.3305e-02, 5.6052e-45, 4.7582e-01, 5.6052e-45, 2.9632e-02, 5.6052e-45,\n",
       "                      4.7591e-03, 1.7056e-08, 5.6052e-45, 4.5095e-02, 4.4399e-02, 1.5502e-02,\n",
       "                      2.9904e-02, 2.4082e+00, 1.3498e-02, 1.8450e+00, 5.6052e-45, 3.3550e-02,\n",
       "                      5.6052e-45, 2.3840e-02, 4.9016e-02, 6.2547e-01, 4.8076e-02, 1.0468e+00,\n",
       "                      5.6052e-45, 2.1013e-01, 2.4910e-28, 5.6052e-45, 5.6052e-45, 5.9467e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 4.4529e+00, 7.4962e-02, 8.6637e-01,\n",
       "                      5.6052e-45, 4.2045e-02, 3.8316e-05, 1.1434e-01, 2.9699e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 3.6524e-01, 2.1508e-02, 2.1763e+00, 2.5127e-02, 6.4232e-02,\n",
       "                      1.5189e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45, 1.0104e-01, 2.6403e-02,\n",
       "                      4.4229e-02, 1.8419e-29, 2.5149e-02, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      7.9807e-02, 1.6394e+01, 6.3971e-09, 5.1197e-02, 1.1103e-11, 4.8322e-02,\n",
       "                      5.6052e-45, 5.6052e-45, 6.6920e-01, 3.1601e-04, 6.6018e-01, 5.6052e-45,\n",
       "                      3.7462e-02, 2.4354e-02, 4.9765e-01, 1.1179e-01, 5.6052e-45, 1.8871e-02,\n",
       "                      2.4216e-04, 2.1947e-02, 1.1235e-01, 2.6845e-02, 3.7592e-02, 3.1924e-02,\n",
       "                      7.8426e-01, 1.1129e-02, 5.6052e-45, 7.5600e-05, 1.2955e-05, 3.4879e-02,\n",
       "                      4.7153e-01, 5.6052e-45, 1.1596e-29, 2.0001e-02, 4.1703e-01, 8.3706e-05,\n",
       "                      5.1441e+00, 5.6266e-06, 5.4189e-02, 5.5419e-01, 5.6052e-45, 4.5507e+00,\n",
       "                      1.1977e+01, 1.8124e-21, 5.6052e-45, 1.2080e+00, 5.6052e-45, 5.0839e-02,\n",
       "                      5.6648e-01, 5.6052e-45, 3.2098e-02, 5.6052e-45, 6.3499e-37, 5.6052e-45,\n",
       "                      3.2651e-01, 3.0585e-01, 5.6052e-45, 4.7201e-02, 4.7506e-01, 8.3733e-07,\n",
       "                      6.0203e-02, 2.7763e-01, 1.2976e-15, 1.8847e-01, 2.0586e-01, 3.6740e-02,\n",
       "                      5.6052e-45, 3.2210e-02, 3.1402e-02, 2.7027e+00, 2.0565e-27, 3.6131e-01,\n",
       "                      5.6052e-45, 7.2691e+00, 7.3023e-02, 3.1251e-02, 5.6052e-45, 5.6052e-45,\n",
       "                      1.8206e-01, 1.4706e-02, 5.6052e-45, 5.6052e-45, 5.5270e+00, 5.6052e-45,\n",
       "                      4.8211e-02, 1.3022e+00, 4.6762e-28, 8.5609e-01, 5.6052e-45, 1.3089e+01,\n",
       "                      4.3258e-02, 1.4717e-12, 2.3705e-28, 5.6052e-45, 2.1481e-04, 5.7682e-02,\n",
       "                      4.2887e-02, 5.6052e-45, 4.7047e-02, 5.6052e-45, 5.1723e-02, 2.3481e-01,\n",
       "                      5.6052e-45, 5.8951e-05, 5.6052e-45, 5.1686e-07, 5.6052e-45, 1.5148e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 1.9772e+00, 2.2611e-02, 6.0425e-02, 4.8770e-02,\n",
       "                      5.6052e-45, 5.4228e-01, 4.6846e-02, 5.6052e-45, 3.8368e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.3805e+00, 5.6052e-45, 5.6052e-45, 3.1923e-02,\n",
       "                      1.0867e-01, 3.3537e-11, 5.6052e-45, 5.2999e-02, 4.4572e-02, 5.6052e-45,\n",
       "                      8.8712e-12, 2.4745e+00, 1.1466e-01, 5.6052e-45, 4.8497e-01, 5.5271e-01,\n",
       "                      1.2647e+00, 4.3407e-01, 9.7563e-02, 5.6052e-45, 5.6052e-45, 1.0447e-03,\n",
       "                      5.9325e+00, 5.6052e-45, 5.6052e-45, 7.6632e-02, 5.6052e-45, 2.9223e-02,\n",
       "                      6.3880e-02, 5.6413e+00, 6.6653e-02, 4.0558e-01, 6.6353e-02, 4.6569e-21,\n",
       "                      2.3751e-02, 4.8884e-02, 8.9846e-01, 4.5011e-02, 6.2448e-28, 5.6052e-45,\n",
       "                      3.2421e-03, 5.6052e-45, 3.6121e-02, 2.5027e-02, 5.6052e-45, 3.4332e-02,\n",
       "                      2.4108e-01, 1.2664e-01, 4.9993e-02, 1.4979e-01, 5.6052e-45, 2.5578e-02,\n",
       "                      9.5001e-02, 5.6052e-45, 2.6195e-05, 1.4619e-01, 5.6052e-45, 3.6376e-28,\n",
       "                      3.3623e-01, 1.9979e-02, 5.6052e-45, 4.4094e-02, 6.1168e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 1.1265e-01, 1.2014e-11, 1.3828e+01, 6.1871e-02, 2.5299e-02,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 3.1909e-02, 5.6052e-45, 3.6376e-05, 7.8692e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.8724e-02, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      3.7861e-02, 1.4130e-01, 5.0929e-02, 4.8342e-02, 2.6020e-02, 5.6052e-45,\n",
       "                      7.8850e-02, 3.1000e-28, 2.7152e-02, 5.1514e-02, 2.2370e-10, 1.2450e-38,\n",
       "                      5.6052e-45, 1.3464e-01, 5.6052e-45, 1.5394e-01, 4.8593e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.1093e-01, 4.4436e-01, 1.3525e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.2256e-22, 5.5711e-02, 2.5688e-02, 3.8738e-03, 2.2136e-02,\n",
       "                      1.2690e-05, 3.9418e-02, 5.6833e-28, 2.0778e-01, 2.6375e-02, 1.8933e-39,\n",
       "                      8.1854e-06, 4.3775e+00, 1.7432e-02, 5.6052e-45, 7.5361e-39, 2.1043e-01,\n",
       "                      5.6052e-45, 1.1146e-38, 1.4225e-01, 5.6052e-45, 1.3228e-01, 6.6211e-02,\n",
       "                      1.6326e+00, 5.6052e-45, 9.4454e-01, 3.1635e-02, 5.6052e-45, 4.0909e+00,\n",
       "                      8.6794e-01, 1.0765e-01, 3.4152e-02, 9.0450e-02, 1.6655e-02, 7.8827e+00,\n",
       "                      3.0162e-02, 5.6052e-45, 6.6550e-27, 1.5280e-02, 4.4874e-14, 1.2084e+01,\n",
       "                      5.1285e-02, 5.6052e-45, 2.4135e-01, 2.5116e-01, 6.2627e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 2.0958e-17, 5.6052e-45, 8.3218e-02, 4.2238e-06, 5.6052e-45,\n",
       "                      7.1840e-01, 5.6127e-01, 2.5887e-02, 5.6052e-45, 2.4725e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 3.2416e-02, 6.4210e-02, 1.5288e-13, 3.2610e-01, 5.6052e-45,\n",
       "                      4.4032e-07, 4.0128e-02, 5.6052e-45, 6.7327e-01, 6.3849e-02, 1.5304e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 2.5789e-02, 6.3811e-04, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 2.0992e-11, 5.6052e-45, 6.9159e-02, 3.7846e-02,\n",
       "                      3.6520e-02, 5.6052e-45, 5.6052e-45, 1.8496e-01, 5.0906e-01, 1.9104e+00,\n",
       "                      8.8357e-02, 4.1406e-02, 5.6052e-45, 7.7524e-02, 3.8921e-02, 1.3101e-02,\n",
       "                      6.5994e-07, 6.1717e-02])),\n",
       "             ('batchnorm.running_var',\n",
       "              tensor([2.8534e-05, 5.6052e-45, 3.1291e-01, 5.6052e-45, 1.3180e-04, 5.6052e-45,\n",
       "                      3.1774e+00, 5.1336e-01, 1.3210e+00, 7.9538e-02, 5.9436e-02, 4.7444e-17,\n",
       "                      8.5697e-06, 2.0554e+00, 5.6052e-45, 5.6052e-45, 5.6052e-45, 2.3637e+01,\n",
       "                      5.6052e-45, 4.2685e+01, 5.1885e-04, 4.6889e+00, 2.5139e-04, 5.6052e-45,\n",
       "                      3.2315e+00, 9.3859e-06, 1.4858e+00, 5.6052e-45, 9.2634e-12, 1.1517e+01,\n",
       "                      1.1194e+02, 2.4848e-01, 2.1391e-40, 2.8521e-01, 2.2678e-01, 7.3005e-01,\n",
       "                      1.9893e-12, 5.6052e-45, 1.8221e-01, 8.4606e-04, 5.6052e-45, 6.3332e-04,\n",
       "                      3.3111e-10, 4.5585e+01, 5.6052e-45, 4.1426e-39, 4.1579e+01, 2.3937e+00,\n",
       "                      1.4053e-01, 1.7137e+00, 9.6609e-01, 1.5993e-30, 2.2200e+00, 5.6052e-45,\n",
       "                      3.9321e-04, 5.4693e+00, 5.6052e-45, 1.3681e-08, 1.4900e-01, 2.8671e-01,\n",
       "                      5.6052e-45, 9.1419e+00, 2.3104e-01, 6.1865e-01, 5.5467e+00, 9.7955e-06,\n",
       "                      6.9150e+00, 5.6052e-45, 3.8627e-01, 1.0929e+01, 3.5723e+01, 5.6052e-45,\n",
       "                      6.8585e-01, 9.5252e-02, 5.6052e-45, 3.4145e-01, 4.4504e-01, 1.3140e-10,\n",
       "                      5.6052e-45, 4.2689e+00, 6.0926e-05, 7.3357e-01, 5.6052e-45, 1.5479e-40,\n",
       "                      1.4806e-04, 5.0665e-01, 3.1883e+00, 3.9208e-01, 1.5661e+00, 1.4754e-01,\n",
       "                      5.6052e-45, 4.3723e-23, 5.1124e-01, 3.0463e+00, 5.1757e+01, 5.6052e-45,\n",
       "                      7.6496e-02, 1.9808e-01, 9.0947e-01, 5.6052e-45, 5.6052e-45, 2.3077e+00,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 1.7092e-06, 3.3416e-01, 9.3153e-06,\n",
       "                      5.6052e-45, 3.6449e-11, 1.4412e+00, 5.6052e-45, 8.2004e+00, 1.1009e+01,\n",
       "                      6.5778e-02, 1.8589e-01, 5.6052e-45, 8.6292e-02, 7.2417e+00, 6.8456e-01,\n",
       "                      4.8658e-01, 5.6052e-45, 2.8507e+00, 5.6052e-45, 1.5224e-01, 5.6052e-45,\n",
       "                      4.9186e-02, 1.8020e-08, 5.6052e-45, 2.9937e-01, 2.2093e-01, 8.3692e-02,\n",
       "                      1.6926e-01, 1.6884e+01, 8.9263e-02, 1.7116e+01, 5.6052e-45, 1.6227e-01,\n",
       "                      5.6052e-45, 1.1581e-01, 2.0298e-01, 3.7076e+00, 2.8149e-01, 7.0466e+00,\n",
       "                      5.6052e-45, 1.4075e+00, 1.5497e-28, 5.6052e-45, 5.6052e-45, 3.0157e+00,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.8520e+01, 4.6144e-01, 4.9689e+00,\n",
       "                      5.6052e-45, 2.1622e-01, 6.5977e-05, 5.4834e-01, 1.7180e+00, 5.6052e-45,\n",
       "                      5.6052e-45, 2.2683e+00, 9.0879e-02, 2.0862e+01, 1.4426e-01, 4.0787e-01,\n",
       "                      7.7020e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.3073e-01, 1.7329e-01,\n",
       "                      2.2264e-01, 1.9079e-29, 1.9623e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      4.9743e-01, 1.2669e+02, 4.0565e-08, 3.5746e-01, 1.0368e-11, 2.3827e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 2.8638e+00, 3.0471e-03, 3.5071e+00, 5.6052e-45,\n",
       "                      2.1762e-01, 1.4094e-01, 4.1792e+00, 6.3451e-01, 5.6052e-45, 9.9053e-02,\n",
       "                      5.0573e-04, 1.2919e-01, 6.9798e-01, 1.3660e-01, 3.1685e-01, 1.4087e-01,\n",
       "                      4.8720e+00, 9.6167e-02, 5.6052e-45, 1.5723e-04, 5.8777e-05, 2.2782e-01,\n",
       "                      3.7036e+00, 5.6052e-45, 4.8870e-30, 8.4423e-02, 2.6621e+00, 2.5487e-04,\n",
       "                      4.3121e+01, 1.1257e-05, 3.6340e-01, 4.3134e+00, 5.6052e-45, 2.8209e+01,\n",
       "                      8.0954e+01, 4.4059e-22, 5.6052e-45, 7.1036e+00, 5.6052e-45, 3.7277e-01,\n",
       "                      4.9073e+00, 5.6052e-45, 2.0798e-01, 5.6052e-45, 1.1009e-36, 5.6052e-45,\n",
       "                      1.7495e+00, 2.8527e+00, 5.6052e-45, 2.6696e-01, 3.7668e+00, 9.2899e-07,\n",
       "                      3.8827e-01, 2.3922e+00, 2.7043e-15, 1.0922e+00, 1.0776e+00, 1.9606e-01,\n",
       "                      5.6052e-45, 1.4064e-01, 1.8115e-01, 7.1792e+00, 1.4903e-27, 4.0449e+00,\n",
       "                      5.6052e-45, 5.9102e+01, 4.8725e-01, 1.3780e-01, 5.6052e-45, 5.6052e-45,\n",
       "                      9.6272e-01, 1.0381e-01, 5.6052e-45, 5.6052e-45, 4.4634e+01, 5.6052e-45,\n",
       "                      2.6712e-01, 8.0564e+00, 5.4543e-28, 5.2527e+00, 5.6052e-45, 8.9158e+01,\n",
       "                      2.1716e-01, 1.3276e-12, 1.4034e-28, 5.6052e-45, 7.8540e-04, 2.5277e-01,\n",
       "                      2.8299e-01, 5.6052e-45, 2.6961e-01, 5.6052e-45, 2.6564e-01, 1.4034e+00,\n",
       "                      5.6052e-45, 1.9267e-04, 5.6052e-45, 6.0370e-07, 5.6052e-45, 8.8335e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 1.3859e+01, 1.6462e-01, 3.5435e-01, 2.5807e-01,\n",
       "                      5.6052e-45, 3.8674e+00, 2.6405e-01, 5.6052e-45, 1.9853e+00, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 7.4056e+00, 5.6052e-45, 5.6052e-45, 1.9965e-01,\n",
       "                      6.8956e-01, 8.0746e-11, 5.6052e-45, 2.1985e-01, 2.8354e-01, 5.6052e-45,\n",
       "                      2.4106e-11, 1.8410e+01, 9.4397e-01, 5.6052e-45, 3.6944e+00, 3.3474e+00,\n",
       "                      1.1589e+01, 2.9441e+00, 5.3544e-01, 5.6052e-45, 5.6052e-45, 4.6153e-03,\n",
       "                      4.5649e+01, 5.6052e-45, 5.6052e-45, 3.6570e-01, 5.6052e-45, 1.2720e-01,\n",
       "                      4.2688e-01, 5.0448e+01, 4.1129e-01, 3.4746e+00, 3.9449e-01, 1.0299e-20,\n",
       "                      1.3387e-01, 2.4582e-01, 5.5301e+00, 3.3614e-01, 9.7396e-28, 5.6052e-45,\n",
       "                      2.9873e-02, 5.6052e-45, 2.4052e-01, 2.1368e-01, 5.6052e-45, 1.5769e-01,\n",
       "                      1.5211e+00, 5.9584e-01, 2.5166e-01, 6.5549e-01, 5.6052e-45, 1.4049e-01,\n",
       "                      6.5774e-01, 5.6052e-45, 6.5360e-05, 8.1513e-01, 5.6052e-45, 3.3048e-28,\n",
       "                      2.9290e+00, 9.7488e-02, 5.6052e-45, 2.2622e-01, 3.8270e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 7.4297e-01, 4.8802e-12, 9.2236e+01, 3.5912e-01, 1.2881e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 2.0848e-01, 5.6052e-45, 4.1148e-05, 4.9279e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.2777e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      2.8828e-01, 7.9913e-01, 3.1760e-01, 2.1687e-01, 1.4687e-01, 5.6052e-45,\n",
       "                      3.5505e-01, 2.4002e-28, 1.6100e-01, 2.9796e-01, 9.1675e-10, 3.4369e-38,\n",
       "                      5.6052e-45, 6.1168e-01, 5.6052e-45, 9.7859e-01, 3.7303e+00, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 6.8292e-01, 3.0755e+00, 9.7755e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 6.9986e-22, 3.0300e-01, 1.6659e-01, 3.8257e-02, 1.5880e-01,\n",
       "                      4.5371e-06, 1.9666e-01, 8.0670e-28, 1.0744e+00, 1.3058e-01, 6.4380e-40,\n",
       "                      4.0752e-07, 2.3089e+01, 7.8448e-02, 5.6052e-45, 1.2592e-38, 1.1780e+00,\n",
       "                      5.6052e-45, 2.7544e-38, 8.6012e-01, 5.6052e-45, 8.7330e-01, 3.7217e-01,\n",
       "                      1.2853e+01, 5.6052e-45, 6.0468e+00, 2.1921e-01, 5.6052e-45, 3.7250e+01,\n",
       "                      6.0316e+00, 6.0223e-01, 2.2649e-01, 5.3216e-01, 8.7062e-02, 7.5514e+01,\n",
       "                      1.7818e-01, 5.6052e-45, 1.0489e-26, 8.0094e-02, 7.5148e-14, 8.4594e+01,\n",
       "                      2.7736e-01, 5.6052e-45, 1.7774e+00, 2.1512e+00, 3.3427e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 1.1104e-17, 5.6052e-45, 3.9417e-01, 6.2484e-06, 5.6052e-45,\n",
       "                      4.2114e+00, 4.8074e+00, 1.2927e-01, 5.6052e-45, 1.3594e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 2.2698e-01, 3.3126e-01, 3.3822e-13, 1.7253e+00, 5.6052e-45,\n",
       "                      9.0017e-07, 2.6023e-01, 5.6052e-45, 3.4991e+00, 3.8097e-01, 1.1273e+00,\n",
       "                      5.6052e-45, 5.6052e-45, 1.3167e-01, 2.4766e-03, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 3.7061e-11, 5.6052e-45, 4.4467e-01, 1.9664e-01,\n",
       "                      2.6126e-01, 5.6052e-45, 5.6052e-45, 1.0565e+00, 2.8277e+00, 1.2307e+01,\n",
       "                      5.1082e-01, 2.1219e-01, 5.6052e-45, 4.8630e-01, 1.8863e-01, 5.5108e-02,\n",
       "                      5.7147e-07, 3.0761e-01])),\n",
       "             ('batchnorm.num_batches_tracked', tensor(64630))])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### frequency mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_with_frequency_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, cfg):\n",
    "    fr_vocab = len(training_corpus_dct.token2id)\n",
    "    \n",
    "    emb_en = model_en.state_dict()[\"embedding.weight\"]\n",
    "    emb_fr = torch.zeros((fr_vocab, cfg.WORD_EMB_SIZE))\n",
    "    \n",
    "    freq_list_fr = vocab_list_sorted_by_freq(training_corpus_dct.dfs)\n",
    "    freq_list_en = vocab_list_sorted_by_freq(training_corpus_dct_en.dfs)\n",
    "    \n",
    "    for i in range(fr_vocab):\n",
    "        emb_fr[freq_list_fr[i][0],:] = emb_en[freq_list_en[i][0],:]\n",
    "\n",
    "    model_dict.update({\"embedding.weight\":emb_fr}) \n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_with_frequency_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, cfg)\n",
    "mapping_method_name = 'frequency-mapping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[ 1.3175,  1.0528,  0.5883,  ..., -1.1466, -1.3102, -0.8317],\n",
       "                      [ 0.3094, -0.1517, -0.6532,  ..., -0.7903, -0.3482,  1.2893],\n",
       "                      [-0.2944,  0.5825, -0.0491,  ..., -1.7214, -0.8061, -0.4443],\n",
       "                      ...,\n",
       "                      [ 0.5979,  0.1612,  0.1444,  ...,  1.5991,  0.0714, -0.3345],\n",
       "                      [ 0.0619, -1.5072, -1.0641,  ...,  1.3852,  0.5280,  0.1745],\n",
       "                      [-1.5339, -0.4095, -0.4112,  ...,  0.5635,  1.0083, -0.6595]])),\n",
       "             ('lstm.weight_ih_l0',\n",
       "              tensor([[-8.2271e-02, -2.6502e-02,  1.3620e-01,  ...,  1.7146e-01,\n",
       "                        1.5154e-01, -8.0110e-02],\n",
       "                      [-1.4765e-01,  7.7709e-02, -4.5470e-02,  ..., -1.7563e-01,\n",
       "                       -5.4936e-02,  1.5066e-01],\n",
       "                      [ 1.1844e-01,  5.8075e-03,  1.9253e-04,  ...,  9.0586e-02,\n",
       "                       -1.2200e-01,  2.1301e-02],\n",
       "                      ...,\n",
       "                      [ 3.5888e-01, -8.1858e-02, -6.5284e-02,  ..., -4.0579e-02,\n",
       "                        2.4097e-02,  2.1075e-01],\n",
       "                      [ 1.1874e-01,  2.2968e-01,  1.1914e-01,  ..., -1.8865e-03,\n",
       "                       -2.9639e-01, -2.0719e-01],\n",
       "                      [ 1.2594e-01, -1.1320e-01,  1.0662e-01,  ...,  7.6919e-02,\n",
       "                       -1.1031e-01, -9.1731e-02]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[ 0.2194,  0.1908, -0.0803,  ...,  0.1767,  0.0452, -0.0051],\n",
       "                      [-0.1178, -0.1192,  0.1934,  ...,  0.0464, -0.2070, -0.3033],\n",
       "                      [ 0.0826, -0.0236, -0.0321,  ..., -0.0195, -0.1177,  0.0623],\n",
       "                      ...,\n",
       "                      [ 0.1186, -0.0156,  0.1487,  ...,  0.0937,  0.0233, -0.1020],\n",
       "                      [ 0.0175, -0.0755, -0.0923,  ..., -0.0776, -0.0231,  0.0331],\n",
       "                      [ 0.0695,  0.0480,  0.1871,  ...,  0.0549, -0.2409,  0.2596]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([0.2554, 0.1750, 0.0706,  ..., 0.1238, 0.2089, 0.0962])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([0.2048, 0.2110, 0.0321,  ..., 0.0843, 0.1780, 0.0777])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-1.3531e-02, -1.1848e-01,  1.2078e-02,  ...,  2.8935e-01,\n",
       "                        5.2006e-01,  1.3240e-01],\n",
       "                      [ 5.1532e-02, -5.1827e-02, -8.8378e-02,  ...,  7.9595e-04,\n",
       "                        2.6064e-01,  2.3051e-01],\n",
       "                      [-3.1399e-04,  4.0559e-02, -1.6089e-01,  ...,  2.8618e-01,\n",
       "                       -4.5120e-01,  1.2146e-01],\n",
       "                      ...,\n",
       "                      [ 1.7859e-02, -1.3444e-01, -4.4722e-02,  ..., -2.1683e-02,\n",
       "                       -1.5643e-01,  1.1762e-01],\n",
       "                      [ 4.5331e-03,  3.3103e-02, -4.3278e-02,  ...,  7.6261e-02,\n",
       "                        5.4129e-02,  1.4174e-01],\n",
       "                      [ 2.8152e-02,  3.0245e-02,  5.5006e-02,  ...,  2.0770e-02,\n",
       "                        2.2741e-02, -4.4565e-02]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-1.5350e-01, -1.3668e-01, -1.7624e-01, -1.8935e-01,  4.4374e-02,\n",
       "                       5.8577e-02, -1.6065e-01, -1.3972e-01, -1.4403e-01, -1.8469e-01,\n",
       "                      -1.7393e-01,  2.5929e-03, -2.1059e-01, -2.6876e-03, -5.4330e-02,\n",
       "                      -5.5322e-02,  7.5502e-03, -1.1710e-01, -7.7378e-02, -7.4364e-02,\n",
       "                      -8.0652e-02, -6.1286e-02,  1.8424e-02,  2.5973e-02, -1.6902e-01,\n",
       "                      -3.1871e-02, -7.2310e-02, -1.6188e-01,  8.7697e-03, -1.5675e-01,\n",
       "                      -3.2950e-02, -2.2285e-02, -3.0631e-02, -1.5788e-01, -1.6293e-01,\n",
       "                      -1.7604e-01, -1.5516e-01, -5.1527e-02, -2.7132e-02, -1.3193e-02,\n",
       "                       1.6449e-02, -1.9822e-01, -1.5373e-01, -2.0102e-01, -1.9324e-01,\n",
       "                      -1.4015e-01, -2.2384e-01, -1.5826e-01, -1.2310e-01, -1.3940e-01,\n",
       "                      -5.6517e-01, -3.9108e-02, -1.6601e-01, -1.8011e-01,  2.5789e-03,\n",
       "                      -2.7699e-01, -1.5704e-01,  4.3695e-02, -2.4958e-01, -1.5977e-01,\n",
       "                      -1.6518e-01, -1.5995e-02, -1.2427e-02, -2.7229e-01, -4.4743e-02,\n",
       "                       4.5488e-02, -2.2504e-02, -1.4278e-01, -2.2279e-01, -3.7095e-03,\n",
       "                       8.9180e-03, -1.6039e-01, -1.7843e-02, -1.4495e-01, -3.2041e-02,\n",
       "                      -2.2840e-01, -2.2018e-01, -6.4286e-02, -2.3452e-01, -4.5656e-02,\n",
       "                      -5.4573e-02, -7.9613e-02, -8.2687e-02, -1.7561e-01, -1.7136e-01,\n",
       "                      -1.6650e-01, -1.5505e-01, -1.3681e-01, -1.1172e-01, -1.7471e-01,\n",
       "                      -1.8406e-01, -1.6769e-01, -1.9988e-01, -1.6463e-01, -1.5199e-01,\n",
       "                      -1.5894e-01, -1.2147e-01, -1.9045e-01, -1.8264e-01, -2.2107e-02,\n",
       "                      -1.9796e-01, -1.8601e-01, -2.0958e-01, -2.4878e-01, -2.8161e-02,\n",
       "                      -2.9271e-02, -6.4088e-02, -6.6982e-02,  4.3636e-03, -1.1936e-01,\n",
       "                      -1.5312e-01, -1.8285e-01, -7.2093e-02, -1.9254e-01, -1.5900e-01,\n",
       "                      -4.1352e-02, -2.0361e-01,  9.8274e-03, -2.5661e-02, -1.8314e-01,\n",
       "                       4.2460e-03, -4.7761e-01, -2.1031e-01, -5.3291e-02, -1.5485e-01,\n",
       "                      -1.5944e-01, -1.3236e-02, -5.8721e-02, -2.6642e-01, -1.4322e-01,\n",
       "                      -1.8556e-01, -2.2713e-01, -2.2515e-01, -3.5318e-02, -2.0136e-01,\n",
       "                      -8.6484e-02, -4.5261e-02, -1.7719e-01, -1.5194e-01, -8.1825e-02,\n",
       "                       6.1066e-02, -1.6875e-02, -1.0634e-01, -1.6235e-01, -3.1741e-02,\n",
       "                      -1.3256e-01, -1.8511e-01, -1.4524e-01, -2.1996e-01, -1.7203e-01,\n",
       "                      -1.5576e-01, -1.9460e-01, -2.1659e-01, -3.3081e-02, -1.4922e-01,\n",
       "                      -1.2643e-01, -1.8405e-02, -5.0146e-02, -1.3206e-01, -1.5229e-01,\n",
       "                      -2.0343e-01, -1.0132e-02, -5.0761e-02, -1.9917e-01,  3.0647e-03,\n",
       "                      -1.5031e-01, -2.4015e-01, -2.1951e-01, -2.9014e-02, -1.7570e-01,\n",
       "                      -1.6064e-01, -3.5808e-02, -1.5673e-01, -7.4531e-03, -1.2216e-01,\n",
       "                      -9.9012e-03, -4.6705e-02, -5.3088e-02, -9.4061e-02, -1.6952e-01,\n",
       "                      -6.8211e-02, -3.2472e-02, -1.7722e-01, -2.1944e-02, -3.5439e-01,\n",
       "                      -2.0666e-01, -1.8383e-01, -3.0936e-02,  3.3983e-02, -1.3386e-01,\n",
       "                       1.6573e-02, -4.3322e-02, -3.9792e-02, -2.1269e-01, -1.3534e-01,\n",
       "                      -2.2193e-01, -1.4627e-01, -1.5101e-01,  1.0130e-02,  8.6656e-02,\n",
       "                      -6.9502e-03, -3.1144e-02, -8.6167e-02, -3.1939e-02, -5.6254e-02,\n",
       "                      -4.6560e-02, -1.3873e-01, -1.6216e-01, -3.0098e-01, -2.1927e-01,\n",
       "                      -2.8719e-02, -2.0693e-01, -1.7085e-01, -2.0240e-01, -1.2623e-01,\n",
       "                      -8.2035e-02, -3.2232e-02, -2.6725e-01, -5.1466e-02, -4.8037e-02,\n",
       "                       1.2979e-02, -5.1403e-02, -5.1205e-01, -2.6405e-02, -1.6406e-01,\n",
       "                      -2.7590e-02, -3.1509e-02, -1.7123e-01, -1.5869e-01, -5.7678e-03,\n",
       "                      -4.2869e-02, -9.8121e-02, -9.5176e-02, -3.0344e-02, -1.8964e-02,\n",
       "                       2.4364e-02, -2.3356e-01, -3.2238e-02,  2.8267e-02, -1.9834e-01,\n",
       "                      -1.4597e-01, -1.4741e-01, -1.8411e-01, -1.2850e-02, -8.1743e-02,\n",
       "                      -4.0142e-02, -2.7927e-02, -2.9763e-02, -6.7642e-02, -6.5575e-02,\n",
       "                      -3.9042e-02, -2.2050e-01, -2.0642e-01, -2.7809e-02, -6.0581e-02,\n",
       "                      -1.0567e-01, -3.4514e-02, -9.3806e-03, -2.2648e-02, -2.5527e-01,\n",
       "                      -1.6970e-01, -1.5409e-01, -1.7265e-01, -1.9450e-01, -5.4704e-03,\n",
       "                      -1.4139e-01, -1.3742e-02, -1.3672e-02, -8.5522e-03, -2.2822e-01,\n",
       "                      -3.4118e-02, -7.3435e-02, -6.1664e-02, -1.7495e-01,  5.8636e-03,\n",
       "                      -2.1599e-02, -6.0500e-02, -1.5697e-01, -3.2492e-02, -3.1032e-02,\n",
       "                      -2.0304e-02, -1.8507e-01, -9.3517e-02, -1.7981e-01, -3.4291e-02,\n",
       "                      -1.8027e-01, -2.4442e-02,  1.0088e-01, -1.0068e-02, -2.0641e-01,\n",
       "                      -2.5418e-01, -3.0785e-01, -2.1228e-01, -3.8926e-02, -2.6811e-02,\n",
       "                      -3.2785e-02, -1.9086e-01, -1.3167e-02, -2.0831e-01, -1.5578e-01,\n",
       "                      -2.3053e-01, -1.5561e-01,  5.4110e-02,  8.7048e-02, -1.2492e-01,\n",
       "                      -2.1152e-01, -5.4741e-02, -5.1655e-02, -3.4360e-02, -2.4845e-01,\n",
       "                      -1.7250e-01,  1.1089e-02, -1.5379e-02, -2.1278e-01,  4.4422e-02,\n",
       "                      -1.8561e-01, -1.8226e-01, -2.8930e-02, -1.8159e-02, -4.2032e-02,\n",
       "                      -4.0426e-02, -5.9784e-02, -4.8985e-02, -1.0157e-01, -8.8918e-02,\n",
       "                      -2.4865e-01, -1.1871e-01,  1.3418e-01, -3.9417e-02, -2.3168e-02,\n",
       "                      -1.3263e-02, -4.1198e-02, -5.0836e-02, -5.2208e-02, -1.5311e-01,\n",
       "                      -2.5401e-02, -3.3811e-02, -1.0450e-01, -1.7397e-01, -2.4919e-01,\n",
       "                      -1.7290e-01, -1.2624e-01, -1.5359e-01, -1.9513e-01, -2.2641e-02,\n",
       "                      -5.3485e-02,  1.7105e-03, -5.2798e-02, -1.8175e-01,  2.8607e-02,\n",
       "                      -3.6188e-02, -1.5625e-04, -1.5248e-01, -1.2854e-01, -1.3349e-01,\n",
       "                      -7.5856e-02, -1.9724e-01,  6.9651e-04, -1.5492e-01,  3.0098e-03,\n",
       "                      -3.7499e-01, -1.5018e-01, -5.9444e-02, -1.4709e-01,  1.8810e-01,\n",
       "                      -1.8158e-01, -1.4275e-01, -1.3449e-01, -5.9478e-03, -2.0086e-01,\n",
       "                       2.8648e-03, -7.2425e-02, -1.9158e-01, -1.5488e-02, -2.2436e-02,\n",
       "                      -2.0338e-01, -2.0696e-01, -1.7018e-01, -5.4065e-02, -2.9895e-01,\n",
       "                      -1.7175e-01, -7.4188e-02,  3.2183e-03, -6.7791e-02, -1.1235e-01,\n",
       "                      -5.4820e-02, -2.2053e-01, -1.0354e-02, -1.8138e-01,  1.1004e-01,\n",
       "                      -1.3764e-01, -6.2183e-02, -1.6856e-01,  1.7962e-02, -6.8705e-02,\n",
       "                      -1.1972e-01, -1.4574e-01, -1.8620e-01, -1.0653e-02, -9.8637e-02,\n",
       "                      -4.1593e-02, -2.0689e-01, -2.7483e-02, -1.2393e-02, -6.3546e-02,\n",
       "                       5.5911e-03, -3.1846e-02, -1.4407e-01, -1.4196e-01, -3.5980e-02,\n",
       "                      -1.9061e-01, -2.2665e-02, -4.0746e-02, -2.2764e-01, -2.8095e-02,\n",
       "                      -1.4707e-01, -2.0443e-01, -1.9375e-01, -1.1269e-01, -3.1755e-02,\n",
       "                      -1.5742e-01, -2.2417e-01, -2.8592e-01, -1.1976e-04, -1.4684e-01,\n",
       "                      -2.0838e-01, -4.5753e-02, -2.7247e-01, -1.3865e-01, -8.3999e-03,\n",
       "                       3.2023e-02,  1.3440e-03,  1.8518e-02, -2.2927e-01, -1.9137e-01,\n",
       "                      -1.8418e-01, -9.2459e-03, -1.8355e-01, -7.4203e-03, -2.0658e-01,\n",
       "                      -1.3940e-01, -1.8775e-01, -1.7530e-01, -2.3366e-01, -8.8494e-02,\n",
       "                      -1.6830e-01, -2.4919e-01, -1.7980e-02, -2.0212e-01, -2.4615e-01,\n",
       "                      -1.1547e-01,  1.2699e-02, -1.6425e-01, -1.6780e-01, -2.3221e-02,\n",
       "                      -1.5806e-01,  6.9017e-02, -3.1158e-02, -3.0639e-02, -1.3762e-01,\n",
       "                      -9.1835e-02, -1.2012e-02, -1.3026e-01, -1.7594e-01, -8.3937e-02,\n",
       "                      -1.9191e-01, -1.6504e-01, -5.9432e-02, -7.9799e-02, -1.4081e-01,\n",
       "                      -2.0532e-01, -2.0691e-01, -1.6140e-01, -4.4731e-02, -2.7867e-02,\n",
       "                      -4.5116e-02, -1.8817e-01, -1.6116e-01, -2.3826e-01, -1.7587e-01,\n",
       "                       2.4856e-02, -1.4798e-01, -7.4049e-02,  9.3399e-03, -4.2828e-02,\n",
       "                      -1.8180e-01, -7.6563e-02, -1.8730e-01, -1.8554e-01, -2.1853e-02,\n",
       "                      -1.1266e-02, -1.4883e-01, -2.0201e-01, -4.0968e-02, -2.1379e-01,\n",
       "                      -2.2988e-02, -2.8720e-01, -2.4289e-01, -2.0050e-01, -5.8358e-02,\n",
       "                      -2.0255e-01, -8.8338e-02, -2.0509e-01, -1.5321e-01,  2.9711e-02,\n",
       "                      -8.7013e-02, -9.5652e-02, -1.5350e-01, -7.1536e-02, -1.4427e-01,\n",
       "                      -1.1756e-01, -7.8393e-02])),\n",
       "             ('fc_rank.weight',\n",
       "              tensor([[-1.5208e-01, -1.2868e-01, -1.2694e-01, -2.0865e-01,  2.0146e-02,\n",
       "                        4.5054e-02, -8.9351e-02, -2.7685e-01, -3.3974e-01, -2.0719e-01,\n",
       "                       -1.9640e-01,  2.4794e-02, -8.2954e-02,  4.3773e-02,  3.7726e-02,\n",
       "                        3.5356e-02,  7.1335e-02,  5.9520e-03,  4.0732e-02,  3.0064e-02,\n",
       "                        5.2796e-02,  2.5857e-02,  3.6663e-02,  7.3622e-02, -1.1180e-01,\n",
       "                       -1.1886e-02, -1.3018e-02, -1.7937e-01,  2.3277e-02, -2.1247e-01,\n",
       "                        4.7353e-02,  2.7146e-02,  2.8973e-02, -2.3658e-01, -2.3460e-01,\n",
       "                       -8.2271e-02, -6.4900e-02,  2.2642e-02,  3.4282e-02,  3.2043e-02,\n",
       "                        6.8746e-02, -1.4857e-01, -8.8111e-02, -1.6172e-01, -1.0359e-01,\n",
       "                       -4.5988e-02, -2.4441e-01, -1.4208e-01, -1.2382e-01, -1.3146e-01,\n",
       "                       -6.6572e-02,  3.3345e-02, -1.2595e-01, -3.2612e-01,  2.6722e-02,\n",
       "                       -1.9288e-01, -1.3401e-01,  2.1255e-02, -7.1126e-02, -2.4116e-01,\n",
       "                       -1.0553e-01,  5.1093e-02,  4.6723e-02,  9.9119e-02,  4.9564e-02,\n",
       "                       -2.4711e-02,  7.9027e-02, -8.5705e-02, -1.6387e-01,  7.4999e-02,\n",
       "                        2.2310e-02, -2.3483e-01,  3.3992e-02, -2.3541e-01,  5.7652e-02,\n",
       "                       -1.8926e-01, -1.9915e-01,  7.8645e-02, -1.6032e-01,  1.0105e-01,\n",
       "                        2.9346e-02, -3.9634e-02, -3.2042e-02, -1.2542e-01, -1.0847e-01,\n",
       "                       -2.2022e-01, -1.5397e-01, -8.1227e-02, -1.9959e-01, -1.0632e-01,\n",
       "                       -2.6796e-01, -1.1496e-01, -2.1565e-01, -1.0740e-01, -1.2342e-01,\n",
       "                       -2.0005e-01, -1.0741e-01, -9.4138e-02, -1.4109e-01,  4.9374e-02,\n",
       "                       -1.6934e-01, -1.4880e-01, -8.7474e-02, -2.2259e-01,  8.1771e-02,\n",
       "                        8.1696e-02,  4.0891e-02,  1.6494e-02,  5.3239e-02,  9.1929e-02,\n",
       "                       -9.2365e-02, -1.1329e-01,  4.4711e-02, -1.3983e-01, -1.4055e-01,\n",
       "                        9.5304e-02, -2.1961e-01,  9.7075e-02,  2.8914e-02, -1.2448e-01,\n",
       "                        6.6557e-02, -5.1312e-02, -1.3754e-01, -2.5299e-02, -9.4424e-02,\n",
       "                       -1.4267e-01,  3.5721e-02,  6.4956e-02, -2.3894e-01, -1.5421e-01,\n",
       "                       -2.3274e-01, -9.5475e-02, -1.7021e-01,  7.6872e-02, -1.0042e-01,\n",
       "                       -1.2267e-02, -2.2467e-02, -8.5053e-02, -2.5716e-01,  4.5514e-02,\n",
       "                        4.0077e-02,  3.0949e-02, -2.9603e-02, -1.3064e-01,  2.9492e-02,\n",
       "                       -2.2494e-02, -1.5302e-01, -1.1826e-01, -1.7578e-01, -9.8167e-02,\n",
       "                       -1.2080e-01, -1.2620e-01, -1.6158e-01,  2.3466e-02, -1.2691e-01,\n",
       "                       -7.4451e-02,  4.3622e-02,  5.0082e-02, -1.1148e-01, -2.4260e-01,\n",
       "                       -2.0755e-01,  7.0735e-02,  5.8547e-02, -2.7467e-01,  3.8522e-02,\n",
       "                       -6.8225e-02, -1.7048e-01, -2.1353e-01,  2.5356e-02, -2.2801e-01,\n",
       "                       -1.2522e-01,  8.8101e-02, -1.4638e-01,  2.9732e-02, -1.9030e-01,\n",
       "                        3.0427e-02,  8.8934e-02,  2.7320e-02,  1.6905e-02, -1.8989e-01,\n",
       "                        8.9647e-02,  4.4736e-02, -1.5400e-01,  4.7738e-02, -1.1691e-01,\n",
       "                       -1.3761e-01, -1.1143e-01,  7.0106e-02,  2.3611e-02, -2.0160e-01,\n",
       "                        3.5193e-02,  6.7442e-02,  4.8292e-02, -2.8591e-01, -6.9320e-02,\n",
       "                       -1.4438e-01, -2.4814e-01, -1.2509e-01,  3.3882e-02,  2.8817e-02,\n",
       "                        6.7288e-02,  4.6658e-02,  3.6718e-02,  3.5568e-02,  6.2967e-02,\n",
       "                       -1.8624e-02, -1.7235e-01,  3.3234e-02, -1.1540e-01, -2.2245e-01,\n",
       "                       -1.9563e-02,  3.9947e-03, -1.6430e-01, -1.7416e-01, -1.3395e-01,\n",
       "                        1.7810e-02,  3.9895e-02, -7.2726e-02,  3.5841e-02, -1.0694e-01,\n",
       "                        2.6977e-02,  4.1634e-02, -3.9792e-02,  2.7762e-02, -1.7236e-01,\n",
       "                        2.0697e-02,  2.0406e-02, -2.4252e-01, -1.6120e-01,  2.8556e-02,\n",
       "                        4.2524e-02, -9.0027e-03, -8.1547e-02,  8.1307e-02,  3.4940e-02,\n",
       "                        3.0390e-02, -1.0768e-01,  7.1774e-02,  1.8775e-02, -3.3696e-01,\n",
       "                       -1.3146e-01, -1.1817e-01, -2.1932e-01,  3.0707e-02,  6.7114e-02,\n",
       "                        4.3179e-02,  5.4870e-02,  3.0639e-02,  9.8481e-02,  8.9549e-02,\n",
       "                        4.3228e-02, -1.5279e-01, -1.3944e-01,  6.1598e-02,  7.4892e-02,\n",
       "                       -3.1648e-03,  4.8037e-02,  1.9952e-02,  4.3174e-02, -1.0681e-01,\n",
       "                       -8.1895e-02, -1.3289e-01, -3.0153e-01, -2.1601e-01,  2.8928e-02,\n",
       "                       -1.4275e-01,  3.3117e-02,  5.5026e-02,  2.6431e-02, -2.6049e-01,\n",
       "                        6.7457e-02,  4.5570e-02,  4.4486e-02, -1.2683e-01,  4.1059e-02,\n",
       "                        3.0023e-02,  5.8264e-02, -1.5234e-01,  2.7388e-02,  4.3815e-02,\n",
       "                        3.1406e-02, -9.2281e-02, -2.2308e-01, -1.7225e-01,  2.9619e-02,\n",
       "                       -2.1001e-01,  6.8453e-02, -4.9835e-02,  4.3026e-02, -1.6010e-01,\n",
       "                       -2.0607e-01, -1.4118e-01, -1.0595e-01,  4.4938e-02,  3.3273e-02,\n",
       "                        2.8077e-02, -5.0768e-02,  2.5923e-02, -1.9086e-01, -9.3134e-02,\n",
       "                       -1.1686e-01, -8.5738e-02, -5.0609e-02, -2.9115e-02, -9.1895e-02,\n",
       "                       -1.9225e-01,  6.2381e-02,  2.3264e-02,  4.5427e-02, -1.8628e-01,\n",
       "                       -9.1672e-02,  6.9610e-02,  4.1153e-02, -2.3402e-01,  4.7168e-02,\n",
       "                       -2.1703e-01, -2.0093e-01,  7.7296e-02,  3.8840e-02,  8.6140e-02,\n",
       "                        1.0935e-01,  8.9288e-02,  2.4340e-02, -1.5484e-01,  2.4417e-02,\n",
       "                       -1.7633e-01, -1.3133e-01, -2.4266e-02,  3.4828e-02,  2.2803e-02,\n",
       "                        2.4183e-02,  4.8287e-02,  5.2536e-02,  5.5118e-02, -1.5961e-01,\n",
       "                        3.6868e-02,  4.9110e-02, -1.5932e-01, -1.3982e-01, -1.8676e-01,\n",
       "                       -1.2430e-01, -1.9457e-01, -1.2587e-01, -8.1594e-02,  2.0079e-02,\n",
       "                        2.6806e-02,  3.5257e-02,  3.2891e-02, -1.3492e-01,  4.1991e-02,\n",
       "                        4.3881e-02,  2.4941e-02, -1.3177e-01, -2.3523e-01, -1.2903e-01,\n",
       "                        9.6773e-02, -1.4856e-01,  4.6607e-02, -1.5919e-01,  3.9956e-02,\n",
       "                       -7.9878e-02, -7.5418e-02,  9.2321e-02, -3.0985e-01, -5.8488e-02,\n",
       "                       -1.9788e-01, -1.8814e-01, -1.2486e-01,  6.8098e-02, -2.0914e-01,\n",
       "                        2.1637e-02,  1.9711e-02, -1.4146e-01,  2.2644e-02,  5.7708e-02,\n",
       "                       -9.7300e-02, -1.9301e-01, -9.9693e-02,  7.4168e-02, -1.1762e-01,\n",
       "                       -2.1645e-01,  5.2838e-02,  3.4707e-02,  5.7000e-02,  1.3878e-02,\n",
       "                       -4.4107e-03, -1.2236e-01,  4.6629e-02, -1.5330e-01, -3.1437e-02,\n",
       "                       -7.7253e-02,  3.2450e-02, -2.6349e-01,  1.2272e-02,  6.0353e-02,\n",
       "                       -9.9611e-02, -1.3175e-01, -1.1538e-01,  3.8518e-02, -1.8551e-01,\n",
       "                        5.4468e-02, -2.2894e-01,  6.1848e-02,  4.5322e-02,  6.0674e-02,\n",
       "                        2.3442e-02,  2.8300e-02, -2.3593e-01, -8.1880e-02,  3.0983e-02,\n",
       "                       -1.6309e-01,  2.2222e-02,  2.4968e-02, -2.8224e-01,  5.2124e-02,\n",
       "                       -1.6697e-01, -2.1075e-01, -1.4358e-01,  9.5067e-02,  5.5622e-02,\n",
       "                        1.4193e-02, -2.0105e-01, -1.2986e-01, -5.4396e-02, -2.3543e-01,\n",
       "                       -2.6100e-01,  2.6640e-02, -1.5277e-01, -2.6336e-01,  8.7545e-02,\n",
       "                        4.4974e-02,  2.5254e-02, -2.4448e-02, -1.0341e-01, -1.1355e-01,\n",
       "                       -2.1825e-02,  5.1576e-02, -1.3973e-01,  3.8885e-02, -1.5379e-01,\n",
       "                       -9.5970e-02, -1.6143e-01, -1.8640e-01,  5.5858e-02,  1.3923e-03,\n",
       "                       -1.1799e-01, -1.1804e-01,  5.1171e-02, -2.0445e-01, -1.2722e-01,\n",
       "                       -1.5386e-01,  2.5063e-02, -1.2947e-01, -1.8790e-01,  7.5192e-02,\n",
       "                       -1.5336e-01, -1.2133e-02,  1.9151e-02,  3.3896e-02, -1.7296e-01,\n",
       "                        7.3719e-02,  3.6452e-02, -1.3188e-01, -1.4005e-01,  4.8869e-02,\n",
       "                       -2.0547e-01, -2.9499e-01,  3.1174e-02,  3.8645e-02, -1.0237e-01,\n",
       "                       -1.2100e-01, -2.0373e-01, -2.2154e-01,  5.5259e-02,  4.5460e-02,\n",
       "                        4.1666e-02, -2.1433e-01, -3.0357e-01, -1.6585e-01, -2.1654e-01,\n",
       "                        4.7398e-02, -1.5108e-01, -2.4493e-04,  7.9401e-02,  2.9549e-02,\n",
       "                       -1.9420e-01,  3.5547e-02, -1.2779e-01, -1.5447e-01,  2.4059e-02,\n",
       "                        2.4143e-02, -1.2213e-01, -1.1906e-01,  8.7930e-02, -2.6791e-01,\n",
       "                        3.1829e-02, -4.1606e-02, -1.1495e-01, -2.2182e-01,  2.8038e-02,\n",
       "                       -2.6073e-01,  5.4091e-02, -1.0543e-01, -1.0658e-01,  2.0930e-02,\n",
       "                        3.0828e-02,  6.5904e-02, -1.4169e-01,  1.9053e-02, -1.8390e-01,\n",
       "                       -7.4741e-02, -9.6680e-02]])),\n",
       "             ('fc_rank.bias', tensor([-1.7595])),\n",
       "             ('batchnorm.weight',\n",
       "              tensor([ 0.8168,  0.7923,  0.9404,  0.3899,  0.4678,  0.3453,  0.9203,  0.3772,\n",
       "                       0.3389,  0.5303,  0.4620,  0.5162,  0.9382,  0.2493,  0.3042,  0.4079,\n",
       "                       0.1623,  0.1539,  0.2864,  0.6242,  0.1963,  0.4865,  0.3155,  0.1397,\n",
       "                       0.9179,  0.5414,  0.1242,  0.4616,  0.4130,  0.4243,  0.2885,  0.3167,\n",
       "                       0.4605,  0.4202,  0.2408,  0.6651,  0.7905,  0.5623,  0.2982,  0.3446,\n",
       "                       0.1105,  0.7479,  0.8682,  0.5556,  0.7572,  0.3141,  0.2846,  0.6796,\n",
       "                       0.5893,  0.7064,  0.1918,  0.5753,  0.9771,  0.2916,  0.5634,  0.5332,\n",
       "                       0.6675,  0.5159,  0.1955,  0.2674,  0.9298,  0.2515,  0.5807, -0.1264,\n",
       "                       0.2201,  0.5488,  0.1212,  0.9238,  0.7276,  0.2218,  0.4274,  0.3744,\n",
       "                       0.6300,  0.3908,  0.2659,  0.2779,  0.3983,  0.1367,  0.6607,  0.1495,\n",
       "                       0.6268,  0.3161,  0.1398,  0.8620,  0.7585,  0.3282,  0.4007,  0.8001,\n",
       "                       0.4382,  0.6340,  0.2759,  0.8397,  0.5027,  0.7547,  0.8325,  0.3762,\n",
       "                       0.9285,  0.7051,  0.6101,  0.5961,  0.4922,  0.4596,  0.8662,  0.3046,\n",
       "                       0.1813,  0.0991,  0.6119,  0.5448,  0.2687,  0.1432,  0.7802,  0.8019,\n",
       "                       0.1844,  0.5603,  0.6236,  0.1491,  0.3248,  0.1345,  0.5407,  0.7678,\n",
       "                       0.1685,  0.2817,  0.6698,  0.1289,  1.0075,  0.5749,  0.1602,  0.1608,\n",
       "                       0.2429,  0.6092,  0.3676,  0.4443,  0.4897,  0.1180,  0.8837,  0.6543,\n",
       "                       0.3612,  0.6677,  0.3812,  0.2619,  0.3442,  0.4030,  0.9517,  0.6234,\n",
       "                       0.2690,  0.5359,  0.4906,  0.6071,  0.4568,  0.8536,  0.9212,  0.8736,\n",
       "                       0.6380,  0.5048,  0.6445, -0.1056,  0.3901,  0.6814,  0.6487,  0.3952,\n",
       "                       0.2294,  0.1584,  0.4528,  0.3355,  0.3099,  0.7033,  0.3358,  0.3388,\n",
       "                       0.6912,  0.2406,  0.8687,  0.1473,  0.4919,  0.5383,  0.3903,  0.4168,\n",
       "                       0.1796,  0.5859,  0.0425,  0.4888,  0.1580,  0.2875,  0.6793,  0.2691,\n",
       "                       0.2659,  0.5003,  0.7726,  0.1190,  0.6173,  0.3773,  0.4012,  0.1875,\n",
       "                       0.2541,  0.2884,  0.9245,  0.6297,  0.3606,  0.8425,  0.4137,  0.3626,\n",
       "                       0.1203,  0.2424,  0.2254,  0.5305,  0.2980,  0.1511,  0.5632,  0.1503,\n",
       "                       0.4107,  0.4641,  0.5370,  0.6518,  0.4582,  0.4163,  0.6925,  0.5986,\n",
       "                       0.3415,  0.5374,  0.4262, -0.1162,  0.4720,  0.2253,  0.4061,  0.7935,\n",
       "                       0.7095,  0.4408,  0.5359,  0.4608,  0.4995,  0.5933,  0.2033,  0.6592,\n",
       "                       0.6727,  0.1147,  0.3838,  0.4611,  0.9341,  0.1869,  0.4966,  0.2897,\n",
       "                       0.7229,  0.6207,  0.3106,  0.2624,  0.1875,  0.3410,  0.3191,  0.4409,\n",
       "                       0.1010,  0.1182,  0.5431,  0.7041,  0.5495,  0.2069,  0.2176,  0.4156,\n",
       "                       0.2583,  0.4905,  0.3907,  0.9280,  0.8183,  0.9067,  0.3495,  0.5546,\n",
       "                       0.4695,  0.5380,  0.4786,  0.1852,  0.4358,  0.2699,  0.2147,  0.3340,\n",
       "                       0.3801,  0.7586,  0.2748,  0.5229,  0.4004,  0.6488,  0.4371,  0.3639,\n",
       "                       0.4389,  0.7055,  0.4323,  0.6183,  0.3943,  0.4830,  0.1769,  0.8612,\n",
       "                       0.4115,  0.8281,  0.2543,  0.2181,  0.8166,  0.3794,  0.3271,  0.4313,\n",
       "                       0.6806,  0.3615,  0.3136,  0.1266,  0.9415,  0.8785,  0.2569,  0.6283,\n",
       "                      -0.0967,  0.5050,  0.0934,  0.5497,  0.2641,  0.3548,  0.8930,  0.1581,\n",
       "                       0.4506,  0.3348,  0.2334,  0.3883,  0.3986,  0.1911,  0.2914,  0.1505,\n",
       "                       0.1121,  0.1430,  0.3840,  0.6905,  0.5521,  0.4033,  0.8734,  0.5298,\n",
       "                       0.3951,  0.5606,  0.4968,  0.1513,  0.1593,  0.2326,  0.5355,  0.4118,\n",
       "                       0.2050,  0.5021,  0.7496,  0.4554,  0.7116,  0.3840,  0.5712,  0.8105,\n",
       "                       0.4798,  0.5724,  0.3153,  0.3573,  0.5978,  0.2898,  0.5425,  0.4674,\n",
       "                       0.5852,  0.3597,  0.7430,  0.1172,  0.5711,  0.6218,  0.5875,  0.3621,\n",
       "                       0.2432,  0.1736,  0.1911,  0.3423,  0.7056,  0.4190,  0.3579,  0.7598,\n",
       "                       0.1492,  0.4656,  0.5281,  0.5067,  0.8619,  0.5099,  0.2289,  0.9135,\n",
       "                       0.4191,  0.7457,  0.2091,  0.1497,  0.3207,  0.3710,  0.4056,  0.1901,\n",
       "                       0.6615,  0.4596,  0.7493,  0.3265,  0.5105,  0.8986,  0.6356,  0.4228,\n",
       "                       0.2852,  0.5374,  0.1497,  0.6240,  0.8404,  0.7795,  0.3178,  0.6767,\n",
       "                       0.3145,  0.2563,  0.2547,  0.2651,  0.2758,  0.6044,  0.6183,  0.3001,\n",
       "                       0.8136,  0.3693,  0.5310,  0.6231,  0.6538,  0.3296,  0.4199,  0.5787,\n",
       "                       0.2893,  0.4625, -0.1301,  0.2378,  0.1080,  0.5874,  0.7949,  0.3305,\n",
       "                       0.3376,  0.3224,  0.3862,  0.3554,  0.4449,  0.1115,  0.1899,  0.6128,\n",
       "                       0.7763,  0.8584,  0.8034,  0.1270,  0.2687,  0.9776,  0.6373,  0.6802,\n",
       "                       0.7951,  0.5646,  0.4275,  0.1553,  0.1440,  0.8372,  0.9002,  0.1760,\n",
       "                       0.6108,  1.0235,  0.5798,  0.6071,  0.5374,  0.3698,  0.1175,  0.4592,\n",
       "                       0.6939,  0.5353,  0.5397,  0.3402,  0.1116,  0.2772,  0.8564,  0.6200,\n",
       "                       0.7735,  0.4042,  0.3311,  0.5959,  0.2634,  0.8933,  0.9568,  0.3155,\n",
       "                       0.4204,  0.2503,  0.3246,  0.3712,  0.4209,  0.2790,  0.5483,  0.3782,\n",
       "                       0.2802,  0.7500,  0.0038,  0.1448,  0.5764,  0.4364,  0.2906,  0.4889,\n",
       "                       0.7878,  0.6922,  0.4501,  0.6059,  0.7445,  0.1225,  0.2569,  0.4639,\n",
       "                       0.3048,  0.9519,  0.3279,  0.6113,  0.4191,  0.2329,  0.8241,  0.7849,\n",
       "                       0.6045,  0.6049,  0.1276,  0.4497,  0.4803,  0.4816,  0.1762,  0.1198])),\n",
       "             ('batchnorm.bias',\n",
       "              tensor([ 2.6856e-01,  3.0927e-01,  3.2250e-01,  1.1019e-01, -1.2865e-01,\n",
       "                      -4.1813e-02,  2.7891e-01,  1.5833e-01,  1.5513e-01,  1.8758e-01,\n",
       "                       2.0373e-01, -8.3961e-02,  2.5908e-01, -1.7115e-01, -4.8813e-02,\n",
       "                      -6.6992e-03, -3.2541e-02, -1.4751e-02, -1.4862e-02,  8.8922e-03,\n",
       "                      -5.9220e-02, -1.1261e-02, -1.3434e-01, -3.9400e-02,  2.5839e-01,\n",
       "                       1.2153e-02,  1.1271e-02,  1.1080e-01, -7.3989e-02,  1.2600e-01,\n",
       "                       1.2830e-02, -1.9629e-01, -4.2003e-02,  1.8175e-01,  7.9238e-02,\n",
       "                       3.7723e-01,  3.3950e-01, -6.4135e-02, -3.6043e-02, -9.1971e-02,\n",
       "                      -7.5431e-02,  3.7648e-01,  2.7384e-01,  2.4744e-01,  3.2404e-01,\n",
       "                       1.0960e-01,  1.0474e-01,  2.5330e-01,  1.8056e-01,  2.7958e-01,\n",
       "                       1.1892e-01, -4.1158e-02,  2.3688e-01,  1.3002e-01, -1.8295e-01,\n",
       "                       2.1726e-01,  1.5953e-01, -1.1882e-01,  7.6568e-02,  1.0179e-01,\n",
       "                       3.3147e-01, -7.6678e-02,  1.4673e-02, -5.5458e-02, -3.4776e-02,\n",
       "                      -3.6249e-03, -7.6332e-02,  2.2592e-01,  2.4480e-01, -2.3469e-02,\n",
       "                      -1.2282e-01,  1.0296e-01,  3.8868e-03,  1.5022e-01, -3.9363e-02,\n",
       "                       1.7745e-01,  1.7610e-01, -2.6606e-02,  2.9011e-01, -2.5475e-02,\n",
       "                       2.2888e-02,  4.8586e-02, -2.8927e-02,  3.3516e-01,  2.7126e-01,\n",
       "                       1.3339e-01,  1.3026e-01,  2.6928e-01,  2.1458e-01,  2.3329e-01,\n",
       "                       8.1707e-02,  3.3450e-01,  2.9782e-01,  2.5948e-01,  2.6186e-01,\n",
       "                       1.0350e-01,  2.7041e-01,  2.4757e-01,  3.5106e-01,  4.0868e-02,\n",
       "                       1.2223e-01,  3.1261e-01,  2.2016e-01,  9.5057e-02, -2.6980e-02,\n",
       "                      -1.1355e-01,  2.3386e-02, -2.6223e-01, -3.4427e-02, -5.2728e-02,\n",
       "                       2.8072e-01,  3.8476e-01, -3.5631e-02,  1.6585e-01,  2.1074e-01,\n",
       "                      -1.4789e-02,  1.0896e-01, -2.4367e-02, -2.2483e-02,  2.4665e-01,\n",
       "                      -2.6148e-03,  1.6652e-01,  1.9605e-01,  2.4655e-02,  2.8898e-01,\n",
       "                       1.6165e-01, -8.6826e-04, -3.3464e-02,  1.0962e-01,  2.4673e-01,\n",
       "                       9.9782e-02,  1.7955e-01,  1.8059e-01, -2.9436e-02,  2.2231e-01,\n",
       "                      -3.6969e-03, -1.4544e-02,  1.6376e-01,  1.3515e-01, -3.4833e-02,\n",
       "                      -6.7995e-02, -7.0709e-02,  8.3033e-03,  1.6333e-01, -4.2957e-02,\n",
       "                      -2.3182e-02,  1.2953e-01,  1.8421e-01,  1.6423e-01,  3.1929e-01,\n",
       "                       2.7842e-01,  3.7805e-01,  2.4979e-01, -1.6211e-01,  2.0418e-01,\n",
       "                       1.8417e-02, -6.0821e-02,  7.1757e-02,  2.0924e-01,  1.3949e-01,\n",
       "                       1.4362e-01, -3.9171e-02,  2.1138e-02,  1.0059e-01, -8.5277e-02,\n",
       "                       2.7807e-01,  1.3901e-01,  8.9149e-02,  3.6990e-02,  1.6069e-01,\n",
       "                       2.3005e-01, -2.4260e-02,  1.3854e-01, -7.1315e-02,  1.8563e-01,\n",
       "                      -9.9192e-02,  5.7674e-03, -3.0967e-03,  1.8600e-02,  1.5516e-01,\n",
       "                      -2.7339e-03, -3.7177e-02,  2.4737e-01, -6.9517e-02,  1.1231e-01,\n",
       "                       1.6077e-01,  4.5138e-01, -3.9878e-02, -7.1359e-02,  1.1811e-01,\n",
       "                      -1.3496e-01, -2.4464e-02, -4.1597e-02,  1.7177e-01,  2.9220e-01,\n",
       "                       2.0332e-01,  1.7914e-01,  2.9110e-01, -6.4403e-02, -1.9955e-01,\n",
       "                      -3.5049e-02, -6.5520e-02, -2.4045e-02,  1.6338e-02, -8.5266e-03,\n",
       "                      -1.8719e-02,  1.6202e-01, -3.4113e-02,  1.4754e-01,  2.4754e-01,\n",
       "                       2.8194e-03,  1.6135e-03,  1.7448e-01,  1.6581e-01,  2.8435e-01,\n",
       "                      -1.3789e-01, -4.1109e-02,  2.1754e-01,  1.4732e-02,  7.5918e-03,\n",
       "                      -3.5728e-02, -1.1399e-01,  1.7685e-01,  6.0791e-02,  2.7922e-01,\n",
       "                      -1.3443e-01, -1.4034e-01,  1.4061e-01,  1.3298e-01,  2.6069e-02,\n",
       "                      -2.5982e-02,  1.3333e-02,  2.0343e-01, -2.4682e-02, -4.3866e-02,\n",
       "                      -9.9521e-02,  2.0304e-01, -2.5830e-02, -1.3490e-01,  1.4140e-01,\n",
       "                       2.2295e-01,  2.8664e-01,  7.4618e-02, -7.3100e-02, -7.5497e-02,\n",
       "                      -7.1344e-02,  7.6933e-03, -8.4373e-02, -1.4548e-02, -4.4191e-03,\n",
       "                       2.7140e-02,  2.9379e-01,  2.4027e-01, -1.4002e-02,  3.0464e-03,\n",
       "                       6.8616e-03, -1.8378e-02, -3.0047e-01, -1.3232e-02,  4.0095e-01,\n",
       "                       3.5408e-01,  4.3403e-01,  1.7050e-01,  2.1555e-01, -1.0473e-01,\n",
       "                       1.9448e-01, -7.8460e-03, -8.7963e-02, -2.0444e-01,  7.6497e-02,\n",
       "                      -8.7418e-02,  6.1583e-03,  3.8794e-02,  4.5999e-01, -1.3545e-01,\n",
       "                      -5.5704e-02, -4.9838e-03,  1.8145e-01, -5.1178e-02, -2.7029e-02,\n",
       "                      -7.4478e-03,  2.9989e-01,  1.2574e-01,  2.0003e-01, -7.6309e-02,\n",
       "                       1.7387e-01, -4.6775e-02,  2.5688e-02,  1.0909e-02,  2.5152e-01,\n",
       "                       1.0467e-01,  1.3540e-01,  3.0997e-01, -2.5951e-02, -8.4452e-02,\n",
       "                      -6.2370e-02,  2.8588e-01, -6.8832e-02,  9.6593e-02,  5.5573e-02,\n",
       "                       3.3050e-01,  2.6257e-01,  6.0510e-02, -1.8038e-02, -1.0077e-02,\n",
       "                       1.6790e-01, -7.1435e-02, -2.9266e-02, -2.5735e-02,  1.4998e-01,\n",
       "                       3.0129e-01, -1.7990e-02, -1.8004e-02,  1.5658e-01, -7.9340e-02,\n",
       "                       1.4055e-01,  9.3265e-02, -2.4881e-02, -1.1337e-01, -3.6162e-02,\n",
       "                      -2.8333e-02, -1.7541e-02, -2.0531e-01,  2.4553e-01, -8.1918e-02,\n",
       "                       1.4006e-01,  2.6177e-01,  1.1245e-02, -6.6041e-02,  1.7554e-02,\n",
       "                      -1.1356e-01, -7.9010e-03, -4.2250e-02, -4.5378e-02,  2.0531e-01,\n",
       "                      -2.2297e-02, -2.3714e-02,  1.7299e-01,  3.1834e-01,  2.4103e-01,\n",
       "                       4.1730e-01,  1.9381e-01,  1.1455e-01,  2.0352e-01, -1.2525e-01,\n",
       "                      -7.1242e-02, -6.3358e-02, -1.2270e-01,  1.9830e-01, -1.0049e-01,\n",
       "                       2.5949e-02,  4.1722e-02,  1.6740e-01,  1.8773e-01,  3.1792e-01,\n",
       "                      -1.9210e-02,  1.3510e-01,  3.3930e-02,  2.0267e-01, -2.4989e-02,\n",
       "                       1.1014e-01,  4.6547e-02,  4.6709e-03,  1.4427e-01, -7.7965e-03,\n",
       "                       1.0023e-01,  1.6399e-01,  2.3031e-01, -6.1112e-02,  1.1622e-01,\n",
       "                      -8.1313e-02, -4.4910e-02,  3.3849e-01, -1.5949e-02,  5.7958e-03,\n",
       "                       3.2546e-01,  1.0420e-01,  2.1561e-01, -3.8243e-02,  5.1317e-02,\n",
       "                       1.1605e-01, -2.1470e-02, -4.5477e-02, -9.4693e-02, -2.1820e-02,\n",
       "                      -1.0552e-02,  2.0561e-01, -1.3027e-02,  1.6626e-01,  2.8202e-02,\n",
       "                       1.2352e-01, -8.8986e-02,  1.0768e-01, -3.2983e-01, -8.2187e-02,\n",
       "                       2.7285e-01,  3.1788e-01,  2.9308e-01, -1.1922e-01,  2.3179e-01,\n",
       "                       1.1787e-02,  1.5627e-01, -5.4614e-03, -6.3809e-02, -2.8136e-02,\n",
       "                      -1.7824e-01, -6.7102e-02,  1.8550e-01,  2.2655e-01, -1.0233e-01,\n",
       "                       1.3963e-01, -9.6534e-03, -8.0557e-02,  9.9271e-02, -3.4456e-03,\n",
       "                       3.1160e-01,  6.2674e-02,  2.6852e-01, -2.5312e-02, -9.3132e-03,\n",
       "                      -1.6575e-02,  1.6351e-01,  3.0982e-01,  6.4524e-02,  2.2990e-01,\n",
       "                       1.9243e-01, -1.6074e-01,  9.3028e-02,  1.6068e-01, -8.9357e-02,\n",
       "                      -1.6876e-01, -6.4591e-02,  6.7283e-03,  2.3316e-01,  3.5723e-01,\n",
       "                      -2.2927e-02, -4.8483e-02,  3.5769e-01,  6.0529e-03,  3.2630e-01,\n",
       "                       2.7239e-01,  3.0888e-01,  1.2189e-01, -9.4757e-03,  3.6190e-03,\n",
       "                       3.6985e-01,  2.3060e-01, -8.0466e-02,  1.7366e-01,  2.4625e-01,\n",
       "                       1.6220e-01, -1.0220e-01,  1.7258e-01,  1.5241e-01, -1.0690e-01,\n",
       "                       1.8189e-01,  5.9309e-03, -9.9538e-02, -1.2347e-02,  1.4488e-01,\n",
       "                      -2.2883e-02, -1.1215e-01,  3.6971e-01,  3.4377e-01,  3.7454e-02,\n",
       "                       1.0293e-01,  1.4580e-01,  2.7452e-02, -6.5214e-02,  2.8402e-01,\n",
       "                       4.2789e-01,  7.3494e-02,  2.2136e-01, -3.2487e-02,  2.4683e-03,\n",
       "                      -1.2009e-02,  1.9547e-01,  1.5785e-01,  1.3010e-01,  2.1159e-01,\n",
       "                      -9.8648e-02,  1.8942e-01, -1.2731e-04, -3.9489e-02, -5.6775e-03,\n",
       "                       1.4659e-01, -5.9194e-02,  2.3659e-01,  2.5243e-01, -1.7155e-02,\n",
       "                      -4.6603e-02,  1.6346e-01,  1.9457e-01, -5.8816e-02,  9.1039e-02,\n",
       "                      -8.6085e-02,  8.8464e-02,  3.3208e-01,  1.2057e-01, -1.6693e-04,\n",
       "                       1.3743e-01, -1.7904e-02,  2.2657e-01,  3.3055e-01, -2.1172e-01,\n",
       "                       1.7273e-02, -8.2132e-02,  2.3530e-01, -1.5380e-01,  2.4048e-01,\n",
       "                       1.0204e-01,  4.4816e-02])),\n",
       "             ('batchnorm.running_mean',\n",
       "              tensor([2.0628e+00, 2.5637e+00, 2.3246e+00, 1.8503e+00, 4.8040e-01, 6.7406e-01,\n",
       "                      2.4180e+00, 3.0123e+00, 3.7543e+00, 2.1828e+00, 3.8467e+00, 1.9526e-01,\n",
       "                      1.4846e+00, 8.1235e-01, 6.8736e-02, 6.6111e-02, 2.4329e-01, 7.7975e-04,\n",
       "                      2.9077e-02, 1.7110e-01, 2.6616e-01, 4.3634e-02, 9.1123e-01, 4.1325e-01,\n",
       "                      1.7360e+00, 9.5780e-04, 1.2112e-03, 8.7910e-01, 2.3157e-01, 1.6506e+00,\n",
       "                      1.2572e-01, 2.8136e-01, 4.1132e-01, 3.5591e+00, 3.0962e+00, 9.2111e+00,\n",
       "                      5.0820e+00, 4.0282e-01, 2.7502e-01, 2.5751e-01, 1.5932e+00, 4.6581e+00,\n",
       "                      2.5862e+00, 4.1882e+00, 4.2120e+00, 7.4607e+01, 2.0331e+00, 3.1065e+00,\n",
       "                      1.8000e+00, 3.5824e+00, 4.0402e+01, 3.5387e-01, 1.3411e+00, 3.6185e+00,\n",
       "                      6.9030e-01, 2.3912e+00, 1.1213e+00, 6.6742e-01, 7.1362e+01, 3.3832e+00,\n",
       "                      2.6569e+00, 4.8315e-01, 1.1611e-01, 7.1224e+01, 1.7807e-01, 1.6793e-03,\n",
       "                      2.8794e-01, 1.0287e+00, 1.8738e+00, 1.6759e-01, 2.5086e-01, 2.4726e+00,\n",
       "                      5.6351e-02, 2.1412e+00, 1.3173e-01, 9.9576e+00, 4.1195e+00, 1.2916e-01,\n",
       "                      3.2761e+00, 3.7310e-01, 2.5039e-01, 6.7297e+01, 6.4034e-05, 2.5913e+00,\n",
       "                      3.5124e+00, 3.0474e+00, 2.4695e+00, 2.2359e+00, 3.8031e+00, 3.3639e+00,\n",
       "                      2.0860e+00, 3.3569e+00, 4.9924e+00, 2.2085e+00, 1.5587e+00, 1.9553e+00,\n",
       "                      1.4497e+00, 3.0942e+00, 6.7476e+00, 1.6306e-01, 1.4959e+00, 1.2471e+01,\n",
       "                      1.3447e+00, 2.7539e+00, 2.6331e-01, 7.1102e-01, 1.9942e-01, 2.3889e-01,\n",
       "                      2.3108e-01, 4.3062e-01, 2.9124e+00, 4.4902e+00, 1.0426e-01, 1.4707e+00,\n",
       "                      2.5765e+00, 2.5627e-01, 2.1121e+00, 1.8559e-01, 2.5636e-01, 2.3793e+00,\n",
       "                      9.1452e-02, 3.2326e+01, 2.0832e+00, 9.7098e-07, 1.8612e+00, 1.4914e+00,\n",
       "                      2.6122e-02, 1.5232e-01, 5.7460e+00, 2.5902e+00, 1.3607e+00, 5.8833e+00,\n",
       "                      3.2453e+00, 1.2730e-01, 1.4598e+00, 8.1279e-04, 8.1209e-06, 2.0569e+00,\n",
       "                      2.9130e+00, 9.2444e-02, 1.2047e+00, 3.2979e-01, 1.9067e-05, 1.6454e+00,\n",
       "                      2.3249e-01, 1.2919e-03, 1.3334e+00, 1.9417e+00, 2.5654e+00, 3.0954e+00,\n",
       "                      1.8990e+00, 3.8534e+00, 3.2478e+00, 3.5269e-01, 1.9395e+00, 1.4101e-01,\n",
       "                      6.1685e-01, 1.8239e-01, 2.5636e+00, 2.8004e+00, 9.8554e+00, 3.2321e-01,\n",
       "                      1.2183e-01, 2.4435e+00, 2.2246e-01, 5.0379e+00, 3.4763e+00, 1.3456e+00,\n",
       "                      5.6006e-01, 1.2180e+01, 1.3724e+00, 2.0319e-01, 1.5208e+00, 3.8710e-01,\n",
       "                      4.5964e+00, 1.7966e-01, 8.2714e-02, 1.3660e-01, 6.0271e-04, 1.6573e+00,\n",
       "                      1.9636e-01, 2.2347e-02, 2.2404e+00, 4.3780e-01, 8.0942e+00, 2.0315e+00,\n",
       "                      7.0842e+00, 2.3253e-01, 1.2126e+00, 2.0677e+00, 3.0953e-01, 1.0603e-01,\n",
       "                      2.8023e-01, 7.9868e+00, 2.4101e+00, 1.7214e+00, 5.1571e+00, 2.3296e+00,\n",
       "                      6.0562e-01, 1.8350e+00, 5.4419e-01, 5.4966e-01, 2.1502e-01, 5.9613e-02,\n",
       "                      1.0996e-01, 1.4730e-05, 1.0127e+00, 4.5947e-04, 2.8322e+00, 5.7921e+00,\n",
       "                      9.9293e-06, 3.6899e-06, 2.1099e+00, 3.0023e+00, 2.6983e+00, 3.0595e-01,\n",
       "                      2.1936e-01, 8.1442e+00, 4.7869e-02, 1.6848e-01, 3.8933e-01, 3.4186e-01,\n",
       "                      3.0601e+01, 1.5377e-01, 2.8089e+00, 2.5275e-01, 3.3907e-01, 1.6856e+00,\n",
       "                      1.5012e+00, 8.2052e-01, 1.4036e-01, 7.8416e-07, 1.7388e+00, 1.1288e-01,\n",
       "                      9.6383e-02, 5.3894e-01, 5.8255e-01, 2.2413e-01, 5.4274e-01, 4.7514e+00,\n",
       "                      1.7570e+00, 4.3019e+00, 1.8803e+00, 3.0232e-01, 2.7694e-01, 3.3001e-01,\n",
       "                      3.6493e-01, 3.8705e-01, 6.8601e-02, 1.0845e-01, 4.6052e-01, 3.1232e+00,\n",
       "                      4.7747e+00, 3.7595e-01, 1.6458e-01, 6.7933e-07, 3.6180e-01, 1.0282e+00,\n",
       "                      8.6166e-02, 2.8846e+00, 4.3098e+00, 4.4268e+00, 5.1736e+00, 1.9862e+00,\n",
       "                      4.1829e-01, 2.7061e+00, 2.7110e-01, 6.5361e-01, 1.2022e+00, 1.9120e+00,\n",
       "                      2.1908e-01, 1.0016e-02, 6.0055e-01, 7.8229e+00, 5.7316e-01, 7.4197e-01,\n",
       "                      1.2172e-01, 1.8311e+00, 2.5432e-01, 1.4368e-01, 1.0455e-01, 3.9295e+00,\n",
       "                      1.7169e+00, 2.6518e+00, 2.9128e-01, 2.5847e+00, 2.7254e-01, 1.9479e-04,\n",
       "                      5.2495e-01, 1.8594e+00, 3.7320e+00, 1.1284e+01, 3.4778e+00, 1.0999e-01,\n",
       "                      1.2091e-01, 2.0449e-01, 5.5340e+00, 1.8558e-01, 2.2543e+00, 5.6634e+01,\n",
       "                      1.8257e+00, 2.6289e+00, 7.1747e+01, 5.4560e-05, 1.4120e-04, 2.5426e+00,\n",
       "                      6.8328e-01, 5.7318e-02, 2.0835e-01, 3.5858e+00, 2.1664e+00, 6.9220e-02,\n",
       "                      1.1820e-01, 4.0302e+00, 1.0770e+00, 2.4050e+00, 1.4250e+00, 1.4983e-01,\n",
       "                      1.3444e-01, 2.2161e-01, 1.4820e-01, 6.4679e-02, 2.0956e-01, 2.4641e+00,\n",
       "                      9.1096e-02, 2.6495e+00, 1.5644e+00, 9.2486e-05, 1.8971e-01, 1.0431e-01,\n",
       "                      5.0264e-01, 1.0471e-01, 1.1207e-01, 2.4483e-01, 2.5092e+00, 3.2428e-01,\n",
       "                      6.8825e-02, 2.5590e+00, 2.8250e+00, 4.4063e+00, 6.4675e+00, 7.1799e+00,\n",
       "                      1.2118e+00, 1.5103e+00, 2.8946e-01, 1.8845e-01, 5.5972e-01, 2.1121e-01,\n",
       "                      2.8345e+00, 1.0390e+00, 3.7267e-01, 2.0151e-01, 1.6420e+00, 4.9613e+00,\n",
       "                      4.0635e+00, 8.2755e-02, 8.7671e-01, 1.5314e-01, 1.9971e+00, 1.5123e-01,\n",
       "                      1.7338e+01, 6.3991e+01, 8.2055e-02, 3.9496e+00, 1.2717e-03, 1.7258e+00,\n",
       "                      3.5285e+00, 1.9070e+00, 4.5942e-01, 1.2675e+00, 7.0841e-01, 9.9200e-02,\n",
       "                      2.8165e+00, 1.4895e-01, 1.0856e-01, 3.3423e+00, 1.2078e+00, 1.2373e+00,\n",
       "                      2.9214e-01, 1.4789e+01, 1.9312e+00, 2.8028e-01, 3.9173e-01, 2.4701e-01,\n",
       "                      3.2142e-04, 6.3783e-05, 1.3011e+00, 3.1368e-01, 2.1420e+00, 1.4875e-03,\n",
       "                      7.0244e-01, 1.4409e-01, 2.9654e+00, 7.2730e-01, 4.3725e-01, 3.4217e+00,\n",
       "                      2.6429e+00, 2.5926e+00, 6.5382e-01, 2.4738e+00, 3.5947e-02, 8.2733e+00,\n",
       "                      1.2497e-01, 3.7313e-01, 3.1706e-01, 9.6717e-01, 2.5038e-01, 7.3847e+00,\n",
       "                      1.6571e+00, 5.1909e-01, 1.3709e+00, 2.2771e-01, 6.2359e-01, 2.2515e+00,\n",
       "                      3.3616e-01, 6.1238e+00, 1.3238e+00, 8.7232e+00, 9.0593e+01, 1.8728e-01,\n",
       "                      2.7570e-05, 1.7974e+00, 2.8355e+00, 1.6167e+00, 1.0878e+01, 8.6799e+00,\n",
       "                      4.3070e-01, 2.0520e+00, 2.5063e+00, 5.3185e-01, 1.1652e+00, 3.3852e-01,\n",
       "                      3.7205e-06, 1.2956e+00, 4.5365e+00, 4.4449e-07, 2.5244e-01, 2.4430e+00,\n",
       "                      1.7599e-01, 4.4261e+00, 1.8810e+00, 6.0510e+00, 2.4763e+00, 6.1698e-04,\n",
       "                      7.6396e-05, 3.3812e+00, 9.7611e-01, 2.7461e-01, 1.0421e+00, 1.0774e+00,\n",
       "                      1.9754e+00, 4.9959e-01, 1.9676e+00, 3.0547e+00, 3.7281e-01, 2.9642e+00,\n",
       "                      1.8673e+01, 4.3903e-01, 8.7182e-02, 3.6143e+00, 1.1699e-01, 5.3439e-01,\n",
       "                      3.9241e+00, 5.7152e+00, 7.7126e-02, 1.8708e+00, 4.2618e+00, 1.9737e-01,\n",
       "                      4.4442e-01, 1.9007e+00, 3.2023e+00, 2.0387e+00, 6.1368e+00, 1.3879e-01,\n",
       "                      3.1535e-01, 3.3940e-01, 3.9688e+00, 8.3413e+00, 1.2427e+00, 8.2305e+00,\n",
       "                      3.3410e-01, 1.3218e+00, 1.1052e-03, 3.7568e-01, 1.8371e-01, 1.9929e+00,\n",
       "                      3.1345e-01, 5.6100e+00, 1.3506e+00, 3.9796e-01, 3.2257e-01, 2.2738e+00,\n",
       "                      1.5892e+00, 2.4894e-01, 3.2121e+00, 2.6926e-01, 5.3698e+01, 2.3228e+00,\n",
       "                      2.4749e+00, 1.4464e-01, 2.0010e+00, 1.4463e-01, 1.5080e+00, 3.6959e+00,\n",
       "                      5.5271e-01, 1.9713e-02, 3.7062e-01, 7.3036e+00, 3.3163e-01, 4.7515e+00,\n",
       "                      7.2474e+01, 7.9814e+01])),\n",
       "             ('batchnorm.running_var',\n",
       "              tensor([3.5456e+01, 3.4688e+01, 4.4976e+01, 2.9879e+01, 4.6702e+00, 6.9521e+00,\n",
       "                      3.7243e+01, 4.6709e+01, 5.8808e+01, 3.3780e+01, 5.7459e+01, 1.7717e+00,\n",
       "                      2.2298e+01, 6.9972e+00, 5.3253e-01, 5.5253e-01, 2.1208e+00, 5.2887e-03,\n",
       "                      3.0103e-01, 1.6686e+00, 2.3601e+00, 3.9969e-01, 8.4175e+00, 4.1109e+00,\n",
       "                      2.7206e+01, 4.6210e-03, 8.9952e-03, 1.1838e+01, 2.4068e+00, 2.4930e+01,\n",
       "                      1.2342e+00, 1.9298e+00, 4.0157e+00, 5.9794e+01, 5.3878e+01, 1.5482e+02,\n",
       "                      6.5154e+01, 3.6841e+00, 2.8988e+00, 2.4730e+00, 1.9887e+01, 8.4197e+01,\n",
       "                      3.7108e+01, 5.9503e+01, 6.8953e+01, 4.5149e+02, 3.0451e+01, 5.0945e+01,\n",
       "                      2.7639e+01, 4.8185e+01, 4.2525e+02, 3.2454e+00, 2.6228e+01, 5.1962e+01,\n",
       "                      7.0992e+00, 3.1161e+01, 1.6948e+01, 5.8380e+00, 5.3705e+02, 5.5542e+01,\n",
       "                      3.9819e+01, 4.6868e+00, 9.6128e-01, 4.8095e+02, 1.7153e+00, 1.0439e-02,\n",
       "                      2.4519e+00, 1.4287e+01, 2.6130e+01, 1.1697e+00, 2.2539e+00, 4.4052e+01,\n",
       "                      4.1832e-01, 3.1627e+01, 1.2854e+00, 1.4546e+02, 6.0389e+01, 1.1422e+00,\n",
       "                      5.3123e+01, 3.3833e+00, 2.3614e+00, 4.7174e+02, 2.4746e-04, 3.6430e+01,\n",
       "                      6.1572e+01, 4.4990e+01, 3.2878e+01, 2.5795e+01, 5.8808e+01, 4.6109e+01,\n",
       "                      3.6696e+01, 5.8204e+01, 7.4639e+01, 2.8386e+01, 2.6350e+01, 3.0850e+01,\n",
       "                      1.8447e+01, 4.1959e+01, 1.1205e+02, 1.3964e+00, 2.0684e+01, 2.1794e+02,\n",
       "                      2.5300e+01, 4.5613e+01, 2.6884e+00, 7.1934e+00, 2.0578e+00, 2.0490e+00,\n",
       "                      1.9511e+00, 4.2560e+00, 3.9549e+01, 7.4003e+01, 1.1439e+00, 2.0018e+01,\n",
       "                      4.0479e+01, 2.4120e+00, 3.1890e+01, 1.8216e+00, 2.3723e+00, 4.2134e+01,\n",
       "                      8.0602e-01, 4.0921e+02, 3.4245e+01, 4.2097e-06, 3.0785e+01, 2.3072e+01,\n",
       "                      2.8868e-01, 1.5495e+00, 8.9963e+01, 3.6298e+01, 2.0290e+01, 8.1291e+01,\n",
       "                      4.4442e+01, 1.0957e+00, 1.9500e+01, 2.9422e-03, 1.6284e-05, 3.2935e+01,\n",
       "                      4.5701e+01, 7.8281e-01, 1.2535e+01, 3.1144e+00, 3.0446e-05, 2.6886e+01,\n",
       "                      2.2824e+00, 7.6351e-03, 2.0171e+01, 2.7021e+01, 3.6969e+01, 4.6365e+01,\n",
       "                      2.9408e+01, 6.3218e+01, 5.0193e+01, 3.5165e+00, 3.3551e+01, 1.7490e+00,\n",
       "                      5.5491e+00, 1.9241e+00, 4.1998e+01, 4.2981e+01, 1.3909e+02, 3.3418e+00,\n",
       "                      1.0750e+00, 4.7164e+01, 1.6881e+00, 8.2677e+01, 5.1802e+01, 2.0733e+01,\n",
       "                      4.8585e+00, 1.9436e+02, 2.3412e+01, 1.5145e+00, 2.4962e+01, 3.7320e+00,\n",
       "                      6.8598e+01, 1.8223e+00, 8.5162e-01, 1.1004e+00, 3.4016e-03, 2.5641e+01,\n",
       "                      1.8215e+00, 1.6295e-01, 3.4133e+01, 3.9829e+00, 1.2081e+02, 3.1512e+01,\n",
       "                      1.1300e+02, 1.9125e+00, 1.3236e+01, 3.9971e+01, 2.5985e+00, 9.3784e-01,\n",
       "                      2.0440e+00, 1.2347e+02, 3.4702e+01, 2.4033e+01, 7.6841e+01, 3.0921e+01,\n",
       "                      6.0887e+00, 2.1994e+01, 7.2919e+00, 4.7345e+00, 2.2195e+00, 5.9581e-01,\n",
       "                      1.0886e+00, 3.7514e-05, 1.3307e+01, 1.3043e-03, 3.7470e+01, 1.0910e+02,\n",
       "                      1.7003e-05, 8.0490e-06, 2.8339e+01, 4.1850e+01, 3.6220e+01, 2.4263e+00,\n",
       "                      2.1984e+00, 1.2689e+02, 4.0481e-01, 1.4805e+00, 3.9411e+00, 2.5872e+00,\n",
       "                      3.9754e+02, 1.2610e+00, 4.6723e+01, 2.0815e+00, 2.8205e+00, 2.4460e+01,\n",
       "                      2.6747e+01, 9.3159e+00, 1.3750e+00, 1.5944e-06, 2.6327e+01, 9.4743e-01,\n",
       "                      8.1037e-01, 4.5655e+00, 6.9705e+00, 1.7491e+00, 5.8605e+00, 8.8186e+01,\n",
       "                      2.9837e+01, 6.2743e+01, 3.1369e+01, 3.2387e+00, 1.9633e+00, 2.9595e+00,\n",
       "                      3.4697e+00, 3.1111e+00, 6.6108e-01, 1.1902e+00, 3.9808e+00, 4.3593e+01,\n",
       "                      8.0911e+01, 3.8911e+00, 1.3830e+00, 9.9508e-07, 3.4323e+00, 9.6678e+00,\n",
       "                      7.5829e-01, 3.3587e+01, 6.7272e+01, 6.6616e+01, 9.6047e+01, 2.6703e+01,\n",
       "                      3.5882e+00, 3.7865e+01, 2.3576e+00, 5.2890e+00, 1.3433e+01, 2.7918e+01,\n",
       "                      1.7271e+00, 1.3163e-01, 6.5618e+00, 1.4751e+02, 4.5318e+00, 6.9087e+00,\n",
       "                      1.1398e+00, 2.9122e+01, 1.9734e+00, 1.1269e+00, 1.1127e+00, 5.6775e+01,\n",
       "                      2.8362e+01, 4.7315e+01, 2.9229e+00, 3.8366e+01, 2.2450e+00, 4.6362e-04,\n",
       "                      5.0637e+00, 3.0928e+01, 5.1524e+01, 1.3175e+02, 5.8758e+01, 9.3782e-01,\n",
       "                      8.3053e-01, 1.9858e+00, 8.2277e+01, 1.6741e+00, 3.0137e+01, 3.6726e+02,\n",
       "                      1.9347e+01, 4.0593e+01, 3.4296e+02, 1.9135e-04, 1.0092e-03, 3.9709e+01,\n",
       "                      6.9797e+00, 4.2765e-01, 2.0956e+00, 4.3057e+01, 2.9406e+01, 6.6294e-01,\n",
       "                      1.0404e+00, 6.8784e+01, 1.1090e+01, 3.0403e+01, 2.1685e+01, 1.1768e+00,\n",
       "                      1.0386e+00, 2.3842e+00, 1.3069e+00, 6.1806e-01, 1.6528e+00, 4.0510e+01,\n",
       "                      8.5315e-01, 3.3824e+01, 2.4833e+01, 5.0912e-04, 1.5050e+00, 9.5129e-01,\n",
       "                      5.2234e+00, 1.0575e+00, 1.0162e+00, 2.0834e+00, 3.3042e+01, 2.8842e+00,\n",
       "                      5.7266e-01, 4.2490e+01, 4.0467e+01, 5.7624e+01, 9.5725e+01, 1.3837e+02,\n",
       "                      2.1010e+01, 1.8372e+01, 2.2832e+00, 1.5350e+00, 5.8484e+00, 1.5038e+00,\n",
       "                      5.0624e+01, 1.0247e+01, 3.4975e+00, 2.7042e+00, 2.3442e+01, 7.1830e+01,\n",
       "                      6.3268e+01, 9.1860e-01, 1.3927e+01, 1.8180e+00, 2.9662e+01, 1.1170e+00,\n",
       "                      2.4607e+02, 3.7610e+02, 6.8556e-01, 6.6374e+01, 8.7031e-03, 2.8661e+01,\n",
       "                      5.6562e+01, 2.8392e+01, 3.9527e+00, 1.9222e+01, 7.6643e+00, 8.8752e-01,\n",
       "                      4.3709e+01, 1.2845e+00, 1.1080e+00, 6.2072e+01, 1.6924e+01, 1.6184e+01,\n",
       "                      2.6957e+00, 1.8048e+02, 2.5888e+01, 2.3017e+00, 4.0822e+00, 1.8325e+00,\n",
       "                      9.8343e-04, 1.7331e-04, 1.6124e+01, 2.9780e+00, 3.4423e+01, 8.8640e-03,\n",
       "                      9.8025e+00, 1.2619e+00, 4.6226e+01, 6.4386e+00, 4.0392e+00, 4.8737e+01,\n",
       "                      4.2809e+01, 3.7219e+01, 6.4133e+00, 3.8637e+01, 2.8318e-01, 1.5341e+02,\n",
       "                      1.0455e+00, 2.6290e+00, 2.7220e+00, 1.0846e+01, 2.0161e+00, 1.0771e+02,\n",
       "                      2.3197e+01, 4.2418e+00, 1.9333e+01, 2.1474e+00, 5.7397e+00, 3.9218e+01,\n",
       "                      2.9328e+00, 1.1349e+02, 1.7509e+01, 1.5061e+02, 6.3843e+02, 1.8213e+00,\n",
       "                      5.3097e-05, 3.5608e+01, 3.8173e+01, 1.9672e+01, 2.1946e+02, 1.6869e+02,\n",
       "                      3.7290e+00, 3.0561e+01, 3.7801e+01, 4.5118e+00, 1.0779e+01, 3.5641e+00,\n",
       "                      1.0641e-05, 1.8253e+01, 8.6807e+01, 1.0812e-07, 2.2032e+00, 3.5257e+01,\n",
       "                      1.4043e+00, 7.7483e+01, 2.8120e+01, 1.0844e+02, 4.3601e+01, 1.5856e-03,\n",
       "                      4.1834e-04, 4.5832e+01, 1.1617e+01, 2.4267e+00, 1.4865e+01, 1.7744e+01,\n",
       "                      3.3810e+01, 4.4653e+00, 2.5576e+01, 4.7194e+01, 3.1021e+00, 3.6419e+01,\n",
       "                      8.4340e+01, 4.6497e+00, 7.4946e-01, 5.0382e+01, 1.0919e+00, 5.4124e+00,\n",
       "                      6.3985e+01, 9.2649e+01, 6.1129e-01, 3.7042e+01, 6.6117e+01, 2.0667e+00,\n",
       "                      3.8539e+00, 2.9391e+01, 4.5860e+01, 3.3993e+01, 1.0921e+02, 1.0489e+00,\n",
       "                      3.4397e+00, 3.5741e+00, 5.7012e+01, 1.6041e+02, 2.0429e+01, 1.7063e+02,\n",
       "                      3.4431e+00, 1.9653e+01, 4.8048e-03, 4.1398e+00, 1.6027e+00, 4.1432e+01,\n",
       "                      2.9050e+00, 7.8762e+01, 1.9030e+01, 3.7577e+00, 3.4421e+00, 4.1576e+01,\n",
       "                      3.2072e+01, 1.9279e+00, 5.3391e+01, 2.3532e+00, 4.0379e+02, 3.9288e+01,\n",
       "                      3.3979e+01, 1.0046e+00, 2.9031e+01, 1.4817e+00, 2.4392e+01, 6.7462e+01,\n",
       "                      5.2469e+00, 1.6996e-01, 3.0576e+00, 1.3001e+02, 3.2939e+00, 7.0346e+01,\n",
       "                      3.4982e+02, 5.1226e+02])),\n",
       "             ('batchnorm.num_batches_tracked', tensor(32315))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General dictionary mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_with_general_dictionary_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, general_dictionary_file, cfg):\n",
    "    with open(general_dictionary_file, 'r') as f:\n",
    "        dictionary_file_content = f.readlines()\n",
    "\n",
    "    fr_to_english_dict = {}\n",
    "    for line in dictionary_file_content:\n",
    "        parts = line[:-1].split(' ')  # line example: 'garçons boys\\n'\n",
    "        fr_to_english_dict[parts[0]] = parts[1]\n",
    "        \n",
    "    #print(len(fr_to_english_dict))\n",
    "        \n",
    "    fr_vocab = len(training_corpus_dct.token2id)\n",
    "    en_vocab = len(training_corpus_dct_en.token2id)\n",
    "    emb_en = model_en.state_dict()[\"embedding.weight\"]\n",
    "    emb_fr = torch.zeros((fr_vocab, cfg.WORD_EMB_SIZE))\n",
    "\n",
    "    for i in range(fr_vocab):\n",
    "        fr_word = training_corpus_dct[i]\n",
    "        if fr_word in fr_to_english_dict:\n",
    "            en_word = fr_to_english_dict[fr_word]  \n",
    "            if en_word in training_corpus_dct_en.token2id:\n",
    "                en_word_id = training_corpus_dct_en.token2id[en_word]\n",
    "                emb_fr[i,:] = emb_en[en_word_id,:]\n",
    "            else: # the most probable English word doesn't appear in the training corpus, then assign a word vector randomly\n",
    "                emb_fr[i,:] = emb_en[random.randint(0, en_vocab-1),:]\n",
    "        else:  # the French word is not included in the dictionary, then assign a word vector randomly\n",
    "            emb_fr[i,:] = emb_en[random.randint(0, en_vocab-1),:]\n",
    "\n",
    "    model_dict.update({\"embedding.weight\":emb_fr}) \n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_with_general_dictionary_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, general_dictionary_file, cfg)\n",
    "mapping_method_name = 'general-dictionary-mapping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[-0.2658,  0.0549,  0.4890,  ...,  0.0826,  0.2337,  0.7131],\n",
       "                      [-0.2111,  1.5043,  1.1583,  ..., -0.0491,  0.0518, -0.0579],\n",
       "                      [-0.6135, -0.5034,  1.0074,  ...,  1.1505,  0.5815,  0.6985],\n",
       "                      ...,\n",
       "                      [ 0.2072,  0.2672, -1.3863,  ..., -1.0217, -1.5519, -1.4724],\n",
       "                      [-0.4063,  0.2065, -1.4636,  ..., -0.2110, -0.8497,  0.4557],\n",
       "                      [-0.4537, -0.1088, -0.6727,  ..., -1.4015,  0.9618,  1.3071]])),\n",
       "             ('lstm.weight_ih_l0',\n",
       "              tensor([[-8.2271e-02, -2.6502e-02,  1.3620e-01,  ...,  1.7146e-01,\n",
       "                        1.5154e-01, -8.0110e-02],\n",
       "                      [-1.4765e-01,  7.7709e-02, -4.5470e-02,  ..., -1.7563e-01,\n",
       "                       -5.4936e-02,  1.5066e-01],\n",
       "                      [ 1.1844e-01,  5.8075e-03,  1.9253e-04,  ...,  9.0586e-02,\n",
       "                       -1.2200e-01,  2.1301e-02],\n",
       "                      ...,\n",
       "                      [ 3.5888e-01, -8.1858e-02, -6.5284e-02,  ..., -4.0579e-02,\n",
       "                        2.4097e-02,  2.1075e-01],\n",
       "                      [ 1.1874e-01,  2.2968e-01,  1.1914e-01,  ..., -1.8865e-03,\n",
       "                       -2.9639e-01, -2.0719e-01],\n",
       "                      [ 1.2594e-01, -1.1320e-01,  1.0662e-01,  ...,  7.6919e-02,\n",
       "                       -1.1031e-01, -9.1731e-02]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[ 0.2194,  0.1908, -0.0803,  ...,  0.1767,  0.0452, -0.0051],\n",
       "                      [-0.1178, -0.1192,  0.1934,  ...,  0.0464, -0.2070, -0.3033],\n",
       "                      [ 0.0826, -0.0236, -0.0321,  ..., -0.0195, -0.1177,  0.0623],\n",
       "                      ...,\n",
       "                      [ 0.1186, -0.0156,  0.1487,  ...,  0.0937,  0.0233, -0.1020],\n",
       "                      [ 0.0175, -0.0755, -0.0923,  ..., -0.0776, -0.0231,  0.0331],\n",
       "                      [ 0.0695,  0.0480,  0.1871,  ...,  0.0549, -0.2409,  0.2596]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([0.2554, 0.1750, 0.0706,  ..., 0.1238, 0.2089, 0.0962])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([0.2048, 0.2110, 0.0321,  ..., 0.0843, 0.1780, 0.0777])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-1.3531e-02, -1.1848e-01,  1.2078e-02,  ...,  2.8935e-01,\n",
       "                        5.2006e-01,  1.3240e-01],\n",
       "                      [ 5.1532e-02, -5.1827e-02, -8.8378e-02,  ...,  7.9595e-04,\n",
       "                        2.6064e-01,  2.3051e-01],\n",
       "                      [-3.1399e-04,  4.0559e-02, -1.6089e-01,  ...,  2.8618e-01,\n",
       "                       -4.5120e-01,  1.2146e-01],\n",
       "                      ...,\n",
       "                      [ 1.7859e-02, -1.3444e-01, -4.4722e-02,  ..., -2.1683e-02,\n",
       "                       -1.5643e-01,  1.1762e-01],\n",
       "                      [ 4.5331e-03,  3.3103e-02, -4.3278e-02,  ...,  7.6261e-02,\n",
       "                        5.4129e-02,  1.4174e-01],\n",
       "                      [ 2.8152e-02,  3.0245e-02,  5.5006e-02,  ...,  2.0770e-02,\n",
       "                        2.2741e-02, -4.4565e-02]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-1.5350e-01, -1.3668e-01, -1.7624e-01, -1.8935e-01,  4.4374e-02,\n",
       "                       5.8577e-02, -1.6065e-01, -1.3972e-01, -1.4403e-01, -1.8469e-01,\n",
       "                      -1.7393e-01,  2.5929e-03, -2.1059e-01, -2.6876e-03, -5.4330e-02,\n",
       "                      -5.5322e-02,  7.5502e-03, -1.1710e-01, -7.7378e-02, -7.4364e-02,\n",
       "                      -8.0652e-02, -6.1286e-02,  1.8424e-02,  2.5973e-02, -1.6902e-01,\n",
       "                      -3.1871e-02, -7.2310e-02, -1.6188e-01,  8.7697e-03, -1.5675e-01,\n",
       "                      -3.2950e-02, -2.2285e-02, -3.0631e-02, -1.5788e-01, -1.6293e-01,\n",
       "                      -1.7604e-01, -1.5516e-01, -5.1527e-02, -2.7132e-02, -1.3193e-02,\n",
       "                       1.6449e-02, -1.9822e-01, -1.5373e-01, -2.0102e-01, -1.9324e-01,\n",
       "                      -1.4015e-01, -2.2384e-01, -1.5826e-01, -1.2310e-01, -1.3940e-01,\n",
       "                      -5.6517e-01, -3.9108e-02, -1.6601e-01, -1.8011e-01,  2.5789e-03,\n",
       "                      -2.7699e-01, -1.5704e-01,  4.3695e-02, -2.4958e-01, -1.5977e-01,\n",
       "                      -1.6518e-01, -1.5995e-02, -1.2427e-02, -2.7229e-01, -4.4743e-02,\n",
       "                       4.5488e-02, -2.2504e-02, -1.4278e-01, -2.2279e-01, -3.7095e-03,\n",
       "                       8.9180e-03, -1.6039e-01, -1.7843e-02, -1.4495e-01, -3.2041e-02,\n",
       "                      -2.2840e-01, -2.2018e-01, -6.4286e-02, -2.3452e-01, -4.5656e-02,\n",
       "                      -5.4573e-02, -7.9613e-02, -8.2687e-02, -1.7561e-01, -1.7136e-01,\n",
       "                      -1.6650e-01, -1.5505e-01, -1.3681e-01, -1.1172e-01, -1.7471e-01,\n",
       "                      -1.8406e-01, -1.6769e-01, -1.9988e-01, -1.6463e-01, -1.5199e-01,\n",
       "                      -1.5894e-01, -1.2147e-01, -1.9045e-01, -1.8264e-01, -2.2107e-02,\n",
       "                      -1.9796e-01, -1.8601e-01, -2.0958e-01, -2.4878e-01, -2.8161e-02,\n",
       "                      -2.9271e-02, -6.4088e-02, -6.6982e-02,  4.3636e-03, -1.1936e-01,\n",
       "                      -1.5312e-01, -1.8285e-01, -7.2093e-02, -1.9254e-01, -1.5900e-01,\n",
       "                      -4.1352e-02, -2.0361e-01,  9.8274e-03, -2.5661e-02, -1.8314e-01,\n",
       "                       4.2460e-03, -4.7761e-01, -2.1031e-01, -5.3291e-02, -1.5485e-01,\n",
       "                      -1.5944e-01, -1.3236e-02, -5.8721e-02, -2.6642e-01, -1.4322e-01,\n",
       "                      -1.8556e-01, -2.2713e-01, -2.2515e-01, -3.5318e-02, -2.0136e-01,\n",
       "                      -8.6484e-02, -4.5261e-02, -1.7719e-01, -1.5194e-01, -8.1825e-02,\n",
       "                       6.1066e-02, -1.6875e-02, -1.0634e-01, -1.6235e-01, -3.1741e-02,\n",
       "                      -1.3256e-01, -1.8511e-01, -1.4524e-01, -2.1996e-01, -1.7203e-01,\n",
       "                      -1.5576e-01, -1.9460e-01, -2.1659e-01, -3.3081e-02, -1.4922e-01,\n",
       "                      -1.2643e-01, -1.8405e-02, -5.0146e-02, -1.3206e-01, -1.5229e-01,\n",
       "                      -2.0343e-01, -1.0132e-02, -5.0761e-02, -1.9917e-01,  3.0647e-03,\n",
       "                      -1.5031e-01, -2.4015e-01, -2.1951e-01, -2.9014e-02, -1.7570e-01,\n",
       "                      -1.6064e-01, -3.5808e-02, -1.5673e-01, -7.4531e-03, -1.2216e-01,\n",
       "                      -9.9012e-03, -4.6705e-02, -5.3088e-02, -9.4061e-02, -1.6952e-01,\n",
       "                      -6.8211e-02, -3.2472e-02, -1.7722e-01, -2.1944e-02, -3.5439e-01,\n",
       "                      -2.0666e-01, -1.8383e-01, -3.0936e-02,  3.3983e-02, -1.3386e-01,\n",
       "                       1.6573e-02, -4.3322e-02, -3.9792e-02, -2.1269e-01, -1.3534e-01,\n",
       "                      -2.2193e-01, -1.4627e-01, -1.5101e-01,  1.0130e-02,  8.6656e-02,\n",
       "                      -6.9502e-03, -3.1144e-02, -8.6167e-02, -3.1939e-02, -5.6254e-02,\n",
       "                      -4.6560e-02, -1.3873e-01, -1.6216e-01, -3.0098e-01, -2.1927e-01,\n",
       "                      -2.8719e-02, -2.0693e-01, -1.7085e-01, -2.0240e-01, -1.2623e-01,\n",
       "                      -8.2035e-02, -3.2232e-02, -2.6725e-01, -5.1466e-02, -4.8037e-02,\n",
       "                       1.2979e-02, -5.1403e-02, -5.1205e-01, -2.6405e-02, -1.6406e-01,\n",
       "                      -2.7590e-02, -3.1509e-02, -1.7123e-01, -1.5869e-01, -5.7678e-03,\n",
       "                      -4.2869e-02, -9.8121e-02, -9.5176e-02, -3.0344e-02, -1.8964e-02,\n",
       "                       2.4364e-02, -2.3356e-01, -3.2238e-02,  2.8267e-02, -1.9834e-01,\n",
       "                      -1.4597e-01, -1.4741e-01, -1.8411e-01, -1.2850e-02, -8.1743e-02,\n",
       "                      -4.0142e-02, -2.7927e-02, -2.9763e-02, -6.7642e-02, -6.5575e-02,\n",
       "                      -3.9042e-02, -2.2050e-01, -2.0642e-01, -2.7809e-02, -6.0581e-02,\n",
       "                      -1.0567e-01, -3.4514e-02, -9.3806e-03, -2.2648e-02, -2.5527e-01,\n",
       "                      -1.6970e-01, -1.5409e-01, -1.7265e-01, -1.9450e-01, -5.4704e-03,\n",
       "                      -1.4139e-01, -1.3742e-02, -1.3672e-02, -8.5522e-03, -2.2822e-01,\n",
       "                      -3.4118e-02, -7.3435e-02, -6.1664e-02, -1.7495e-01,  5.8636e-03,\n",
       "                      -2.1599e-02, -6.0500e-02, -1.5697e-01, -3.2492e-02, -3.1032e-02,\n",
       "                      -2.0304e-02, -1.8507e-01, -9.3517e-02, -1.7981e-01, -3.4291e-02,\n",
       "                      -1.8027e-01, -2.4442e-02,  1.0088e-01, -1.0068e-02, -2.0641e-01,\n",
       "                      -2.5418e-01, -3.0785e-01, -2.1228e-01, -3.8926e-02, -2.6811e-02,\n",
       "                      -3.2785e-02, -1.9086e-01, -1.3167e-02, -2.0831e-01, -1.5578e-01,\n",
       "                      -2.3053e-01, -1.5561e-01,  5.4110e-02,  8.7048e-02, -1.2492e-01,\n",
       "                      -2.1152e-01, -5.4741e-02, -5.1655e-02, -3.4360e-02, -2.4845e-01,\n",
       "                      -1.7250e-01,  1.1089e-02, -1.5379e-02, -2.1278e-01,  4.4422e-02,\n",
       "                      -1.8561e-01, -1.8226e-01, -2.8930e-02, -1.8159e-02, -4.2032e-02,\n",
       "                      -4.0426e-02, -5.9784e-02, -4.8985e-02, -1.0157e-01, -8.8918e-02,\n",
       "                      -2.4865e-01, -1.1871e-01,  1.3418e-01, -3.9417e-02, -2.3168e-02,\n",
       "                      -1.3263e-02, -4.1198e-02, -5.0836e-02, -5.2208e-02, -1.5311e-01,\n",
       "                      -2.5401e-02, -3.3811e-02, -1.0450e-01, -1.7397e-01, -2.4919e-01,\n",
       "                      -1.7290e-01, -1.2624e-01, -1.5359e-01, -1.9513e-01, -2.2641e-02,\n",
       "                      -5.3485e-02,  1.7105e-03, -5.2798e-02, -1.8175e-01,  2.8607e-02,\n",
       "                      -3.6188e-02, -1.5625e-04, -1.5248e-01, -1.2854e-01, -1.3349e-01,\n",
       "                      -7.5856e-02, -1.9724e-01,  6.9651e-04, -1.5492e-01,  3.0098e-03,\n",
       "                      -3.7499e-01, -1.5018e-01, -5.9444e-02, -1.4709e-01,  1.8810e-01,\n",
       "                      -1.8158e-01, -1.4275e-01, -1.3449e-01, -5.9478e-03, -2.0086e-01,\n",
       "                       2.8648e-03, -7.2425e-02, -1.9158e-01, -1.5488e-02, -2.2436e-02,\n",
       "                      -2.0338e-01, -2.0696e-01, -1.7018e-01, -5.4065e-02, -2.9895e-01,\n",
       "                      -1.7175e-01, -7.4188e-02,  3.2183e-03, -6.7791e-02, -1.1235e-01,\n",
       "                      -5.4820e-02, -2.2053e-01, -1.0354e-02, -1.8138e-01,  1.1004e-01,\n",
       "                      -1.3764e-01, -6.2183e-02, -1.6856e-01,  1.7962e-02, -6.8705e-02,\n",
       "                      -1.1972e-01, -1.4574e-01, -1.8620e-01, -1.0653e-02, -9.8637e-02,\n",
       "                      -4.1593e-02, -2.0689e-01, -2.7483e-02, -1.2393e-02, -6.3546e-02,\n",
       "                       5.5911e-03, -3.1846e-02, -1.4407e-01, -1.4196e-01, -3.5980e-02,\n",
       "                      -1.9061e-01, -2.2665e-02, -4.0746e-02, -2.2764e-01, -2.8095e-02,\n",
       "                      -1.4707e-01, -2.0443e-01, -1.9375e-01, -1.1269e-01, -3.1755e-02,\n",
       "                      -1.5742e-01, -2.2417e-01, -2.8592e-01, -1.1976e-04, -1.4684e-01,\n",
       "                      -2.0838e-01, -4.5753e-02, -2.7247e-01, -1.3865e-01, -8.3999e-03,\n",
       "                       3.2023e-02,  1.3440e-03,  1.8518e-02, -2.2927e-01, -1.9137e-01,\n",
       "                      -1.8418e-01, -9.2459e-03, -1.8355e-01, -7.4203e-03, -2.0658e-01,\n",
       "                      -1.3940e-01, -1.8775e-01, -1.7530e-01, -2.3366e-01, -8.8494e-02,\n",
       "                      -1.6830e-01, -2.4919e-01, -1.7980e-02, -2.0212e-01, -2.4615e-01,\n",
       "                      -1.1547e-01,  1.2699e-02, -1.6425e-01, -1.6780e-01, -2.3221e-02,\n",
       "                      -1.5806e-01,  6.9017e-02, -3.1158e-02, -3.0639e-02, -1.3762e-01,\n",
       "                      -9.1835e-02, -1.2012e-02, -1.3026e-01, -1.7594e-01, -8.3937e-02,\n",
       "                      -1.9191e-01, -1.6504e-01, -5.9432e-02, -7.9799e-02, -1.4081e-01,\n",
       "                      -2.0532e-01, -2.0691e-01, -1.6140e-01, -4.4731e-02, -2.7867e-02,\n",
       "                      -4.5116e-02, -1.8817e-01, -1.6116e-01, -2.3826e-01, -1.7587e-01,\n",
       "                       2.4856e-02, -1.4798e-01, -7.4049e-02,  9.3399e-03, -4.2828e-02,\n",
       "                      -1.8180e-01, -7.6563e-02, -1.8730e-01, -1.8554e-01, -2.1853e-02,\n",
       "                      -1.1266e-02, -1.4883e-01, -2.0201e-01, -4.0968e-02, -2.1379e-01,\n",
       "                      -2.2988e-02, -2.8720e-01, -2.4289e-01, -2.0050e-01, -5.8358e-02,\n",
       "                      -2.0255e-01, -8.8338e-02, -2.0509e-01, -1.5321e-01,  2.9711e-02,\n",
       "                      -8.7013e-02, -9.5652e-02, -1.5350e-01, -7.1536e-02, -1.4427e-01,\n",
       "                      -1.1756e-01, -7.8393e-02])),\n",
       "             ('fc_rank.weight',\n",
       "              tensor([[-1.5208e-01, -1.2868e-01, -1.2694e-01, -2.0865e-01,  2.0146e-02,\n",
       "                        4.5054e-02, -8.9351e-02, -2.7685e-01, -3.3974e-01, -2.0719e-01,\n",
       "                       -1.9640e-01,  2.4794e-02, -8.2954e-02,  4.3773e-02,  3.7726e-02,\n",
       "                        3.5356e-02,  7.1335e-02,  5.9520e-03,  4.0732e-02,  3.0064e-02,\n",
       "                        5.2796e-02,  2.5857e-02,  3.6663e-02,  7.3622e-02, -1.1180e-01,\n",
       "                       -1.1886e-02, -1.3018e-02, -1.7937e-01,  2.3277e-02, -2.1247e-01,\n",
       "                        4.7353e-02,  2.7146e-02,  2.8973e-02, -2.3658e-01, -2.3460e-01,\n",
       "                       -8.2271e-02, -6.4900e-02,  2.2642e-02,  3.4282e-02,  3.2043e-02,\n",
       "                        6.8746e-02, -1.4857e-01, -8.8111e-02, -1.6172e-01, -1.0359e-01,\n",
       "                       -4.5988e-02, -2.4441e-01, -1.4208e-01, -1.2382e-01, -1.3146e-01,\n",
       "                       -6.6572e-02,  3.3345e-02, -1.2595e-01, -3.2612e-01,  2.6722e-02,\n",
       "                       -1.9288e-01, -1.3401e-01,  2.1255e-02, -7.1126e-02, -2.4116e-01,\n",
       "                       -1.0553e-01,  5.1093e-02,  4.6723e-02,  9.9119e-02,  4.9564e-02,\n",
       "                       -2.4711e-02,  7.9027e-02, -8.5705e-02, -1.6387e-01,  7.4999e-02,\n",
       "                        2.2310e-02, -2.3483e-01,  3.3992e-02, -2.3541e-01,  5.7652e-02,\n",
       "                       -1.8926e-01, -1.9915e-01,  7.8645e-02, -1.6032e-01,  1.0105e-01,\n",
       "                        2.9346e-02, -3.9634e-02, -3.2042e-02, -1.2542e-01, -1.0847e-01,\n",
       "                       -2.2022e-01, -1.5397e-01, -8.1227e-02, -1.9959e-01, -1.0632e-01,\n",
       "                       -2.6796e-01, -1.1496e-01, -2.1565e-01, -1.0740e-01, -1.2342e-01,\n",
       "                       -2.0005e-01, -1.0741e-01, -9.4138e-02, -1.4109e-01,  4.9374e-02,\n",
       "                       -1.6934e-01, -1.4880e-01, -8.7474e-02, -2.2259e-01,  8.1771e-02,\n",
       "                        8.1696e-02,  4.0891e-02,  1.6494e-02,  5.3239e-02,  9.1929e-02,\n",
       "                       -9.2365e-02, -1.1329e-01,  4.4711e-02, -1.3983e-01, -1.4055e-01,\n",
       "                        9.5304e-02, -2.1961e-01,  9.7075e-02,  2.8914e-02, -1.2448e-01,\n",
       "                        6.6557e-02, -5.1312e-02, -1.3754e-01, -2.5299e-02, -9.4424e-02,\n",
       "                       -1.4267e-01,  3.5721e-02,  6.4956e-02, -2.3894e-01, -1.5421e-01,\n",
       "                       -2.3274e-01, -9.5475e-02, -1.7021e-01,  7.6872e-02, -1.0042e-01,\n",
       "                       -1.2267e-02, -2.2467e-02, -8.5053e-02, -2.5716e-01,  4.5514e-02,\n",
       "                        4.0077e-02,  3.0949e-02, -2.9603e-02, -1.3064e-01,  2.9492e-02,\n",
       "                       -2.2494e-02, -1.5302e-01, -1.1826e-01, -1.7578e-01, -9.8167e-02,\n",
       "                       -1.2080e-01, -1.2620e-01, -1.6158e-01,  2.3466e-02, -1.2691e-01,\n",
       "                       -7.4451e-02,  4.3622e-02,  5.0082e-02, -1.1148e-01, -2.4260e-01,\n",
       "                       -2.0755e-01,  7.0735e-02,  5.8547e-02, -2.7467e-01,  3.8522e-02,\n",
       "                       -6.8225e-02, -1.7048e-01, -2.1353e-01,  2.5356e-02, -2.2801e-01,\n",
       "                       -1.2522e-01,  8.8101e-02, -1.4638e-01,  2.9732e-02, -1.9030e-01,\n",
       "                        3.0427e-02,  8.8934e-02,  2.7320e-02,  1.6905e-02, -1.8989e-01,\n",
       "                        8.9647e-02,  4.4736e-02, -1.5400e-01,  4.7738e-02, -1.1691e-01,\n",
       "                       -1.3761e-01, -1.1143e-01,  7.0106e-02,  2.3611e-02, -2.0160e-01,\n",
       "                        3.5193e-02,  6.7442e-02,  4.8292e-02, -2.8591e-01, -6.9320e-02,\n",
       "                       -1.4438e-01, -2.4814e-01, -1.2509e-01,  3.3882e-02,  2.8817e-02,\n",
       "                        6.7288e-02,  4.6658e-02,  3.6718e-02,  3.5568e-02,  6.2967e-02,\n",
       "                       -1.8624e-02, -1.7235e-01,  3.3234e-02, -1.1540e-01, -2.2245e-01,\n",
       "                       -1.9563e-02,  3.9947e-03, -1.6430e-01, -1.7416e-01, -1.3395e-01,\n",
       "                        1.7810e-02,  3.9895e-02, -7.2726e-02,  3.5841e-02, -1.0694e-01,\n",
       "                        2.6977e-02,  4.1634e-02, -3.9792e-02,  2.7762e-02, -1.7236e-01,\n",
       "                        2.0697e-02,  2.0406e-02, -2.4252e-01, -1.6120e-01,  2.8556e-02,\n",
       "                        4.2524e-02, -9.0027e-03, -8.1547e-02,  8.1307e-02,  3.4940e-02,\n",
       "                        3.0390e-02, -1.0768e-01,  7.1774e-02,  1.8775e-02, -3.3696e-01,\n",
       "                       -1.3146e-01, -1.1817e-01, -2.1932e-01,  3.0707e-02,  6.7114e-02,\n",
       "                        4.3179e-02,  5.4870e-02,  3.0639e-02,  9.8481e-02,  8.9549e-02,\n",
       "                        4.3228e-02, -1.5279e-01, -1.3944e-01,  6.1598e-02,  7.4892e-02,\n",
       "                       -3.1648e-03,  4.8037e-02,  1.9952e-02,  4.3174e-02, -1.0681e-01,\n",
       "                       -8.1895e-02, -1.3289e-01, -3.0153e-01, -2.1601e-01,  2.8928e-02,\n",
       "                       -1.4275e-01,  3.3117e-02,  5.5026e-02,  2.6431e-02, -2.6049e-01,\n",
       "                        6.7457e-02,  4.5570e-02,  4.4486e-02, -1.2683e-01,  4.1059e-02,\n",
       "                        3.0023e-02,  5.8264e-02, -1.5234e-01,  2.7388e-02,  4.3815e-02,\n",
       "                        3.1406e-02, -9.2281e-02, -2.2308e-01, -1.7225e-01,  2.9619e-02,\n",
       "                       -2.1001e-01,  6.8453e-02, -4.9835e-02,  4.3026e-02, -1.6010e-01,\n",
       "                       -2.0607e-01, -1.4118e-01, -1.0595e-01,  4.4938e-02,  3.3273e-02,\n",
       "                        2.8077e-02, -5.0768e-02,  2.5923e-02, -1.9086e-01, -9.3134e-02,\n",
       "                       -1.1686e-01, -8.5738e-02, -5.0609e-02, -2.9115e-02, -9.1895e-02,\n",
       "                       -1.9225e-01,  6.2381e-02,  2.3264e-02,  4.5427e-02, -1.8628e-01,\n",
       "                       -9.1672e-02,  6.9610e-02,  4.1153e-02, -2.3402e-01,  4.7168e-02,\n",
       "                       -2.1703e-01, -2.0093e-01,  7.7296e-02,  3.8840e-02,  8.6140e-02,\n",
       "                        1.0935e-01,  8.9288e-02,  2.4340e-02, -1.5484e-01,  2.4417e-02,\n",
       "                       -1.7633e-01, -1.3133e-01, -2.4266e-02,  3.4828e-02,  2.2803e-02,\n",
       "                        2.4183e-02,  4.8287e-02,  5.2536e-02,  5.5118e-02, -1.5961e-01,\n",
       "                        3.6868e-02,  4.9110e-02, -1.5932e-01, -1.3982e-01, -1.8676e-01,\n",
       "                       -1.2430e-01, -1.9457e-01, -1.2587e-01, -8.1594e-02,  2.0079e-02,\n",
       "                        2.6806e-02,  3.5257e-02,  3.2891e-02, -1.3492e-01,  4.1991e-02,\n",
       "                        4.3881e-02,  2.4941e-02, -1.3177e-01, -2.3523e-01, -1.2903e-01,\n",
       "                        9.6773e-02, -1.4856e-01,  4.6607e-02, -1.5919e-01,  3.9956e-02,\n",
       "                       -7.9878e-02, -7.5418e-02,  9.2321e-02, -3.0985e-01, -5.8488e-02,\n",
       "                       -1.9788e-01, -1.8814e-01, -1.2486e-01,  6.8098e-02, -2.0914e-01,\n",
       "                        2.1637e-02,  1.9711e-02, -1.4146e-01,  2.2644e-02,  5.7708e-02,\n",
       "                       -9.7300e-02, -1.9301e-01, -9.9693e-02,  7.4168e-02, -1.1762e-01,\n",
       "                       -2.1645e-01,  5.2838e-02,  3.4707e-02,  5.7000e-02,  1.3878e-02,\n",
       "                       -4.4107e-03, -1.2236e-01,  4.6629e-02, -1.5330e-01, -3.1437e-02,\n",
       "                       -7.7253e-02,  3.2450e-02, -2.6349e-01,  1.2272e-02,  6.0353e-02,\n",
       "                       -9.9611e-02, -1.3175e-01, -1.1538e-01,  3.8518e-02, -1.8551e-01,\n",
       "                        5.4468e-02, -2.2894e-01,  6.1848e-02,  4.5322e-02,  6.0674e-02,\n",
       "                        2.3442e-02,  2.8300e-02, -2.3593e-01, -8.1880e-02,  3.0983e-02,\n",
       "                       -1.6309e-01,  2.2222e-02,  2.4968e-02, -2.8224e-01,  5.2124e-02,\n",
       "                       -1.6697e-01, -2.1075e-01, -1.4358e-01,  9.5067e-02,  5.5622e-02,\n",
       "                        1.4193e-02, -2.0105e-01, -1.2986e-01, -5.4396e-02, -2.3543e-01,\n",
       "                       -2.6100e-01,  2.6640e-02, -1.5277e-01, -2.6336e-01,  8.7545e-02,\n",
       "                        4.4974e-02,  2.5254e-02, -2.4448e-02, -1.0341e-01, -1.1355e-01,\n",
       "                       -2.1825e-02,  5.1576e-02, -1.3973e-01,  3.8885e-02, -1.5379e-01,\n",
       "                       -9.5970e-02, -1.6143e-01, -1.8640e-01,  5.5858e-02,  1.3923e-03,\n",
       "                       -1.1799e-01, -1.1804e-01,  5.1171e-02, -2.0445e-01, -1.2722e-01,\n",
       "                       -1.5386e-01,  2.5063e-02, -1.2947e-01, -1.8790e-01,  7.5192e-02,\n",
       "                       -1.5336e-01, -1.2133e-02,  1.9151e-02,  3.3896e-02, -1.7296e-01,\n",
       "                        7.3719e-02,  3.6452e-02, -1.3188e-01, -1.4005e-01,  4.8869e-02,\n",
       "                       -2.0547e-01, -2.9499e-01,  3.1174e-02,  3.8645e-02, -1.0237e-01,\n",
       "                       -1.2100e-01, -2.0373e-01, -2.2154e-01,  5.5259e-02,  4.5460e-02,\n",
       "                        4.1666e-02, -2.1433e-01, -3.0357e-01, -1.6585e-01, -2.1654e-01,\n",
       "                        4.7398e-02, -1.5108e-01, -2.4493e-04,  7.9401e-02,  2.9549e-02,\n",
       "                       -1.9420e-01,  3.5547e-02, -1.2779e-01, -1.5447e-01,  2.4059e-02,\n",
       "                        2.4143e-02, -1.2213e-01, -1.1906e-01,  8.7930e-02, -2.6791e-01,\n",
       "                        3.1829e-02, -4.1606e-02, -1.1495e-01, -2.2182e-01,  2.8038e-02,\n",
       "                       -2.6073e-01,  5.4091e-02, -1.0543e-01, -1.0658e-01,  2.0930e-02,\n",
       "                        3.0828e-02,  6.5904e-02, -1.4169e-01,  1.9053e-02, -1.8390e-01,\n",
       "                       -7.4741e-02, -9.6680e-02]])),\n",
       "             ('fc_rank.bias', tensor([-1.7595])),\n",
       "             ('batchnorm.weight',\n",
       "              tensor([ 0.8168,  0.7923,  0.9404,  0.3899,  0.4678,  0.3453,  0.9203,  0.3772,\n",
       "                       0.3389,  0.5303,  0.4620,  0.5162,  0.9382,  0.2493,  0.3042,  0.4079,\n",
       "                       0.1623,  0.1539,  0.2864,  0.6242,  0.1963,  0.4865,  0.3155,  0.1397,\n",
       "                       0.9179,  0.5414,  0.1242,  0.4616,  0.4130,  0.4243,  0.2885,  0.3167,\n",
       "                       0.4605,  0.4202,  0.2408,  0.6651,  0.7905,  0.5623,  0.2982,  0.3446,\n",
       "                       0.1105,  0.7479,  0.8682,  0.5556,  0.7572,  0.3141,  0.2846,  0.6796,\n",
       "                       0.5893,  0.7064,  0.1918,  0.5753,  0.9771,  0.2916,  0.5634,  0.5332,\n",
       "                       0.6675,  0.5159,  0.1955,  0.2674,  0.9298,  0.2515,  0.5807, -0.1264,\n",
       "                       0.2201,  0.5488,  0.1212,  0.9238,  0.7276,  0.2218,  0.4274,  0.3744,\n",
       "                       0.6300,  0.3908,  0.2659,  0.2779,  0.3983,  0.1367,  0.6607,  0.1495,\n",
       "                       0.6268,  0.3161,  0.1398,  0.8620,  0.7585,  0.3282,  0.4007,  0.8001,\n",
       "                       0.4382,  0.6340,  0.2759,  0.8397,  0.5027,  0.7547,  0.8325,  0.3762,\n",
       "                       0.9285,  0.7051,  0.6101,  0.5961,  0.4922,  0.4596,  0.8662,  0.3046,\n",
       "                       0.1813,  0.0991,  0.6119,  0.5448,  0.2687,  0.1432,  0.7802,  0.8019,\n",
       "                       0.1844,  0.5603,  0.6236,  0.1491,  0.3248,  0.1345,  0.5407,  0.7678,\n",
       "                       0.1685,  0.2817,  0.6698,  0.1289,  1.0075,  0.5749,  0.1602,  0.1608,\n",
       "                       0.2429,  0.6092,  0.3676,  0.4443,  0.4897,  0.1180,  0.8837,  0.6543,\n",
       "                       0.3612,  0.6677,  0.3812,  0.2619,  0.3442,  0.4030,  0.9517,  0.6234,\n",
       "                       0.2690,  0.5359,  0.4906,  0.6071,  0.4568,  0.8536,  0.9212,  0.8736,\n",
       "                       0.6380,  0.5048,  0.6445, -0.1056,  0.3901,  0.6814,  0.6487,  0.3952,\n",
       "                       0.2294,  0.1584,  0.4528,  0.3355,  0.3099,  0.7033,  0.3358,  0.3388,\n",
       "                       0.6912,  0.2406,  0.8687,  0.1473,  0.4919,  0.5383,  0.3903,  0.4168,\n",
       "                       0.1796,  0.5859,  0.0425,  0.4888,  0.1580,  0.2875,  0.6793,  0.2691,\n",
       "                       0.2659,  0.5003,  0.7726,  0.1190,  0.6173,  0.3773,  0.4012,  0.1875,\n",
       "                       0.2541,  0.2884,  0.9245,  0.6297,  0.3606,  0.8425,  0.4137,  0.3626,\n",
       "                       0.1203,  0.2424,  0.2254,  0.5305,  0.2980,  0.1511,  0.5632,  0.1503,\n",
       "                       0.4107,  0.4641,  0.5370,  0.6518,  0.4582,  0.4163,  0.6925,  0.5986,\n",
       "                       0.3415,  0.5374,  0.4262, -0.1162,  0.4720,  0.2253,  0.4061,  0.7935,\n",
       "                       0.7095,  0.4408,  0.5359,  0.4608,  0.4995,  0.5933,  0.2033,  0.6592,\n",
       "                       0.6727,  0.1147,  0.3838,  0.4611,  0.9341,  0.1869,  0.4966,  0.2897,\n",
       "                       0.7229,  0.6207,  0.3106,  0.2624,  0.1875,  0.3410,  0.3191,  0.4409,\n",
       "                       0.1010,  0.1182,  0.5431,  0.7041,  0.5495,  0.2069,  0.2176,  0.4156,\n",
       "                       0.2583,  0.4905,  0.3907,  0.9280,  0.8183,  0.9067,  0.3495,  0.5546,\n",
       "                       0.4695,  0.5380,  0.4786,  0.1852,  0.4358,  0.2699,  0.2147,  0.3340,\n",
       "                       0.3801,  0.7586,  0.2748,  0.5229,  0.4004,  0.6488,  0.4371,  0.3639,\n",
       "                       0.4389,  0.7055,  0.4323,  0.6183,  0.3943,  0.4830,  0.1769,  0.8612,\n",
       "                       0.4115,  0.8281,  0.2543,  0.2181,  0.8166,  0.3794,  0.3271,  0.4313,\n",
       "                       0.6806,  0.3615,  0.3136,  0.1266,  0.9415,  0.8785,  0.2569,  0.6283,\n",
       "                      -0.0967,  0.5050,  0.0934,  0.5497,  0.2641,  0.3548,  0.8930,  0.1581,\n",
       "                       0.4506,  0.3348,  0.2334,  0.3883,  0.3986,  0.1911,  0.2914,  0.1505,\n",
       "                       0.1121,  0.1430,  0.3840,  0.6905,  0.5521,  0.4033,  0.8734,  0.5298,\n",
       "                       0.3951,  0.5606,  0.4968,  0.1513,  0.1593,  0.2326,  0.5355,  0.4118,\n",
       "                       0.2050,  0.5021,  0.7496,  0.4554,  0.7116,  0.3840,  0.5712,  0.8105,\n",
       "                       0.4798,  0.5724,  0.3153,  0.3573,  0.5978,  0.2898,  0.5425,  0.4674,\n",
       "                       0.5852,  0.3597,  0.7430,  0.1172,  0.5711,  0.6218,  0.5875,  0.3621,\n",
       "                       0.2432,  0.1736,  0.1911,  0.3423,  0.7056,  0.4190,  0.3579,  0.7598,\n",
       "                       0.1492,  0.4656,  0.5281,  0.5067,  0.8619,  0.5099,  0.2289,  0.9135,\n",
       "                       0.4191,  0.7457,  0.2091,  0.1497,  0.3207,  0.3710,  0.4056,  0.1901,\n",
       "                       0.6615,  0.4596,  0.7493,  0.3265,  0.5105,  0.8986,  0.6356,  0.4228,\n",
       "                       0.2852,  0.5374,  0.1497,  0.6240,  0.8404,  0.7795,  0.3178,  0.6767,\n",
       "                       0.3145,  0.2563,  0.2547,  0.2651,  0.2758,  0.6044,  0.6183,  0.3001,\n",
       "                       0.8136,  0.3693,  0.5310,  0.6231,  0.6538,  0.3296,  0.4199,  0.5787,\n",
       "                       0.2893,  0.4625, -0.1301,  0.2378,  0.1080,  0.5874,  0.7949,  0.3305,\n",
       "                       0.3376,  0.3224,  0.3862,  0.3554,  0.4449,  0.1115,  0.1899,  0.6128,\n",
       "                       0.7763,  0.8584,  0.8034,  0.1270,  0.2687,  0.9776,  0.6373,  0.6802,\n",
       "                       0.7951,  0.5646,  0.4275,  0.1553,  0.1440,  0.8372,  0.9002,  0.1760,\n",
       "                       0.6108,  1.0235,  0.5798,  0.6071,  0.5374,  0.3698,  0.1175,  0.4592,\n",
       "                       0.6939,  0.5353,  0.5397,  0.3402,  0.1116,  0.2772,  0.8564,  0.6200,\n",
       "                       0.7735,  0.4042,  0.3311,  0.5959,  0.2634,  0.8933,  0.9568,  0.3155,\n",
       "                       0.4204,  0.2503,  0.3246,  0.3712,  0.4209,  0.2790,  0.5483,  0.3782,\n",
       "                       0.2802,  0.7500,  0.0038,  0.1448,  0.5764,  0.4364,  0.2906,  0.4889,\n",
       "                       0.7878,  0.6922,  0.4501,  0.6059,  0.7445,  0.1225,  0.2569,  0.4639,\n",
       "                       0.3048,  0.9519,  0.3279,  0.6113,  0.4191,  0.2329,  0.8241,  0.7849,\n",
       "                       0.6045,  0.6049,  0.1276,  0.4497,  0.4803,  0.4816,  0.1762,  0.1198])),\n",
       "             ('batchnorm.bias',\n",
       "              tensor([ 2.6856e-01,  3.0927e-01,  3.2250e-01,  1.1019e-01, -1.2865e-01,\n",
       "                      -4.1813e-02,  2.7891e-01,  1.5833e-01,  1.5513e-01,  1.8758e-01,\n",
       "                       2.0373e-01, -8.3961e-02,  2.5908e-01, -1.7115e-01, -4.8813e-02,\n",
       "                      -6.6992e-03, -3.2541e-02, -1.4751e-02, -1.4862e-02,  8.8922e-03,\n",
       "                      -5.9220e-02, -1.1261e-02, -1.3434e-01, -3.9400e-02,  2.5839e-01,\n",
       "                       1.2153e-02,  1.1271e-02,  1.1080e-01, -7.3989e-02,  1.2600e-01,\n",
       "                       1.2830e-02, -1.9629e-01, -4.2003e-02,  1.8175e-01,  7.9238e-02,\n",
       "                       3.7723e-01,  3.3950e-01, -6.4135e-02, -3.6043e-02, -9.1971e-02,\n",
       "                      -7.5431e-02,  3.7648e-01,  2.7384e-01,  2.4744e-01,  3.2404e-01,\n",
       "                       1.0960e-01,  1.0474e-01,  2.5330e-01,  1.8056e-01,  2.7958e-01,\n",
       "                       1.1892e-01, -4.1158e-02,  2.3688e-01,  1.3002e-01, -1.8295e-01,\n",
       "                       2.1726e-01,  1.5953e-01, -1.1882e-01,  7.6568e-02,  1.0179e-01,\n",
       "                       3.3147e-01, -7.6678e-02,  1.4673e-02, -5.5458e-02, -3.4776e-02,\n",
       "                      -3.6249e-03, -7.6332e-02,  2.2592e-01,  2.4480e-01, -2.3469e-02,\n",
       "                      -1.2282e-01,  1.0296e-01,  3.8868e-03,  1.5022e-01, -3.9363e-02,\n",
       "                       1.7745e-01,  1.7610e-01, -2.6606e-02,  2.9011e-01, -2.5475e-02,\n",
       "                       2.2888e-02,  4.8586e-02, -2.8927e-02,  3.3516e-01,  2.7126e-01,\n",
       "                       1.3339e-01,  1.3026e-01,  2.6928e-01,  2.1458e-01,  2.3329e-01,\n",
       "                       8.1707e-02,  3.3450e-01,  2.9782e-01,  2.5948e-01,  2.6186e-01,\n",
       "                       1.0350e-01,  2.7041e-01,  2.4757e-01,  3.5106e-01,  4.0868e-02,\n",
       "                       1.2223e-01,  3.1261e-01,  2.2016e-01,  9.5057e-02, -2.6980e-02,\n",
       "                      -1.1355e-01,  2.3386e-02, -2.6223e-01, -3.4427e-02, -5.2728e-02,\n",
       "                       2.8072e-01,  3.8476e-01, -3.5631e-02,  1.6585e-01,  2.1074e-01,\n",
       "                      -1.4789e-02,  1.0896e-01, -2.4367e-02, -2.2483e-02,  2.4665e-01,\n",
       "                      -2.6148e-03,  1.6652e-01,  1.9605e-01,  2.4655e-02,  2.8898e-01,\n",
       "                       1.6165e-01, -8.6826e-04, -3.3464e-02,  1.0962e-01,  2.4673e-01,\n",
       "                       9.9782e-02,  1.7955e-01,  1.8059e-01, -2.9436e-02,  2.2231e-01,\n",
       "                      -3.6969e-03, -1.4544e-02,  1.6376e-01,  1.3515e-01, -3.4833e-02,\n",
       "                      -6.7995e-02, -7.0709e-02,  8.3033e-03,  1.6333e-01, -4.2957e-02,\n",
       "                      -2.3182e-02,  1.2953e-01,  1.8421e-01,  1.6423e-01,  3.1929e-01,\n",
       "                       2.7842e-01,  3.7805e-01,  2.4979e-01, -1.6211e-01,  2.0418e-01,\n",
       "                       1.8417e-02, -6.0821e-02,  7.1757e-02,  2.0924e-01,  1.3949e-01,\n",
       "                       1.4362e-01, -3.9171e-02,  2.1138e-02,  1.0059e-01, -8.5277e-02,\n",
       "                       2.7807e-01,  1.3901e-01,  8.9149e-02,  3.6990e-02,  1.6069e-01,\n",
       "                       2.3005e-01, -2.4260e-02,  1.3854e-01, -7.1315e-02,  1.8563e-01,\n",
       "                      -9.9192e-02,  5.7674e-03, -3.0967e-03,  1.8600e-02,  1.5516e-01,\n",
       "                      -2.7339e-03, -3.7177e-02,  2.4737e-01, -6.9517e-02,  1.1231e-01,\n",
       "                       1.6077e-01,  4.5138e-01, -3.9878e-02, -7.1359e-02,  1.1811e-01,\n",
       "                      -1.3496e-01, -2.4464e-02, -4.1597e-02,  1.7177e-01,  2.9220e-01,\n",
       "                       2.0332e-01,  1.7914e-01,  2.9110e-01, -6.4403e-02, -1.9955e-01,\n",
       "                      -3.5049e-02, -6.5520e-02, -2.4045e-02,  1.6338e-02, -8.5266e-03,\n",
       "                      -1.8719e-02,  1.6202e-01, -3.4113e-02,  1.4754e-01,  2.4754e-01,\n",
       "                       2.8194e-03,  1.6135e-03,  1.7448e-01,  1.6581e-01,  2.8435e-01,\n",
       "                      -1.3789e-01, -4.1109e-02,  2.1754e-01,  1.4732e-02,  7.5918e-03,\n",
       "                      -3.5728e-02, -1.1399e-01,  1.7685e-01,  6.0791e-02,  2.7922e-01,\n",
       "                      -1.3443e-01, -1.4034e-01,  1.4061e-01,  1.3298e-01,  2.6069e-02,\n",
       "                      -2.5982e-02,  1.3333e-02,  2.0343e-01, -2.4682e-02, -4.3866e-02,\n",
       "                      -9.9521e-02,  2.0304e-01, -2.5830e-02, -1.3490e-01,  1.4140e-01,\n",
       "                       2.2295e-01,  2.8664e-01,  7.4618e-02, -7.3100e-02, -7.5497e-02,\n",
       "                      -7.1344e-02,  7.6933e-03, -8.4373e-02, -1.4548e-02, -4.4191e-03,\n",
       "                       2.7140e-02,  2.9379e-01,  2.4027e-01, -1.4002e-02,  3.0464e-03,\n",
       "                       6.8616e-03, -1.8378e-02, -3.0047e-01, -1.3232e-02,  4.0095e-01,\n",
       "                       3.5408e-01,  4.3403e-01,  1.7050e-01,  2.1555e-01, -1.0473e-01,\n",
       "                       1.9448e-01, -7.8460e-03, -8.7963e-02, -2.0444e-01,  7.6497e-02,\n",
       "                      -8.7418e-02,  6.1583e-03,  3.8794e-02,  4.5999e-01, -1.3545e-01,\n",
       "                      -5.5704e-02, -4.9838e-03,  1.8145e-01, -5.1178e-02, -2.7029e-02,\n",
       "                      -7.4478e-03,  2.9989e-01,  1.2574e-01,  2.0003e-01, -7.6309e-02,\n",
       "                       1.7387e-01, -4.6775e-02,  2.5688e-02,  1.0909e-02,  2.5152e-01,\n",
       "                       1.0467e-01,  1.3540e-01,  3.0997e-01, -2.5951e-02, -8.4452e-02,\n",
       "                      -6.2370e-02,  2.8588e-01, -6.8832e-02,  9.6593e-02,  5.5573e-02,\n",
       "                       3.3050e-01,  2.6257e-01,  6.0510e-02, -1.8038e-02, -1.0077e-02,\n",
       "                       1.6790e-01, -7.1435e-02, -2.9266e-02, -2.5735e-02,  1.4998e-01,\n",
       "                       3.0129e-01, -1.7990e-02, -1.8004e-02,  1.5658e-01, -7.9340e-02,\n",
       "                       1.4055e-01,  9.3265e-02, -2.4881e-02, -1.1337e-01, -3.6162e-02,\n",
       "                      -2.8333e-02, -1.7541e-02, -2.0531e-01,  2.4553e-01, -8.1918e-02,\n",
       "                       1.4006e-01,  2.6177e-01,  1.1245e-02, -6.6041e-02,  1.7554e-02,\n",
       "                      -1.1356e-01, -7.9010e-03, -4.2250e-02, -4.5378e-02,  2.0531e-01,\n",
       "                      -2.2297e-02, -2.3714e-02,  1.7299e-01,  3.1834e-01,  2.4103e-01,\n",
       "                       4.1730e-01,  1.9381e-01,  1.1455e-01,  2.0352e-01, -1.2525e-01,\n",
       "                      -7.1242e-02, -6.3358e-02, -1.2270e-01,  1.9830e-01, -1.0049e-01,\n",
       "                       2.5949e-02,  4.1722e-02,  1.6740e-01,  1.8773e-01,  3.1792e-01,\n",
       "                      -1.9210e-02,  1.3510e-01,  3.3930e-02,  2.0267e-01, -2.4989e-02,\n",
       "                       1.1014e-01,  4.6547e-02,  4.6709e-03,  1.4427e-01, -7.7965e-03,\n",
       "                       1.0023e-01,  1.6399e-01,  2.3031e-01, -6.1112e-02,  1.1622e-01,\n",
       "                      -8.1313e-02, -4.4910e-02,  3.3849e-01, -1.5949e-02,  5.7958e-03,\n",
       "                       3.2546e-01,  1.0420e-01,  2.1561e-01, -3.8243e-02,  5.1317e-02,\n",
       "                       1.1605e-01, -2.1470e-02, -4.5477e-02, -9.4693e-02, -2.1820e-02,\n",
       "                      -1.0552e-02,  2.0561e-01, -1.3027e-02,  1.6626e-01,  2.8202e-02,\n",
       "                       1.2352e-01, -8.8986e-02,  1.0768e-01, -3.2983e-01, -8.2187e-02,\n",
       "                       2.7285e-01,  3.1788e-01,  2.9308e-01, -1.1922e-01,  2.3179e-01,\n",
       "                       1.1787e-02,  1.5627e-01, -5.4614e-03, -6.3809e-02, -2.8136e-02,\n",
       "                      -1.7824e-01, -6.7102e-02,  1.8550e-01,  2.2655e-01, -1.0233e-01,\n",
       "                       1.3963e-01, -9.6534e-03, -8.0557e-02,  9.9271e-02, -3.4456e-03,\n",
       "                       3.1160e-01,  6.2674e-02,  2.6852e-01, -2.5312e-02, -9.3132e-03,\n",
       "                      -1.6575e-02,  1.6351e-01,  3.0982e-01,  6.4524e-02,  2.2990e-01,\n",
       "                       1.9243e-01, -1.6074e-01,  9.3028e-02,  1.6068e-01, -8.9357e-02,\n",
       "                      -1.6876e-01, -6.4591e-02,  6.7283e-03,  2.3316e-01,  3.5723e-01,\n",
       "                      -2.2927e-02, -4.8483e-02,  3.5769e-01,  6.0529e-03,  3.2630e-01,\n",
       "                       2.7239e-01,  3.0888e-01,  1.2189e-01, -9.4757e-03,  3.6190e-03,\n",
       "                       3.6985e-01,  2.3060e-01, -8.0466e-02,  1.7366e-01,  2.4625e-01,\n",
       "                       1.6220e-01, -1.0220e-01,  1.7258e-01,  1.5241e-01, -1.0690e-01,\n",
       "                       1.8189e-01,  5.9309e-03, -9.9538e-02, -1.2347e-02,  1.4488e-01,\n",
       "                      -2.2883e-02, -1.1215e-01,  3.6971e-01,  3.4377e-01,  3.7454e-02,\n",
       "                       1.0293e-01,  1.4580e-01,  2.7452e-02, -6.5214e-02,  2.8402e-01,\n",
       "                       4.2789e-01,  7.3494e-02,  2.2136e-01, -3.2487e-02,  2.4683e-03,\n",
       "                      -1.2009e-02,  1.9547e-01,  1.5785e-01,  1.3010e-01,  2.1159e-01,\n",
       "                      -9.8648e-02,  1.8942e-01, -1.2731e-04, -3.9489e-02, -5.6775e-03,\n",
       "                       1.4659e-01, -5.9194e-02,  2.3659e-01,  2.5243e-01, -1.7155e-02,\n",
       "                      -4.6603e-02,  1.6346e-01,  1.9457e-01, -5.8816e-02,  9.1039e-02,\n",
       "                      -8.6085e-02,  8.8464e-02,  3.3208e-01,  1.2057e-01, -1.6693e-04,\n",
       "                       1.3743e-01, -1.7904e-02,  2.2657e-01,  3.3055e-01, -2.1172e-01,\n",
       "                       1.7273e-02, -8.2132e-02,  2.3530e-01, -1.5380e-01,  2.4048e-01,\n",
       "                       1.0204e-01,  4.4816e-02])),\n",
       "             ('batchnorm.running_mean',\n",
       "              tensor([2.0628e+00, 2.5637e+00, 2.3246e+00, 1.8503e+00, 4.8040e-01, 6.7406e-01,\n",
       "                      2.4180e+00, 3.0123e+00, 3.7543e+00, 2.1828e+00, 3.8467e+00, 1.9526e-01,\n",
       "                      1.4846e+00, 8.1235e-01, 6.8736e-02, 6.6111e-02, 2.4329e-01, 7.7975e-04,\n",
       "                      2.9077e-02, 1.7110e-01, 2.6616e-01, 4.3634e-02, 9.1123e-01, 4.1325e-01,\n",
       "                      1.7360e+00, 9.5780e-04, 1.2112e-03, 8.7910e-01, 2.3157e-01, 1.6506e+00,\n",
       "                      1.2572e-01, 2.8136e-01, 4.1132e-01, 3.5591e+00, 3.0962e+00, 9.2111e+00,\n",
       "                      5.0820e+00, 4.0282e-01, 2.7502e-01, 2.5751e-01, 1.5932e+00, 4.6581e+00,\n",
       "                      2.5862e+00, 4.1882e+00, 4.2120e+00, 7.4607e+01, 2.0331e+00, 3.1065e+00,\n",
       "                      1.8000e+00, 3.5824e+00, 4.0402e+01, 3.5387e-01, 1.3411e+00, 3.6185e+00,\n",
       "                      6.9030e-01, 2.3912e+00, 1.1213e+00, 6.6742e-01, 7.1362e+01, 3.3832e+00,\n",
       "                      2.6569e+00, 4.8315e-01, 1.1611e-01, 7.1224e+01, 1.7807e-01, 1.6793e-03,\n",
       "                      2.8794e-01, 1.0287e+00, 1.8738e+00, 1.6759e-01, 2.5086e-01, 2.4726e+00,\n",
       "                      5.6351e-02, 2.1412e+00, 1.3173e-01, 9.9576e+00, 4.1195e+00, 1.2916e-01,\n",
       "                      3.2761e+00, 3.7310e-01, 2.5039e-01, 6.7297e+01, 6.4034e-05, 2.5913e+00,\n",
       "                      3.5124e+00, 3.0474e+00, 2.4695e+00, 2.2359e+00, 3.8031e+00, 3.3639e+00,\n",
       "                      2.0860e+00, 3.3569e+00, 4.9924e+00, 2.2085e+00, 1.5587e+00, 1.9553e+00,\n",
       "                      1.4497e+00, 3.0942e+00, 6.7476e+00, 1.6306e-01, 1.4959e+00, 1.2471e+01,\n",
       "                      1.3447e+00, 2.7539e+00, 2.6331e-01, 7.1102e-01, 1.9942e-01, 2.3889e-01,\n",
       "                      2.3108e-01, 4.3062e-01, 2.9124e+00, 4.4902e+00, 1.0426e-01, 1.4707e+00,\n",
       "                      2.5765e+00, 2.5627e-01, 2.1121e+00, 1.8559e-01, 2.5636e-01, 2.3793e+00,\n",
       "                      9.1452e-02, 3.2326e+01, 2.0832e+00, 9.7098e-07, 1.8612e+00, 1.4914e+00,\n",
       "                      2.6122e-02, 1.5232e-01, 5.7460e+00, 2.5902e+00, 1.3607e+00, 5.8833e+00,\n",
       "                      3.2453e+00, 1.2730e-01, 1.4598e+00, 8.1279e-04, 8.1209e-06, 2.0569e+00,\n",
       "                      2.9130e+00, 9.2444e-02, 1.2047e+00, 3.2979e-01, 1.9067e-05, 1.6454e+00,\n",
       "                      2.3249e-01, 1.2919e-03, 1.3334e+00, 1.9417e+00, 2.5654e+00, 3.0954e+00,\n",
       "                      1.8990e+00, 3.8534e+00, 3.2478e+00, 3.5269e-01, 1.9395e+00, 1.4101e-01,\n",
       "                      6.1685e-01, 1.8239e-01, 2.5636e+00, 2.8004e+00, 9.8554e+00, 3.2321e-01,\n",
       "                      1.2183e-01, 2.4435e+00, 2.2246e-01, 5.0379e+00, 3.4763e+00, 1.3456e+00,\n",
       "                      5.6006e-01, 1.2180e+01, 1.3724e+00, 2.0319e-01, 1.5208e+00, 3.8710e-01,\n",
       "                      4.5964e+00, 1.7966e-01, 8.2714e-02, 1.3660e-01, 6.0271e-04, 1.6573e+00,\n",
       "                      1.9636e-01, 2.2347e-02, 2.2404e+00, 4.3780e-01, 8.0942e+00, 2.0315e+00,\n",
       "                      7.0842e+00, 2.3253e-01, 1.2126e+00, 2.0677e+00, 3.0953e-01, 1.0603e-01,\n",
       "                      2.8023e-01, 7.9868e+00, 2.4101e+00, 1.7214e+00, 5.1571e+00, 2.3296e+00,\n",
       "                      6.0562e-01, 1.8350e+00, 5.4419e-01, 5.4966e-01, 2.1502e-01, 5.9613e-02,\n",
       "                      1.0996e-01, 1.4730e-05, 1.0127e+00, 4.5947e-04, 2.8322e+00, 5.7921e+00,\n",
       "                      9.9293e-06, 3.6899e-06, 2.1099e+00, 3.0023e+00, 2.6983e+00, 3.0595e-01,\n",
       "                      2.1936e-01, 8.1442e+00, 4.7869e-02, 1.6848e-01, 3.8933e-01, 3.4186e-01,\n",
       "                      3.0601e+01, 1.5377e-01, 2.8089e+00, 2.5275e-01, 3.3907e-01, 1.6856e+00,\n",
       "                      1.5012e+00, 8.2052e-01, 1.4036e-01, 7.8416e-07, 1.7388e+00, 1.1288e-01,\n",
       "                      9.6383e-02, 5.3894e-01, 5.8255e-01, 2.2413e-01, 5.4274e-01, 4.7514e+00,\n",
       "                      1.7570e+00, 4.3019e+00, 1.8803e+00, 3.0232e-01, 2.7694e-01, 3.3001e-01,\n",
       "                      3.6493e-01, 3.8705e-01, 6.8601e-02, 1.0845e-01, 4.6052e-01, 3.1232e+00,\n",
       "                      4.7747e+00, 3.7595e-01, 1.6458e-01, 6.7933e-07, 3.6180e-01, 1.0282e+00,\n",
       "                      8.6166e-02, 2.8846e+00, 4.3098e+00, 4.4268e+00, 5.1736e+00, 1.9862e+00,\n",
       "                      4.1829e-01, 2.7061e+00, 2.7110e-01, 6.5361e-01, 1.2022e+00, 1.9120e+00,\n",
       "                      2.1908e-01, 1.0016e-02, 6.0055e-01, 7.8229e+00, 5.7316e-01, 7.4197e-01,\n",
       "                      1.2172e-01, 1.8311e+00, 2.5432e-01, 1.4368e-01, 1.0455e-01, 3.9295e+00,\n",
       "                      1.7169e+00, 2.6518e+00, 2.9128e-01, 2.5847e+00, 2.7254e-01, 1.9479e-04,\n",
       "                      5.2495e-01, 1.8594e+00, 3.7320e+00, 1.1284e+01, 3.4778e+00, 1.0999e-01,\n",
       "                      1.2091e-01, 2.0449e-01, 5.5340e+00, 1.8558e-01, 2.2543e+00, 5.6634e+01,\n",
       "                      1.8257e+00, 2.6289e+00, 7.1747e+01, 5.4560e-05, 1.4120e-04, 2.5426e+00,\n",
       "                      6.8328e-01, 5.7318e-02, 2.0835e-01, 3.5858e+00, 2.1664e+00, 6.9220e-02,\n",
       "                      1.1820e-01, 4.0302e+00, 1.0770e+00, 2.4050e+00, 1.4250e+00, 1.4983e-01,\n",
       "                      1.3444e-01, 2.2161e-01, 1.4820e-01, 6.4679e-02, 2.0956e-01, 2.4641e+00,\n",
       "                      9.1096e-02, 2.6495e+00, 1.5644e+00, 9.2486e-05, 1.8971e-01, 1.0431e-01,\n",
       "                      5.0264e-01, 1.0471e-01, 1.1207e-01, 2.4483e-01, 2.5092e+00, 3.2428e-01,\n",
       "                      6.8825e-02, 2.5590e+00, 2.8250e+00, 4.4063e+00, 6.4675e+00, 7.1799e+00,\n",
       "                      1.2118e+00, 1.5103e+00, 2.8946e-01, 1.8845e-01, 5.5972e-01, 2.1121e-01,\n",
       "                      2.8345e+00, 1.0390e+00, 3.7267e-01, 2.0151e-01, 1.6420e+00, 4.9613e+00,\n",
       "                      4.0635e+00, 8.2755e-02, 8.7671e-01, 1.5314e-01, 1.9971e+00, 1.5123e-01,\n",
       "                      1.7338e+01, 6.3991e+01, 8.2055e-02, 3.9496e+00, 1.2717e-03, 1.7258e+00,\n",
       "                      3.5285e+00, 1.9070e+00, 4.5942e-01, 1.2675e+00, 7.0841e-01, 9.9200e-02,\n",
       "                      2.8165e+00, 1.4895e-01, 1.0856e-01, 3.3423e+00, 1.2078e+00, 1.2373e+00,\n",
       "                      2.9214e-01, 1.4789e+01, 1.9312e+00, 2.8028e-01, 3.9173e-01, 2.4701e-01,\n",
       "                      3.2142e-04, 6.3783e-05, 1.3011e+00, 3.1368e-01, 2.1420e+00, 1.4875e-03,\n",
       "                      7.0244e-01, 1.4409e-01, 2.9654e+00, 7.2730e-01, 4.3725e-01, 3.4217e+00,\n",
       "                      2.6429e+00, 2.5926e+00, 6.5382e-01, 2.4738e+00, 3.5947e-02, 8.2733e+00,\n",
       "                      1.2497e-01, 3.7313e-01, 3.1706e-01, 9.6717e-01, 2.5038e-01, 7.3847e+00,\n",
       "                      1.6571e+00, 5.1909e-01, 1.3709e+00, 2.2771e-01, 6.2359e-01, 2.2515e+00,\n",
       "                      3.3616e-01, 6.1238e+00, 1.3238e+00, 8.7232e+00, 9.0593e+01, 1.8728e-01,\n",
       "                      2.7570e-05, 1.7974e+00, 2.8355e+00, 1.6167e+00, 1.0878e+01, 8.6799e+00,\n",
       "                      4.3070e-01, 2.0520e+00, 2.5063e+00, 5.3185e-01, 1.1652e+00, 3.3852e-01,\n",
       "                      3.7205e-06, 1.2956e+00, 4.5365e+00, 4.4449e-07, 2.5244e-01, 2.4430e+00,\n",
       "                      1.7599e-01, 4.4261e+00, 1.8810e+00, 6.0510e+00, 2.4763e+00, 6.1698e-04,\n",
       "                      7.6396e-05, 3.3812e+00, 9.7611e-01, 2.7461e-01, 1.0421e+00, 1.0774e+00,\n",
       "                      1.9754e+00, 4.9959e-01, 1.9676e+00, 3.0547e+00, 3.7281e-01, 2.9642e+00,\n",
       "                      1.8673e+01, 4.3903e-01, 8.7182e-02, 3.6143e+00, 1.1699e-01, 5.3439e-01,\n",
       "                      3.9241e+00, 5.7152e+00, 7.7126e-02, 1.8708e+00, 4.2618e+00, 1.9737e-01,\n",
       "                      4.4442e-01, 1.9007e+00, 3.2023e+00, 2.0387e+00, 6.1368e+00, 1.3879e-01,\n",
       "                      3.1535e-01, 3.3940e-01, 3.9688e+00, 8.3413e+00, 1.2427e+00, 8.2305e+00,\n",
       "                      3.3410e-01, 1.3218e+00, 1.1052e-03, 3.7568e-01, 1.8371e-01, 1.9929e+00,\n",
       "                      3.1345e-01, 5.6100e+00, 1.3506e+00, 3.9796e-01, 3.2257e-01, 2.2738e+00,\n",
       "                      1.5892e+00, 2.4894e-01, 3.2121e+00, 2.6926e-01, 5.3698e+01, 2.3228e+00,\n",
       "                      2.4749e+00, 1.4464e-01, 2.0010e+00, 1.4463e-01, 1.5080e+00, 3.6959e+00,\n",
       "                      5.5271e-01, 1.9713e-02, 3.7062e-01, 7.3036e+00, 3.3163e-01, 4.7515e+00,\n",
       "                      7.2474e+01, 7.9814e+01])),\n",
       "             ('batchnorm.running_var',\n",
       "              tensor([3.5456e+01, 3.4688e+01, 4.4976e+01, 2.9879e+01, 4.6702e+00, 6.9521e+00,\n",
       "                      3.7243e+01, 4.6709e+01, 5.8808e+01, 3.3780e+01, 5.7459e+01, 1.7717e+00,\n",
       "                      2.2298e+01, 6.9972e+00, 5.3253e-01, 5.5253e-01, 2.1208e+00, 5.2887e-03,\n",
       "                      3.0103e-01, 1.6686e+00, 2.3601e+00, 3.9969e-01, 8.4175e+00, 4.1109e+00,\n",
       "                      2.7206e+01, 4.6210e-03, 8.9952e-03, 1.1838e+01, 2.4068e+00, 2.4930e+01,\n",
       "                      1.2342e+00, 1.9298e+00, 4.0157e+00, 5.9794e+01, 5.3878e+01, 1.5482e+02,\n",
       "                      6.5154e+01, 3.6841e+00, 2.8988e+00, 2.4730e+00, 1.9887e+01, 8.4197e+01,\n",
       "                      3.7108e+01, 5.9503e+01, 6.8953e+01, 4.5149e+02, 3.0451e+01, 5.0945e+01,\n",
       "                      2.7639e+01, 4.8185e+01, 4.2525e+02, 3.2454e+00, 2.6228e+01, 5.1962e+01,\n",
       "                      7.0992e+00, 3.1161e+01, 1.6948e+01, 5.8380e+00, 5.3705e+02, 5.5542e+01,\n",
       "                      3.9819e+01, 4.6868e+00, 9.6128e-01, 4.8095e+02, 1.7153e+00, 1.0439e-02,\n",
       "                      2.4519e+00, 1.4287e+01, 2.6130e+01, 1.1697e+00, 2.2539e+00, 4.4052e+01,\n",
       "                      4.1832e-01, 3.1627e+01, 1.2854e+00, 1.4546e+02, 6.0389e+01, 1.1422e+00,\n",
       "                      5.3123e+01, 3.3833e+00, 2.3614e+00, 4.7174e+02, 2.4746e-04, 3.6430e+01,\n",
       "                      6.1572e+01, 4.4990e+01, 3.2878e+01, 2.5795e+01, 5.8808e+01, 4.6109e+01,\n",
       "                      3.6696e+01, 5.8204e+01, 7.4639e+01, 2.8386e+01, 2.6350e+01, 3.0850e+01,\n",
       "                      1.8447e+01, 4.1959e+01, 1.1205e+02, 1.3964e+00, 2.0684e+01, 2.1794e+02,\n",
       "                      2.5300e+01, 4.5613e+01, 2.6884e+00, 7.1934e+00, 2.0578e+00, 2.0490e+00,\n",
       "                      1.9511e+00, 4.2560e+00, 3.9549e+01, 7.4003e+01, 1.1439e+00, 2.0018e+01,\n",
       "                      4.0479e+01, 2.4120e+00, 3.1890e+01, 1.8216e+00, 2.3723e+00, 4.2134e+01,\n",
       "                      8.0602e-01, 4.0921e+02, 3.4245e+01, 4.2097e-06, 3.0785e+01, 2.3072e+01,\n",
       "                      2.8868e-01, 1.5495e+00, 8.9963e+01, 3.6298e+01, 2.0290e+01, 8.1291e+01,\n",
       "                      4.4442e+01, 1.0957e+00, 1.9500e+01, 2.9422e-03, 1.6284e-05, 3.2935e+01,\n",
       "                      4.5701e+01, 7.8281e-01, 1.2535e+01, 3.1144e+00, 3.0446e-05, 2.6886e+01,\n",
       "                      2.2824e+00, 7.6351e-03, 2.0171e+01, 2.7021e+01, 3.6969e+01, 4.6365e+01,\n",
       "                      2.9408e+01, 6.3218e+01, 5.0193e+01, 3.5165e+00, 3.3551e+01, 1.7490e+00,\n",
       "                      5.5491e+00, 1.9241e+00, 4.1998e+01, 4.2981e+01, 1.3909e+02, 3.3418e+00,\n",
       "                      1.0750e+00, 4.7164e+01, 1.6881e+00, 8.2677e+01, 5.1802e+01, 2.0733e+01,\n",
       "                      4.8585e+00, 1.9436e+02, 2.3412e+01, 1.5145e+00, 2.4962e+01, 3.7320e+00,\n",
       "                      6.8598e+01, 1.8223e+00, 8.5162e-01, 1.1004e+00, 3.4016e-03, 2.5641e+01,\n",
       "                      1.8215e+00, 1.6295e-01, 3.4133e+01, 3.9829e+00, 1.2081e+02, 3.1512e+01,\n",
       "                      1.1300e+02, 1.9125e+00, 1.3236e+01, 3.9971e+01, 2.5985e+00, 9.3784e-01,\n",
       "                      2.0440e+00, 1.2347e+02, 3.4702e+01, 2.4033e+01, 7.6841e+01, 3.0921e+01,\n",
       "                      6.0887e+00, 2.1994e+01, 7.2919e+00, 4.7345e+00, 2.2195e+00, 5.9581e-01,\n",
       "                      1.0886e+00, 3.7514e-05, 1.3307e+01, 1.3043e-03, 3.7470e+01, 1.0910e+02,\n",
       "                      1.7003e-05, 8.0490e-06, 2.8339e+01, 4.1850e+01, 3.6220e+01, 2.4263e+00,\n",
       "                      2.1984e+00, 1.2689e+02, 4.0481e-01, 1.4805e+00, 3.9411e+00, 2.5872e+00,\n",
       "                      3.9754e+02, 1.2610e+00, 4.6723e+01, 2.0815e+00, 2.8205e+00, 2.4460e+01,\n",
       "                      2.6747e+01, 9.3159e+00, 1.3750e+00, 1.5944e-06, 2.6327e+01, 9.4743e-01,\n",
       "                      8.1037e-01, 4.5655e+00, 6.9705e+00, 1.7491e+00, 5.8605e+00, 8.8186e+01,\n",
       "                      2.9837e+01, 6.2743e+01, 3.1369e+01, 3.2387e+00, 1.9633e+00, 2.9595e+00,\n",
       "                      3.4697e+00, 3.1111e+00, 6.6108e-01, 1.1902e+00, 3.9808e+00, 4.3593e+01,\n",
       "                      8.0911e+01, 3.8911e+00, 1.3830e+00, 9.9508e-07, 3.4323e+00, 9.6678e+00,\n",
       "                      7.5829e-01, 3.3587e+01, 6.7272e+01, 6.6616e+01, 9.6047e+01, 2.6703e+01,\n",
       "                      3.5882e+00, 3.7865e+01, 2.3576e+00, 5.2890e+00, 1.3433e+01, 2.7918e+01,\n",
       "                      1.7271e+00, 1.3163e-01, 6.5618e+00, 1.4751e+02, 4.5318e+00, 6.9087e+00,\n",
       "                      1.1398e+00, 2.9122e+01, 1.9734e+00, 1.1269e+00, 1.1127e+00, 5.6775e+01,\n",
       "                      2.8362e+01, 4.7315e+01, 2.9229e+00, 3.8366e+01, 2.2450e+00, 4.6362e-04,\n",
       "                      5.0637e+00, 3.0928e+01, 5.1524e+01, 1.3175e+02, 5.8758e+01, 9.3782e-01,\n",
       "                      8.3053e-01, 1.9858e+00, 8.2277e+01, 1.6741e+00, 3.0137e+01, 3.6726e+02,\n",
       "                      1.9347e+01, 4.0593e+01, 3.4296e+02, 1.9135e-04, 1.0092e-03, 3.9709e+01,\n",
       "                      6.9797e+00, 4.2765e-01, 2.0956e+00, 4.3057e+01, 2.9406e+01, 6.6294e-01,\n",
       "                      1.0404e+00, 6.8784e+01, 1.1090e+01, 3.0403e+01, 2.1685e+01, 1.1768e+00,\n",
       "                      1.0386e+00, 2.3842e+00, 1.3069e+00, 6.1806e-01, 1.6528e+00, 4.0510e+01,\n",
       "                      8.5315e-01, 3.3824e+01, 2.4833e+01, 5.0912e-04, 1.5050e+00, 9.5129e-01,\n",
       "                      5.2234e+00, 1.0575e+00, 1.0162e+00, 2.0834e+00, 3.3042e+01, 2.8842e+00,\n",
       "                      5.7266e-01, 4.2490e+01, 4.0467e+01, 5.7624e+01, 9.5725e+01, 1.3837e+02,\n",
       "                      2.1010e+01, 1.8372e+01, 2.2832e+00, 1.5350e+00, 5.8484e+00, 1.5038e+00,\n",
       "                      5.0624e+01, 1.0247e+01, 3.4975e+00, 2.7042e+00, 2.3442e+01, 7.1830e+01,\n",
       "                      6.3268e+01, 9.1860e-01, 1.3927e+01, 1.8180e+00, 2.9662e+01, 1.1170e+00,\n",
       "                      2.4607e+02, 3.7610e+02, 6.8556e-01, 6.6374e+01, 8.7031e-03, 2.8661e+01,\n",
       "                      5.6562e+01, 2.8392e+01, 3.9527e+00, 1.9222e+01, 7.6643e+00, 8.8752e-01,\n",
       "                      4.3709e+01, 1.2845e+00, 1.1080e+00, 6.2072e+01, 1.6924e+01, 1.6184e+01,\n",
       "                      2.6957e+00, 1.8048e+02, 2.5888e+01, 2.3017e+00, 4.0822e+00, 1.8325e+00,\n",
       "                      9.8343e-04, 1.7331e-04, 1.6124e+01, 2.9780e+00, 3.4423e+01, 8.8640e-03,\n",
       "                      9.8025e+00, 1.2619e+00, 4.6226e+01, 6.4386e+00, 4.0392e+00, 4.8737e+01,\n",
       "                      4.2809e+01, 3.7219e+01, 6.4133e+00, 3.8637e+01, 2.8318e-01, 1.5341e+02,\n",
       "                      1.0455e+00, 2.6290e+00, 2.7220e+00, 1.0846e+01, 2.0161e+00, 1.0771e+02,\n",
       "                      2.3197e+01, 4.2418e+00, 1.9333e+01, 2.1474e+00, 5.7397e+00, 3.9218e+01,\n",
       "                      2.9328e+00, 1.1349e+02, 1.7509e+01, 1.5061e+02, 6.3843e+02, 1.8213e+00,\n",
       "                      5.3097e-05, 3.5608e+01, 3.8173e+01, 1.9672e+01, 2.1946e+02, 1.6869e+02,\n",
       "                      3.7290e+00, 3.0561e+01, 3.7801e+01, 4.5118e+00, 1.0779e+01, 3.5641e+00,\n",
       "                      1.0641e-05, 1.8253e+01, 8.6807e+01, 1.0812e-07, 2.2032e+00, 3.5257e+01,\n",
       "                      1.4043e+00, 7.7483e+01, 2.8120e+01, 1.0844e+02, 4.3601e+01, 1.5856e-03,\n",
       "                      4.1834e-04, 4.5832e+01, 1.1617e+01, 2.4267e+00, 1.4865e+01, 1.7744e+01,\n",
       "                      3.3810e+01, 4.4653e+00, 2.5576e+01, 4.7194e+01, 3.1021e+00, 3.6419e+01,\n",
       "                      8.4340e+01, 4.6497e+00, 7.4946e-01, 5.0382e+01, 1.0919e+00, 5.4124e+00,\n",
       "                      6.3985e+01, 9.2649e+01, 6.1129e-01, 3.7042e+01, 6.6117e+01, 2.0667e+00,\n",
       "                      3.8539e+00, 2.9391e+01, 4.5860e+01, 3.3993e+01, 1.0921e+02, 1.0489e+00,\n",
       "                      3.4397e+00, 3.5741e+00, 5.7012e+01, 1.6041e+02, 2.0429e+01, 1.7063e+02,\n",
       "                      3.4431e+00, 1.9653e+01, 4.8048e-03, 4.1398e+00, 1.6027e+00, 4.1432e+01,\n",
       "                      2.9050e+00, 7.8762e+01, 1.9030e+01, 3.7577e+00, 3.4421e+00, 4.1576e+01,\n",
       "                      3.2072e+01, 1.9279e+00, 5.3391e+01, 2.3532e+00, 4.0379e+02, 3.9288e+01,\n",
       "                      3.3979e+01, 1.0046e+00, 2.9031e+01, 1.4817e+00, 2.4392e+01, 6.7462e+01,\n",
       "                      5.2469e+00, 1.6996e-01, 3.0576e+00, 1.3001e+02, 3.2939e+00, 7.0346e+01,\n",
       "                      3.4982e+02, 5.1226e+02])),\n",
       "             ('batchnorm.num_batches_tracked', tensor(32315))])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data-specific dictionary mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_with_specific_dictionary_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, specific_dictionary_file, cfg):\n",
    "    with open(specific_dictionary_file, 'r') as f:\n",
    "        dictionary_file_content = f.readlines()\n",
    "\n",
    "    fr_to_english_dict = {}\n",
    "    for line in dictionary_file_content:\n",
    "        parts = line[:-1].split(' ')  # line example: 'focus intérêt 1.0000000\\n'\n",
    "        if parts[1] in fr_to_english_dict:\n",
    "            fr_to_english_dict[parts[1]].append((parts[0], float(parts[2]))) \n",
    "        else:\n",
    "            fr_to_english_dict[parts[1]] = [(parts[0], float(parts[2])),]\n",
    "    \n",
    "    fr_vocab = len(training_corpus_dct.token2id)\n",
    "    en_vocab = len(training_corpus_dct_en.token2id)\n",
    "    emb_en = model_en.state_dict()[\"embedding.weight\"]\n",
    "    emb_fr = torch.zeros((fr_vocab, cfg.WORD_EMB_SIZE))\n",
    "\n",
    "    from operator import itemgetter\n",
    "    emb_fr = torch.zeros((fr_vocab, cfg.WORD_EMB_SIZE))\n",
    "    for i in range(fr_vocab):\n",
    "        fr_word = training_corpus_dct[i]\n",
    "        if fr_word in fr_to_english_dict:\n",
    "            en_words = fr_to_english_dict[training_corpus_dct[i]] \n",
    "            most_probable_word = max(en_words ,key=itemgetter(1))[0] \n",
    "            if most_probable_word in training_corpus_dct_en.token2id:\n",
    "                most_probable_word_id = training_corpus_dct_en.token2id[most_probable_word]\n",
    "                emb_fr[i,:] = emb_en[most_probable_word_id,:]\n",
    "            else: # the most probable English word doesn't appear in the training corpus, then assign a word vector randomly\n",
    "                emb_fr[i,:] = emb_en[random.randint(0, en_vocab-1),:]\n",
    "        else:  # the French word is not included in the dictionary, then assign a word vector randomly\n",
    "            emb_fr[i,:] = emb_en[random.randint(0, en_vocab-1),:]\n",
    "\n",
    "    model_dict.update({\"embedding.weight\":emb_fr}) \n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_with_specific_dictionary_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, specific_dictionary_file, cfg)\n",
    "mapping_method_name = 'specific-dictionary-mapping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[-0.0883, -2.0011, -0.0120,  ..., -0.6942, -0.4052,  0.6851],\n",
       "                      [-1.1616, -0.4044, -0.7676,  ...,  0.4761,  0.7653, -0.2832],\n",
       "                      [ 0.9664, -0.7332, -0.4540,  ..., -0.2169,  0.2373,  0.6230],\n",
       "                      ...,\n",
       "                      [ 0.7155, -1.1885,  2.2836,  ..., -0.1535, -0.1503,  0.6213],\n",
       "                      [ 1.9670,  2.1834, -0.2799,  ..., -0.5885, -0.9022,  0.7944],\n",
       "                      [ 0.5293, -1.4683,  0.1948,  ...,  0.6403,  0.9529,  1.4447]])),\n",
       "             ('lstm.weight_ih_l0',\n",
       "              tensor([[-0.0512,  0.0411,  0.0453,  ..., -0.0619,  0.1240, -0.0714],\n",
       "                      [ 0.1037,  0.0532, -0.1620,  ..., -0.0452,  0.0265, -0.1414],\n",
       "                      [ 0.0513, -0.0808, -0.0294,  ..., -0.1921, -0.0320, -0.0887],\n",
       "                      ...,\n",
       "                      [ 0.0155, -0.0932,  0.0118,  ...,  0.1192, -0.0158,  0.0475],\n",
       "                      [-0.1830, -0.0217,  0.1311,  ...,  0.0062, -0.0633, -0.0942],\n",
       "                      [ 0.0346,  0.0523,  0.0663,  ..., -0.1833,  0.1532, -0.1337]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-0.0297, -0.0894,  0.0724,  ...,  0.0756, -0.0841, -0.0651],\n",
       "                      [ 0.0949,  0.0570,  0.0391,  ...,  0.0820, -0.2257,  0.1743],\n",
       "                      [ 0.0880,  0.0672,  0.0773,  ..., -0.0064, -0.0006, -0.0990],\n",
       "                      ...,\n",
       "                      [ 0.0939,  0.0442,  0.1249,  ..., -0.1698, -0.0206, -0.0310],\n",
       "                      [ 0.0597, -0.0308, -0.0672,  ..., -0.0822, -0.0718,  0.2376],\n",
       "                      [-0.0992, -0.0623, -0.1139,  ..., -0.0358, -0.2093,  0.0688]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([ 0.0408,  0.0678, -0.0664,  ..., -0.0339, -0.0782, -0.0694])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([ 0.0225,  0.0794, -0.0518,  ..., -0.0231, -0.0311, -0.0304])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0953, -0.0443, -0.0284,  ..., -0.0365,  0.1162, -0.1964],\n",
       "                      [-0.0228, -0.0413, -0.0138,  ..., -0.0266,  0.0698, -0.0554],\n",
       "                      [-0.0591, -0.0014,  0.1901,  ...,  0.0229,  0.0583, -0.0190],\n",
       "                      ...,\n",
       "                      [-0.1423, -0.0622,  0.0036,  ...,  0.0337,  0.0640,  0.0023],\n",
       "                      [ 0.0262,  0.0120, -0.0229,  ...,  0.0229, -0.0123, -0.0972],\n",
       "                      [ 0.1148, -0.1269,  0.0256,  ..., -0.0292,  0.0070,  0.0229]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.2484, -0.0970, -0.3423, -0.1425, -0.0345, -0.1170, -0.0793, -0.1452,\n",
       "                      -0.1512, -0.1889, -0.1858, -0.0890, -0.1203, -0.2160, -0.0831, -0.0773,\n",
       "                      -0.1259, -0.0817, -0.0892, -0.0505, -0.1092, -0.1113, -0.0572, -0.1263,\n",
       "                      -0.0324, -0.1002, -0.2795, -0.0713, -0.0928,  0.0477,  0.1634, -0.2789,\n",
       "                      -0.1511, -0.2138,  0.0365, -0.0080, -0.0226, -0.0119, -0.1665,  0.0693,\n",
       "                      -0.0568, -0.1237, -0.0020, -0.0415, -0.1750, -0.0965,  0.0060,  0.0256,\n",
       "                      -0.3199, -0.0015, -0.1191, -0.0705, -0.1525, -0.1055, -0.0538,  0.0221,\n",
       "                      -0.1279, -0.1503, -0.2341, -0.1607, -0.0987, -0.0675, -0.0670, -0.0674,\n",
       "                      -0.0878, -0.0367, -0.0933, -0.0618, -0.1887,  0.0374,  0.1311, -0.0879,\n",
       "                      -0.1431, -0.1836, -0.0868, -0.2619, -0.0726, -0.1418, -0.0660,  0.1069,\n",
       "                      -0.1201, -0.3026, -0.1191, -0.1333, -0.0423, -0.0857, -0.0533, -0.1359,\n",
       "                      -0.3286, -0.0488, -0.1006, -0.1125, -0.0367, -0.0062,  0.0507, -0.0310,\n",
       "                      -0.1554, -0.1436, -0.3174, -0.1187, -0.1732, -0.0149, -0.1000, -0.0576,\n",
       "                      -0.1265, -0.1010, -0.2488, -0.0416, -0.1480, -0.0954, -0.2913, -0.0754,\n",
       "                       0.0045,  0.0761, -0.2004, -0.1671, -0.0967, -0.2461, -0.0082,  0.0063,\n",
       "                      -0.3405, -0.1369, -0.0779, -0.1020, -0.1527, -0.0517, -0.1426, -0.0491,\n",
       "                      -0.0908, -0.0446, -0.2342, -0.2448, -0.2127,  0.0234, -0.1448, -0.0181,\n",
       "                      -0.1198, -0.0907, -0.1005, -0.0689, -0.2744, -0.0075, -0.1203,  0.0409,\n",
       "                      -0.0413, -0.0975, -0.0450, -0.0369, -0.1226,  0.0274, -0.1511, -0.0939,\n",
       "                      -0.0756,  0.0271, -0.2213, -0.0060, -0.0914, -0.2429, -0.0565, -0.0336,\n",
       "                      -0.0470, -0.0754,  0.0139, -0.0263, -0.2339,  0.0281, -0.1889, -0.0597,\n",
       "                      -0.1443, -0.0958, -0.1081, -0.1155, -0.0687, -0.2397, -0.2810, -0.1703,\n",
       "                      -0.3088, -0.0209, -0.0433, -0.1131, -0.1108,  0.0012, -0.1430, -0.3027,\n",
       "                      -0.0775, -0.1417, -0.0737, -0.0520,  0.0315, -0.0803,  0.0176, -0.0442,\n",
       "                      -0.0682, -0.2553, -0.2531, -0.0829, -0.0276, -0.1194,  0.0148, -0.1857,\n",
       "                      -0.2666, -0.0480, -0.3621, -0.0882, -0.0147, -0.2551, -0.1500, -0.0486,\n",
       "                      -0.0958, -0.2242, -0.0874, -0.1455, -0.0014, -0.1377, -0.0013, -0.0246,\n",
       "                       0.2377, -0.2160, -0.2806, -0.0783, -0.1260,  0.1047,  0.2421, -0.1700,\n",
       "                      -0.0120,  0.0226, -0.1255, -0.2882, -0.0632, -0.0293, -0.2397, -0.1857,\n",
       "                       0.0224, -0.1979, -0.0061, -0.1260, -0.1362, -0.2702, -0.1277, -0.0307,\n",
       "                      -0.2202, -0.2860, -0.1557, -0.1722, -0.0349, -0.2120, -0.1252, -0.0451,\n",
       "                      -0.1193, -0.0682, -0.0755, -0.1498, -0.1026,  0.1231, -0.3420, -0.1876,\n",
       "                      -0.0162, -0.1027, -0.2171, -0.0790, -0.0745, -0.0747,  0.1085, -0.0739,\n",
       "                       0.0362,  0.0561, -0.0499,  0.0055, -0.1140,  0.2535, -0.1606, -0.1627,\n",
       "                      -0.0299, -0.0327, -0.0453, -0.0930, -0.0546, -0.0200, -0.2515, -0.0330,\n",
       "                      -0.1211, -0.0787, -0.0583, -0.1175, -0.1368, -0.0603, -0.0491, -0.0694,\n",
       "                      -0.1056, -0.0662,  0.0213, -0.2204, -0.0873,  0.0238, -0.0764, -0.0799,\n",
       "                      -0.1676, -0.0415, -0.0106, -0.0792, -0.1058, -0.0663,  0.1037, -0.0379,\n",
       "                      -0.0671, -0.1743, -0.0089, -0.0895, -0.0622, -0.1913, -0.1542, -0.0547,\n",
       "                      -0.1398,  0.0375, -0.0173, -0.0947, -0.1023, -0.0469, -0.0676,  0.0261,\n",
       "                       0.0015, -0.0356, -0.0581, -0.0300,  0.1233, -0.2323, -0.1710, -0.0892,\n",
       "                      -0.1420, -0.2856, -0.1858, -0.0680, -0.3979, -0.1120, -0.2476, -0.0695,\n",
       "                      -0.1465, -0.0687,  0.0099, -0.3368, -0.0628, -0.1007, -0.2731, -0.0506,\n",
       "                      -0.1419, -0.2824, -0.0762, -0.1287, -0.1148, -0.1658, -0.2742, -0.0079,\n",
       "                      -0.0982, -0.1938, -0.0781, -0.0931, -0.0940, -0.0476, -0.0594, -0.0852,\n",
       "                      -0.1904, -0.1952, -0.0398, -0.1903, -0.0518, -0.1465, -0.0720, -0.1644,\n",
       "                      -0.1233,  0.0828, -0.0626,  0.0088, -0.1160, -0.1365, -0.1067, -0.1408,\n",
       "                      -0.0781, -0.0869, -0.1108, -0.0044, -0.0680, -0.1224, -0.1012, -0.1385,\n",
       "                      -0.0934, -0.0280, -0.0769, -0.0303, -0.1447, -0.0291, -0.3379, -0.0655,\n",
       "                       0.0324, -0.1183, -0.1015, -0.1378, -0.0602, -0.1535, -0.0171, -0.0748,\n",
       "                      -0.1413, -0.1016, -0.1443, -0.0103, -0.0836, -0.1499, -0.0805, -0.1613,\n",
       "                      -0.0703, -0.0675, -0.1676, -0.0512, -0.1919, -0.0482, -0.0772, -0.0868,\n",
       "                      -0.1924, -0.3188, -0.1288, -0.1800, -0.1121, -0.1103,  0.0187, -0.0468,\n",
       "                      -0.1961, -0.0253, -0.0850,  0.0127, -0.1388, -0.1273, -0.1702, -0.0613,\n",
       "                      -0.1057, -0.1727, -0.1199, -0.0943, -0.1004, -0.2355,  0.0095, -0.1892,\n",
       "                      -0.0262, -0.3431, -0.1430, -0.0174, -0.0024, -0.0570, -0.3087, -0.1618,\n",
       "                      -0.0646,  0.0543, -0.2149, -0.1254, -0.1496, -0.1177, -0.1112,  0.2071,\n",
       "                      -0.0872, -0.1202, -0.1041, -0.2916, -0.1008, -0.1391, -0.1152, -0.0894,\n",
       "                      -0.0748,  0.0305, -0.0790, -0.1105,  0.0512, -0.1052, -0.2471, -0.0740,\n",
       "                      -0.1538, -0.0587,  0.0167, -0.2293, -0.1868, -0.0080, -0.0805, -0.0708,\n",
       "                      -0.2237, -0.3088, -0.1573, -0.3384, -0.0912, -0.3074, -0.0679, -0.0962,\n",
       "                      -0.1764, -0.1506, -0.1647, -0.0822, -0.1009, -0.0146, -0.0346, -0.1623,\n",
       "                      -0.1035, -0.2110,  0.0452, -0.1346, -0.0522, -0.1299, -0.0176, -0.0034,\n",
       "                      -0.0821, -0.2333, -0.0388, -0.0289, -0.1493, -0.1191, -0.1187, -0.3156])),\n",
       "             ('fc_rank.weight',\n",
       "              tensor([[-2.0015e-02,  1.8432e-03,  2.6302e-02, -1.0846e-04,  9.6639e-03,\n",
       "                        1.8415e-03,  2.5366e-02,  2.0318e-02, -3.5270e-02,  1.9251e-02,\n",
       "                       -3.7442e-02,  1.9477e-03, -2.1483e-02,  4.3168e-02, -9.2513e-04,\n",
       "                        1.1174e-03, -4.3654e-03,  1.6537e-02,  2.5312e-03,  7.8040e-03,\n",
       "                        5.5865e-03,  3.9724e-02, -1.9484e-02, -3.2410e-03, -2.0331e-02,\n",
       "                        4.4651e-03,  4.2267e-02, -1.8659e-02,  1.5759e-04, -1.3901e-02,\n",
       "                       -3.4262e-02,  1.9079e-02, -5.4943e-03,  2.8920e-02, -3.1611e-02,\n",
       "                       -3.3291e-02, -1.3631e-02, -4.3907e-03,  3.0536e-02, -2.4107e-02,\n",
       "                       -5.4155e-04, -1.6163e-02, -3.8707e-03, -3.7142e-02,  2.6015e-04,\n",
       "                       -7.9374e-04,  1.7172e-02, -2.6525e-02,  3.3726e-02, -1.5000e-02,\n",
       "                        2.0157e-02,  3.9586e-02,  3.6072e-02,  1.7111e-03, -1.2621e-02,\n",
       "                       -1.6629e-02,  3.4693e-03, -6.9095e-03,  1.5063e-02,  4.3120e-02,\n",
       "                       -3.7831e-03,  2.8720e-02, -3.1454e-02,  1.4446e-02,  4.0606e-02,\n",
       "                       -1.4240e-02,  3.5776e-02, -4.9682e-03,  2.4400e-02, -1.4586e-02,\n",
       "                       -1.6060e-02, -7.3309e-03,  2.3040e-02,  2.5882e-02,  4.3900e-04,\n",
       "                        2.2453e-02, -2.5961e-02,  3.5732e-03, -6.3213e-04, -3.2615e-02,\n",
       "                        6.3731e-03,  2.6511e-02, -4.2581e-03,  3.2412e-03, -7.8336e-03,\n",
       "                        3.2110e-02, -1.4035e-02,  1.9353e-02,  9.3562e-03, -3.0518e-02,\n",
       "                        2.4024e-04, -1.5850e-02, -1.6887e-02, -1.4649e-02, -2.3472e-02,\n",
       "                        1.4748e-02, -3.4253e-02,  3.4860e-02,  3.9760e-02, -3.9902e-19,\n",
       "                       -4.5550e-03, -2.4021e-02,  9.7061e-03, -5.9025e-03,  1.4399e-02,\n",
       "                        1.2305e-03,  1.2943e-02, -1.2550e-02, -1.7975e-04, -4.4746e-03,\n",
       "                        1.9416e-02,  7.3313e-03, -2.8342e-02, -2.0048e-02,  3.5668e-02,\n",
       "                        1.9995e-02, -2.4513e-04,  3.5320e-02, -1.3957e-02, -3.9937e-02,\n",
       "                        4.9905e-02,  1.0634e-03,  1.9388e-02, -7.1028e-03, -3.2986e-02,\n",
       "                        2.0933e-03,  4.6417e-02, -2.2558e-03,  1.9535e-03, -3.5629e-02,\n",
       "                        1.2378e-02,  3.2455e-02,  3.8755e-02, -2.6068e-02, -3.9376e-02,\n",
       "                        2.5665e-02, -2.5791e-12,  1.2627e-02, -9.7862e-04, -2.6121e-02,\n",
       "                        1.8275e-02, -3.0625e-02,  2.2641e-02, -1.5852e-02,  1.0344e-07,\n",
       "                        3.6454e-02, -1.1462e-03, -1.6360e-03, -3.4674e-03, -1.5700e-02,\n",
       "                        2.4613e-03, -4.7912e-03,  3.9881e-03, -3.7809e-02,  1.6141e-02,\n",
       "                       -2.5208e-02, -2.0658e-03,  2.4098e-02, -1.8354e-02, -2.5929e-02,\n",
       "                        3.8527e-02, -5.2064e-04,  4.4614e-03, -1.4570e-02,  1.5495e-02,\n",
       "                        1.8937e-02,  2.0168e-02, -3.5464e-02,  1.9827e-02,  1.3151e-03,\n",
       "                        1.8037e-03,  2.0248e-03, -2.0585e-02,  2.5886e-02,  2.8745e-02,\n",
       "                       -3.5857e-04,  3.2200e-02, -1.1621e-02,  4.2407e-04, -2.6062e-04,\n",
       "                       -3.3759e-02, -2.0581e-02,  2.2962e-03,  1.9214e-02, -3.5401e-03,\n",
       "                        1.7598e-02, -3.3474e-03,  9.0367e-04, -3.1085e-02,  1.5818e-02,\n",
       "                       -1.1139e-02,  5.5686e-08, -3.3008e-02,  2.6647e-02,  3.0271e-02,\n",
       "                       -3.0178e-02, -4.8683e-03, -3.5159e-02, -2.1412e-02,  4.1068e-02,\n",
       "                        2.9590e-02, -1.9880e-02,  2.5388e-02, -1.7612e-02, -2.3402e-02,\n",
       "                        3.6272e-02, -1.9602e-03,  1.7546e-02, -3.4833e-03,  2.8683e-02,\n",
       "                        3.2068e-02,  2.5628e-03, -1.3859e-03,  4.0897e-02, -3.0240e-02,\n",
       "                       -1.1162e-02, -3.4474e-02, -7.0414e-03,  2.1806e-02,  3.2538e-02,\n",
       "                        3.4616e-10, -2.2336e-02, -3.2187e-02, -2.1285e-03, -2.2984e-03,\n",
       "                       -1.5420e-02,  2.1471e-03,  3.5955e-02, -4.3249e-02,  7.1731e-04,\n",
       "                        3.1948e-02,  6.8761e-03, -1.0037e-02, -1.1015e-03, -3.1168e-02,\n",
       "                        3.2575e-02,  3.8796e-03,  4.4245e-02,  3.3295e-02,  1.8369e-02,\n",
       "                        4.1243e-02,  1.3003e-02, -1.7556e-02,  2.3606e-02, -1.6011e-02,\n",
       "                        4.4324e-02,  9.4069e-04,  2.0673e-02,  2.8225e-02, -2.9648e-02,\n",
       "                       -3.3123e-03,  3.5530e-02,  3.0239e-04, -2.4929e-02,  4.0934e-02,\n",
       "                        1.3614e-02, -6.1306e-03,  6.1356e-16,  1.6512e-02, -3.4607e-02,\n",
       "                        1.1435e-03,  3.9694e-03, -2.2371e-02, -1.3119e-02, -3.8633e-02,\n",
       "                       -2.8210e-02, -1.3493e-03, -2.4615e-02, -6.8108e-03, -2.6455e-02,\n",
       "                        2.0126e-02, -1.3577e-02,  8.2126e-03,  1.1185e-02, -8.9898e-03,\n",
       "                       -3.2259e-02, -3.0694e-02,  3.5637e-03,  3.8881e-02,  1.7342e-03,\n",
       "                       -2.9371e-02, -1.7702e-02,  2.1632e-03, -8.9268e-03, -2.1027e-04,\n",
       "                       -1.9188e-02,  6.3729e-03, -3.3621e-02,  3.4051e-03, -7.2467e-05,\n",
       "                       -2.3776e-02,  3.0356e-02, -2.4272e-02, -3.2595e-02, -2.9812e-04,\n",
       "                        3.3714e-02,  3.3796e-02,  5.2652e-03, -1.2162e-02,  2.8071e-03,\n",
       "                        5.2706e-03,  3.9817e-04, -2.1216e-02,  7.3666e-04,  2.0860e-03,\n",
       "                        1.8295e-02, -3.5730e-02,  9.7953e-03, -1.6939e-03, -2.5586e-02,\n",
       "                       -2.9627e-02, -1.7634e-02, -1.7692e-02, -2.6633e-02, -3.3500e-02,\n",
       "                       -4.2243e-20,  3.2715e-02, -1.7421e-02,  3.4241e-02, -2.5882e-02,\n",
       "                       -1.6606e-02, -7.2485e-03,  6.4745e-03,  4.7639e-03, -3.1269e-02,\n",
       "                        1.2646e-03, -4.9929e-03,  3.3329e-02, -5.2055e-03,  2.4012e-02,\n",
       "                        3.2940e-02,  8.1706e-03,  4.6059e-02,  1.1995e-02,  1.9049e-02,\n",
       "                        3.1852e-03,  2.4748e-02, -3.8098e-02, -1.9398e-02,  3.9679e-02,\n",
       "                       -3.7179e-03, -3.2224e-03,  3.6296e-02,  9.5988e-03,  2.9679e-02,\n",
       "                        2.7464e-02,  5.7881e-03,  2.4336e-02,  4.2414e-02,  1.2166e-02,\n",
       "                        2.9114e-02, -1.8104e-02, -6.4564e-03, -4.4368e-02,  3.8481e-02,\n",
       "                        4.5094e-03,  2.2196e-03, -2.3948e-02,  5.8125e-04, -2.3675e-03,\n",
       "                        3.8728e-02,  2.1118e-02,  1.7571e-03,  1.7816e-02, -3.6297e-02,\n",
       "                        9.6137e-03, -7.8903e-04,  3.5850e-02, -9.6457e-03, -2.8663e-02,\n",
       "                       -2.8325e-02, -2.7903e-02,  4.3883e-03,  6.3760e-04, -1.2989e-21,\n",
       "                        2.3416e-03,  4.8175e-03, -7.2374e-06, -2.3319e-04, -3.7952e-02,\n",
       "                        4.4198e-23, -1.2660e-02,  3.2243e-02, -1.5444e-02, -2.0811e-04,\n",
       "                       -7.8683e-03, -2.9705e-02, -3.3393e-03,  3.9887e-03, -2.3858e-02,\n",
       "                        4.2822e-02, -3.1511e-02, -2.9862e-02, -2.8330e-02,  2.3886e-02,\n",
       "                       -2.8437e-03,  1.7968e-02,  6.2271e-03, -3.4559e-02,  2.2321e-02,\n",
       "                       -8.0348e-03,  7.9191e-03,  4.8791e-03, -1.9848e-02,  1.3583e-04,\n",
       "                        1.4565e-02,  3.0079e-02,  1.8923e-17,  2.9419e-03, -3.7500e-03,\n",
       "                        3.6784e-02, -1.6348e-02,  2.9025e-02,  1.6867e-03,  3.7324e-04,\n",
       "                       -2.9645e-03,  3.3094e-02,  4.0738e-02,  3.6252e-02, -3.5757e-02,\n",
       "                       -1.6114e-02,  1.1784e-02, -5.8706e-03, -1.6298e-02, -3.5936e-02,\n",
       "                        1.6599e-03,  2.0033e-02,  3.2733e-02, -2.6463e-02,  1.7747e-02,\n",
       "                       -5.5692e-03, -2.1873e-02,  4.5575e-03, -9.7574e-05,  3.1071e-02,\n",
       "                        2.4572e-03, -1.9243e-02,  3.9315e-02, -2.0953e-02, -2.5718e-03,\n",
       "                       -3.0735e-02,  4.6396e-02, -2.9111e-03,  2.4174e-02, -2.2369e-02,\n",
       "                       -2.0285e-02,  3.8740e-02,  2.5452e-02, -3.0551e-02, -2.5050e-02,\n",
       "                        3.6906e-02,  1.8708e-03, -1.0826e-02, -4.0078e-02, -1.6674e-03,\n",
       "                       -2.5414e-02, -3.0117e-02, -5.8480e-04,  1.0952e-02,  1.8164e-02,\n",
       "                       -1.7891e-02,  2.8777e-03,  6.5272e-04, -8.9961e-03, -1.1011e-06,\n",
       "                       -3.7967e-02, -2.4466e-03, -2.9851e-03, -2.1299e-02,  2.5492e-02,\n",
       "                        3.5516e-02,  3.4720e-04,  2.4937e-02,  2.8691e-18, -5.0126e-03,\n",
       "                        3.8441e-02,  1.4758e-02, -1.6606e-02, -1.5617e-02, -1.8634e-03,\n",
       "                       -1.2191e-02,  3.8211e-02,  3.2916e-03,  2.8376e-02, -2.6124e-02,\n",
       "                        1.5724e-02,  1.2779e-10, -3.7347e-03,  2.3775e-02, -1.6062e-02,\n",
       "                       -1.3981e-04,  7.2862e-04, -3.6227e-03,  1.0661e-02, -5.7883e-03,\n",
       "                        7.3168e-04,  3.4703e-02,  4.6457e-02, -3.7531e-02,  7.9994e-04,\n",
       "                        2.0075e-02,  2.0390e-02, -1.7667e-02, -2.5597e-02, -3.2396e-02,\n",
       "                        2.9568e-02, -4.3597e-03, -3.8132e-02,  1.4470e-02, -4.4075e-02,\n",
       "                       -9.9847e-03,  2.1937e-02]])),\n",
       "             ('fc_rank.bias', tensor([-4.6522])),\n",
       "             ('batchnorm.weight',\n",
       "              tensor([ 0.0580,  0.6417,  0.1053,  0.0669,  0.0247,  0.5738,  0.0746,  0.1314,\n",
       "                       0.0539,  0.1331,  0.0517,  0.6082,  0.0514,  0.0576, -0.0304,  0.0092,\n",
       "                       0.1522,  0.0895,  0.4464,  0.1982,  0.0090,  0.0573,  0.0390,  0.0669,\n",
       "                       0.1019,  0.0627,  0.0513,  0.8267,  0.4456,  0.1425,  0.0451,  0.1530,\n",
       "                       0.3552,  0.0914,  0.0516,  0.0611,  0.0454,  0.4073,  0.0844,  0.0371,\n",
       "                       0.7048,  0.0679,  0.0353, -0.0439,  0.0510,  0.2788,  0.0958,  0.0774,\n",
       "                       0.0876,  0.1322,  0.1300, -0.0759,  0.0598,  0.2556, -0.0315,  0.1177,\n",
       "                       0.5484,  0.0662,  0.1746,  0.0619,  0.0951,  0.0612,  0.0708,  0.0919,\n",
       "                       0.0569,  0.0627,  0.0511,  0.3739,  0.1304,  0.1429,  0.1090,  0.1777,\n",
       "                       0.1137,  0.1070,  0.0485,  0.1224,  0.0829, -0.0098,  0.5145,  0.0594,\n",
       "                       0.0279,  0.0453,  0.4685,  0.2026,  0.1836,  0.0853,  0.1480,  0.1128,\n",
       "                       0.2345,  0.0655,  0.0414,  0.0688,  0.1273,  0.1289,  0.0688,  0.3289,\n",
       "                       0.0653,  0.0666,  0.0694,  0.5819,  0.1474,  0.0922,  0.6983,  0.8988,\n",
       "                       0.2289,  0.7163,  0.2284,  0.0392,  0.6593,  0.5719,  0.1270,  0.5095,\n",
       "                       0.0729,  0.1063,  0.0613,  0.1593,  0.0056,  0.0625,  0.1536,  0.0494,\n",
       "                       0.0530,  0.4780,  0.1224,  0.3906,  0.0624,  0.3029,  0.0550,  0.6807,\n",
       "                       0.3894,  0.0506,  0.2342,  0.0908,  0.0613,  0.0658,  0.0476,  0.0712,\n",
       "                       0.2992,  0.1660,  0.2164,  0.0891,  0.1528,  0.0677,  0.1234,  0.1280,\n",
       "                       0.5975,  0.0646,  0.0029, -0.0462,  0.1962,  0.1336,  0.0227,  0.6378,\n",
       "                       0.3962, -0.0460,  0.1817,  0.0760,  0.1423,  0.1126, -0.0336,  0.0878,\n",
       "                       0.0457,  0.0570,  0.1704,  0.1502,  0.1811,  0.0984,  0.1386,  0.0505,\n",
       "                       0.1485,  0.1670,  0.1564,  0.7420,  0.0983,  0.1018,  0.1042,  0.0756,\n",
       "                       0.0727,  0.8130,  0.2809,  0.8033,  0.0538,  0.0691,  0.2735,  0.1591,\n",
       "                       0.3336,  0.1349,  0.8925,  0.0895,  0.0479,  0.0318,  0.1562,  0.7143,\n",
       "                       0.0557,  0.1018,  0.0785,  0.0659,  0.1124,  0.0640,  0.0378,  0.0648,\n",
       "                       0.0865,  0.0938,  0.0927,  0.1293,  0.0797,  0.0680,  0.0872, -0.0423,\n",
       "                       0.3560,  0.0988,  0.0645,  0.6075,  0.2136,  0.0588,  0.0676,  0.0833,\n",
       "                       0.0518, -0.0225,  0.1476,  0.0578,  0.7737,  0.0799,  0.0511,  0.0109,\n",
       "                       0.1299,  0.1240,  0.7321,  0.0841, -0.0486,  0.5149,  0.0900,  0.6660,\n",
       "                       0.1599,  0.4891,  0.0701,  0.0653,  0.0537,  0.0683,  0.0599, -0.0441,\n",
       "                       0.0626,  0.1764,  0.0860,  0.1185,  0.1342, -0.0549,  0.8432,  0.1255,\n",
       "                       0.1097,  0.0363,  0.1003,  0.0601,  0.1040,  0.0653,  0.0728,  0.2229,\n",
       "                       0.0228, -0.0024,  0.1695,  0.0521,  0.0768,  0.4639,  0.0756,  0.6964,\n",
       "                       0.0591,  0.0686, -0.0246,  0.0768,  0.3140,  0.0623,  0.1694,  0.0621,\n",
       "                       0.4386,  0.1884, -0.0181,  0.0659,  0.0742,  0.4199,  0.0731,  0.0513,\n",
       "                       0.0622,  0.1181,  0.3390,  0.2543,  0.2128,  0.0664,  0.3180,  0.0575,\n",
       "                       0.6098,  0.7625,  0.0788,  0.0770,  0.0715,  0.0563,  0.6845,  0.0680,\n",
       "                       0.0772,  0.0286,  0.1525,  0.0639,  0.0212,  0.1773,  0.0905,  0.0602,\n",
       "                       0.0292,  0.1565,  0.0483,  0.0356,  0.2356,  0.0899,  0.0720,  0.4702,\n",
       "                       0.0497,  0.0659,  0.0489,  0.5335,  0.0846,  0.1353,  0.0473,  0.0807,\n",
       "                       0.1171,  0.4957,  0.6054, -0.0088,  0.0547,  0.2337,  0.8549,  0.0728,\n",
       "                       0.2629,  0.1176,  0.0817,  0.1721,  0.0616,  0.1957,  0.1470,  0.2344,\n",
       "                       0.1272,  0.0580,  0.0969,  0.0713,  0.4817,  0.6636,  0.0664,  0.7100,\n",
       "                       0.0623,  0.0939,  0.0972,  0.1392,  0.0479,  0.2200,  0.1031,  0.0736,\n",
       "                       0.0979,  0.0534,  0.0516,  0.2558,  0.1015,  0.0879,  0.0362,  0.0605,\n",
       "                       0.0577,  0.1409,  0.6654,  0.1349,  0.0655,  0.5209,  0.5386,  0.0698,\n",
       "                       0.0876,  0.0506,  0.0691,  0.0549,  0.5807, -0.0275,  0.8512,  0.1182,\n",
       "                       0.2065,  0.0704, -0.0188,  0.0484,  0.6966,  0.0979,  0.0690,  0.5532,\n",
       "                       0.3631,  0.2517,  0.0582,  0.7908,  0.8614,  0.2188,  0.0596,  0.0666,\n",
       "                       0.0603,  0.0737,  0.1128,  0.7022,  0.1586,  0.6990,  0.0664,  0.0873,\n",
       "                       0.0652,  0.4353,  0.6855,  0.0961,  0.7642,  0.1738,  0.0667,  0.5226,\n",
       "                       0.7869,  0.0780,  0.0793,  0.1110,  0.0903,  0.5870,  0.1286,  0.0146,\n",
       "                       0.0858,  0.0590,  0.0902,  0.0467,  0.0834,  0.2000,  0.0644,  0.1224,\n",
       "                       0.0732,  0.3336, -0.0419, -0.0384,  0.0733,  0.7687,  0.3395,  0.0850,\n",
       "                       0.4680,  0.4628,  0.0807,  0.2351,  0.1020,  0.0731,  0.0872,  0.4469,\n",
       "                       0.0632,  0.0604,  0.8270,  0.0701,  0.0857,  0.1128,  0.0613,  0.1085,\n",
       "                       0.0674,  0.0592,  0.0745,  0.4086,  0.0567,  0.0603,  0.6014,  0.0589,\n",
       "                       0.0716,  0.6299,  0.1505,  0.1195,  0.1142,  0.2214,  0.0414,  0.1432,\n",
       "                       0.0153,  0.0513,  0.3617,  0.2474,  0.0943,  0.1014,  0.0750,  0.6004,\n",
       "                       0.1228,  0.7779,  0.5752,  0.0808,  0.2095,  0.0539,  0.1335,  0.3982,\n",
       "                       0.0533,  0.0693,  0.2059,  0.0531,  0.0795,  0.1371,  0.6534,  0.5317,\n",
       "                       0.1084,  0.0475,  0.1067,  0.6424,  0.2577,  0.7509,  0.2337,  0.5041,\n",
       "                       0.0865,  0.0564,  0.0487,  0.2695,  0.4468,  0.1252,  0.1129,  0.0708,\n",
       "                       0.0635,  0.0876,  0.5506,  0.0511,  0.1953,  0.0598,  0.0910,  0.1329])),\n",
       "             ('batchnorm.bias',\n",
       "              tensor([-1.8195e-03, -1.8838e-03, -2.8090e-03, -7.5463e-04, -1.0393e-03,\n",
       "                       5.5506e-03, -3.5568e-03, -4.6174e-03,  6.4714e-04, -2.3292e-03,\n",
       "                      -9.0015e-04, -6.3063e-03,  3.3629e-03, -4.3136e-03,  4.5117e-04,\n",
       "                      -2.5416e-03,  3.3134e-04, -4.0933e-03,  2.0095e-03, -1.1725e-02,\n",
       "                      -8.0679e-03, -4.7196e-03, -1.2185e-03,  1.8469e-03, -1.0136e-03,\n",
       "                      -4.3244e-03, -4.2357e-03,  2.4652e-04,  1.0937e-03,  9.5436e-04,\n",
       "                       3.1627e-03, -2.7453e-03,  4.3532e-03, -2.6108e-03,  6.7849e-04,\n",
       "                      -2.2530e-03,  9.8014e-04, -7.5062e-04, -1.3159e-03,  5.1973e-04,\n",
       "                       1.2511e-03,  5.5726e-04, -3.4345e-04,  1.7597e-03, -1.8906e-03,\n",
       "                       4.9969e-03, -8.2922e-03,  1.9174e-03, -2.5659e-03, -1.0296e-03,\n",
       "                      -3.2080e-03,  2.2814e-03, -4.0150e-03,  3.5236e-03, -6.6973e-04,\n",
       "                       6.5135e-04,  1.3022e-02, -1.3997e-03, -5.3503e-03, -1.4648e-03,\n",
       "                       4.3773e-03, -2.1894e-03, -1.0640e-03,  1.6603e-04, -5.0279e-03,\n",
       "                       4.1285e-04, -2.5183e-03, -3.1683e-03, -4.5054e-03,  5.2206e-03,\n",
       "                       1.4422e-03, -9.8114e-04, -4.2690e-03, -4.1812e-04, -2.5804e-03,\n",
       "                      -4.1913e-03,  1.2863e-03,  4.9785e-03, -5.4067e-03,  6.0544e-04,\n",
       "                       1.6883e-03, -4.3585e-04,  4.2382e-03,  8.8185e-03, -1.2975e-04,\n",
       "                      -7.2790e-04, -1.5941e-03, -2.6520e-03, -1.8961e-02, -2.2863e-03,\n",
       "                      -5.8330e-04, -2.2689e-03, -2.2802e-03, -3.6544e-03,  1.1412e-03,\n",
       "                       2.3883e-03, -9.9573e-04, -6.1800e-04, -2.2603e-03, -1.4275e-19,\n",
       "                       3.2284e-03,  1.7344e-03,  3.5567e-03,  4.3547e-04, -2.1680e-03,\n",
       "                       2.5830e-03, -3.6560e-03, -3.0619e-03, -6.3225e-03, -1.2093e-03,\n",
       "                      -8.3755e-03, -5.2877e-03,  2.0346e-04,  1.8560e-03, -7.7315e-04,\n",
       "                      -5.3240e-03, -2.5875e-03, -2.7925e-03,  2.6176e-03, -1.4528e-03,\n",
       "                      -1.6650e-03, -3.1840e-03, -3.8352e-03, -3.6299e-03, -3.1147e-04,\n",
       "                       7.1700e-03,  4.8760e-04, -2.2541e-03,  2.6562e-03,  8.4822e-04,\n",
       "                      -7.8830e-03, -2.9809e-03, -6.9444e-04, -2.1933e-03, -1.7519e-03,\n",
       "                      -1.9826e-03, -2.6144e-12, -5.6256e-03, -7.3377e-04, -2.6569e-03,\n",
       "                      -3.2721e-03, -9.4056e-04, -1.9142e-03,  2.4879e-04,  8.9927e-04,\n",
       "                      -1.4331e-03,  4.6977e-03,  6.2851e-03, -4.4109e-03, -8.1759e-04,\n",
       "                       2.2311e-03, -4.8004e-03, -4.5358e-03,  1.9352e-03, -4.2971e-03,\n",
       "                       1.7314e-04,  9.5479e-04, -5.4920e-04,  8.6889e-04, -1.9721e-03,\n",
       "                      -1.7253e-04,  4.7741e-03,  3.3243e-03, -9.7999e-04, -8.1366e-03,\n",
       "                      -4.6799e-03, -2.2941e-03,  5.3504e-04, -5.2995e-03,  1.7154e-04,\n",
       "                      -8.3053e-03, -7.2611e-03, -7.7659e-04, -4.2749e-03,  5.8694e-04,\n",
       "                      -5.9901e-04,  3.9655e-04,  2.4273e-03, -2.5358e-03, -2.6050e-04,\n",
       "                      -8.0380e-04,  3.0945e-03, -3.1765e-04, -3.1462e-03,  5.4686e-03,\n",
       "                      -6.1032e-03,  5.4809e-03,  1.9961e-03,  2.4554e-03, -3.9139e-04,\n",
       "                      -2.0546e-03, -5.6256e-08, -4.2915e-04, -9.2118e-04, -4.6704e-03,\n",
       "                      -1.3030e-03, -1.1264e-02, -9.7847e-04,  5.2211e-04,  1.2934e-04,\n",
       "                      -5.1106e-03, -8.0921e-04, -2.9447e-03, -6.4069e-04,  1.1083e-03,\n",
       "                      -2.7143e-03,  7.1255e-03,  9.2282e-04,  3.9142e-03, -2.8913e-03,\n",
       "                      -2.2338e-03, -2.8680e-03, -1.8880e-03, -1.1601e-03,  2.2353e-05,\n",
       "                      -4.4011e-04,  9.1612e-04, -1.0708e-03, -3.4011e-03, -4.3979e-03,\n",
       "                      -3.4620e-10,  8.5111e-04,  3.1073e-03, -1.5483e-03, -5.9683e-03,\n",
       "                       2.4002e-03,  3.9048e-03, -8.3581e-04,  2.5189e-03, -2.7430e-03,\n",
       "                      -2.8961e-03,  2.8218e-03,  4.6227e-03,  3.8869e-04,  1.6410e-03,\n",
       "                      -4.1903e-03,  7.7847e-03, -7.8609e-04, -4.6323e-03,  1.3404e-03,\n",
       "                      -1.3206e-03, -7.9464e-03, -1.6435e-03, -7.1192e-04, -1.9865e-03,\n",
       "                      -6.8963e-04, -1.7741e-03, -2.4760e-03, -2.2196e-03,  9.2947e-04,\n",
       "                       6.6811e-03, -2.7047e-03, -1.3449e-04,  1.0968e-03, -6.0757e-04,\n",
       "                      -5.5624e-03,  1.9240e-03,  1.2084e-15, -7.6989e-03,  5.2953e-04,\n",
       "                      -9.1523e-04, -8.5625e-04,  9.7105e-04,  7.6597e-05, -1.5525e-03,\n",
       "                       2.8585e-03, -6.5714e-03,  9.6428e-04,  3.8026e-03,  1.8713e-04,\n",
       "                      -4.9426e-04,  4.6456e-03,  2.8010e-03, -1.7252e-03,  1.5974e-03,\n",
       "                      -9.3569e-06,  1.4592e-04, -7.9116e-04, -2.8049e-03,  2.1577e-04,\n",
       "                      -5.3665e-04, -2.9005e-04, -1.1694e-03,  1.7493e-03,  6.6435e-03,\n",
       "                      -3.1856e-03, -6.8061e-03,  1.4740e-03,  3.8426e-03,  5.1856e-04,\n",
       "                       1.4340e-03, -1.7359e-04,  1.6627e-03,  6.3251e-04,  1.1619e-02,\n",
       "                      -2.7679e-03, -2.2526e-03, -6.6816e-03, -3.8366e-03, -7.2269e-03,\n",
       "                       4.6487e-03,  3.0929e-03, -5.1326e-04, -3.8228e-03, -2.6373e-03,\n",
       "                      -1.6086e-03, -7.7879e-05, -1.0696e-03,  6.6408e-03, -2.0298e-03,\n",
       "                      -3.6229e-04, -1.1198e-03, -8.4992e-04,  4.1576e-04, -4.1936e-04,\n",
       "                      -2.1572e-20, -2.2018e-03, -1.5650e-03, -1.3482e-03,  2.4700e-04,\n",
       "                      -2.9881e-04, -1.5738e-03,  2.9762e-03,  5.5825e-03,  3.3420e-03,\n",
       "                      -2.3338e-03,  4.1516e-03, -2.6168e-03, -6.1249e-04, -2.0151e-03,\n",
       "                       7.8745e-04, -1.1289e-02, -6.4478e-04, -8.8859e-03, -6.7448e-03,\n",
       "                       5.2551e-03, -1.6691e-03, -1.5412e-03, -9.3816e-04, -1.8227e-03,\n",
       "                      -1.0782e-03,  1.6193e-03,  4.7713e-04, -1.8553e-03, -2.0606e-03,\n",
       "                      -3.5134e-03,  4.4449e-04, -2.5096e-03, -1.0288e-03, -1.0231e-02,\n",
       "                      -3.0835e-03, -1.4250e-03,  5.7764e-03,  4.3151e-04, -1.1788e-03,\n",
       "                       1.9940e-03, -3.8920e-03, -3.0566e-03, -1.1189e-03, -4.4654e-03,\n",
       "                      -3.6451e-03,  4.8841e-05,  8.7019e-03, -4.6222e-03,  2.4392e-04,\n",
       "                      -8.2011e-04,  1.3529e-04, -2.9530e-03, -7.5157e-04,  4.3037e-03,\n",
       "                      -1.3814e-03,  1.1846e-03, -1.8460e-03, -6.6780e-03, -1.2998e-21,\n",
       "                       2.2690e-03, -1.0833e-02, -8.1738e-05,  1.3884e-03, -2.0729e-04,\n",
       "                       4.4453e-23, -1.9758e-04, -2.1159e-03, -6.1175e-05, -3.1398e-03,\n",
       "                      -2.3344e-04, -7.3144e-04, -4.2998e-03, -2.0373e-03,  3.3786e-05,\n",
       "                      -1.7235e-03, -1.4626e-03, -9.3986e-04, -1.4841e-03, -3.9179e-04,\n",
       "                       3.4992e-04, -2.2410e-03, -6.6747e-03,  1.5669e-03, -1.4330e-03,\n",
       "                      -1.0658e-03, -3.6468e-03,  2.5309e-04, -2.3989e-03,  1.3513e-04,\n",
       "                      -6.4654e-03, -3.5738e-03, -2.1465e-18, -3.2855e-03,  7.5407e-04,\n",
       "                      -2.5509e-03,  4.0112e-04, -2.3553e-03, -5.7129e-03,  1.8348e-03,\n",
       "                       2.8336e-03, -4.4287e-03, -1.9368e-03, -2.5843e-03,  3.7003e-04,\n",
       "                      -2.1397e-03, -1.0287e-02, -1.1881e-03,  1.8464e-03, -1.7563e-03,\n",
       "                       9.0541e-03,  2.4071e-03, -1.5411e-03,  3.2280e-04, -1.2775e-03,\n",
       "                      -5.1650e-03,  1.6394e-04, -8.4188e-03, -1.8269e-03, -1.4064e-03,\n",
       "                      -7.5576e-03, -1.4059e-03, -3.6199e-03,  2.2436e-03, -2.1446e-03,\n",
       "                       3.6300e-03, -1.0332e-03, -3.3106e-04, -3.4523e-03,  1.6734e-03,\n",
       "                      -1.9937e-03, -2.1995e-03, -2.4140e-03,  8.4180e-04,  6.1199e-04,\n",
       "                      -1.3193e-03,  7.0333e-03,  5.8094e-04, -1.0536e-04, -6.3984e-04,\n",
       "                       3.0741e-03, -1.7647e-03,  3.0909e-03, -1.0127e-02, -6.4918e-03,\n",
       "                       1.8559e-03,  3.7946e-03,  1.5711e-03,  1.5054e-03, -1.2483e-06,\n",
       "                       1.8196e-03,  1.7646e-03,  6.0758e-03,  9.5896e-04, -4.5090e-03,\n",
       "                      -1.3512e-03,  5.9659e-04, -3.2478e-03, -2.8745e-18,  1.6373e-03,\n",
       "                      -3.5088e-03, -8.3302e-03,  1.3097e-03, -1.5660e-03,  2.6439e-03,\n",
       "                       3.3852e-03, -2.2086e-03, -2.3379e-03,  1.6691e-03, -1.8636e-03,\n",
       "                      -9.8770e-03, -1.2479e-10, -3.0738e-03, -3.8583e-03,  1.6179e-03,\n",
       "                      -2.6826e-04, -6.2093e-03, -3.1663e-03, -6.9150e-04, -5.9368e-03,\n",
       "                      -7.0396e-03, -3.3376e-03, -9.1868e-04, -9.4449e-04,  3.9203e-03,\n",
       "                      -1.5120e-03, -6.0026e-03, -3.4925e-04,  6.5179e-04, -2.3615e-04,\n",
       "                      -2.7707e-03, -1.7929e-03, -6.6388e-04, -7.7983e-03,  2.7694e-04,\n",
       "                       2.0329e-04, -5.0138e-03])),\n",
       "             ('batchnorm.running_mean',\n",
       "              tensor([3.2211e-05, 5.6052e-45, 5.3300e-02, 5.6052e-45, 3.9206e-05, 5.6052e-45,\n",
       "                      4.5151e-01, 8.7379e-02, 1.7585e-01, 1.4060e-02, 1.0505e-02, 1.0855e-16,\n",
       "                      2.0522e-06, 2.7587e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45, 3.0961e+00,\n",
       "                      5.6052e-45, 4.5233e+00, 7.3423e-05, 5.5184e-01, 1.2662e-04, 5.6052e-45,\n",
       "                      4.9924e-01, 4.0045e-06, 1.8564e-01, 5.6052e-45, 1.0495e-11, 1.7964e+00,\n",
       "                      1.5009e+01, 3.6504e-02, 2.5918e-40, 5.1519e-02, 4.5959e-02, 1.2429e-01,\n",
       "                      3.5063e-13, 5.6052e-45, 3.2889e-02, 4.4593e-04, 5.6052e-45, 3.1850e-04,\n",
       "                      5.7795e-10, 4.5348e+00, 5.6052e-45, 4.3224e-39, 3.3186e+00, 5.0192e-01,\n",
       "                      2.9646e-02, 3.4109e-01, 1.5534e-01, 1.6120e-30, 2.9170e-01, 5.6052e-45,\n",
       "                      6.7341e-05, 9.5224e-01, 5.6052e-45, 8.6420e-10, 2.5882e-02, 5.1756e-02,\n",
       "                      5.6052e-45, 1.1389e+00, 5.4623e-02, 9.3623e-02, 6.2883e-01, 5.5201e-06,\n",
       "                      8.3785e-01, 5.6052e-45, 6.3745e-02, 1.6414e+00, 5.8875e+00, 5.6052e-45,\n",
       "                      1.2493e-01, 1.9763e-02, 5.6052e-45, 7.8611e-02, 1.0542e-01, 5.7089e-11,\n",
       "                      5.6052e-45, 8.5827e-01, 2.4314e-05, 1.3527e-01, 5.6052e-45, 9.2838e-40,\n",
       "                      1.5610e-04, 9.4185e-02, 5.9519e-01, 8.2232e-02, 2.1361e-01, 2.5380e-02,\n",
       "                      5.6052e-45, 4.8823e-24, 1.0096e-01, 5.6634e-01, 8.1874e+00, 5.6052e-45,\n",
       "                      1.3910e-02, 4.2392e-02, 1.3182e-01, 5.6052e-45, 5.6052e-45, 4.1442e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6580e-07, 4.7518e-02, 2.1751e-06,\n",
       "                      5.6052e-45, 2.0818e-11, 2.0501e-01, 5.6052e-45, 1.2325e+00, 1.7790e+00,\n",
       "                      1.1284e-02, 3.4818e-02, 5.6052e-45, 9.8489e-03, 1.2409e+00, 1.2099e-01,\n",
       "                      6.3305e-02, 5.6052e-45, 4.7582e-01, 5.6052e-45, 2.9632e-02, 5.6052e-45,\n",
       "                      4.7591e-03, 1.7056e-08, 5.6052e-45, 4.5095e-02, 4.4399e-02, 1.5502e-02,\n",
       "                      2.9904e-02, 2.4082e+00, 1.3498e-02, 1.8450e+00, 5.6052e-45, 3.3550e-02,\n",
       "                      5.6052e-45, 2.3840e-02, 4.9016e-02, 6.2547e-01, 4.8076e-02, 1.0468e+00,\n",
       "                      5.6052e-45, 2.1013e-01, 2.4910e-28, 5.6052e-45, 5.6052e-45, 5.9467e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 4.4529e+00, 7.4962e-02, 8.6637e-01,\n",
       "                      5.6052e-45, 4.2045e-02, 3.8316e-05, 1.1434e-01, 2.9699e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 3.6524e-01, 2.1508e-02, 2.1763e+00, 2.5127e-02, 6.4232e-02,\n",
       "                      1.5189e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45, 1.0104e-01, 2.6403e-02,\n",
       "                      4.4229e-02, 1.8419e-29, 2.5149e-02, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      7.9807e-02, 1.6394e+01, 6.3971e-09, 5.1197e-02, 1.1103e-11, 4.8322e-02,\n",
       "                      5.6052e-45, 5.6052e-45, 6.6920e-01, 3.1601e-04, 6.6018e-01, 5.6052e-45,\n",
       "                      3.7462e-02, 2.4354e-02, 4.9765e-01, 1.1179e-01, 5.6052e-45, 1.8871e-02,\n",
       "                      2.4216e-04, 2.1947e-02, 1.1235e-01, 2.6845e-02, 3.7592e-02, 3.1924e-02,\n",
       "                      7.8426e-01, 1.1129e-02, 5.6052e-45, 7.5600e-05, 1.2955e-05, 3.4879e-02,\n",
       "                      4.7153e-01, 5.6052e-45, 1.1596e-29, 2.0001e-02, 4.1703e-01, 8.3706e-05,\n",
       "                      5.1441e+00, 5.6266e-06, 5.4189e-02, 5.5419e-01, 5.6052e-45, 4.5507e+00,\n",
       "                      1.1977e+01, 1.8124e-21, 5.6052e-45, 1.2080e+00, 5.6052e-45, 5.0839e-02,\n",
       "                      5.6648e-01, 5.6052e-45, 3.2098e-02, 5.6052e-45, 6.3499e-37, 5.6052e-45,\n",
       "                      3.2651e-01, 3.0585e-01, 5.6052e-45, 4.7201e-02, 4.7506e-01, 8.3733e-07,\n",
       "                      6.0203e-02, 2.7763e-01, 1.2976e-15, 1.8847e-01, 2.0586e-01, 3.6740e-02,\n",
       "                      5.6052e-45, 3.2210e-02, 3.1402e-02, 2.7027e+00, 2.0565e-27, 3.6131e-01,\n",
       "                      5.6052e-45, 7.2691e+00, 7.3023e-02, 3.1251e-02, 5.6052e-45, 5.6052e-45,\n",
       "                      1.8206e-01, 1.4706e-02, 5.6052e-45, 5.6052e-45, 5.5270e+00, 5.6052e-45,\n",
       "                      4.8211e-02, 1.3022e+00, 4.6762e-28, 8.5609e-01, 5.6052e-45, 1.3089e+01,\n",
       "                      4.3258e-02, 1.4717e-12, 2.3705e-28, 5.6052e-45, 2.1481e-04, 5.7682e-02,\n",
       "                      4.2887e-02, 5.6052e-45, 4.7047e-02, 5.6052e-45, 5.1723e-02, 2.3481e-01,\n",
       "                      5.6052e-45, 5.8951e-05, 5.6052e-45, 5.1686e-07, 5.6052e-45, 1.5148e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 1.9772e+00, 2.2611e-02, 6.0425e-02, 4.8770e-02,\n",
       "                      5.6052e-45, 5.4228e-01, 4.6846e-02, 5.6052e-45, 3.8368e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.3805e+00, 5.6052e-45, 5.6052e-45, 3.1923e-02,\n",
       "                      1.0867e-01, 3.3537e-11, 5.6052e-45, 5.2999e-02, 4.4572e-02, 5.6052e-45,\n",
       "                      8.8712e-12, 2.4745e+00, 1.1466e-01, 5.6052e-45, 4.8497e-01, 5.5271e-01,\n",
       "                      1.2647e+00, 4.3407e-01, 9.7563e-02, 5.6052e-45, 5.6052e-45, 1.0447e-03,\n",
       "                      5.9325e+00, 5.6052e-45, 5.6052e-45, 7.6632e-02, 5.6052e-45, 2.9223e-02,\n",
       "                      6.3880e-02, 5.6413e+00, 6.6653e-02, 4.0558e-01, 6.6353e-02, 4.6569e-21,\n",
       "                      2.3751e-02, 4.8884e-02, 8.9846e-01, 4.5011e-02, 6.2448e-28, 5.6052e-45,\n",
       "                      3.2421e-03, 5.6052e-45, 3.6121e-02, 2.5027e-02, 5.6052e-45, 3.4332e-02,\n",
       "                      2.4108e-01, 1.2664e-01, 4.9993e-02, 1.4979e-01, 5.6052e-45, 2.5578e-02,\n",
       "                      9.5001e-02, 5.6052e-45, 2.6195e-05, 1.4619e-01, 5.6052e-45, 3.6376e-28,\n",
       "                      3.3623e-01, 1.9979e-02, 5.6052e-45, 4.4094e-02, 6.1168e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 1.1265e-01, 1.2014e-11, 1.3828e+01, 6.1871e-02, 2.5299e-02,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 3.1909e-02, 5.6052e-45, 3.6376e-05, 7.8692e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.8724e-02, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      3.7861e-02, 1.4130e-01, 5.0929e-02, 4.8342e-02, 2.6020e-02, 5.6052e-45,\n",
       "                      7.8850e-02, 3.1000e-28, 2.7152e-02, 5.1514e-02, 2.2370e-10, 1.2450e-38,\n",
       "                      5.6052e-45, 1.3464e-01, 5.6052e-45, 1.5394e-01, 4.8593e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.1093e-01, 4.4436e-01, 1.3525e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.2256e-22, 5.5711e-02, 2.5688e-02, 3.8738e-03, 2.2136e-02,\n",
       "                      1.2690e-05, 3.9418e-02, 5.6833e-28, 2.0778e-01, 2.6375e-02, 1.8933e-39,\n",
       "                      8.1854e-06, 4.3775e+00, 1.7432e-02, 5.6052e-45, 7.5361e-39, 2.1043e-01,\n",
       "                      5.6052e-45, 1.1146e-38, 1.4225e-01, 5.6052e-45, 1.3228e-01, 6.6211e-02,\n",
       "                      1.6326e+00, 5.6052e-45, 9.4454e-01, 3.1635e-02, 5.6052e-45, 4.0909e+00,\n",
       "                      8.6794e-01, 1.0765e-01, 3.4152e-02, 9.0450e-02, 1.6655e-02, 7.8827e+00,\n",
       "                      3.0162e-02, 5.6052e-45, 6.6550e-27, 1.5280e-02, 4.4874e-14, 1.2084e+01,\n",
       "                      5.1285e-02, 5.6052e-45, 2.4135e-01, 2.5116e-01, 6.2627e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 2.0958e-17, 5.6052e-45, 8.3218e-02, 4.2238e-06, 5.6052e-45,\n",
       "                      7.1840e-01, 5.6127e-01, 2.5887e-02, 5.6052e-45, 2.4725e-02, 5.6052e-45,\n",
       "                      5.6052e-45, 3.2416e-02, 6.4210e-02, 1.5288e-13, 3.2610e-01, 5.6052e-45,\n",
       "                      4.4032e-07, 4.0128e-02, 5.6052e-45, 6.7327e-01, 6.3849e-02, 1.5304e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 2.5789e-02, 6.3811e-04, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 2.0992e-11, 5.6052e-45, 6.9159e-02, 3.7846e-02,\n",
       "                      3.6520e-02, 5.6052e-45, 5.6052e-45, 1.8496e-01, 5.0906e-01, 1.9104e+00,\n",
       "                      8.8357e-02, 4.1406e-02, 5.6052e-45, 7.7524e-02, 3.8921e-02, 1.3101e-02,\n",
       "                      6.5994e-07, 6.1717e-02])),\n",
       "             ('batchnorm.running_var',\n",
       "              tensor([2.8534e-05, 5.6052e-45, 3.1291e-01, 5.6052e-45, 1.3180e-04, 5.6052e-45,\n",
       "                      3.1774e+00, 5.1336e-01, 1.3210e+00, 7.9538e-02, 5.9436e-02, 4.7444e-17,\n",
       "                      8.5697e-06, 2.0554e+00, 5.6052e-45, 5.6052e-45, 5.6052e-45, 2.3637e+01,\n",
       "                      5.6052e-45, 4.2685e+01, 5.1885e-04, 4.6889e+00, 2.5139e-04, 5.6052e-45,\n",
       "                      3.2315e+00, 9.3859e-06, 1.4858e+00, 5.6052e-45, 9.2634e-12, 1.1517e+01,\n",
       "                      1.1194e+02, 2.4848e-01, 2.1391e-40, 2.8521e-01, 2.2678e-01, 7.3005e-01,\n",
       "                      1.9893e-12, 5.6052e-45, 1.8221e-01, 8.4606e-04, 5.6052e-45, 6.3332e-04,\n",
       "                      3.3111e-10, 4.5585e+01, 5.6052e-45, 4.1426e-39, 4.1579e+01, 2.3937e+00,\n",
       "                      1.4053e-01, 1.7137e+00, 9.6609e-01, 1.5993e-30, 2.2200e+00, 5.6052e-45,\n",
       "                      3.9321e-04, 5.4693e+00, 5.6052e-45, 1.3681e-08, 1.4900e-01, 2.8671e-01,\n",
       "                      5.6052e-45, 9.1419e+00, 2.3104e-01, 6.1865e-01, 5.5467e+00, 9.7955e-06,\n",
       "                      6.9150e+00, 5.6052e-45, 3.8627e-01, 1.0929e+01, 3.5723e+01, 5.6052e-45,\n",
       "                      6.8585e-01, 9.5252e-02, 5.6052e-45, 3.4145e-01, 4.4504e-01, 1.3140e-10,\n",
       "                      5.6052e-45, 4.2689e+00, 6.0926e-05, 7.3357e-01, 5.6052e-45, 1.5479e-40,\n",
       "                      1.4806e-04, 5.0665e-01, 3.1883e+00, 3.9208e-01, 1.5661e+00, 1.4754e-01,\n",
       "                      5.6052e-45, 4.3723e-23, 5.1124e-01, 3.0463e+00, 5.1757e+01, 5.6052e-45,\n",
       "                      7.6496e-02, 1.9808e-01, 9.0947e-01, 5.6052e-45, 5.6052e-45, 2.3077e+00,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 1.7092e-06, 3.3416e-01, 9.3153e-06,\n",
       "                      5.6052e-45, 3.6449e-11, 1.4412e+00, 5.6052e-45, 8.2004e+00, 1.1009e+01,\n",
       "                      6.5778e-02, 1.8589e-01, 5.6052e-45, 8.6292e-02, 7.2417e+00, 6.8456e-01,\n",
       "                      4.8658e-01, 5.6052e-45, 2.8507e+00, 5.6052e-45, 1.5224e-01, 5.6052e-45,\n",
       "                      4.9186e-02, 1.8020e-08, 5.6052e-45, 2.9937e-01, 2.2093e-01, 8.3692e-02,\n",
       "                      1.6926e-01, 1.6884e+01, 8.9263e-02, 1.7116e+01, 5.6052e-45, 1.6227e-01,\n",
       "                      5.6052e-45, 1.1581e-01, 2.0298e-01, 3.7076e+00, 2.8149e-01, 7.0466e+00,\n",
       "                      5.6052e-45, 1.4075e+00, 1.5497e-28, 5.6052e-45, 5.6052e-45, 3.0157e+00,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.8520e+01, 4.6144e-01, 4.9689e+00,\n",
       "                      5.6052e-45, 2.1622e-01, 6.5977e-05, 5.4834e-01, 1.7180e+00, 5.6052e-45,\n",
       "                      5.6052e-45, 2.2683e+00, 9.0879e-02, 2.0862e+01, 1.4426e-01, 4.0787e-01,\n",
       "                      7.7020e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.3073e-01, 1.7329e-01,\n",
       "                      2.2264e-01, 1.9079e-29, 1.9623e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      4.9743e-01, 1.2669e+02, 4.0565e-08, 3.5746e-01, 1.0368e-11, 2.3827e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 2.8638e+00, 3.0471e-03, 3.5071e+00, 5.6052e-45,\n",
       "                      2.1762e-01, 1.4094e-01, 4.1792e+00, 6.3451e-01, 5.6052e-45, 9.9053e-02,\n",
       "                      5.0573e-04, 1.2919e-01, 6.9798e-01, 1.3660e-01, 3.1685e-01, 1.4087e-01,\n",
       "                      4.8720e+00, 9.6167e-02, 5.6052e-45, 1.5723e-04, 5.8777e-05, 2.2782e-01,\n",
       "                      3.7036e+00, 5.6052e-45, 4.8870e-30, 8.4423e-02, 2.6621e+00, 2.5487e-04,\n",
       "                      4.3121e+01, 1.1257e-05, 3.6340e-01, 4.3134e+00, 5.6052e-45, 2.8209e+01,\n",
       "                      8.0954e+01, 4.4059e-22, 5.6052e-45, 7.1036e+00, 5.6052e-45, 3.7277e-01,\n",
       "                      4.9073e+00, 5.6052e-45, 2.0798e-01, 5.6052e-45, 1.1009e-36, 5.6052e-45,\n",
       "                      1.7495e+00, 2.8527e+00, 5.6052e-45, 2.6696e-01, 3.7668e+00, 9.2899e-07,\n",
       "                      3.8827e-01, 2.3922e+00, 2.7043e-15, 1.0922e+00, 1.0776e+00, 1.9606e-01,\n",
       "                      5.6052e-45, 1.4064e-01, 1.8115e-01, 7.1792e+00, 1.4903e-27, 4.0449e+00,\n",
       "                      5.6052e-45, 5.9102e+01, 4.8725e-01, 1.3780e-01, 5.6052e-45, 5.6052e-45,\n",
       "                      9.6272e-01, 1.0381e-01, 5.6052e-45, 5.6052e-45, 4.4634e+01, 5.6052e-45,\n",
       "                      2.6712e-01, 8.0564e+00, 5.4543e-28, 5.2527e+00, 5.6052e-45, 8.9158e+01,\n",
       "                      2.1716e-01, 1.3276e-12, 1.4034e-28, 5.6052e-45, 7.8540e-04, 2.5277e-01,\n",
       "                      2.8299e-01, 5.6052e-45, 2.6961e-01, 5.6052e-45, 2.6564e-01, 1.4034e+00,\n",
       "                      5.6052e-45, 1.9267e-04, 5.6052e-45, 6.0370e-07, 5.6052e-45, 8.8335e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 1.3859e+01, 1.6462e-01, 3.5435e-01, 2.5807e-01,\n",
       "                      5.6052e-45, 3.8674e+00, 2.6405e-01, 5.6052e-45, 1.9853e+00, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 7.4056e+00, 5.6052e-45, 5.6052e-45, 1.9965e-01,\n",
       "                      6.8956e-01, 8.0746e-11, 5.6052e-45, 2.1985e-01, 2.8354e-01, 5.6052e-45,\n",
       "                      2.4106e-11, 1.8410e+01, 9.4397e-01, 5.6052e-45, 3.6944e+00, 3.3474e+00,\n",
       "                      1.1589e+01, 2.9441e+00, 5.3544e-01, 5.6052e-45, 5.6052e-45, 4.6153e-03,\n",
       "                      4.5649e+01, 5.6052e-45, 5.6052e-45, 3.6570e-01, 5.6052e-45, 1.2720e-01,\n",
       "                      4.2688e-01, 5.0448e+01, 4.1129e-01, 3.4746e+00, 3.9449e-01, 1.0299e-20,\n",
       "                      1.3387e-01, 2.4582e-01, 5.5301e+00, 3.3614e-01, 9.7396e-28, 5.6052e-45,\n",
       "                      2.9873e-02, 5.6052e-45, 2.4052e-01, 2.1368e-01, 5.6052e-45, 1.5769e-01,\n",
       "                      1.5211e+00, 5.9584e-01, 2.5166e-01, 6.5549e-01, 5.6052e-45, 1.4049e-01,\n",
       "                      6.5774e-01, 5.6052e-45, 6.5360e-05, 8.1513e-01, 5.6052e-45, 3.3048e-28,\n",
       "                      2.9290e+00, 9.7488e-02, 5.6052e-45, 2.2622e-01, 3.8270e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 7.4297e-01, 4.8802e-12, 9.2236e+01, 3.5912e-01, 1.2881e-01,\n",
       "                      5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 2.0848e-01, 5.6052e-45, 4.1148e-05, 4.9279e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 1.2777e-01, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
       "                      2.8828e-01, 7.9913e-01, 3.1760e-01, 2.1687e-01, 1.4687e-01, 5.6052e-45,\n",
       "                      3.5505e-01, 2.4002e-28, 1.6100e-01, 2.9796e-01, 9.1675e-10, 3.4369e-38,\n",
       "                      5.6052e-45, 6.1168e-01, 5.6052e-45, 9.7859e-01, 3.7303e+00, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 6.8292e-01, 3.0755e+00, 9.7755e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 6.9986e-22, 3.0300e-01, 1.6659e-01, 3.8257e-02, 1.5880e-01,\n",
       "                      4.5371e-06, 1.9666e-01, 8.0670e-28, 1.0744e+00, 1.3058e-01, 6.4380e-40,\n",
       "                      4.0752e-07, 2.3089e+01, 7.8448e-02, 5.6052e-45, 1.2592e-38, 1.1780e+00,\n",
       "                      5.6052e-45, 2.7544e-38, 8.6012e-01, 5.6052e-45, 8.7330e-01, 3.7217e-01,\n",
       "                      1.2853e+01, 5.6052e-45, 6.0468e+00, 2.1921e-01, 5.6052e-45, 3.7250e+01,\n",
       "                      6.0316e+00, 6.0223e-01, 2.2649e-01, 5.3216e-01, 8.7062e-02, 7.5514e+01,\n",
       "                      1.7818e-01, 5.6052e-45, 1.0489e-26, 8.0094e-02, 7.5148e-14, 8.4594e+01,\n",
       "                      2.7736e-01, 5.6052e-45, 1.7774e+00, 2.1512e+00, 3.3427e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 1.1104e-17, 5.6052e-45, 3.9417e-01, 6.2484e-06, 5.6052e-45,\n",
       "                      4.2114e+00, 4.8074e+00, 1.2927e-01, 5.6052e-45, 1.3594e-01, 5.6052e-45,\n",
       "                      5.6052e-45, 2.2698e-01, 3.3126e-01, 3.3822e-13, 1.7253e+00, 5.6052e-45,\n",
       "                      9.0017e-07, 2.6023e-01, 5.6052e-45, 3.4991e+00, 3.8097e-01, 1.1273e+00,\n",
       "                      5.6052e-45, 5.6052e-45, 1.3167e-01, 2.4766e-03, 5.6052e-45, 5.6052e-45,\n",
       "                      5.6052e-45, 5.6052e-45, 3.7061e-11, 5.6052e-45, 4.4467e-01, 1.9664e-01,\n",
       "                      2.6126e-01, 5.6052e-45, 5.6052e-45, 1.0565e+00, 2.8277e+00, 1.2307e+01,\n",
       "                      5.1082e-01, 2.1219e-01, 5.6052e-45, 4.8630e-01, 1.8863e-01, 5.5108e-02,\n",
       "                      5.7147e-07, 3.0761e-01])),\n",
       "             ('batchnorm.num_batches_tracked', tensor(64630))])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('castle', 1.0)]\n",
      "1.000002899999999\n"
     ]
    }
   ],
   "source": [
    "print(fr_to_english_dict['chateau'])\n",
    "s = 0.0\n",
    "for t in fr_to_english_dict['est']:\n",
    "    s += t[1]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emptywordtoken': 0,\n",
       " 'unknownword': 1,\n",
       " 'blancs': 2,\n",
       " 'deux': 3,\n",
       " 'hommes': 4,\n",
       " 'jeunes': 5,\n",
       " 'buissons': 6,\n",
       " 'de': 7,\n",
       " 'plusieurs': 8,\n",
       " 'casque': 9,\n",
       " 'géant': 10,\n",
       " 'poulies': 11,\n",
       " 'système': 12,\n",
       " 'un': 13,\n",
       " 'fille': 14,\n",
       " 'petite': 15,\n",
       " 'une': 16,\n",
       " 'bois': 17,\n",
       " 'en': 18,\n",
       " 'maisonnette': 19,\n",
       " 'homme': 20,\n",
       " 'bleue': 21,\n",
       " 'chemise': 22,\n",
       " 'échelle': 23,\n",
       " 'fenêtre': 24,\n",
       " 'fourneaux': 25,\n",
       " 'vert': 26,\n",
       " 'guitare': 27,\n",
       " 'autre': 28,\n",
       " 'sa': 29,\n",
       " 'ours': 30,\n",
       " 'peluche': 31,\n",
       " 'branchée': 32,\n",
       " 'portable': 33,\n",
       " 'son': 34,\n",
       " 'la': 35,\n",
       " 'rue': 36,\n",
       " 'femme': 37,\n",
       " 'gros': 38,\n",
       " 'sac': 39,\n",
       " 'porte': 40,\n",
       " 'des': 41,\n",
       " 'garçons': 42,\n",
       " 'barres': 43,\n",
       " ',': 44,\n",
       " 'ballet': 45,\n",
       " 'cinq': 46,\n",
       " 'classe': 47,\n",
       " 'composée': 48,\n",
       " 'filles': 49,\n",
       " 'gars': 50,\n",
       " 'quatre': 51,\n",
       " 'chapeaux': 52,\n",
       " \"'\": 53,\n",
       " 'd': 54,\n",
       " 'escalier': 55,\n",
       " 'haut': 56,\n",
       " 'chien': 57,\n",
       " 'noir': 58,\n",
       " 'tâches': 59,\n",
       " 'à': 60,\n",
       " 'orange': 61,\n",
       " 'uniforme': 62,\n",
       " 'tracteur': 63,\n",
       " 'femmes': 64,\n",
       " 'lunettes': 65,\n",
       " 'sucre': 66,\n",
       " 'bundt': 67,\n",
       " 'cake': 68,\n",
       " 'arc-en-ciel': 69,\n",
       " 'grand': 70,\n",
       " 'peint': 71,\n",
       " '[': 72,\n",
       " 'banc': 73,\n",
       " 'blanc': 74,\n",
       " 'personnes': 75,\n",
       " 'cercle': 76,\n",
       " 'instruments': 77,\n",
       " 'leurs': 78,\n",
       " 'groupe': 79,\n",
       " 'âgées': 80,\n",
       " 'clarinette': 81,\n",
       " 'leur': 82,\n",
       " 'partition': 83,\n",
       " 'grande': 84,\n",
       " 'structure': 85,\n",
       " 'chaussée': 86,\n",
       " 'foule': 87,\n",
       " 'gens': 88,\n",
       " 'importante': 89,\n",
       " 'dos': 90,\n",
       " 'enfants': 91,\n",
       " 'bascule': 92,\n",
       " 'manège': 93,\n",
       " 'petit': 94,\n",
       " 'le': 95,\n",
       " 'sable': 96,\n",
       " 'gilet': 97,\n",
       " 'réfléchissant': 98,\n",
       " 'drapeau': 99,\n",
       " 'route': 100,\n",
       " 'personne': 101,\n",
       " 'bleu': 102,\n",
       " 'manteau': 103,\n",
       " 'encombré': 104,\n",
       " 'trottoir': 105,\n",
       " 'peinture': 106,\n",
       " 'représentant': 107,\n",
       " 'scène': 108,\n",
       " 'pantalon': 109,\n",
       " 'enfant': 110,\n",
       " 'rouge': 111,\n",
       " 'jeune': 112,\n",
       " 'et': 113,\n",
       " 'jaune': 114,\n",
       " 'noire': 115,\n",
       " 'veste': 116,\n",
       " 'urinoir': 117,\n",
       " 'café': 118,\n",
       " 'tasse': 119,\n",
       " 'vieil': 120,\n",
       " 'bière': 121,\n",
       " 'dressé': 122,\n",
       " 'policier': 123,\n",
       " 'maître': 124,\n",
       " 'fourgon': 125,\n",
       " 'police': 126,\n",
       " 'vélo': 127,\n",
       " 'enneigée': 128,\n",
       " 'blanche': 129,\n",
       " 'cravate': 130,\n",
       " 'arrière': 131,\n",
       " 'l': 132,\n",
       " 'ouvert': 133,\n",
       " 'chapeau': 134,\n",
       " 'machines': 135,\n",
       " 'bougies': 136,\n",
       " 'cartons': 137,\n",
       " 'asiatique': 138,\n",
       " 'voiture': 139,\n",
       " 'conducteur': 140,\n",
       " 'bambins': 141,\n",
       " 'véhicule': 142,\n",
       " 'étrange': 143,\n",
       " 'argenté': 144,\n",
       " 'belle': 145,\n",
       " 'mariée': 146,\n",
       " 'mari': 147,\n",
       " 'nouveau': 148,\n",
       " 'garçon': 149,\n",
       " 'gamecube': 150,\n",
       " 'mcdonald': 151,\n",
       " 'bord': 152,\n",
       " 'plage': 153,\n",
       " 'balle': 154,\n",
       " 'soleil': 155,\n",
       " 'chemisier': 156,\n",
       " 'ballons': 157,\n",
       " 'picnic': 158,\n",
       " 'tables': 159,\n",
       " 'trois': 160,\n",
       " 'du': 161,\n",
       " 'eau': 162,\n",
       " 'morceau': 163,\n",
       " 'papier': 164,\n",
       " 'salopette': 165,\n",
       " 'mur': 166,\n",
       " 'pierre': 167,\n",
       " 'bûche': 168,\n",
       " 'costume': 169,\n",
       " 'autres': 170,\n",
       " 'messieurs': 171,\n",
       " 'nus': 172,\n",
       " 'pieds': 173,\n",
       " 'fort': 174,\n",
       " 'olive': 175,\n",
       " 'hotdogs': 176,\n",
       " 'réchaud': 177,\n",
       " 'plastique': 178,\n",
       " 'neige': 179,\n",
       " 'skis': 180,\n",
       " 'illustrations': 181,\n",
       " 'les': 182,\n",
       " 'alpinistes': 183,\n",
       " 'sept': 184,\n",
       " 'rocher': 185,\n",
       " 'corde': 186,\n",
       " 'corps': 187,\n",
       " 'gymnaste': 188,\n",
       " 'souple': 189,\n",
       " 'poutre': 190,\n",
       " 'équilibre': 191,\n",
       " 'atv': 192,\n",
       " 'jouet': 193,\n",
       " 'caoutchouc': 194,\n",
       " 'piscine': 195,\n",
       " 'coupe-vent': 196,\n",
       " 'objet': 197,\n",
       " 'avion': 198,\n",
       " 'tuyau': 199,\n",
       " 'chariot': 200,\n",
       " 'chiens': 201,\n",
       " 'pour': 202,\n",
       " 'type': 203,\n",
       " 'verte': 204,\n",
       " 'main': 205,\n",
       " 'partie': 206,\n",
       " 'visage': 207,\n",
       " 'restaurant': 208,\n",
       " 'randonneurs': 209,\n",
       " 'création': 210,\n",
       " 'nouvelle': 211,\n",
       " 'père': 212,\n",
       " 'âgé': 213,\n",
       " 'adulte': 214,\n",
       " 'fils': 215,\n",
       " 'barbu': 216,\n",
       " 'voyageur': 217,\n",
       " 'carte': 218,\n",
       " 'canard': 219,\n",
       " 'parc': 220,\n",
       " 'couple': 221,\n",
       " 'herbe': 222,\n",
       " 'bébé': 223,\n",
       " 'poussette': 224,\n",
       " 'quelques': 225,\n",
       " 'immeuble': 226,\n",
       " 'stationnement': 227,\n",
       " 'gelé': 228,\n",
       " 'glace': 229,\n",
       " 'étang': 230,\n",
       " 'beiges': 231,\n",
       " 'imposants': 232,\n",
       " 'pics': 233,\n",
       " 'chemin': 234,\n",
       " 'fait': 235,\n",
       " 'pelletées': 236,\n",
       " 'gâteau': 237,\n",
       " 'mariage': 238,\n",
       " 'mouillé': 239,\n",
       " 'villageois': 240,\n",
       " 'récolte': 241,\n",
       " 'chanteur': 242,\n",
       " 't-shirt': 243,\n",
       " 'skateboard': 244,\n",
       " 'kayak': 245,\n",
       " 'chantier': 246,\n",
       " 'construction': 247,\n",
       " 'panneau': 248,\n",
       " 'publicitaire': 249,\n",
       " 'drapeaux': 250,\n",
       " 'poisson': 251,\n",
       " 'débardeur': 252,\n",
       " 'jupe': 253,\n",
       " 'extérieur': 254,\n",
       " 'marches': 255,\n",
       " 'bouche': 256,\n",
       " 'but': 257,\n",
       " 'gardien': 258,\n",
       " 'hockey': 259,\n",
       " 'objectif': 260,\n",
       " 'bâton': 261,\n",
       " 'bâtiment': 262,\n",
       " 'cour': 263,\n",
       " '.': 264,\n",
       " 'art': 265,\n",
       " 'sculpture': 266,\n",
       " 'tout': 267,\n",
       " 'garde-corps': 268,\n",
       " 'champ': 269,\n",
       " 'herbeux': 270,\n",
       " 'gratte-ciel': 271,\n",
       " 'fruits': 272,\n",
       " 'blond': 273,\n",
       " 'aux': 274,\n",
       " 'cheveux': 275,\n",
       " 'noirs': 276,\n",
       " 'table': 277,\n",
       " 'nourriture': 278,\n",
       " 'électrique': 279,\n",
       " 'couleur': 280,\n",
       " 'béton': 281,\n",
       " 'couverture': 282,\n",
       " 'solitaire': 283,\n",
       " 'pont': 284,\n",
       " 'haricots': 285,\n",
       " 'verts': 286,\n",
       " 'barbecue': 287,\n",
       " 'rebord': 288,\n",
       " 'montagne': 289,\n",
       " 'passerelle': 290,\n",
       " 'très': 291,\n",
       " 'petites': 292,\n",
       " 'blonde': 293,\n",
       " 'gris': 294,\n",
       " 'chaise': 295,\n",
       " 'instrument': 296,\n",
       " 'bambou': 297,\n",
       " 'fréquentée': 298,\n",
       " '30': 299,\n",
       " 'ans': 300,\n",
       " 'plus': 301,\n",
       " 'nouilles': 302,\n",
       " 'bol': 303,\n",
       " 'tête': 304,\n",
       " 'trou': 305,\n",
       " 'individus': 306,\n",
       " 'baignoire': 307,\n",
       " 'dort': 308,\n",
       " 'rayé': 309,\n",
       " 'rose': 310,\n",
       " 'africaine': 311,\n",
       " 'membre': 312,\n",
       " 'tribu': 313,\n",
       " 'robe': 314,\n",
       " 'tribale': 315,\n",
       " 'guerrier': 316,\n",
       " 'samouraï': 317,\n",
       " 'épée': 318,\n",
       " 'fourreau': 319,\n",
       " 'entraînement': 320,\n",
       " 'tapis': 321,\n",
       " 'rail': 322,\n",
       " 'rivière': 323,\n",
       " 'rocheuse': 324,\n",
       " 'agent': 325,\n",
       " 'sécurité': 326,\n",
       " 'pourpre': 327,\n",
       " 'téléphone': 328,\n",
       " 'multicolore': 329,\n",
       " 'boule': 330,\n",
       " 'droite': 331,\n",
       " 'maison': 332,\n",
       " 'sol': 333,\n",
       " 'planchiste': 334,\n",
       " 'planche': 335,\n",
       " 'bouteille': 336,\n",
       " 'pilote': 337,\n",
       " 'talkie-walkie': 338,\n",
       " 'nattes': 339,\n",
       " 'pulls': 340,\n",
       " 'repas': 341,\n",
       " 'ouvriers': 342,\n",
       " 'acier': 343,\n",
       " 'ballon': 344,\n",
       " 'boue': 345,\n",
       " 'brochure': 346,\n",
       " 'plongeoir': 347,\n",
       " 'claire': 348,\n",
       " 'bassine': 349,\n",
       " 'fruit': 350,\n",
       " 'arrêt': 351,\n",
       " 'bus': 352,\n",
       " 'jean': 353,\n",
       " 'arbre': 354,\n",
       " 'crêpe': 355,\n",
       " 'pompiers': 356,\n",
       " 'camions': 357,\n",
       " 'rivage': 358,\n",
       " 'casques': 359,\n",
       " 'gilets': 360,\n",
       " 'magazines': 361,\n",
       " 'vendeur': 362,\n",
       " 'collage': 363,\n",
       " 'coloré': 364,\n",
       " 'boulangerie': 365,\n",
       " 'apprenti': 366,\n",
       " 'nu': 367,\n",
       " 'torse': 368,\n",
       " 'ombre': 369,\n",
       " 'tropicale': 370,\n",
       " 'bain': 371,\n",
       " 'short': 372,\n",
       " 'skieur': 373,\n",
       " 'juste': 374,\n",
       " 'monticule': 375,\n",
       " 'terre': 376,\n",
       " 'coureurs': 377,\n",
       " 'tas': 378,\n",
       " 'milieu': 379,\n",
       " 'canne': 380,\n",
       " 'médecin': 381,\n",
       " 'infirmières': 382,\n",
       " 'bleues': 383,\n",
       " 'blouses': 384,\n",
       " 'laineux': 385,\n",
       " 'doberman': 386,\n",
       " 'bowling': 387,\n",
       " 'piste': 388,\n",
       " 'ridé': 389,\n",
       " 'magnifique': 390,\n",
       " 'âne': 391,\n",
       " 'rochers': 392,\n",
       " 'canapé': 393,\n",
       " 'maillot': 394,\n",
       " 'javelot': 395,\n",
       " 'montgolfières': 396,\n",
       " 'magazine': 397,\n",
       " 'épaule': 398,\n",
       " 'allumer': 399,\n",
       " 'centre': 400,\n",
       " 'commercial': 401,\n",
       " 'pièce': 402,\n",
       " 'sombre': 403,\n",
       " 'mousse': 404,\n",
       " 'dizaines': 405,\n",
       " 'bikini': 406,\n",
       " 'cowboy': 407,\n",
       " 'paille': 408,\n",
       " 'toboggan': 409,\n",
       " 'colorés': 410,\n",
       " 'tubes': 411,\n",
       " 'combinaison': 412,\n",
       " 'plongée': 413,\n",
       " 'tout-petit': 414,\n",
       " 'camion': 415,\n",
       " 'rurale': 416,\n",
       " 'zone': 417,\n",
       " 'chefs': 418,\n",
       " 'hamburgers': 419,\n",
       " 'cuisine': 420,\n",
       " 'grimaces': 421,\n",
       " 'brun': 422,\n",
       " 'étincelles': 423,\n",
       " 'colline': 424,\n",
       " 'croix': 425,\n",
       " 'fer': 426,\n",
       " 'chevaux': 427,\n",
       " 'contenu': 428,\n",
       " 'feu': 429,\n",
       " 'travailleurs': 430,\n",
       " 'réfléchissants': 431,\n",
       " 'wagon': 432,\n",
       " 'beetle': 433,\n",
       " 'classique': 434,\n",
       " 'rustique': 435,\n",
       " 'volkswagen': 436,\n",
       " 'armature': 437,\n",
       " 'métal': 438,\n",
       " 'sans': 439,\n",
       " 'ponton': 440,\n",
       " 'matériel': 441,\n",
       " 'mascara': 442,\n",
       " 'ces': 443,\n",
       " 'cils': 444,\n",
       " 'intérieur': 445,\n",
       " 'beaucoup': 446,\n",
       " 'scooters': 447,\n",
       " 'hélicoptère': 448,\n",
       " 'régional': 449,\n",
       " 'échaffaudage': 450,\n",
       " 'quatorze': 451,\n",
       " 'diner': 452,\n",
       " 'adolescent': 453,\n",
       " 'gonflable': 454,\n",
       " 'famille': 455,\n",
       " 'vieille': 456,\n",
       " 'aliments': 457,\n",
       " 'flamboyante': 458,\n",
       " 'coiffe': 459,\n",
       " 'plume': 460,\n",
       " 'skieurs': 461,\n",
       " 'couverte': 462,\n",
       " 'sommet': 463,\n",
       " 'document': 464,\n",
       " 'clair': 465,\n",
       " 'violet': 466,\n",
       " 'corsage': 467,\n",
       " 'mains': 468,\n",
       " 'ses': 469,\n",
       " 'genoux': 470,\n",
       " 'mère': 471,\n",
       " 'promenade': 472,\n",
       " 'six': 473,\n",
       " 'palettes': 474,\n",
       " 'antique': 475,\n",
       " 'automobile': 476,\n",
       " 'moteur': 477,\n",
       " 'jerrican': 478,\n",
       " 'poney': 479,\n",
       " 'charette': 480,\n",
       " 'falaise': 481,\n",
       " 'craie': 482,\n",
       " 'adultes': 483,\n",
       " 'frapper': 484,\n",
       " 'plateforme': 485,\n",
       " 'vaste': 486,\n",
       " 'étendue': 487,\n",
       " 'coudre': 488,\n",
       " 'machine': 489,\n",
       " 'bland': 490,\n",
       " 'marché': 491,\n",
       " 'vendant': 492,\n",
       " 'poivrons': 493,\n",
       " 'agée': 494,\n",
       " 'chaine': 495,\n",
       " '4': 496,\n",
       " 'bulles': 497,\n",
       " 'pré': 498,\n",
       " 'tunnel': 499,\n",
       " 'poussière': 500,\n",
       " 'fleuri': 501,\n",
       " 'imprimé': 502,\n",
       " 'barrière': 503,\n",
       " 'casquettes': 504,\n",
       " 'colorées': 505,\n",
       " 'rangée': 506,\n",
       " 'moto-neige': 507,\n",
       " 'sortie': 508,\n",
       " 'pliante': 509,\n",
       " 'pile': 510,\n",
       " 'ville': 511,\n",
       " 'bruns': 512,\n",
       " 'pétales': 513,\n",
       " 'fleur': 514,\n",
       " 'quad': 515,\n",
       " 'foncés': 516,\n",
       " 'poêle': 517,\n",
       " 'spatule': 518,\n",
       " 'champs': 519,\n",
       " 'entouré': 520,\n",
       " 'vache': 521,\n",
       " 'bateau': 522,\n",
       " 'jetée': 523,\n",
       " 'sandales': 524,\n",
       " 'cardigan': 525,\n",
       " 'micro': 526,\n",
       " 'mecs': 527,\n",
       " 'three': 528,\n",
       " 'éléphant': 529,\n",
       " 'forme': 530,\n",
       " 'arbres': 531,\n",
       " 'mexicain': 532,\n",
       " 'capot': 533,\n",
       " 'jaunes': 534,\n",
       " 'rousse': 535,\n",
       " 'différents': 536,\n",
       " 'types': 537,\n",
       " 'renversé': 538,\n",
       " 'foot': 539,\n",
       " 'terrain': 540,\n",
       " 'mec': 541,\n",
       " 'congélateur': 542,\n",
       " 'tabourets': 543,\n",
       " 'américain': 544,\n",
       " 'cycliste': 545,\n",
       " 'virage': 546,\n",
       " 'coline': 547,\n",
       " 'jeans': 548,\n",
       " 'pouces': 549,\n",
       " 'escalator': 550,\n",
       " 'football': 551,\n",
       " 'joueur': 552,\n",
       " 'coéquipiers': 553,\n",
       " 'uns': 554,\n",
       " 'adverse': 555,\n",
       " 'désert': 556,\n",
       " 'amies': 557,\n",
       " 'maquillage': 558,\n",
       " 'bandeaux': 559,\n",
       " 'dame': 560,\n",
       " 'bandoulière': 561,\n",
       " 'blouson': 562,\n",
       " 'caméra': 563,\n",
       " 'bizarres': 564,\n",
       " 'vêtements': 565,\n",
       " 'porche': 566,\n",
       " 'funky': 567,\n",
       " 'habits': 568,\n",
       " 'opposée': 569,\n",
       " 'équipe': 570,\n",
       " 'tablier': 571,\n",
       " 'marron': 572,\n",
       " 'frisbee': 573,\n",
       " 'public': 574,\n",
       " 'joueurs': 575,\n",
       " 'tennis': 576,\n",
       " 'court': 577,\n",
       " 'jongleurs': 578,\n",
       " 'enflammées': 579,\n",
       " 'torches': 580,\n",
       " 'chaussures': 581,\n",
       " 'galets': 582,\n",
       " 'casquette': 583,\n",
       " 'gap': 584,\n",
       " 'grimace': 585,\n",
       " 'photo': 586,\n",
       " 'speedo': 587,\n",
       " 'scooter': 588,\n",
       " 'cartes': 589,\n",
       " 'jeu': 590,\n",
       " 'blue': 591,\n",
       " 'pabst': 592,\n",
       " 'ribbon': 593,\n",
       " 'coca': 594,\n",
       " 'light': 595,\n",
       " 'rouges': 596,\n",
       " 'alpiniste': 597,\n",
       " 'grenouille': 598,\n",
       " 'journal': 599,\n",
       " 'oiseau': 600,\n",
       " 'graines': 601,\n",
       " 'tournesol': 602,\n",
       " 'toit': 603,\n",
       " 'appareil': 604,\n",
       " 'campeur': 605,\n",
       " 'garés': 606,\n",
       " 'véhicules': 607,\n",
       " 'vagues': 608,\n",
       " 'musulmane': 609,\n",
       " 'tenue': 610,\n",
       " 'plate-forme': 611,\n",
       " 'surélevée': 612,\n",
       " 'gueule': 613,\n",
       " 'ouverte': 614,\n",
       " 'souriante': 615,\n",
       " 'extérieure': 616,\n",
       " 'navire': 617,\n",
       " 'lit': 618,\n",
       " 'réparations': 619,\n",
       " 'briques': 620,\n",
       " 'ouvrier': 621,\n",
       " 'snowboard': 622,\n",
       " 'karaté': 623,\n",
       " 'trophée': 624,\n",
       " 'gamin': 625,\n",
       " 'flotteurs': 626,\n",
       " 'lac': 627,\n",
       " 'hamburger': 628,\n",
       " 'sale': 629,\n",
       " 'hauteur': 630,\n",
       " 'mer': 631,\n",
       " 'statue': 632,\n",
       " 'bambin': 633,\n",
       " 'grise': 634,\n",
       " 'bijoux': 635,\n",
       " 'comptoir': 636,\n",
       " 'magasin': 637,\n",
       " 'escaliers': 638,\n",
       " 'église': 639,\n",
       " 'certain': 640,\n",
       " 'nombre': 641,\n",
       " 'côte': 642,\n",
       " 'menuiserie': 643,\n",
       " 'projet': 644,\n",
       " 'manuels': 645,\n",
       " 'outils': 646,\n",
       " 'mallette': 647,\n",
       " 'brune': 648,\n",
       " 'chauve': 649,\n",
       " 'poulet': 650,\n",
       " 'plan': 651,\n",
       " 'bouches': 652,\n",
       " 'écharpe': 653,\n",
       " 'tricoté': 654,\n",
       " 'algues': 655,\n",
       " 'sauteuse': 656,\n",
       " 'scie': 657,\n",
       " 'derby': 658,\n",
       " 'feminine': 659,\n",
       " 'roller': 660,\n",
       " 'entre': 661,\n",
       " 'lits': 662,\n",
       " 'tronçonneuse': 663,\n",
       " 'énorme': 664,\n",
       " 'moto': 665,\n",
       " 'affiche': 666,\n",
       " 'manuscrite': 667,\n",
       " 'bienvenue': 668,\n",
       " 'motards': 669,\n",
       " 'chose': 670,\n",
       " 'quelque': 671,\n",
       " 'ligne': 672,\n",
       " 'assis': 673,\n",
       " 'certains': 674,\n",
       " 'debout': 675,\n",
       " 'pistes': 676,\n",
       " 'décorations': 677,\n",
       " 'plafond': 678,\n",
       " 'forgeron': 679,\n",
       " 'cheval': 680,\n",
       " 'dreadlocks': 681,\n",
       " 'kilt': 682,\n",
       " 'joue': 683,\n",
       " 'passagers': 684,\n",
       " 'porcs': 685,\n",
       " 'parking': 686,\n",
       " 'flaque': 687,\n",
       " 'marchandises': 688,\n",
       " 'signe': 689,\n",
       " 'canyon': 690,\n",
       " 'clôture': 691,\n",
       " 'seau': 692,\n",
       " 'sweat-shirt': 693,\n",
       " 'velours': 694,\n",
       " 'pinceau': 695,\n",
       " 'chiffons': 696,\n",
       " 'vieillard': 697,\n",
       " 'épaules': 698,\n",
       " 'brosse': 699,\n",
       " 'grosse': 700,\n",
       " 'marteau': 701,\n",
       " 'quarte': 702,\n",
       " 'blanches': 703,\n",
       " 'chemises': 704,\n",
       " 'coupée': 705,\n",
       " 'livres': 706,\n",
       " 'poubelle': 707,\n",
       " 'ferrée': 708,\n",
       " 'voie': 709,\n",
       " 'jumelles': 710,\n",
       " 'hutte': 711,\n",
       " 'vélos': 712,\n",
       " 'échafaudage': 713,\n",
       " 'bavoir': 714,\n",
       " 'filet': 715,\n",
       " 'au': 716,\n",
       " 'baseball': 717,\n",
       " 'couvercle': 718,\n",
       " 'grill': 719,\n",
       " 'kebab': 720,\n",
       " 'shish': 721,\n",
       " 'protection': 722,\n",
       " 'chirurgicale': 723,\n",
       " 'pelle': 724,\n",
       " 'petits': 725,\n",
       " 'buisson': 726,\n",
       " 'pantalons': 727,\n",
       " 'fourche': 728,\n",
       " 'branches': 729,\n",
       " 'appartements': 730,\n",
       " 'complexe': 731,\n",
       " 'surface': 732,\n",
       " 'bâtons': 733,\n",
       " 'brettelles': 734,\n",
       " 'amis': 735,\n",
       " 'chargement': 736,\n",
       " 'rampe': 737,\n",
       " 'livre': 738,\n",
       " 'dinosaures': 739,\n",
       " 'verre': 740,\n",
       " 'traîneau': 741,\n",
       " 'pain': 742,\n",
       " 'paniers': 743,\n",
       " 'bagages': 744,\n",
       " 'propriété': 745,\n",
       " 'nageuse': 746,\n",
       " 'bonnet': 747,\n",
       " 'pince-nez': 748,\n",
       " 'ordinateurs': 749,\n",
       " 'portables': 750,\n",
       " 'fosse': 751,\n",
       " 'lumières': 752,\n",
       " 'noël': 753,\n",
       " 'poupée': 754,\n",
       " 'princesse': 755,\n",
       " 'dehors': 756,\n",
       " 'moyenne': 757,\n",
       " 'taille': 758,\n",
       " 'récipient': 759,\n",
       " 'ami': 760,\n",
       " 'laisse': 761,\n",
       " 'bassin': 762,\n",
       " 'toison': 763,\n",
       " 'manger': 764,\n",
       " 'maman': 765,\n",
       " 'grue': 766,\n",
       " 'tonnelle': 767,\n",
       " 'monde': 768,\n",
       " 'articles': 769,\n",
       " 'berge': 770,\n",
       " 'cocotte': 771,\n",
       " 'tongs': 772,\n",
       " 'transport': 773,\n",
       " 'bout': 774,\n",
       " 'client': 775,\n",
       " 'fleurs': 776,\n",
       " 'tubercules': 777,\n",
       " 'capuche': 778,\n",
       " 'tente': 779,\n",
       " 'gazon': 780,\n",
       " 'jouets': 781,\n",
       " '5': 782,\n",
       " 'athlètes': 783,\n",
       " 'hauts': 784,\n",
       " 'bas': 785,\n",
       " 'câbles': 786,\n",
       " 'joyeux': 787,\n",
       " 'elmo': 788,\n",
       " 'nourrisson': 789,\n",
       " 'désordonnée': 790,\n",
       " 'anneau': 791,\n",
       " 'nez': 792,\n",
       " 'cet': 793,\n",
       " 'fontaine': 794,\n",
       " 'foncé': 795,\n",
       " 'château': 796,\n",
       " 'seule': 797,\n",
       " 'amc': 798,\n",
       " 'bulle': 799,\n",
       " 'a': 800,\n",
       " 'beige': 801,\n",
       " 'auvent': 802,\n",
       " 'roses': 803,\n",
       " 'employés': 804,\n",
       " 'parents': 805,\n",
       " 'chariots': 806,\n",
       " 'voitures': 807,\n",
       " 'arrosage': 808,\n",
       " 'bâches': 809,\n",
       " 'florida': 810,\n",
       " 'marlins': 811,\n",
       " 'courses': 812,\n",
       " 'monsieur': 813,\n",
       " 'sentier': 814,\n",
       " 'cette': 815,\n",
       " 'image': 816,\n",
       " 'cantonniers': 817,\n",
       " 'vestes': 818,\n",
       " 'oranges': 819,\n",
       " 'brouette': 820,\n",
       " 'pilotis': 821,\n",
       " 'batteurs': 822,\n",
       " 'terrier': 823,\n",
       " 'gazonné': 824,\n",
       " 'carreaux': 825,\n",
       " 'carnaval': 826,\n",
       " 'tour': 827,\n",
       " 'clown': 828,\n",
       " 'faux': 829,\n",
       " 'blonds': 830,\n",
       " 'sales': 831,\n",
       " 'age': 832,\n",
       " 'moyen': 833,\n",
       " 'couettes': 834,\n",
       " 'ordinateur': 835,\n",
       " 'écran': 836,\n",
       " 'chers': 837,\n",
       " 'vitrine': 838,\n",
       " 'boutiques': 839,\n",
       " 'peut-être': 840,\n",
       " 'publicité': 841,\n",
       " 'rétro-éclairé': 842,\n",
       " 'agens': 843,\n",
       " 'murale': 844,\n",
       " 'grosses': 845,\n",
       " 'manches': 846,\n",
       " 'barbe': 847,\n",
       " 'argent': 848,\n",
       " 'monocycle': 849,\n",
       " 'trottinette': 850,\n",
       " 'ski': 851,\n",
       " 'crabe': 852,\n",
       " 'bétonné': 853,\n",
       " 'pull': 854,\n",
       " 'dragon': 855,\n",
       " 'marionnette': 856,\n",
       " 'jardin': 857,\n",
       " 'bâtiments': 858,\n",
       " 'murs': 859,\n",
       " 'vertes': 860,\n",
       " 'jour': 861,\n",
       " 'brillante': 862,\n",
       " 'violette': 863,\n",
       " 'clients': 864,\n",
       " 'guichet': 865,\n",
       " 'bonnets': 866,\n",
       " 'sur': 867,\n",
       " 'navetteurs': 868,\n",
       " 'haute': 869,\n",
       " 'pratiquants': 870,\n",
       " 'clavier': 871,\n",
       " 'spectateurs': 872,\n",
       " 'visière': 873,\n",
       " 'ceintures': 874,\n",
       " 'noires': 875,\n",
       " 'martiaux': 876,\n",
       " 'étudiante': 877,\n",
       " 'arme': 878,\n",
       " 'arts': 879,\n",
       " 'stand': 880,\n",
       " 'papa': 881,\n",
       " '8': 882,\n",
       " 'pierres': 883,\n",
       " 'tuiles': 884,\n",
       " 'clairs': 885,\n",
       " 'sandwich': 886,\n",
       " 'blocs': 887,\n",
       " 'rectangulaires': 888,\n",
       " 'roue': 889,\n",
       " 'balles': 890,\n",
       " 'multicolores': 891,\n",
       " 'quilles': 892,\n",
       " 'gravillonnée': 893,\n",
       " 'afro-américains': 894,\n",
       " 'trompette': 895,\n",
       " 'badauds': 896,\n",
       " 'officiers': 897,\n",
       " 'brunes': 898,\n",
       " 'tenues': 899,\n",
       " 'boussole': 900,\n",
       " 'coté': 901,\n",
       " 'péniche': 902,\n",
       " 'balancelle': 903,\n",
       " 'gant': 904,\n",
       " 'abondante': 905,\n",
       " 'fluo': 906,\n",
       " 'agents': 907,\n",
       " 'voirie': 908,\n",
       " 'toile': 909,\n",
       " 'balançoire': 910,\n",
       " 'avec': 911,\n",
       " 'pêchent': 912,\n",
       " 'cuillère': 913,\n",
       " 'pêcheur': 914,\n",
       " 'baume': 915,\n",
       " 'lèvres': 916,\n",
       " 'boutons': 917,\n",
       " 'mixage': 918,\n",
       " 'rayures': 919,\n",
       " 'stands': 920,\n",
       " 'plaine': 921,\n",
       " 'adolescentes': 922,\n",
       " 'tétine': 923,\n",
       " 'fauteuil': 924,\n",
       " 'rickshaw': 925,\n",
       " 'élégant': 926,\n",
       " 'navigable': 927,\n",
       " 'surveillance': 928,\n",
       " 'rembourré': 929,\n",
       " 'fermier': 930,\n",
       " 'bar': 931,\n",
       " 'canettes': 932,\n",
       " 'soda': 933,\n",
       " 'autour': 934,\n",
       " 'grills': 935,\n",
       " 'viande': 936,\n",
       " 'grands': 937,\n",
       " 'bancs': 938,\n",
       " 'secouristes': 939,\n",
       " 'argile': 940,\n",
       " 'potier': 941,\n",
       " 'artiste': 942,\n",
       " 'dessin': 943,\n",
       " 'section': 944,\n",
       " 'élaboré': 945,\n",
       " 'imposante': 946,\n",
       " 'batterie': 947,\n",
       " 'onze': 948,\n",
       " 'tabouret': 949,\n",
       " 'cages': 950,\n",
       " 'lot': 951,\n",
       " 'inhabituelle': 952,\n",
       " 'manière': 953,\n",
       " 'vêtu': 954,\n",
       " 'crème': 955,\n",
       " 'glacée': 956,\n",
       " 'réfrigérateur': 957,\n",
       " 'tiare': 958,\n",
       " 'error': 959,\n",
       " 'bouclé': 960,\n",
       " 'reflet': 961,\n",
       " 'marbre': 962,\n",
       " 'poli': 963,\n",
       " 'hanches': 964,\n",
       " 'cigarette': 965,\n",
       " 'important': 966,\n",
       " 'cuisinier': 967,\n",
       " 'vin': 968,\n",
       " 'poils': 969,\n",
       " 'steak': 970,\n",
       " 'plateau': 971,\n",
       " 'paix': 972,\n",
       " 'masques': 973,\n",
       " 'costumes': 974,\n",
       " 'statues': 975,\n",
       " 'chat': 976,\n",
       " 'longs': 977,\n",
       " 'tipi': 978,\n",
       " 'roues': 979,\n",
       " 'enclume': 980,\n",
       " 'violoncelle': 981,\n",
       " 'tranquille': 982,\n",
       " 'billard': 983,\n",
       " 'circuit': 984,\n",
       " 'motocross': 985,\n",
       " 'bibliothèque': 986,\n",
       " 'sous-vêtements': 987,\n",
       " 'hangar': 988,\n",
       " 'cyclistes': 989,\n",
       " 'grille': 990,\n",
       " 'employées': 991,\n",
       " 'assiette': 992,\n",
       " 'indiquant': 993,\n",
       " 'mongol': 994,\n",
       " 'néon': 995,\n",
       " 'deere': 996,\n",
       " 'john': 997,\n",
       " 'remorque': 998,\n",
       " 'baril': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus_dct.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blancs'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus_dct[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('white', 0.9565217),\n",
       " ('caucasian', 0.0096618),\n",
       " ('NULL', 0.0048309),\n",
       " (',', 0.0048309),\n",
       " ('white-haired', 0.0193237),\n",
       " ('off-white', 0.0048309)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_to_english_dict[training_corpus_dct[2]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'white'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(fr_to_english_dict[training_corpus_dct[2]] ,key=itemgetter(1))[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8527,  0.5294, -0.6895,  ...,  2.0311, -0.0134,  1.1480],\n",
       "        [ 1.2868, -0.8130,  0.7805,  ...,  0.6445, -0.9368,  0.3593],\n",
       "        [ 0.4793, -1.3415,  0.6454,  ...,  0.0378,  0.4528,  0.2666],\n",
       "        ...,\n",
       "        [ 0.4754,  0.1144,  0.1752,  ...,  0.6446,  0.1226,  0.1080],\n",
       "        [ 1.4716,  0.0152, -0.0180,  ..., -0.3622,  0.9209, -0.7837],\n",
       "        [-0.0265,  0.3146, -0.0446,  ...,  0.7971,  0.3188, -0.7310]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping examples comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2453\n",
      "14384\n"
     ]
    }
   ],
   "source": [
    "print(len(training_corpus_dct.token2id))\n",
    "print(len(training_corpus_dct_en.token2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = []\n",
    "for i in range(sample_size):\n",
    "    sample_list.append(random.randint(0, len(training_corpus_dct.token2id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[603,\n",
       " 335,\n",
       " 340,\n",
       " 409,\n",
       " 1491,\n",
       " 125,\n",
       " 1137,\n",
       " 2183,\n",
       " 128,\n",
       " 2109,\n",
       " 2027,\n",
       " 1576,\n",
       " 1566,\n",
       " 493,\n",
       " 1807,\n",
       " 1540,\n",
       " 1317,\n",
       " 147,\n",
       " 2029,\n",
       " 158]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_samples = [training_corpus_dct[index] for index in sample_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toit\n",
      "planche\n",
      "pulls\n",
      "toboggan\n",
      "âgée\n",
      "fourgon\n",
      "aride\n",
      "percussion\n",
      "enneigée\n",
      "dorures\n",
      "mendiant\n",
      "tricolore\n",
      "motocyclette\n",
      "poivrons\n",
      "évier\n",
      "percés\n",
      "tenant\n",
      "mari\n",
      "contreplaqué\n",
      "picnic\n"
     ]
    }
   ],
   "source": [
    "for elt in fr_samples:\n",
    "    print(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random mapping results:\n",
    "en_random_indices = []\n",
    "for i in range(sample_size):\n",
    "    en_random_indices.append(random.randint(0, len(training_corpus_dct_en.token2id)))\n",
    "en_random_mapping = [training_corpus_dct_en[index] for index in en_random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brownish-red\n",
      "turban\n",
      "refreshments\n",
      "deere\n",
      "refinery\n",
      "array\n",
      "cloth\n",
      "megaphones\n",
      "throng\n",
      "forrest\n",
      "shutter\n",
      "rancher\n",
      "incomplete\n",
      "reflections\n",
      "britain\n",
      "thick-striped\n",
      "studying\n",
      "pallet\n",
      "fishers\n",
      "smirnoff\n"
     ]
    }
   ],
   "source": [
    "for elt in en_random_mapping:\n",
    "    print(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pitcher',\n",
       " 'flags',\n",
       " 'railing',\n",
       " 'shore',\n",
       " 'shelf',\n",
       " 'bag',\n",
       " 'ceiling',\n",
       " 'slot',\n",
       " 'shirts',\n",
       " 'extreme',\n",
       " 'teddy',\n",
       " 'marble',\n",
       " 'portrait',\n",
       " 'brightly',\n",
       " 'bundle',\n",
       " 'nurse',\n",
       " 'trucks',\n",
       " 'clothes',\n",
       " 'skin',\n",
       " 'outfit']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_freq_mapping = []\n",
    "for i in range(sample_size):\n",
    "    fr_word_index = sample_list[i]\n",
    "    en_word = training_corpus_dct_en[freq_list_en[fr_word_index][0]]\n",
    "    en_freq_mapping.append(en_word)\n",
    "en_freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitcher\n",
      "flags\n",
      "railing\n",
      "shore\n",
      "shelf\n",
      "bag\n",
      "ceiling\n",
      "slot\n",
      "shirts\n",
      "extreme\n",
      "teddy\n",
      "marble\n",
      "portrait\n",
      "brightly\n",
      "bundle\n",
      "nurse\n",
      "trucks\n",
      "clothes\n",
      "skin\n",
      "outfit\n"
     ]
    }
   ],
   "source": [
    "for elt in en_freq_mapping:\n",
    "    print(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(general_dictionary_file, 'r') as f:\n",
    "    dictionary_file_content = f.readlines()\n",
    "\n",
    "fr_to_english_gn_dict = {}\n",
    "for line in dictionary_file_content:\n",
    "    parts = line[:-1].split(' ')  # line example: 'garçons boys\\n'\n",
    "    fr_to_english_gn_dict[parts[0]] = parts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emptywordtoken': 'emptywordtoken',\n",
       " 'unknownword': 'unknownword',\n",
       " 'blancs': 'whites',\n",
       " 'deux': 'two',\n",
       " 'hommes': 'men',\n",
       " 'jeunes': 'youth',\n",
       " 'buissons': 'bushes',\n",
       " 'de': 'of',\n",
       " 'plusieurs': 'many',\n",
       " 'casque': 'helmet',\n",
       " 'géant': 'giant',\n",
       " 'poulies': 'pulleys',\n",
       " 'système': 'system',\n",
       " 'un': 'a',\n",
       " 'fille': 'girl',\n",
       " 'petite': 'small',\n",
       " 'une': 'a',\n",
       " 'bois': 'wood',\n",
       " 'en': 'in',\n",
       " 'maisonnette': 'house',\n",
       " 'homme': 'man',\n",
       " 'bleue': 'blue',\n",
       " 'chemise': 'shirt',\n",
       " 'échelle': 'ladder',\n",
       " 'fenêtre': 'window',\n",
       " 'fourneaux': 'furnaces',\n",
       " 'vert': 'green',\n",
       " 'guitare': 'guitar',\n",
       " 'autre': 'other',\n",
       " 'sa': 'her',\n",
       " 'ours': 'bear',\n",
       " 'peluche': 'plush',\n",
       " 'branchée': 'connected',\n",
       " 'portable': 'portable',\n",
       " 'son': 'his',\n",
       " 'la': 'the',\n",
       " 'rue': 'street',\n",
       " 'femme': 'women',\n",
       " 'gros': 'large',\n",
       " 'sac': 'bag',\n",
       " 'porte': 'door',\n",
       " 'des': 'the',\n",
       " 'garçons': 'boys',\n",
       " 'barres': 'bars',\n",
       " ',': ',',\n",
       " 'ballet': 'ballet',\n",
       " 'cinq': 'five',\n",
       " 'classe': 'class',\n",
       " 'composée': 'composite',\n",
       " 'filles': 'girls',\n",
       " 'gars': 'guys',\n",
       " 'quatre': 'four',\n",
       " 'chapeaux': 'hats',\n",
       " \"'\": \"'\",\n",
       " 'd': 'd',\n",
       " 'escalier': 'staircase',\n",
       " 'haut': 'top',\n",
       " 'chien': 'dog',\n",
       " 'noir': 'black',\n",
       " 'tâches': 'tasks',\n",
       " 'à': 'at',\n",
       " 'orange': 'orange',\n",
       " 'uniforme': 'uniform',\n",
       " 'tracteur': 'tractor',\n",
       " 'femmes': 'women',\n",
       " 'lunettes': 'glasses',\n",
       " 'sucre': 'sugar',\n",
       " 'bundt': 'bundt',\n",
       " 'cake': 'cake',\n",
       " 'arc-en-ciel': 'Rainbow',\n",
       " 'grand': 'great',\n",
       " 'peint': 'painted',\n",
       " '[': '[',\n",
       " 'banc': 'bench',\n",
       " 'blanc': 'White',\n",
       " 'personnes': 'people',\n",
       " 'cercle': 'circle',\n",
       " 'instruments': 'instruments',\n",
       " 'leurs': 'their',\n",
       " 'groupe': 'group',\n",
       " 'âgées': 'elderly',\n",
       " 'clarinette': 'clarinet',\n",
       " 'leur': 'their',\n",
       " 'partition': 'partition',\n",
       " 'grande': 'great',\n",
       " 'structure': 'structure',\n",
       " 'chaussée': 'roadway',\n",
       " 'foule': 'crowd',\n",
       " 'gens': 'people',\n",
       " 'importante': 'important',\n",
       " 'dos': 'back',\n",
       " 'enfants': 'children',\n",
       " 'bascule': 'rocker',\n",
       " 'manège': 'carousel',\n",
       " 'petit': 'small',\n",
       " 'le': 'the',\n",
       " 'sable': 'sand',\n",
       " 'gilet': 'vest',\n",
       " 'réfléchissant': 'reflective',\n",
       " 'drapeau': 'flag',\n",
       " 'route': 'road',\n",
       " 'personne': 'nobody',\n",
       " 'bleu': 'blue',\n",
       " 'manteau': 'coat',\n",
       " 'encombré': 'crowded',\n",
       " 'trottoir': 'pavement',\n",
       " 'peinture': 'painting',\n",
       " 'représentant': 'representative',\n",
       " 'scène': 'scene',\n",
       " 'pantalon': 'trousers',\n",
       " 'enfant': 'child',\n",
       " 'rouge': 'red',\n",
       " 'jeune': 'young',\n",
       " 'et': 'and',\n",
       " 'jaune': 'yellow',\n",
       " 'noire': 'black',\n",
       " 'veste': 'jacket',\n",
       " 'urinoir': 'urinal',\n",
       " 'café': 'coffee',\n",
       " 'tasse': 'Cup',\n",
       " 'vieil': 'old',\n",
       " 'bière': 'beer',\n",
       " 'dressé': 'trained',\n",
       " 'policier': 'officer',\n",
       " 'maître': 'master',\n",
       " 'fourgon': 'van',\n",
       " 'police': 'police',\n",
       " 'vélo': 'bike',\n",
       " 'enneigée': 'snow',\n",
       " 'blanche': 'white',\n",
       " 'cravate': 'tie',\n",
       " 'arrière': 'back',\n",
       " 'l': 'l',\n",
       " 'ouvert': 'open',\n",
       " 'chapeau': 'hat',\n",
       " 'machines': 'machinery',\n",
       " 'bougies': 'candles',\n",
       " 'cartons': 'cartons',\n",
       " 'asiatique': 'Asian',\n",
       " 'voiture': 'car',\n",
       " 'conducteur': 'driver',\n",
       " 'bambins': 'toddlers',\n",
       " 'véhicule': 'vehicle',\n",
       " 'étrange': 'strange',\n",
       " 'argenté': 'silver',\n",
       " 'belle': 'pretty',\n",
       " 'mariée': 'married',\n",
       " 'mari': 'husband',\n",
       " 'nouveau': 'new',\n",
       " 'garçon': 'boy',\n",
       " 'gamecube': 'gamecube',\n",
       " 'mcdonald': 'mcdonald',\n",
       " 'bord': 'edge',\n",
       " 'plage': 'beach',\n",
       " 'balle': 'ball',\n",
       " 'soleil': 'Sun',\n",
       " 'chemisier': 'blouse',\n",
       " 'ballons': 'balloons',\n",
       " 'picnic': 'picnic',\n",
       " 'tables': 'tables',\n",
       " 'trois': 'three',\n",
       " 'du': 'of',\n",
       " 'eau': 'water',\n",
       " 'morceau': 'piece',\n",
       " 'papier': 'paper',\n",
       " 'salopette': 'overalls',\n",
       " 'mur': 'Wall',\n",
       " 'pierre': 'Pierre',\n",
       " 'bûche': 'log',\n",
       " 'costume': 'suit',\n",
       " 'autres': 'other',\n",
       " 'messieurs': 'gentlemen',\n",
       " 'nus': 'naked',\n",
       " 'pieds': 'feet',\n",
       " 'fort': 'strong',\n",
       " 'olive': 'olive',\n",
       " 'hotdogs': 'hotdogs',\n",
       " 'réchaud': 'stove',\n",
       " 'plastique': 'plastic',\n",
       " 'neige': 'snow',\n",
       " 'skis': 'skis',\n",
       " 'illustrations': 'illustrations',\n",
       " 'les': 'the',\n",
       " 'alpinistes': 'mountaineers',\n",
       " 'sept': 'seven',\n",
       " 'rocher': 'rock',\n",
       " 'corde': 'rope',\n",
       " 'corps': 'body',\n",
       " 'gymnaste': 'gymnast',\n",
       " 'souple': 'flexible',\n",
       " 'poutre': 'beam',\n",
       " 'équilibre': 'balanced',\n",
       " 'atv': 'atv',\n",
       " 'jouet': 'toy',\n",
       " 'caoutchouc': 'rubber',\n",
       " 'piscine': 'pool',\n",
       " 'coupe-vent': 'windbreaker',\n",
       " 'objet': 'object',\n",
       " 'avion': 'plane',\n",
       " 'tuyau': 'pipe',\n",
       " 'chariot': 'cart',\n",
       " 'chiens': 'dogs',\n",
       " 'pour': 'for',\n",
       " 'type': 'type',\n",
       " 'verte': 'green',\n",
       " 'main': 'hand',\n",
       " 'partie': 'part',\n",
       " 'visage': 'face',\n",
       " 'restaurant': 'restaurant',\n",
       " 'randonneurs': 'hikers',\n",
       " 'création': 'creation',\n",
       " 'nouvelle': 'news',\n",
       " 'père': 'Father',\n",
       " 'âgé': 'age',\n",
       " 'adulte': 'adult',\n",
       " 'fils': 'son',\n",
       " 'barbu': 'bearded',\n",
       " 'voyageur': 'traveler',\n",
       " 'carte': 'map',\n",
       " 'canard': 'duck',\n",
       " 'parc': 'Park',\n",
       " 'couple': 'couple',\n",
       " 'herbe': 'grass',\n",
       " 'bébé': 'baby',\n",
       " 'poussette': 'stroller',\n",
       " 'quelques': 'few',\n",
       " 'immeuble': 'building',\n",
       " 'stationnement': 'parking',\n",
       " 'gelé': 'frozen',\n",
       " 'glace': 'cream',\n",
       " 'étang': 'pond',\n",
       " 'beiges': 'beige',\n",
       " 'imposants': 'imposing',\n",
       " 'pics': 'peaks',\n",
       " 'chemin': 'path',\n",
       " 'fait': 'made',\n",
       " 'pelletées': 'Scoops',\n",
       " 'gâteau': 'cake',\n",
       " 'mariage': 'wedding',\n",
       " 'mouillé': 'wet',\n",
       " 'villageois': 'villager',\n",
       " 'récolte': 'harvest',\n",
       " 'chanteur': 'singer',\n",
       " 't-shirt': 'T-shirt',\n",
       " 'skateboard': 'skateboard',\n",
       " 'kayak': 'kayak',\n",
       " 'chantier': 'site',\n",
       " 'construction': 'construction',\n",
       " 'panneau': 'sign',\n",
       " 'publicitaire': 'advertiser',\n",
       " 'drapeaux': 'flags',\n",
       " 'poisson': 'fish',\n",
       " 'débardeur': 'longshoreman',\n",
       " 'jupe': 'skirt',\n",
       " 'extérieur': 'outside',\n",
       " 'marches': 'steps',\n",
       " 'bouche': 'stuffy',\n",
       " 'but': 'goal',\n",
       " 'gardien': 'guardian',\n",
       " 'hockey': 'hockey',\n",
       " 'objectif': 'goal',\n",
       " 'bâton': 'stick',\n",
       " 'bâtiment': 'building',\n",
       " 'cour': 'court',\n",
       " '.': '.',\n",
       " 'art': 'art',\n",
       " 'sculpture': 'sculpture',\n",
       " 'tout': 'all',\n",
       " 'garde-corps': 'bodyguard',\n",
       " 'champ': 'field',\n",
       " 'herbeux': 'grassy',\n",
       " 'gratte-ciel': 'Skyscraper',\n",
       " 'fruits': 'fruits',\n",
       " 'blond': 'blond',\n",
       " 'aux': 'the',\n",
       " 'cheveux': 'hair',\n",
       " 'noirs': 'black',\n",
       " 'table': 'table',\n",
       " 'nourriture': 'food',\n",
       " 'électrique': 'electric',\n",
       " 'couleur': 'color',\n",
       " 'béton': 'concrete',\n",
       " 'couverture': 'blanket',\n",
       " 'solitaire': 'solitary',\n",
       " 'pont': 'bridge',\n",
       " 'haricots': 'beans',\n",
       " 'verts': 'green',\n",
       " 'barbecue': 'barbecue',\n",
       " 'rebord': 'flange',\n",
       " 'montagne': 'Mountain',\n",
       " 'passerelle': 'bridge',\n",
       " 'très': 'very',\n",
       " 'petites': 'small',\n",
       " 'blonde': 'hair',\n",
       " 'gris': 'Grey',\n",
       " 'chaise': 'chair',\n",
       " 'instrument': 'instrument',\n",
       " 'bambou': 'bamboo',\n",
       " 'fréquentée': 'crowded',\n",
       " '30': '30',\n",
       " 'ans': 'years',\n",
       " 'plus': 'more',\n",
       " 'nouilles': 'noodles',\n",
       " 'bol': 'bowl',\n",
       " 'tête': 'head',\n",
       " 'trou': 'hole',\n",
       " 'individus': 'people',\n",
       " 'baignoire': 'bath',\n",
       " 'dort': 'sleeps',\n",
       " 'rayé': 'striped',\n",
       " 'rose': 'pink',\n",
       " 'africaine': 'African',\n",
       " 'membre': 'member',\n",
       " 'tribu': 'tribe',\n",
       " 'robe': 'dress',\n",
       " 'tribale': 'tribal',\n",
       " 'guerrier': 'warrior',\n",
       " 'samouraï': 'samurai',\n",
       " 'épée': 'sword',\n",
       " 'fourreau': 'scabbard',\n",
       " 'entraînement': 'training',\n",
       " 'tapis': 'carpet',\n",
       " 'rail': 'rail',\n",
       " 'rivière': 'river',\n",
       " 'rocheuse': 'rocky',\n",
       " 'agent': 'agent',\n",
       " 'sécurité': 'security',\n",
       " 'pourpre': 'purple',\n",
       " 'téléphone': 'phone',\n",
       " 'multicolore': 'multicolour',\n",
       " 'boule': 'ball',\n",
       " 'droite': 'right',\n",
       " 'maison': 'House',\n",
       " 'sol': 'ground',\n",
       " 'planchiste': 'windsurfer',\n",
       " 'planche': 'board',\n",
       " 'bouteille': 'bottle',\n",
       " 'pilote': 'pilot',\n",
       " 'talkie-walkie': 'Walkie',\n",
       " 'nattes': 'mats',\n",
       " 'pulls': 'sweaters',\n",
       " 'repas': 'meal',\n",
       " 'ouvriers': 'workers',\n",
       " 'acier': 'steel',\n",
       " 'ballon': 'ball',\n",
       " 'boue': 'mud',\n",
       " 'brochure': 'brochure',\n",
       " 'plongeoir': 'diving',\n",
       " 'claire': 'clear',\n",
       " 'bassine': 'basin',\n",
       " 'fruit': 'fruit',\n",
       " 'arrêt': 'stop',\n",
       " 'bus': 'bus',\n",
       " 'jean': 'jeans',\n",
       " 'arbre': 'tree',\n",
       " 'crêpe': 'crepe',\n",
       " 'pompiers': 'department',\n",
       " 'camions': 'trucks',\n",
       " 'rivage': 'shore',\n",
       " 'casques': 'helmets',\n",
       " 'gilets': 'vests',\n",
       " 'magazines': 'magazines',\n",
       " 'vendeur': 'seller',\n",
       " 'collage': 'sticking',\n",
       " 'coloré': 'colored',\n",
       " 'boulangerie': 'bakery',\n",
       " 'apprenti': 'apprentice',\n",
       " 'nu': 'bare',\n",
       " 'torse': 'torso',\n",
       " 'ombre': 'shadow',\n",
       " 'tropicale': 'tropical',\n",
       " 'bain': 'bath',\n",
       " 'short': 'shorts',\n",
       " 'skieur': 'skier',\n",
       " 'juste': 'just',\n",
       " 'monticule': 'mound',\n",
       " 'terre': 'Earth',\n",
       " 'coureurs': 'runners',\n",
       " 'tas': 'heap',\n",
       " 'milieu': 'middle',\n",
       " 'canne': 'cane',\n",
       " 'médecin': 'doctor',\n",
       " 'infirmières': 'nurses',\n",
       " 'bleues': 'blue',\n",
       " 'blouses': 'blouses',\n",
       " 'laineux': 'woolly',\n",
       " 'doberman': 'Doberman',\n",
       " 'bowling': 'bowling',\n",
       " 'piste': 'track',\n",
       " 'ridé': 'wrinkled',\n",
       " 'magnifique': 'magnificent',\n",
       " 'âne': 'donkey',\n",
       " 'rochers': 'rocks',\n",
       " 'canapé': 'sofa',\n",
       " 'maillot': 'shirt',\n",
       " 'javelot': 'javelin',\n",
       " 'montgolfières': 'Balloon',\n",
       " 'magazine': 'magazine',\n",
       " 'épaule': 'shoulder',\n",
       " 'allumer': 'up',\n",
       " 'centre': 'center',\n",
       " 'commercial': 'commercial',\n",
       " 'pièce': 'piece',\n",
       " 'sombre': 'dark',\n",
       " 'mousse': 'foam',\n",
       " 'dizaines': 'tens',\n",
       " 'bikini': 'bikini',\n",
       " 'cowboy': 'cowboy',\n",
       " 'paille': 'Straw',\n",
       " 'toboggan': 'toboggan',\n",
       " 'colorés': 'colorful',\n",
       " 'tubes': 'tubing',\n",
       " 'combinaison': 'combination',\n",
       " 'plongée': 'diving',\n",
       " 'tout-petit': 'tiny',\n",
       " 'camion': 'truck',\n",
       " 'rurale': 'rural',\n",
       " 'zone': 'zoned',\n",
       " 'chefs': 'heads',\n",
       " 'hamburgers': 'burgers',\n",
       " 'cuisine': 'cooked',\n",
       " 'grimaces': 'faces',\n",
       " 'brun': 'brown',\n",
       " 'étincelles': 'Sparks',\n",
       " 'colline': 'hill',\n",
       " 'croix': 'cross',\n",
       " 'fer': 'iron',\n",
       " 'chevaux': 'horses',\n",
       " 'contenu': 'contents',\n",
       " 'feu': 'fire',\n",
       " 'travailleurs': 'workers',\n",
       " 'réfléchissants': 'reflective',\n",
       " 'wagon': 'car',\n",
       " 'beetle': 'beetle',\n",
       " 'classique': 'classical',\n",
       " 'rustique': 'rustic',\n",
       " 'volkswagen': 'volkswagen',\n",
       " 'armature': 'armature',\n",
       " 'métal': 'metal',\n",
       " 'sans': 'without',\n",
       " 'ponton': 'pontoon',\n",
       " 'matériel': 'equipment',\n",
       " 'mascara': 'mascara',\n",
       " 'ces': 'these',\n",
       " 'cils': 'eyelashes',\n",
       " 'intérieur': 'inside',\n",
       " 'beaucoup': 'lot',\n",
       " 'scooters': 'scooters',\n",
       " 'hélicoptère': 'helicopter',\n",
       " 'régional': 'regional',\n",
       " 'échaffaudage': 'scaffolding',\n",
       " 'quatorze': 'fourteen',\n",
       " 'diner': 'dinner',\n",
       " 'adolescent': 'teenager',\n",
       " 'gonflable': 'inflatable',\n",
       " 'famille': 'family',\n",
       " 'vieille': 'old',\n",
       " 'aliments': 'food',\n",
       " 'flamboyante': 'flamboyant',\n",
       " 'coiffe': 'cap',\n",
       " 'plume': 'feather',\n",
       " 'skieurs': 'skiers',\n",
       " 'couverte': 'covered',\n",
       " 'sommet': 'peak',\n",
       " 'document': 'document',\n",
       " 'clair': 'clear',\n",
       " 'violet': 'purple',\n",
       " 'corsage': 'bodice',\n",
       " 'mains': 'hands',\n",
       " 'ses': 'his',\n",
       " 'genoux': 'knees',\n",
       " 'mère': 'mother',\n",
       " 'promenade': 'walk',\n",
       " 'six': 'six',\n",
       " 'palettes': 'pallets',\n",
       " 'antique': 'antique',\n",
       " 'automobile': 'automotive',\n",
       " 'moteur': 'engine',\n",
       " 'jerrican': 'jerry',\n",
       " 'poney': 'pony',\n",
       " 'charette': 'wagon',\n",
       " 'falaise': 'cliff',\n",
       " 'craie': 'chalk',\n",
       " 'adultes': 'adults',\n",
       " 'frapper': 'hit',\n",
       " 'plateforme': 'platform',\n",
       " 'vaste': 'wide',\n",
       " 'étendue': 'scope',\n",
       " 'coudre': 'sew',\n",
       " 'machine': 'machine',\n",
       " 'bland': 'bland',\n",
       " 'marché': 'market',\n",
       " 'vendant': 'selling',\n",
       " 'poivrons': 'peppers',\n",
       " 'agée': 'agée',\n",
       " 'chaine': 'chain',\n",
       " '4': '4',\n",
       " 'bulles': 'bubbles',\n",
       " 'pré': 'pre',\n",
       " 'tunnel': 'tunnel',\n",
       " 'poussière': 'dust',\n",
       " 'fleuri': 'flowery',\n",
       " 'imprimé': 'printed',\n",
       " 'barrière': 'fence',\n",
       " 'casquettes': 'caps',\n",
       " 'colorées': 'colored',\n",
       " 'rangée': 'row',\n",
       " 'moto-neige': 'snowmobile',\n",
       " 'sortie': 'exit',\n",
       " 'pliante': 'folding',\n",
       " 'pile': 'battery',\n",
       " 'ville': 'city',\n",
       " 'bruns': 'brown',\n",
       " 'pétales': 'petals',\n",
       " 'fleur': 'flower',\n",
       " 'quad': 'quad',\n",
       " 'foncés': 'dark',\n",
       " 'poêle': 'stove',\n",
       " 'spatule': 'spatula',\n",
       " 'champs': 'fields',\n",
       " 'entouré': 'surrounded',\n",
       " 'vache': 'cow',\n",
       " 'bateau': 'boat',\n",
       " 'jetée': 'jetty',\n",
       " 'sandales': 'sandals',\n",
       " 'cardigan': 'cardigan',\n",
       " 'micro': 'microphone',\n",
       " 'mecs': 'guys',\n",
       " 'three': 'three',\n",
       " 'éléphant': 'elephant',\n",
       " 'forme': 'form',\n",
       " 'arbres': 'trees',\n",
       " 'mexicain': 'Mexican',\n",
       " 'capot': 'hood',\n",
       " 'jaunes': 'yellows',\n",
       " 'rousse': 'redhead',\n",
       " 'différents': 'different',\n",
       " 'types': 'Types',\n",
       " 'renversé': 'reversed',\n",
       " 'foot': 'football',\n",
       " 'terrain': 'ground',\n",
       " 'mec': 'guy',\n",
       " 'congélateur': 'freezer',\n",
       " 'tabourets': 'stools',\n",
       " 'américain': 'American',\n",
       " 'cycliste': 'cyclist',\n",
       " 'virage': 'turn',\n",
       " 'coline': 'hill',\n",
       " 'jeans': 'jeans',\n",
       " 'pouces': 'inch',\n",
       " 'escalator': 'escalator',\n",
       " 'football': 'soccer',\n",
       " 'joueur': 'player',\n",
       " 'coéquipiers': 'teammates',\n",
       " 'uns': 'each',\n",
       " 'adverse': 'adverse',\n",
       " 'désert': 'desert',\n",
       " 'amies': 'friends',\n",
       " 'maquillage': 'makeup',\n",
       " 'bandeaux': 'headbands',\n",
       " 'dame': 'lady',\n",
       " 'bandoulière': 'strap',\n",
       " 'blouson': 'jacket',\n",
       " 'caméra': 'camera',\n",
       " 'bizarres': 'weird',\n",
       " 'vêtements': 'clothing',\n",
       " 'porche': 'porch',\n",
       " 'funky': 'funky',\n",
       " 'habits': 'clothes',\n",
       " 'opposée': 'opposite',\n",
       " 'équipe': 'team',\n",
       " 'tablier': 'apron',\n",
       " 'marron': 'Brown',\n",
       " 'frisbee': 'Frisbee',\n",
       " 'public': 'public',\n",
       " 'joueurs': 'players',\n",
       " 'tennis': 'tennis',\n",
       " 'court': 'short',\n",
       " 'jongleurs': 'jugglers',\n",
       " 'enflammées': 'inflamed',\n",
       " 'torches': 'torches',\n",
       " 'chaussures': 'shoes',\n",
       " 'galets': 'shingle',\n",
       " 'casquette': 'cap',\n",
       " 'gap': 'gap',\n",
       " 'grimace': 'grimace',\n",
       " 'photo': 'Photo',\n",
       " 'speedo': 'speedo',\n",
       " 'scooter': 'scooter',\n",
       " 'cartes': 'cards',\n",
       " 'jeu': 'Thu',\n",
       " 'blue': 'blue',\n",
       " 'pabst': 'pabst',\n",
       " 'ribbon': 'ribbon',\n",
       " 'coca': 'Coca',\n",
       " 'light': 'light',\n",
       " 'rouges': 'red',\n",
       " 'alpiniste': 'mountaineer',\n",
       " 'grenouille': 'frog',\n",
       " 'journal': 'newspaper',\n",
       " 'oiseau': 'bird',\n",
       " 'graines': 'seeds',\n",
       " 'tournesol': 'sunflower',\n",
       " 'toit': 'roof',\n",
       " 'appareil': 'apparatus',\n",
       " 'campeur': 'camper',\n",
       " 'garés': 'parked',\n",
       " 'véhicules': 'vehicles',\n",
       " 'vagues': 'waves',\n",
       " 'musulmane': 'Muslim',\n",
       " 'tenue': 'outfit',\n",
       " 'plate-forme': 'platform',\n",
       " 'surélevée': 'raised',\n",
       " 'gueule': 'mouth',\n",
       " 'ouverte': 'opened',\n",
       " 'souriante': 'smiling',\n",
       " 'extérieure': 'outer',\n",
       " 'navire': 'ship',\n",
       " 'lit': 'bed',\n",
       " 'réparations': 'repairs',\n",
       " 'briques': 'bricks',\n",
       " 'ouvrier': 'worker',\n",
       " 'snowboard': 'snowboard',\n",
       " 'karaté': 'karate',\n",
       " 'trophée': 'trophy',\n",
       " 'gamin': 'kid',\n",
       " 'flotteurs': 'floats',\n",
       " 'lac': 'lake',\n",
       " 'hamburger': 'hamburger',\n",
       " 'sale': 'dirty',\n",
       " 'hauteur': 'height',\n",
       " 'mer': 'sea',\n",
       " 'statue': 'statue',\n",
       " 'bambin': 'toddler',\n",
       " 'grise': 'gray',\n",
       " 'bijoux': 'jewelry',\n",
       " 'comptoir': 'counter',\n",
       " 'magasin': 'store',\n",
       " 'escaliers': 'stairs',\n",
       " 'église': 'church',\n",
       " 'certain': 'certain',\n",
       " 'nombre': 'number',\n",
       " 'côte': 'side',\n",
       " 'menuiserie': 'carpentry',\n",
       " 'projet': 'project',\n",
       " 'manuels': 'manuals',\n",
       " 'outils': 'tools',\n",
       " 'mallette': 'briefcase',\n",
       " 'brune': 'Brown',\n",
       " 'chauve': 'bald',\n",
       " 'poulet': 'chicken',\n",
       " 'plan': 'plan',\n",
       " 'bouches': 'mouths',\n",
       " 'écharpe': 'scarf',\n",
       " 'tricoté': 'knitted',\n",
       " 'algues': 'algae',\n",
       " 'sauteuse': 'jig',\n",
       " 'scie': 'saw',\n",
       " 'derby': 'Derby',\n",
       " 'feminine': 'feminine',\n",
       " 'roller': 'Roller',\n",
       " 'entre': 'enter',\n",
       " 'lits': 'beds',\n",
       " 'tronçonneuse': 'saw',\n",
       " 'énorme': 'huge',\n",
       " 'moto': 'motorbike',\n",
       " 'affiche': 'poster',\n",
       " 'manuscrite': 'handwritten',\n",
       " 'bienvenue': 'welcome',\n",
       " 'motards': 'bikers',\n",
       " 'chose': 'thing',\n",
       " 'quelque': 'some',\n",
       " 'ligne': 'line',\n",
       " 'assis': 'seated',\n",
       " 'certains': 'some',\n",
       " 'debout': 'standing',\n",
       " 'pistes': 'tracks',\n",
       " 'décorations': 'decorations',\n",
       " 'plafond': 'ceiling',\n",
       " 'forgeron': 'black-smith',\n",
       " 'cheval': 'horse',\n",
       " 'dreadlocks': 'dreadlocks',\n",
       " 'kilt': 'kilt',\n",
       " 'joue': 'play',\n",
       " 'passagers': 'passengers',\n",
       " 'porcs': 'pigs',\n",
       " 'parking': 'park',\n",
       " 'flaque': 'puddle',\n",
       " 'marchandises': 'merchandise',\n",
       " 'signe': 'sign',\n",
       " 'canyon': 'canyon',\n",
       " 'clôture': 'fenced',\n",
       " 'seau': 'bucket',\n",
       " 'sweat-shirt': 'sweatshirt',\n",
       " 'velours': 'velvet',\n",
       " 'pinceau': 'brush',\n",
       " 'chiffons': 'rags',\n",
       " 'vieillard': 'man',\n",
       " 'épaules': 'shoulders',\n",
       " 'brosse': 'brush',\n",
       " 'grosse': 'big',\n",
       " 'marteau': 'hammer',\n",
       " 'quarte': 'fourth',\n",
       " 'blanches': 'white',\n",
       " 'chemises': 'shirts',\n",
       " 'coupée': 'cut',\n",
       " 'livres': 'books',\n",
       " 'poubelle': 'can',\n",
       " 'ferrée': 'railroad',\n",
       " 'voie': 'way',\n",
       " 'jumelles': 'binoculars',\n",
       " 'hutte': 'hut',\n",
       " 'vélos': 'bicycles',\n",
       " 'échafaudage': 'scaffolding',\n",
       " 'bavoir': 'bib',\n",
       " 'filet': 'net',\n",
       " 'au': 'the',\n",
       " 'baseball': 'baseball',\n",
       " 'couvercle': 'lid',\n",
       " 'grill': 'grill',\n",
       " 'kebab': 'kebab',\n",
       " 'shish': 'shish',\n",
       " 'protection': 'protection',\n",
       " 'chirurgicale': 'surgical',\n",
       " 'pelle': 'shovel',\n",
       " 'petits': 'small',\n",
       " 'buisson': 'bush',\n",
       " 'pantalons': 'pants',\n",
       " 'fourche': 'fork',\n",
       " 'branches': 'branches',\n",
       " 'appartements': 'apartments',\n",
       " 'complexe': 'complex',\n",
       " 'surface': 'area',\n",
       " 'bâtons': 'sticks',\n",
       " 'brettelles': 'suspenders',\n",
       " 'amis': 'friends',\n",
       " 'chargement': 'loading',\n",
       " 'rampe': 'ramp',\n",
       " 'livre': 'book',\n",
       " 'dinosaures': 'dinosaurs',\n",
       " 'verre': 'glass',\n",
       " 'traîneau': 'sled',\n",
       " 'pain': 'bread',\n",
       " 'paniers': 'baskets',\n",
       " 'bagages': 'baggage',\n",
       " 'propriété': 'property',\n",
       " 'nageuse': 'swimmer',\n",
       " 'bonnet': 'cap',\n",
       " 'pince-nez': 'pliers',\n",
       " 'ordinateurs': 'computers',\n",
       " 'portables': 'portable',\n",
       " 'fosse': 'pit',\n",
       " 'lumières': 'lights',\n",
       " 'noël': 'Christmas',\n",
       " 'poupée': 'doll',\n",
       " 'princesse': 'princess',\n",
       " 'dehors': 'outside',\n",
       " 'moyenne': 'average',\n",
       " 'taille': 'cut',\n",
       " 'récipient': 'container',\n",
       " 'ami': 'friend',\n",
       " 'laisse': 'leash',\n",
       " 'bassin': 'basin',\n",
       " 'toison': 'fleece',\n",
       " 'manger': 'eat',\n",
       " 'maman': 'mum',\n",
       " 'grue': 'crane',\n",
       " 'tonnelle': 'arbor',\n",
       " 'monde': 'world',\n",
       " 'articles': 'goods',\n",
       " 'berge': 'bank',\n",
       " 'cocotte': 'casserole',\n",
       " 'tongs': 'flops',\n",
       " 'transport': 'transport',\n",
       " 'bout': 'end',\n",
       " 'client': 'customer',\n",
       " 'fleurs': 'flowers',\n",
       " 'tubercules': 'tubers',\n",
       " 'capuche': 'hood',\n",
       " 'tente': 'attempted',\n",
       " 'gazon': 'grass',\n",
       " 'jouets': 'toys',\n",
       " '5': '5',\n",
       " 'athlètes': 'athletes',\n",
       " 'hauts': 'ups',\n",
       " 'bas': 'low',\n",
       " 'câbles': 'cable',\n",
       " 'joyeux': 'happy',\n",
       " 'elmo': 'elmo',\n",
       " 'nourrisson': 'infant',\n",
       " 'désordonnée': 'disorderly',\n",
       " 'anneau': 'ring',\n",
       " 'nez': 'nose',\n",
       " 'cet': 'this',\n",
       " 'fontaine': 'fountain',\n",
       " 'foncé': 'dark',\n",
       " 'château': 'castle',\n",
       " 'seule': 'alone',\n",
       " 'amc': 'amc',\n",
       " 'bulle': 'bubble',\n",
       " 'a': 'at',\n",
       " 'beige': 'beige',\n",
       " 'auvent': 'penthouse',\n",
       " 'roses': 'roses',\n",
       " 'employés': 'employees',\n",
       " 'parents': 'parents',\n",
       " 'chariots': 'carts',\n",
       " 'voitures': 'Car',\n",
       " 'arrosage': 'spray',\n",
       " 'bâches': 'tarpaulins',\n",
       " 'florida': 'Florida',\n",
       " 'marlins': 'marlin',\n",
       " 'courses': 'racing',\n",
       " 'monsieur': 'gentleman',\n",
       " 'sentier': 'path',\n",
       " 'cette': 'this',\n",
       " 'image': 'picture',\n",
       " 'cantonniers': 'menders',\n",
       " 'vestes': 'jackets',\n",
       " 'oranges': 'oranges',\n",
       " 'brouette': 'wheelbarrow',\n",
       " 'pilotis': 'stilt',\n",
       " 'batteurs': 'drummers',\n",
       " 'terrier': 'terrier',\n",
       " 'gazonné': 'turfy',\n",
       " 'carreaux': 'tiles',\n",
       " 'carnaval': 'carnival',\n",
       " 'tour': 'tower',\n",
       " 'clown': 'clown',\n",
       " 'faux': 'false',\n",
       " 'blonds': 'blonde',\n",
       " 'sales': 'dirty',\n",
       " 'age': 'age',\n",
       " 'moyen': 'way',\n",
       " 'couettes': 'quilts',\n",
       " 'ordinateur': 'computer',\n",
       " 'écran': 'screen',\n",
       " 'chers': 'Dear',\n",
       " 'vitrine': 'showcase',\n",
       " 'boutiques': 'shops',\n",
       " 'peut-être': 'perhaps',\n",
       " 'publicité': 'publicity',\n",
       " 'rétro-éclairé': 'backlit',\n",
       " 'agens': 'agents',\n",
       " 'murale': 'wall',\n",
       " 'grosses': 'large',\n",
       " 'manches': 'sleeves',\n",
       " 'barbe': 'beard',\n",
       " 'argent': 'money',\n",
       " 'monocycle': 'unicycle',\n",
       " 'trottinette': 'scooter',\n",
       " 'ski': 'ski',\n",
       " 'crabe': 'crab',\n",
       " 'bétonné': 'concreted',\n",
       " 'pull': 'sweater',\n",
       " 'dragon': 'dragon',\n",
       " 'marionnette': 'marionette',\n",
       " 'jardin': 'garden',\n",
       " 'bâtiments': 'buildings',\n",
       " 'murs': 'walls',\n",
       " 'vertes': 'green',\n",
       " 'jour': 'day',\n",
       " 'brillante': 'bright',\n",
       " 'violette': 'violet',\n",
       " 'clients': 'customers',\n",
       " 'guichet': 'counter',\n",
       " 'bonnets': 'caps',\n",
       " 'sur': 'sure',\n",
       " 'navetteurs': 'commuters',\n",
       " 'haute': 'high',\n",
       " 'pratiquants': 'practitioners',\n",
       " 'clavier': 'keyboard',\n",
       " 'spectateurs': 'spectators',\n",
       " 'visière': 'visor',\n",
       " 'ceintures': 'belts',\n",
       " 'noires': 'black',\n",
       " 'martiaux': 'martial',\n",
       " 'étudiante': 'student',\n",
       " 'arme': 'armed',\n",
       " 'arts': 'arts',\n",
       " 'stand': 'stall',\n",
       " 'papa': 'dad',\n",
       " '8': '8',\n",
       " 'pierres': 'stone',\n",
       " 'tuiles': 'tiles',\n",
       " 'clairs': 'clear',\n",
       " 'sandwich': 'sandwich',\n",
       " 'blocs': 'blocks',\n",
       " 'rectangulaires': 'rectangular',\n",
       " 'roue': 'wheel',\n",
       " 'balles': 'bullets',\n",
       " 'multicolores': 'multicolored',\n",
       " 'quilles': 'bowling',\n",
       " 'gravillonnée': 'gravelled',\n",
       " 'afro-américains': 'American',\n",
       " 'trompette': 'trumpet',\n",
       " 'badauds': 'onlookers',\n",
       " 'officiers': 'officers',\n",
       " 'brunes': 'brown',\n",
       " 'tenues': 'outfits',\n",
       " 'boussole': 'compass',\n",
       " 'coté': 'side',\n",
       " 'péniche': 'barge',\n",
       " 'balancelle': 'lounger',\n",
       " 'gant': 'glove',\n",
       " 'abondante': 'plentiful',\n",
       " 'fluo': 'fluo',\n",
       " 'agents': 'agents',\n",
       " 'voirie': 'road',\n",
       " 'toile': 'canvas',\n",
       " 'balançoire': 'swing',\n",
       " 'avec': 'with',\n",
       " 'pêchent': 'fish',\n",
       " 'cuillère': 'spoon',\n",
       " 'pêcheur': 'sinner',\n",
       " 'baume': 'balm',\n",
       " 'lèvres': 'lips',\n",
       " 'boutons': 'buttons',\n",
       " 'mixage': 'mixing',\n",
       " 'rayures': 'scratch',\n",
       " 'stands': 'stands',\n",
       " 'plaine': 'plain',\n",
       " 'adolescentes': 'teen',\n",
       " 'tétine': 'nipple',\n",
       " 'fauteuil': 'armchair',\n",
       " 'rickshaw': 'rickshaw',\n",
       " 'élégant': 'elegant',\n",
       " 'navigable': 'navigable',\n",
       " 'surveillance': 'oversight',\n",
       " 'rembourré': 'padded',\n",
       " 'fermier': 'farmer',\n",
       " 'bar': 'bar',\n",
       " 'canettes': 'cans',\n",
       " 'soda': 'soda',\n",
       " 'autour': 'around',\n",
       " 'grills': 'grills',\n",
       " 'viande': 'meat',\n",
       " 'grands': 'great',\n",
       " 'bancs': 'shoals',\n",
       " 'secouristes': 'Rescuers',\n",
       " 'argile': 'clay',\n",
       " 'potier': 'potter',\n",
       " 'artiste': 'artist',\n",
       " 'dessin': 'drawing',\n",
       " 'section': 'section',\n",
       " 'élaboré': 'elaborate',\n",
       " 'imposante': 'imposing',\n",
       " 'batterie': 'drums',\n",
       " 'onze': 'eleven',\n",
       " 'tabouret': 'stool',\n",
       " 'cages': 'cages',\n",
       " 'lot': 'lot',\n",
       " 'inhabituelle': 'unusual',\n",
       " 'manière': 'way',\n",
       " 'vêtu': 'dressed',\n",
       " 'crème': 'cream',\n",
       " 'glacée': 'ice',\n",
       " 'réfrigérateur': 'fridge',\n",
       " 'tiare': 'tiara',\n",
       " 'error': 'error',\n",
       " 'bouclé': 'loop',\n",
       " 'reflet': 'reflection',\n",
       " 'marbre': 'marble',\n",
       " 'poli': 'polished',\n",
       " 'hanches': 'hips',\n",
       " 'cigarette': 'cigarette',\n",
       " 'important': 'important',\n",
       " 'cuisinier': 'cook',\n",
       " 'vin': 'wine',\n",
       " 'poils': 'fur',\n",
       " 'steak': 'steak',\n",
       " 'plateau': 'tray',\n",
       " 'paix': 'peace',\n",
       " 'masques': 'masks',\n",
       " 'costumes': 'costume',\n",
       " 'statues': 'statues',\n",
       " 'chat': 'cat',\n",
       " 'longs': 'long',\n",
       " 'tipi': 'tipi',\n",
       " 'roues': 'wheels',\n",
       " 'enclume': 'anvil',\n",
       " 'violoncelle': 'cello',\n",
       " 'tranquille': 'quiet',\n",
       " 'billard': 'billiards',\n",
       " 'circuit': 'circuit',\n",
       " 'motocross': 'motocross',\n",
       " 'bibliothèque': 'library',\n",
       " 'sous-vêtements': 'underwear',\n",
       " 'hangar': 'hangar',\n",
       " 'cyclistes': 'cyclists',\n",
       " 'grille': 'rack',\n",
       " 'employées': 'staff',\n",
       " 'assiette': 'plate',\n",
       " 'indiquant': 'showing',\n",
       " 'mongol': 'Mongolian',\n",
       " 'néon': 'neon',\n",
       " 'deere': 'deere',\n",
       " 'john': 'john',\n",
       " 'remorque': 'trailer',\n",
       " 'baril': 'barrel',\n",
       " ...}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_to_english_gn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['roof',\n",
       " 'board',\n",
       " 'sweaters',\n",
       " 'toboggan',\n",
       " 'elderly',\n",
       " 'van',\n",
       " 'at',\n",
       " 'percussion',\n",
       " 'snow',\n",
       " 'gilding-unknown',\n",
       " 'Beggar-unknown',\n",
       " 'tricolor-unknown',\n",
       " 'motorcycle',\n",
       " 'peppers',\n",
       " 'sink',\n",
       " 'drilled-unknown',\n",
       " 'taking',\n",
       " 'husband',\n",
       " 'plywood',\n",
       " 'picnic']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_gndict_mapping = []\n",
    "for i in range(sample_size):\n",
    "    fr_word_index = sample_list[i]\n",
    "    fr_word = training_corpus_dct[fr_word_index]\n",
    "    en_word = fr_to_english_gn_dict[fr_word]\n",
    "    if en_word in training_corpus_dct_en.token2id:\n",
    "        en_gndict_mapping.append(en_word)\n",
    "    else:\n",
    "        en_gndict_mapping.append(en_word+\"-unknown\")\n",
    "en_gndict_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roof\n",
      "board\n",
      "sweaters\n",
      "toboggan\n",
      "elderly\n",
      "van\n",
      "at\n",
      "percussion\n",
      "snow\n",
      "gilding-unknown\n",
      "Beggar-unknown\n",
      "tricolor-unknown\n",
      "motorcycle\n",
      "peppers\n",
      "sink\n",
      "drilled-unknown\n",
      "taking\n",
      "husband\n",
      "plywood\n",
      "picnic\n"
     ]
    }
   ],
   "source": [
    "for elt in en_gndict_mapping:\n",
    "    print(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(specific_dictionary_file, 'r') as f:\n",
    "    dictionary_file_content = f.readlines()\n",
    "\n",
    "fr_to_english_dict = {}\n",
    "for line in dictionary_file_content:\n",
    "    parts = line[:-1].split(' ')  # line example: 'focus intérêt 1.0000000\\n'\n",
    "    if parts[1] in fr_to_english_dict:\n",
    "        fr_to_english_dict[parts[1]].append((parts[0], float(parts[2]))) \n",
    "    else:\n",
    "        fr_to_english_dict[parts[1]] = [(parts[0], float(parts[2])),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['roof',\n",
       " 'board',\n",
       " 'sweaters',\n",
       " 'slide',\n",
       " 'older',\n",
       " 'van',\n",
       " 'arid',\n",
       " 'drums',\n",
       " 'snowy',\n",
       " 'it',\n",
       " 'begging-unknown',\n",
       " 'tri-colored',\n",
       " 'motorcycle',\n",
       " 'peppers',\n",
       " 'sink',\n",
       " 'wearing',\n",
       " 'holding',\n",
       " 'husband',\n",
       " 'plywood',\n",
       " 'picnic']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_spdict_mapping = []\n",
    "from operator import itemgetter\n",
    "for i in range(sample_size):\n",
    "    fr_word_index = sample_list[i]\n",
    "    fr_word = training_corpus_dct[fr_word_index]\n",
    "    if fr_word in fr_to_english_dict:\n",
    "        en_words = fr_to_english_dict[fr_word] \n",
    "        most_probable_word = max(en_words ,key=itemgetter(1))[0] \n",
    "        if most_probable_word in training_corpus_dct_en.token2id:\n",
    "            en_spdict_mapping.append(most_probable_word)\n",
    "        else: # the most probable English word doesn't appear in the training corpus\n",
    "            en_spdict_mapping.append(most_probable_word+\"-unknown\")\n",
    "    else:  # the French word is not included in the dictionary, then assign a word vector randomly\n",
    "        en_spdict_mapping.append(\"-unknown-\")\n",
    "en_spdict_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roof\n",
      "board\n",
      "sweaters\n",
      "slide\n",
      "older\n",
      "van\n",
      "arid\n",
      "drums\n",
      "snowy\n",
      "it\n",
      "begging-unknown\n",
      "tri-colored\n",
      "motorcycle\n",
      "peppers\n",
      "sink\n",
      "wearing\n",
      "holding\n",
      "husband\n",
      "plywood\n",
      "picnic\n"
     ]
    }
   ],
   "source": [
    "for elt in en_spdict_mapping:\n",
    "    print(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/dongwenjian/SSDBACKUP/newly_added/new_experiments/experiments/2020-05-07_13-36-41_5k_all-trainable_frequency-mapping\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "run_comment = \"_5k_all-trainable_\" + mapping_method_name\n",
    "moment = datetime.datetime.now()\n",
    "run_name = str(moment.date()) + f\"_{moment.hour}-{moment.minute}-{moment.second}\" + run_comment\n",
    "\n",
    "\n",
    "output_root = os.path.join(project_root, \"experiments/\")\n",
    "output_dir_name = run_name  \n",
    "output_dir = os.path.join(output_root, output_dir_name)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "pytorch_model_save_path = output_dir\n",
    "pytorch_result_save_path = output_dir\n",
    "pytorch_checkpoint_save_path = output_dir\n",
    "\n",
    "\n",
    "#log_dir = os.path.join(\"runs/\", run_name)\n",
    "log_dir = os.path.join(output_dir, \"log\")\n",
    "os.mkdir(log_dir)\n",
    "print(output_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "train_logger = SummaryWriter(os.path.join(log_dir, \"training\"))\n",
    "val_logger = SummaryWriter(os.path.join(log_dir, \"validation\"))\n",
    "train_iou_before_refinement_logger = SummaryWriter(os.path.join(log_dir, \"train_iou_before_refinement\"))\n",
    "val_iou_before_refinement_logger = SummaryWriter(os.path.join(log_dir, \"val_iou_before_refinement\"))\n",
    "if cfg.regression_loss:\n",
    "    train_iou_after_refinement_logger = SummaryWriter(os.path.join(log_dir, \"train_iou_after_refinement\"))\n",
    "    val_iou_after_refinement_logger = SummaryWriter(os.path.join(log_dir, \"val_iou_after_refinement\"))\n",
    "\n",
    "pth_filename = \"ddpn.pth\"\n",
    "checkpoint_filename_base = \"checkpoint_\"  # eg. checkpoint_3.tar means the chechpoint after epoch=3\n",
    "process_filename = \"process.dct\" # .dct here simply means saving a dictionary in binary mode by pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on device: cpu\n",
      "log in directory: /media/dongwenjian/SSDBACKUP/newly_added/new_experiments/experiments/2020-05-07_13-36-41_5k_all-trainable_frequency-mapping/log\n",
      "gamma: 1\n",
      "epoch 0 , training phase finished, average loss: 1.9816835470173388\n",
      "\tTraining: accuracy based on original bounding box: 0.45915859937667847\n",
      "epoch 0 , validation phase finished, average loss: 1.675476540674838\n",
      "\tValidation: accuracy based on original bounding box: 0.5217706561088562\n",
      "epoch 0 finished. Time used: 356.8116571903229\n",
      "epoch 1 , training phase finished, average loss: 1.3592142532615281\n",
      "\tTraining: accuracy based on original bounding box: 0.609657347202301\n",
      "epoch 1 , validation phase finished, average loss: 1.5764628307912796\n",
      "\tValidation: accuracy based on original bounding box: 0.565674901008606\n",
      "epoch 1 finished. Time used: 360.7987895011902\n",
      "epoch 2 , training phase finished, average loss: 1.143997546934368\n",
      "\tTraining: accuracy based on original bounding box: 0.6802082061767578\n",
      "epoch 2 , validation phase finished, average loss: 1.5476174777581833\n",
      "\tValidation: accuracy based on original bounding box: 0.579463005065918\n",
      "epoch 2 finished. Time used: 346.7891821861267\n",
      "epoch 3 , training phase finished, average loss: 1.0031717151890294\n",
      "\tTraining: accuracy based on original bounding box: 0.7304466962814331\n",
      "epoch 3 , validation phase finished, average loss: 1.539178456640728\n",
      "\tValidation: accuracy based on original bounding box: 0.5765602588653564\n",
      "epoch 3 finished. Time used: 346.8514504432678\n",
      "epoch 4 , training phase finished, average loss: 0.9207947236774319\n",
      "\tTraining: accuracy based on original bounding box: 0.7563250064849854\n",
      "epoch 4 , validation phase finished, average loss: 1.542309200469572\n",
      "\tValidation: accuracy based on original bounding box: 0.5834543108940125\n",
      "epoch 4 finished. Time used: 349.0748040676117\n",
      "epoch 5 , training phase finished, average loss: 0.8611713165800506\n",
      "\tTraining: accuracy based on original bounding box: 0.7811912894248962\n",
      "epoch 5 , validation phase finished, average loss: 1.5506349277773166\n",
      "\tValidation: accuracy based on original bounding box: 0.5881712436676025\n",
      "epoch 5 finished. Time used: 348.02056074142456\n",
      "epoch 6 , training phase finished, average loss: 0.82506903386864\n",
      "\tTraining: accuracy based on original bounding box: 0.7901546955108643\n",
      "epoch 6 , validation phase finished, average loss: 1.5610984207410772\n",
      "\tValidation: accuracy based on original bounding box: 0.585268497467041\n",
      "epoch 6 finished. Time used: 348.47119760513306\n",
      "epoch 7 , training phase finished, average loss: 0.7977934410862622\n",
      "\tTraining: accuracy based on original bounding box: 0.8007084131240845\n",
      "epoch 7 , validation phase finished, average loss: 1.5667342200161585\n",
      "\tValidation: accuracy based on original bounding box: 0.5867198705673218\n",
      "epoch 7 finished. Time used: 347.5656199455261\n",
      "epoch 8 , training phase finished, average loss: 0.7812480818885796\n",
      "\tTraining: accuracy based on original bounding box: 0.804105818271637\n",
      "epoch 8 , validation phase finished, average loss: 1.565656027876933\n",
      "\tValidation: accuracy based on original bounding box: 0.5907111763954163\n",
      "epoch 8 finished. Time used: 348.1203455924988\n",
      "epoch 9 , training phase finished, average loss: 0.7682366823984637\n",
      "\tTraining: accuracy based on original bounding box: 0.8132861256599426\n",
      "epoch 9 , validation phase finished, average loss: 1.5678010436723817\n",
      "\tValidation: accuracy based on original bounding box: 0.5907111763954163\n",
      "epoch 9 finished. Time used: 348.5231854915619\n",
      "total time: 3509.3707950115204\n",
      "epoch_chosen: 8\n",
      "loaded checkpoint: /media/dongwenjian/SSDBACKUP/newly_added/new_experiments/experiments/2020-05-07_13-36-41_5k_all-trainable_frequency-mapping/checkpoint_8.tar\n",
      "Evaluating on test set: 2789 samples...\n",
      "Test set: good bounding box based on original bounding box: 1660\n",
      "Test set: accuracy based on original bounding box: 0.5951954126358032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'num_workers': 1}\n",
    "\n",
    "training_generator = data.DataLoader(training_set, shuffle=True, **params)\n",
    "validation_generator = data.DataLoader(validation_set, shuffle=True, **params)\n",
    "test_generator = data.DataLoader(test_set, shuffle=True, **params)\n",
    "\n",
    "\n",
    "# if cfg.use_pretrained_word_embedding == None:\n",
    "#     print(\"Non-pretrained embedding is used.\")\n",
    "#     model = DDPN(cfg, vocab_size=len(training_corpus_dct.token2id))\n",
    "# elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "#     print(\"Glove embedding is used.\")\n",
    "#     model = DDPN(cfg, embedding_weights=glove.vectors)\n",
    "# else:\n",
    "#     raise Exception(\"Embedding configuration not recognized\")\n",
    "    \n",
    "\n",
    "# if cfg.use_pretrained_model:    \n",
    "#     print(\"load pre-trained model\")\n",
    "#     model.load_state_dict(torch.load(pretrained_model_path, map_location=device))\n",
    "    \n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.999), lr=0.001) \n",
    "LR_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=cfg.lr_decay_rate)\n",
    "# Warning: Pytorch's Adam does not have the learning rate decay feature. \n",
    "#          Possibly learning rate scheduler may achieve the same effect. \n",
    "# Warning: beta2 is recommended as 0.999 in the original paper and by the community. \n",
    "\n",
    "\n",
    "print(\"training on device:\", device)\n",
    "print(\"log in directory:\", logger.logdir)\n",
    "print(\"gamma:\", cfg.GAMMA)\n",
    "\n",
    "process = {}\n",
    "process['time'] = []\n",
    "process['train_average_losses_by_epoch'] = []\n",
    "process['val_average_losses_by_epoch'] = []\n",
    "process['train_IoU_acc_before_refinement'] = []\n",
    "process['val_IoU_acc_before_refinement'] = []\n",
    "if cfg.regression_loss:\n",
    "    process['train_IoU_acc_after_refinement'] = []\n",
    "    process['val_IoU_acc_after_refinement'] = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "process['configure'] = cfg\n",
    "\n",
    "# output_root = os.path.join(project_root, \"outputs/\")\n",
    "# output_dir_name = run_name  \n",
    "# output_dir = os.path.join(output_root, output_dir_name)\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.mkdir(output_dir)\n",
    "# pytorch_model_save_path = output_dir\n",
    "# pytorch_result_save_path = output_dir\n",
    "# pytorch_checkpoint_save_path = output_dir\n",
    "\n",
    "\n",
    "# Loop over epochs\n",
    "max_epochs = 10\n",
    "\n",
    "\n",
    "\n",
    "# ============The part: fit====================\n",
    "\n",
    "\n",
    "time_start_all = time.time()\n",
    "loss = None\n",
    "train_batch_counter_total = 0\n",
    "val_batch_counter_total = 0\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #  ----------Training-----------\n",
    "    \n",
    "    train_losses_by_epoch = []\n",
    "    train_loss_average_by_epoch = 0.0\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    train_all_ious_original = []\n",
    "    train_all_ious_refined = []\n",
    "    \n",
    "    #for inputs, gt_bboxes in training_generator:\n",
    "    for train_batch_counter, (inputs, gt_bboxes, _) in enumerate(training_generator):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        Xs, queries = inputs\n",
    "        #print(\"train_batch_counter\", train_batch_counter)\n",
    "        #print(\"Xs\", Xs.size())\n",
    "        #print(\"queries\", len(queries))\n",
    "        #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "        \n",
    "        # print('Xs shape:', Xs.size())\n",
    "        #print('queries:\\n', len(queries))  # queries is a tuple of strings. The length of queries is the batch size. \n",
    "        \n",
    "        Qs, seq_lengths = preprocess_query(queries)\n",
    "        #print(Qs)\n",
    "        #print(len(seq_lengths))  # len(seq_lengths) equals to batch_size\n",
    "        #print(seq_lengths)\n",
    "        \n",
    "        \n",
    "        Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "        \n",
    "        pred = model(Xs, Qs, seq_lengths)\n",
    "        targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "        try:\n",
    "            loss = loss_func(pred, targ)\n",
    "        except AssertionError as e:\n",
    "            print(f\"epoch {epoch}, train, batch: {train_batch_counter}\")\n",
    "            with open(\"debug.log\", 'a') as log:\n",
    "                log.write(f\"epoch {epoch}, train, batch: {train_batch_counter}\\n\")\n",
    "            raise e\n",
    "        train_losses_by_epoch.append(loss.item())\n",
    "        train_loss_average_by_epoch += loss.item()*Xs.size(0)\n",
    "        #logger.add_scalar('train_losses_all_batches', train_losses, train_batch_counter)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        print(f\"\\repoch {epoch}, training phase, batch {train_batch_counter}/{len(training_generator)}, loss={loss.item()}\", end='')\n",
    "        logger.add_scalar(\"train_loss_by_batch\", loss.item(), train_batch_counter_total)\n",
    "        \n",
    "        # statistics of IoU score\n",
    "        if cfg.regression_loss:\n",
    "            ious_original, ious_refined = calculate_IoU_scores(Xs, pred, gt_bboxes)\n",
    "        else:\n",
    "            ious_original = calculate_IoU_scores(Xs, pred, gt_bboxes)\n",
    "        #print(ious.size())\n",
    "        train_all_ious_original = train_all_ious_original + ious_original.tolist()\n",
    "        if cfg.regression_loss:\n",
    "            train_all_ious_refined = train_all_ious_refined + ious_refined.tolist()\n",
    "        \n",
    "        #train_batch_counter += 1\n",
    "        train_batch_counter_total += 1\n",
    "        \n",
    "        #print(\"fc_regression 0\", list(model.fc_regression.parameters())[0].size())\n",
    "        #print(\"fc_regression 1\", list(model.fc_regression.parameters())[1].size())\n",
    "        \n",
    "        #if train_batch_counter == 20: break  # For debugging the codes after training phase\n",
    "        \n",
    "    train_losses.append(train_losses_by_epoch)\n",
    "    train_loss_average_by_epoch /= len(training_generator.dataset)\n",
    "    print(\"\\repoch\", epoch, \", training phase finished, average loss:\",train_loss_average_by_epoch)\n",
    "    #logger.add_scalar(\"train_loss_average_by_epoch\", train_loss_average_by_epoch, epoch)\n",
    "    train_logger.add_scalar(\"average_loss_by_epoch\", train_loss_average_by_epoch, epoch)\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    train_good_original = torch.tensor(train_all_ious_original) > 0.5     \n",
    "    #print(\"\\tTraining: good bounding box based on original bounding box:\", train_good_original.sum().item())\n",
    "    train_acc_original = train_good_original.sum().float()/len(training_set)\n",
    "    print(\"\\tTraining: accuracy based on original bounding box:\", train_acc_original.item())\n",
    "    train_iou_before_refinement_logger.add_scalar(\"IoU_accuracy\", train_acc_original, epoch)\n",
    "\n",
    "    if cfg.regression_loss:\n",
    "        train_good_refined = torch.tensor(train_all_ious_refined) > 0.5\n",
    "        #print(\"\\tTraining: good bounding box refined:\", train_good_refined.sum().item())\n",
    "        train_acc_refined = train_good_refined.sum().float()/len(training_set)\n",
    "        print(\"\\tTraining: accuracy of refined bounding box:\", train_acc_refined.item())\n",
    "        train_iou_after_refinement_logger.add_scalar(\"IoU_accuracy\", train_acc_refined, epoch)\n",
    "\n",
    "        \n",
    "        \n",
    "    # Validation\n",
    "    #val_batch_counter = 0\n",
    "    val_losses_by_epoch = []\n",
    "    val_loss_average_by_epoch = 0.0\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    val_all_ious_original = []\n",
    "    if cfg.regression_loss:\n",
    "        val_all_ious_refined = []\n",
    "    \n",
    "    with torch.no_grad():      \n",
    "        #for inputs, gt_bboxes in validation_generator:\n",
    "        for val_batch_counter, (inputs, gt_bboxes, _) in enumerate(validation_generator):\n",
    "            Xs, queries = inputs\n",
    "            #print(\"val_batch_counter\", val_batch_counter)\n",
    "            #print(\"Xs\", Xs.size())\n",
    "            #print(\"queries\", len(queries))\n",
    "            #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "           \n",
    "            Qs, seq_lengths = preprocess_query(queries)\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "            \n",
    "            val_pred = model(Xs, Qs, seq_lengths)\n",
    "            val_targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "            try:\n",
    "                val_loss = loss_func(val_pred, val_targ)\n",
    "            except AssertionError as e:\n",
    "                print(f\"epoch {epoch}, val, batch: {val_batch_counter}\")\n",
    "                with open(\"debug.log\", 'a') as log:\n",
    "                    log.write(f\"epoch {epoch}, val, batch: {val_batch_counter}\\n\")\n",
    "                raise e\n",
    "            val_losses_by_epoch.append(val_loss.item())\n",
    "            val_loss_average_by_epoch += val_loss.item()*Xs.size(0)\n",
    "            #logger.add_scalar('val_losses_all_batches', val_losses, val_batch_counter)\n",
    "        \n",
    "            print(f\"\\repoch {epoch}, validation phase, batch {val_batch_counter}/{len(validation_generator)}, val_loss={val_loss.item()}\", end='')\n",
    "            logger.add_scalar(\"val_loss_by_batch\", val_loss.item(), val_batch_counter_total)\n",
    "            \n",
    "            # Statistics of IoU score\n",
    "            if cfg.regression_loss:\n",
    "                ious_original, ious_refined = calculate_IoU_scores(Xs, val_pred, gt_bboxes)\n",
    "            else:\n",
    "                ious_original = calculate_IoU_scores(Xs, val_pred, gt_bboxes)\n",
    "            val_all_ious_original = val_all_ious_original + ious_original.tolist()\n",
    "            if cfg.regression_loss:\n",
    "                val_all_ious_refined = val_all_ious_refined + ious_refined.tolist()\n",
    "            \n",
    "\n",
    "            #val_batch_counter += 1\n",
    "            val_batch_counter_total += 1\n",
    "            \n",
    "    \n",
    "    \n",
    "    val_losses.append(val_losses_by_epoch)\n",
    "    val_loss_average_by_epoch /= len(validation_generator.dataset)\n",
    "    print(\"\\repoch\", epoch, \", validation phase finished, average loss:\",val_loss_average_by_epoch)\n",
    "    #logger.add_scalar(\"val_loss_average_by_epoch\", val_loss_average_by_epoch, epoch)\n",
    "    val_logger.add_scalar(\"average_loss_by_epoch\", val_loss_average_by_epoch, epoch)\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    val_good_original = torch.tensor(val_all_ious_original) > 0.5     \n",
    "    #print(\"\\tValidation: good bounding box based on original bounding box:\", val_good_original.sum().item())\n",
    "    val_acc_original = val_good_original.sum().float()/len(validation_set)\n",
    "    print(\"\\tValidation: accuracy based on original bounding box:\", val_acc_original.item())\n",
    "    val_iou_before_refinement_logger.add_scalar(\"IoU_accuracy\", val_acc_original, epoch)\n",
    "\n",
    "    if cfg.regression_loss:\n",
    "        val_good_refined = torch.tensor(val_all_ious_refined) > 0.5\n",
    "        #print(\"\\tValidation: good bounding box refined:\", val_good_refined.sum().item())\n",
    "        val_acc_refined = val_good_refined.sum().float()/len(validation_set)\n",
    "        print(\"\\tValidation: accuracy of refined bounding box:\", val_acc_refined.item())\n",
    "        val_iou_after_refinement_logger.add_scalar(\"IoU_accuracy\", val_acc_refined, epoch)  \n",
    "        \n",
    "        \n",
    "        \n",
    "    # ---------------- The work after validation in each epoch -----------    \n",
    "    \n",
    "    LR_scheduler.step() # Decay the learning rate every epoch\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_epoch = time_end - time_start\n",
    "    print(f\"epoch {epoch} finished. Time used: {time_epoch}\")\n",
    "    \n",
    "    model.eval() # Do this before saving the model when dropout or batch normalization is involved. https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "    # Save model's learnable parameters\n",
    "    torch.save(model.state_dict(), os.path.join(pytorch_model_save_path,pth_filename))\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                \n",
    "                }, os.path.join(pytorch_checkpoint_save_path, (checkpoint_filename_base+str(epoch)+'.tar')))\n",
    "    \n",
    "    # Save loss (value) evolution\n",
    "    process['train_losses'] = train_losses\n",
    "    process['val_losses'] = val_losses\n",
    "    process['train_average_losses_by_epoch'].append(train_loss_average_by_epoch)\n",
    "    process['val_average_losses_by_epoch'].append(val_loss_average_by_epoch)\n",
    "    process['train_IoU_acc_before_refinement'].append(train_acc_original)\n",
    "    process['val_IoU_acc_before_refinement'].append(val_acc_original)\n",
    "    if cfg.regression_loss:\n",
    "        process['train_IoU_acc_after_refinement'].append(train_acc_refined)\n",
    "        process['val_IoU_acc_after_refinement'].append(val_acc_refined)\n",
    "    process['time'].append(time_epoch)\n",
    "    with open(os.path.join(pytorch_result_save_path, process_filename), 'wb') as fp:\n",
    "        pickle.dump(process, fp)\n",
    "        \n",
    "    # the vocabulary dictionary also needs saving in the future\n",
    "\n",
    "time_end_all = time.time()\n",
    "time_total = time_end_all - time_start_all\n",
    "print(f\"total time: {time_total}\")\n",
    "process[\"total_time\"] = time_total\n",
    "\n",
    "with open(os.path.join(pytorch_result_save_path, process_filename), 'wb') as fp:\n",
    "    pickle.dump(process, fp)\n",
    "\n",
    "# ================== Evaluation on test set ========================\n",
    "    \n",
    "val_iou_evolution = [elt.item() for elt in process['val_IoU_acc_before_refinement']]\n",
    "val_iou_evolution_array = np.array(val_iou_evolution)\n",
    "epoch_chosen = np.argmax(val_iou_evolution_array)\n",
    "print(\"epoch_chosen:\", epoch_chosen)\n",
    "\n",
    "fr_vocab = len(training_corpus_dct.token2id)\n",
    "model_test = DDPN(cfg, vocab_size=fr_vocab)\n",
    "\n",
    "#model_en.load_state_dict(torch.load(english_pretrained_model_path, map_location=device))\n",
    "model_to_test_path = os.path.join(output_dir, f\"checkpoint_{epoch_chosen}.tar\")\n",
    "checkpoint = torch.load(model_to_test_path, map_location=device)\n",
    "model_test.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(\"loaded checkpoint:\", model_to_test_path)\n",
    "model_test.to(device)\n",
    "\n",
    "# For statistics of IoU score on test set\n",
    "test_all_ious_original = []\n",
    "if cfg.regression_loss:\n",
    "    test_all_ious_refined = []\n",
    "    \n",
    "print(f\"Evaluating on test set: {len(test_set)} samples...\" )\n",
    "with torch.no_grad():      \n",
    "    for test_batch_counter, (inputs, gt_bboxes, _) in enumerate(test_generator):\n",
    "        Xs, queries = inputs\n",
    "        #print(\"val_batch_counter\", val_batch_counter)\n",
    "        #print(\"Xs\", Xs.size())\n",
    "        #print(\"queries\", len(queries))\n",
    "        #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "\n",
    "        Qs, seq_lengths = preprocess_query(queries)\n",
    "\n",
    "        model_test.eval()\n",
    "\n",
    "        Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "        test_pred = model_test(Xs, Qs, seq_lengths)\n",
    "        test_targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "#         try:\n",
    "#             val_loss = loss_func(val_pred, val_targ)\n",
    "#         except AssertionError as e:\n",
    "#             print(f\"epoch {epoch}, val, batch: {val_batch_counter}\")\n",
    "#             with open(\"debug.log\", 'a') as log:\n",
    "#                 log.write(f\"epoch {epoch}, val, batch: {val_batch_counter}\\n\")\n",
    "#             raise e\n",
    "#         test_losses_by_epoch.append(val_loss.item())\n",
    "#         val_loss_average_by_epoch += val_loss.item()*Xs.size(0)\n",
    "        #logger.add_scalar('val_losses_all_batches', val_losses, val_batch_counter)\n",
    "\n",
    "#         print(f\"\\repoch {epoch}, validation phase, batch {val_batch_counter}/{len(validation_generator)}, val_loss={val_loss.item()}\", end='')\n",
    "#         logger.add_scalar(\"val_loss_by_batch\", val_loss.item(), val_batch_counter_total)\n",
    "\n",
    "        # Statistics of IoU score\n",
    "        if cfg.regression_loss:\n",
    "            ious_original, ious_refined = calculate_IoU_scores(Xs, test_pred, gt_bboxes)\n",
    "        else:\n",
    "            ious_original = calculate_IoU_scores(Xs, test_pred, gt_bboxes)\n",
    "        test_all_ious_original = test_all_ious_original + ious_original.tolist()\n",
    "        if cfg.regression_loss:\n",
    "            test_all_ious_refined = test_all_ious_refined + ious_refined.tolist()\n",
    "    \n",
    "    good_original = torch.tensor(test_all_ious_original) > 0.5     \n",
    "    print(\"Test set: good bounding box based on original bounding box:\", good_original.sum().item())\n",
    "    acc_original = good_original.sum().float()/len(test_set)\n",
    "    print(\"Test set: accuracy based on original bounding box:\", acc_original.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test set:\n",
    "\n",
    "5k training from scratch: 0.6073861718177795, 0.6138401031494141\n",
    "\n",
    "5k random mapping: 0.6127644181251526\n",
    "\n",
    "5k frequency mapping: 0.5951954126358032\n",
    "\n",
    "5k general dictionary mapping: 0.6565077304840088, 0.6461097002029419\n",
    "\n",
    "5k specific dictionary mapping: 0.6626030802726746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, training_generator, optimizer, epoch, device, cfg, process, loggers_dct, train_losses):\n",
    "    # Training\n",
    "    \n",
    "    train_losses_by_epoch = []\n",
    "    train_loss_average_by_epoch = 0.0\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    train_all_ious_original = []\n",
    "    train_all_ious_refined = []\n",
    "    \n",
    "    for train_batch_counter, (inputs, gt_bboxes, _) in enumerate(training_generator):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        Xs, queries = inputs\n",
    "        #print(\"train_batch_counter\", train_batch_counter)\n",
    "        #print(\"Xs\", Xs.size())\n",
    "        #print(\"queries\", len(queries))\n",
    "        #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "        \n",
    "        # print('Xs shape:', Xs.size())\n",
    "        #print('queries:\\n', len(queries))  # queries is a tuple of strings. The length of queries is the batch size. \n",
    "        \n",
    "        Qs, seq_lengths = preprocess_query(queries)\n",
    "        #print(Qs)\n",
    "        #print(len(seq_lengths))  # len(seq_lengths) equals to batch_size\n",
    "        #print(seq_lengths)\n",
    "        \n",
    "        \n",
    "        Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "        \n",
    "        pred = model(Xs, Qs, seq_lengths)\n",
    "        targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "        try:\n",
    "            loss = loss_func(pred, targ)\n",
    "        except AssertionError as e:\n",
    "            print(f\"epoch {epoch}, train, batch: {train_batch_counter}\")\n",
    "            with open(\"debug.log\", 'a') as log:\n",
    "                log.write(f\"epoch {epoch}, train, batch: {train_batch_counter}\\n\")\n",
    "            raise e\n",
    "        train_losses_by_epoch.append(loss.item())\n",
    "        train_loss_average_by_epoch += loss.item()*Xs.size(0)\n",
    "        #logger.add_scalar('train_losses_all_batches', train_losses, train_batch_counter)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        print(f\"\\repoch {epoch}, training phase, batch {train_batch_counter}/{len(training_generator)}, loss={loss.item()}\", end='')\n",
    "        loggers_dct['logger'].add_scalar(\"train_loss_by_batch\", loss.item(), train_epoch.counter)\n",
    "        \n",
    "        # statistics of IoU score\n",
    "        if cfg.regression_loss:\n",
    "            ious_original, ious_refined = calculate_IoU_scores(Xs, pred, gt_bboxes)\n",
    "        else:\n",
    "            ious_original = calculate_IoU_scores(Xs, pred, gt_bboxes)\n",
    "        #print(ious.size())\n",
    "        train_all_ious_original = train_all_ious_original + ious_original.tolist()\n",
    "        if cfg.regression_loss:\n",
    "            train_all_ious_refined = train_all_ious_refined + ious_refined.tolist()\n",
    "        \n",
    "        #train_batch_counter_total += 1\n",
    "        train_epoch.counter += 1\n",
    "        \n",
    "        #print(\"fc_regression 0\", list(model.fc_regression.parameters())[0].size())\n",
    "        #print(\"fc_regression 1\", list(model.fc_regression.parameters())[1].size())\n",
    "        \n",
    "        #if train_batch_counter == 20: break  # For debugging the codes after training phase\n",
    "        \n",
    "    train_losses.append(train_losses_by_epoch)\n",
    "    train_loss_average_by_epoch /= len(training_generator.dataset)\n",
    "    print(\"\\repoch\", epoch, \", training phase finished, average loss:\",train_loss_average_by_epoch)\n",
    "    loggers_dct['train_logger'].add_scalar(\"average_loss_by_epoch\", train_loss_average_by_epoch, epoch)\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    train_good_original = torch.tensor(train_all_ious_original) > 0.5     \n",
    "    #print(\"\\tTraining: good bounding box based on original bounding box:\", train_good_original.sum().item())\n",
    "    train_acc_original = train_good_original.sum().float()/len(training_set)\n",
    "    print(\"\\tTraining: accuracy based on original bounding box:\", train_acc_original.item())\n",
    "    loggers_dct['train_iou_before_refinement_logger'].add_scalar(\"IoU_accuracy\", train_acc_original, epoch)\n",
    "\n",
    "    if cfg.regression_loss:\n",
    "        train_good_refined = torch.tensor(train_all_ious_refined) > 0.5\n",
    "        #print(\"\\tTraining: good bounding box refined:\", train_good_refined.sum().item())\n",
    "        train_acc_refined = train_good_refined.sum().float()/len(training_set)\n",
    "        print(\"\\tTraining: accuracy of refined bounding box:\", train_acc_refined.item())\n",
    "        loggers_dct['train_iou_after_refinement_logger'].add_scalar(\"IoU_accuracy\", train_acc_refined, epoch)\n",
    "    \n",
    "    \n",
    "    # The following information is added once in each epoch\n",
    "    process['train_average_losses_by_epoch'].append(train_loss_average_by_epoch)\n",
    "    process['train_IoU_acc_before_refinement'].append(train_acc_original)\n",
    "    if cfg.regression_loss:\n",
    "            process['train_IoU_acc_after_refinement'].append(train_acc_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(model, validation_generator, epoch, device, cfg, process, loggers_dct, val_losses):\n",
    "    # Validation\n",
    "    #val_batch_counter = 0\n",
    "    val_losses_by_epoch = []\n",
    "    val_loss_average_by_epoch = 0.0\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    val_all_ious_original = []\n",
    "    if cfg.regression_loss:\n",
    "        val_all_ious_refined = []\n",
    "    \n",
    "    with torch.no_grad():      \n",
    "        for val_batch_counter, (inputs, gt_bboxes, _) in enumerate(validation_generator):\n",
    "            Xs, queries = inputs\n",
    "            #print(\"val_batch_counter\", val_batch_counter)\n",
    "            #print(\"Xs\", Xs.size())\n",
    "            #print(\"queries\", len(queries))\n",
    "            #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "           \n",
    "            Qs, seq_lengths = preprocess_query(queries)\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "            \n",
    "            val_pred = model(Xs, Qs, seq_lengths)\n",
    "            val_targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "            try:\n",
    "                val_loss = loss_func(val_pred, val_targ)\n",
    "            except AssertionError as e:\n",
    "                print(f\"epoch {epoch}, val, batch: {val_batch_counter}\")\n",
    "                with open(\"debug.log\", 'a') as log:\n",
    "                    log.write(f\"epoch {epoch}, val, batch: {val_batch_counter}\\n\")\n",
    "                raise e\n",
    "            val_losses_by_epoch.append(val_loss.item())\n",
    "            val_loss_average_by_epoch += val_loss.item()*Xs.size(0)\n",
    "            #logger.add_scalar('val_losses_all_batches', val_losses, val_batch_counter)\n",
    "        \n",
    "            print(f\"\\repoch {epoch}, validation phase, batch {val_batch_counter}/{len(validation_generator)}, val_loss={val_loss.item()}\", end='')\n",
    "            loggers_dct['logger'].add_scalar(\"val_loss_by_batch\", val_loss.item(), val_epoch.counter)\n",
    "            \n",
    "            # Statistics of IoU score\n",
    "            if cfg.regression_loss:\n",
    "                ious_original, ious_refined = calculate_IoU_scores(Xs, val_pred, gt_bboxes)\n",
    "            else:\n",
    "                ious_original = calculate_IoU_scores(Xs, val_pred, gt_bboxes)\n",
    "            val_all_ious_original = val_all_ious_original + ious_original.tolist()\n",
    "            if cfg.regression_loss:\n",
    "                val_all_ious_refined = val_all_ious_refined + ious_refined.tolist()\n",
    "            \n",
    "\n",
    "            #val_batch_counter_total += 1\n",
    "            val_epoch.counter += 1\n",
    "    \n",
    "    \n",
    "    val_losses.append(val_losses_by_epoch)\n",
    "    val_loss_average_by_epoch /= len(validation_generator.dataset)\n",
    "    print(\"\\repoch\", epoch, \", validation phase finished, average loss:\",val_loss_average_by_epoch)\n",
    "    #logger.add_scalar(\"val_loss_average_by_epoch\", val_loss_average_by_epoch, epoch)\n",
    "    loggers_dct['val_logger'].add_scalar(\"average_loss_by_epoch\", val_loss_average_by_epoch, epoch)\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    val_good_original = torch.tensor(val_all_ious_original) > 0.5     \n",
    "    #print(\"\\tValidation: good bounding box based on original bounding box:\", val_good_original.sum().item())\n",
    "    val_acc_original = val_good_original.sum().float()/len(validation_set)\n",
    "    print(\"\\tValidation: accuracy based on original bounding box:\", val_acc_original.item())\n",
    "    loggers_dct['val_iou_before_refinement_logger'].add_scalar(\"IoU_accuracy\", val_acc_original, epoch)\n",
    "\n",
    "    if cfg.regression_loss:\n",
    "        val_good_refined = torch.tensor(val_all_ious_refined) > 0.5\n",
    "        #print(\"\\tValidation: good bounding box refined:\", val_good_refined.sum().item())\n",
    "        val_acc_refined = val_good_refined.sum().float()/len(validation_set)\n",
    "        print(\"\\tValidation: accuracy of refined bounding box:\", val_acc_refined.item())\n",
    "        loggers_dct['val_iou_after_refinement_logger'].add_scalar(\"IoU_accuracy\", val_acc_refined, epoch)  \n",
    "    \n",
    "    process['val_average_losses_by_epoch'].append(val_loss_average_by_epoch)\n",
    "    process['val_IoU_acc_before_refinement'].append(val_acc_original)\n",
    "    if cfg.regression_loss:\n",
    "        process['val_IoU_acc_after_refinement'].append(val_acc_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, \n",
    "        training_generator, \n",
    "        validation_generator, \n",
    "        optimizer, \n",
    "        device, \n",
    "        cfg, \n",
    "        max_epochs, \n",
    "        LR_scheduler, \n",
    "        process, \n",
    "        loggers_dct):\n",
    "    time_start_all = time.time()\n",
    "    loss = None\n",
    "    train_epoch.counter = 0\n",
    "    val_epoch.counter = 0\n",
    "    \n",
    "    train_losses = []  # This list will store the loss of all batches in all epochs\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        time_start = time.time()\n",
    "        \n",
    "        #  ----------Training-----------\n",
    "        train_epoch(model, training_generator, optimizer, epoch, device, cfg, process, loggers_dct, train_losses)\n",
    "        \n",
    "        #  ----------Validation-----------\n",
    "        val_epoch(model, validation_generator, epoch, device, cfg, process, loggers_dct, val_losses)\n",
    "        \n",
    "        \n",
    "        # ---------------- The work after validation in each epoch -----------    \n",
    "    \n",
    "        LR_scheduler.step() # Decay the learning rate every epoch\n",
    "\n",
    "        time_end = time.time()\n",
    "        time_epoch = time_end - time_start\n",
    "        print(f\"epoch {epoch} finished. Time used: {time_epoch}\")\n",
    "\n",
    "        model.eval() # Do this before saving the model when dropout or batch normalization is involved. https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "        # Save model's learnable parameters\n",
    "        torch.save(model.state_dict(), os.path.join(cfg.pytorch_model_save_path, cfg.pth_filename))\n",
    "        # Save checkpoint\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "\n",
    "                    }, os.path.join(cfg.pytorch_checkpoint_save_path, (cfg.checkpoint_filename_base+str(epoch)+'.tar')))\n",
    "\n",
    "        # Save loss (value) evolution\n",
    "        process['train_losses'] = train_losses\n",
    "        process['val_losses'] = val_losses\n",
    "        \n",
    "        # The following lines are moved to train_epoch or val_epoch\n",
    "#         process['train_average_losses_by_epoch'].append(train_loss_average_by_epoch)\n",
    "#         process['val_average_losses_by_epoch'].append(val_loss_average_by_epoch)\n",
    "#         process['train_IoU_acc_before_refinement'].append(train_acc_original)\n",
    "#         process['val_IoU_acc_before_refinement'].append(val_acc_original)\n",
    "#         if cfg.regression_loss:\n",
    "#             process['train_IoU_acc_after_refinement'].append(train_acc_refined)\n",
    "#             process['val_IoU_acc_after_refinement'].append(val_acc_refined)\n",
    "\n",
    "        process['time'].append(time_epoch)\n",
    "        with open(os.path.join(cfg.pytorch_result_save_path, cfg.process_filename), 'wb') as fp:\n",
    "            pickle.dump(process, fp)\n",
    "\n",
    "        # the vocabulary dictionary also needs saving in the future\n",
    "    \n",
    "    time_end_all = time.time()\n",
    "    time_total = time_end_all - time_start_all\n",
    "    print(f\"total time: {time_total}\")\n",
    "    process[\"total_time\"] = time_total\n",
    "\n",
    "    with open(os.path.join(cfg.pytorch_result_save_path, cfg.process_filename), 'wb') as fp:\n",
    "        pickle.dump(process, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(process, test_generator, cfg):\n",
    "    val_iou_evolution = [elt.item() for elt in process['val_IoU_acc_before_refinement']]\n",
    "    val_iou_evolution_array = np.array(val_iou_evolution)\n",
    "    epoch_chosen = np.argmax(val_iou_evolution_array)\n",
    "    print(\"epoch_chosen:\", epoch_chosen)\n",
    "\n",
    "    fr_vocab = len(training_corpus_dct.token2id)\n",
    "    model_test = DDPN(cfg, vocab_size=fr_vocab)\n",
    "\n",
    "    #model_en.load_state_dict(torch.load(english_pretrained_model_path, map_location=device))\n",
    "    model_to_test_path = os.path.join(cfg.output_dir, f\"checkpoint_{epoch_chosen}.tar\")\n",
    "    checkpoint = torch.load(model_to_test_path, map_location=device)\n",
    "    model_test.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    print(\"loaded checkpoint:\", model_to_test_path)\n",
    "    model_test.to(device)\n",
    "\n",
    "    # For statistics of IoU score on test set\n",
    "    test_all_ious_original = []\n",
    "    if cfg.regression_loss:\n",
    "        test_all_ious_refined = []\n",
    "\n",
    "    print(f\"Evaluating on test set: {len(test_set)} samples...\" )\n",
    "    with torch.no_grad():      \n",
    "        for test_batch_counter, (inputs, gt_bboxes, _) in enumerate(test_generator):\n",
    "            Xs, queries = inputs\n",
    "            #print(\"val_batch_counter\", val_batch_counter)\n",
    "            #print(\"Xs\", Xs.size())\n",
    "            #print(\"queries\", len(queries))\n",
    "            #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "\n",
    "            Qs, seq_lengths = preprocess_query(queries)\n",
    "\n",
    "            model_test.eval()\n",
    "\n",
    "            Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "            test_pred = model_test(Xs, Qs, seq_lengths)\n",
    "            test_targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "    #         try:\n",
    "    #             val_loss = loss_func(val_pred, val_targ)\n",
    "    #         except AssertionError as e:\n",
    "    #             print(f\"epoch {epoch}, val, batch: {val_batch_counter}\")\n",
    "    #             with open(\"debug.log\", 'a') as log:\n",
    "    #                 log.write(f\"epoch {epoch}, val, batch: {val_batch_counter}\\n\")\n",
    "    #             raise e\n",
    "    #         test_losses_by_epoch.append(val_loss.item())\n",
    "    #         val_loss_average_by_epoch += val_loss.item()*Xs.size(0)\n",
    "            #logger.add_scalar('val_losses_all_batches', val_losses, val_batch_counter)\n",
    "\n",
    "    #         print(f\"\\repoch {epoch}, validation phase, batch {val_batch_counter}/{len(validation_generator)}, val_loss={val_loss.item()}\", end='')\n",
    "    #         logger.add_scalar(\"val_loss_by_batch\", val_loss.item(), val_batch_counter_total)\n",
    "\n",
    "            # Statistics of IoU score\n",
    "            if cfg.regression_loss:\n",
    "                ious_original, ious_refined = calculate_IoU_scores(Xs, test_pred, gt_bboxes)\n",
    "            else:\n",
    "                ious_original = calculate_IoU_scores(Xs, test_pred, gt_bboxes)\n",
    "            test_all_ious_original = test_all_ious_original + ious_original.tolist()\n",
    "            if cfg.regression_loss:\n",
    "                test_all_ious_refined = test_all_ious_refined + ious_refined.tolist()\n",
    "\n",
    "        good_original = torch.tensor(test_all_ious_original) > 0.5     \n",
    "        print(\"Test set: good bounding box based on original bounding box:\", good_original.sum().item())\n",
    "        acc_original = good_original.sum().float()/len(test_set)\n",
    "        print(\"Test set: accuracy based on original bounding box:\", acc_original.item())\n",
    "    \n",
    "    return acc_original.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/dongwenjian/SSDBACKUP/newly_added/new_experiments/experiments/2020-05-08_17-55-11_5k_all-trainable_random-mapping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_comment = \"_5k_all-trainable_\" + mapping_method_name\n",
    "moment = datetime.datetime.now()\n",
    "run_name = str(moment.date()) + f\"_{moment.hour}-{moment.minute}-{moment.second}\" + run_comment\n",
    "\n",
    "\n",
    "cfg.output_root = os.path.join(cfg.project_root, \"experiments/\")\n",
    "cfg.output_dir_name = run_name  \n",
    "cfg.output_dir = os.path.join(cfg.output_root, cfg.output_dir_name)\n",
    "if not os.path.exists(cfg.output_dir):\n",
    "    os.mkdir(cfg.output_dir)\n",
    "cfg.pytorch_model_save_path = cfg.output_dir\n",
    "cfg.pytorch_result_save_path = cfg.output_dir\n",
    "cfg.pytorch_checkpoint_save_path = cfg.output_dir\n",
    "\n",
    "\n",
    "#log_dir = os.path.join(\"runs/\", run_name)\n",
    "cfg.log_dir = os.path.join(cfg.output_dir, \"log\")\n",
    "os.mkdir(cfg.log_dir)\n",
    "print(cfg.output_dir)\n",
    "\n",
    "loggers_dct = {}\n",
    "loggers_dct['logger'] = SummaryWriter(cfg.log_dir)  \n",
    "loggers_dct['train_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"training\"))\n",
    "loggers_dct['val_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"validation\"))\n",
    "loggers_dct['train_iou_before_refinement_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"train_iou_before_refinement\"))\n",
    "loggers_dct['val_iou_before_refinement_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"val_iou_before_refinement\"))\n",
    "if cfg.regression_loss:\n",
    "    loggers_dct['train_iou_after_refinement_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"train_iou_after_refinement\"))\n",
    "    loggers_dct['val_iou_after_refinement_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"val_iou_after_refinement\"))\n",
    "\n",
    "cfg.pth_filename = \"ddpn.pth\"\n",
    "cfg.checkpoint_filename_base = \"checkpoint_\"  # eg. checkpoint_3.tar means the chechpoint after epoch=3\n",
    "cfg.process_filename = \"process.dct\" # .dct here simply means saving a dictionary in binary mode by pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_for_savings_and_log(run_comment, cfg):\n",
    "    '''\n",
    "    Notice that cfg is modified inside the function.\n",
    "    The directories are created inside the function\n",
    "    '''\n",
    "    #run_comment = \"_5k_all-trainable_\" + mapping_method_name\n",
    "    moment = datetime.datetime.now()\n",
    "    run_name = str(moment.date()) + f\"_{moment.hour}-{moment.minute}-{moment.second}\" + run_comment\n",
    "\n",
    "\n",
    "    cfg.output_root = os.path.join(cfg.project_root, \"experiments1/\")\n",
    "    cfg.output_dir_name = run_name  \n",
    "    cfg.output_dir = os.path.join(cfg.output_root, cfg.output_dir_name)\n",
    "    if not os.path.exists(cfg.output_dir):\n",
    "        os.mkdir(cfg.output_dir)\n",
    "    cfg.pytorch_model_save_path = cfg.output_dir\n",
    "    cfg.pytorch_result_save_path = cfg.output_dir\n",
    "    cfg.pytorch_checkpoint_save_path = cfg.output_dir\n",
    "\n",
    "\n",
    "    #log_dir = os.path.join(\"runs/\", run_name)\n",
    "    cfg.log_dir = os.path.join(cfg.output_dir, \"log\")\n",
    "    os.mkdir(cfg.log_dir)\n",
    "    print(cfg.output_dir)\n",
    "\n",
    "    loggers_dct = {}\n",
    "    loggers_dct['logger'] = SummaryWriter(cfg.log_dir)  \n",
    "    loggers_dct['train_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"training\"))\n",
    "    loggers_dct['val_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"validation\"))\n",
    "    loggers_dct['train_iou_before_refinement_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"train_iou_before_refinement\"))\n",
    "    loggers_dct['val_iou_before_refinement_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"val_iou_before_refinement\"))\n",
    "    if cfg.regression_loss:\n",
    "        loggers_dct['train_iou_after_refinement_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"train_iou_after_refinement\"))\n",
    "        loggers_dct['val_iou_after_refinement_logger'] = SummaryWriter(os.path.join(cfg.log_dir, \"val_iou_after_refinement\"))\n",
    "\n",
    "    cfg.pth_filename = \"ddpn.pth\"\n",
    "    cfg.checkpoint_filename_base = \"checkpoint_\"  # eg. checkpoint_3.tar means the chechpoint after epoch=3\n",
    "    cfg.process_filename = \"process.dct\" # .dct here simply means saving a dictionary in binary mode by pickle\n",
    "    \n",
    "    return loggers_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== The experiment No.0 starts ==================\n",
      "/media/dongwenjian/SSDBACKUP/newly_added/new_experiments/experiments1/2020-05-11_21-21-52_5k_freeze-lstm-fc1-fc_rank_general-dictionary-mapping\n",
      "training on device: cpu\n",
      "log in directory: /media/dongwenjian/SSDBACKUP/newly_added/new_experiments/experiments1/2020-05-11_21-21-52_5k_freeze-lstm-fc1-fc_rank_general-dictionary-mapping/log\n",
      "gamma: 1\n",
      "epoch 0 , training phase finished, average loss: 1.2394619739794983\n",
      "\tTraining: accuracy based on original bounding box: 0.6627873182296753\n",
      "epoch 0 , validation phase finished, average loss: 1.4230419341123328\n",
      "\tValidation: accuracy based on original bounding box: 0.6215530037879944\n",
      "epoch 0 finished. Time used: 323.00522232055664\n",
      "epoch 1 , training phase finished, average loss: 1.1623698614469855\n",
      "\tTraining: accuracy based on original bounding box: 0.6814370155334473\n",
      "epoch 1 , validation phase finished, average loss: 1.3900405405567762\n",
      "\tValidation: accuracy based on original bounding box: 0.6280841827392578\n",
      "epoch 1 finished. Time used: 320.92007398605347\n",
      "epoch 2 , training phase finished, average loss: 1.1253265241365376\n",
      "\tTraining: accuracy based on original bounding box: 0.6907618641853333\n",
      "epoch 2 , validation phase finished, average loss: 1.3742333275140284\n",
      "\tValidation: accuracy based on original bounding box: 0.6324383020401001\n",
      "epoch 2 finished. Time used: 361.1191201210022\n",
      "epoch 3 , training phase finished, average loss: 1.1063595143153142\n",
      "\tTraining: accuracy based on original bounding box: 0.6943761706352234\n",
      "epoch 3 , validation phase finished, average loss: 1.363281995274332\n",
      "\tValidation: accuracy based on original bounding box: 0.6342525482177734\n",
      "epoch 3 finished. Time used: 304.85562109947205\n",
      "epoch 4 , training phase finished, average loss: 1.0859115443271727\n",
      "\tTraining: accuracy based on original bounding box: 0.7010987401008606\n",
      "epoch 4 , validation phase finished, average loss: 1.3565942716875339\n",
      "\tValidation: accuracy based on original bounding box: 0.6353410482406616\n",
      "epoch 4 finished. Time used: 323.90556240081787\n",
      "epoch 5 , training phase finished, average loss: 1.0795707198879667\n",
      "\tTraining: accuracy based on original bounding box: 0.7042070031166077\n",
      "epoch 5 , validation phase finished, average loss: 1.3503513651074104\n",
      "\tValidation: accuracy based on original bounding box: 0.6393323540687561\n",
      "epoch 5 finished. Time used: 306.48249650001526\n",
      "epoch 6, training phase, batch 140/217, loss=0.9780502319335938"
     ]
    }
   ],
   "source": [
    "\n",
    "experiment_number = 3\n",
    "\n",
    "accuracies_on_test_set = []\n",
    "\n",
    "mode = 'general-dictionary-mapping'\n",
    "\n",
    "for experiment_index in range(experiment_number):\n",
    "    \n",
    "    print(f'============== The experiment No.{experiment_index} starts ==================')\n",
    "\n",
    "    \n",
    "    # ---------------Initialize model------------------\n",
    "    if mode == 'training-from-scratch':\n",
    "\n",
    "        if cfg.use_pretrained_word_embedding == None:\n",
    "            print(\"Non-pretrained embedding is used.\")\n",
    "            model = DDPN(cfg, vocab_size=len(training_corpus_dct.token2id))\n",
    "        elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "            print(\"Glove embedding is used.\")\n",
    "            model = DDPN(cfg, embedding_weights=glove.vectors)\n",
    "        else:\n",
    "            raise Exception(\"Embedding configuration not recognized\")\n",
    "\n",
    "    else: \n",
    "        model, model_en, model_dict = prepare_model_for_transfer(training_corpus_dct, \n",
    "                                                            training_corpus_dct_en, \n",
    "                                                            english_pretrained_model_path, \n",
    "                                                            cfg)\n",
    "\n",
    "        if mode == 'random-mapping':\n",
    "            transfer_with_random_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, cfg)\n",
    "\n",
    "        elif mode == 'frequency-mapping':\n",
    "            transfer_with_frequency_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, cfg)\n",
    "\n",
    "        elif mode == 'general-dictionary-mapping':\n",
    "            transfer_with_general_dictionary_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, general_dictionary_file, cfg)\n",
    "\n",
    "        elif mode == 'specific-dictionary-mapping':\n",
    "            transfer_with_specific_dictionary_mapping(model, model_en, model_dict, training_corpus_dct, training_corpus_dct_en, specific_dictionary_file, cfg)\n",
    "\n",
    "        else:\n",
    "            raise Exception('unknown mapping mode')\n",
    "    mapping_method_name = mode\n",
    "    \n",
    "    \n",
    "    #-----------------Prepare for training------------------\n",
    "    # Parameters\n",
    "    params = {'batch_size': 64,\n",
    "              'num_workers': 1}\n",
    "\n",
    "    training_generator = data.DataLoader(training_set, shuffle=True, **params)\n",
    "    validation_generator = data.DataLoader(validation_set, shuffle=True, **params)\n",
    "    test_generator = data.DataLoader(test_set, shuffle=True, **params)\n",
    "\n",
    "\n",
    "\n",
    "    #run_comment = \"_5k_all-trainable_\" + mapping_method_name\n",
    "    run_comment = \"_5k_freeze-lstm-fc1-fc_rank_\" + mapping_method_name\n",
    "    loggers_dct = prepare_for_savings_and_log(run_comment, cfg)\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    loss_func = loss_wrapper(cfg, loggers_dct)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.999), lr=0.001) \n",
    "    LR_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=cfg.lr_decay_rate)\n",
    "    # Warning: Pytorch's Adam does not have the learning rate decay feature. \n",
    "    #          Possibly learning rate scheduler may achieve the same effect. \n",
    "    # Warning: beta2 is recommended as 0.999 in the original paper and by the community. But 0.99 is used in original DDPN paper  \n",
    "\n",
    "\n",
    "    print(\"training on device:\", device)\n",
    "    print(\"log in directory:\", loggers_dct['logger'].logdir)\n",
    "    print(\"gamma:\", cfg.GAMMA)\n",
    "\n",
    "    process = {}\n",
    "    process['time'] = []\n",
    "    process['train_average_losses_by_epoch'] = []\n",
    "    process['val_average_losses_by_epoch'] = []\n",
    "    process['train_IoU_acc_before_refinement'] = []\n",
    "    process['val_IoU_acc_before_refinement'] = []\n",
    "    if cfg.regression_loss:\n",
    "        process['train_IoU_acc_after_refinement'] = []\n",
    "        process['val_IoU_acc_after_refinement'] = []\n",
    "    # train_losses = [] # already moved into fit()\n",
    "    # val_losses = []\n",
    "    process['configure'] = cfg\n",
    "\n",
    "\n",
    "\n",
    "    # ---------------------Start training--------------\n",
    "    max_epochs = 10\n",
    "\n",
    "    fit(model, training_generator, validation_generator, optimizer, device, cfg, max_epochs, LR_scheduler, process, loggers_dct)\n",
    "    \n",
    "    # ----------------------Get accuracy---------------\n",
    "    accuracy_on_test_set = test(process, test_generator, cfg)\n",
    "    \n",
    "    accuracies_on_test_set.append(accuracy_on_test_set)\n",
    "    \n",
    "    print('\\n')\n",
    "\n",
    "print('================ all experiments finished ================')\n",
    "print('accuracies_on_test_set', accuracies_on_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5k training from scratch: 0.6066690683364868\n",
    "\n",
    "5k random mapping: 0.6095374822616577, 0.5984223484992981\n",
    "\n",
    "5k frequency mapping: 0.5941197276115417, 0.595912516117096\n",
    "\n",
    "5k general dictionary mapping: 0.6525636315345764\n",
    "\n",
    "5k specific dictionary mapping: 0.6633201837539673, 0.6658300757408142\n",
    "\n",
    "Freeze\n",
    "freze-embedding-lstm-fc1-fc_rank_general-dictionary-mapping\n",
    "5k specific dictionary mapping: 0.6045177578926086, 0.6084617972373962, 0.5991394519805908\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5k training from scratch: 0.6073861718177795, 0.6138401031494141, 0.6066690683364868\n",
    "\n",
    "5k random mapping: 0.6127644181251526, 0.6095374822616577, 0.5984223484992981\n",
    "\n",
    "5k frequency mapping: 0.5951954126358032, 0.5941197276115417, 0.595912516117096\n",
    "\n",
    "5k general dictionary mapping: 0.6565077304840088, 0.6461097002029419, 0.6525636315345764\n",
    "\n",
    "5k specific dictionary mapping: 0.6626030802726746, 0.6633201837539673, 0.6658300757408142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "val_iou_evolution = [elt.item() for elt in process['val_IoU_acc_before_refinement']]\n",
    "val_iou_evolution_array = np.array(val_iou_evolution)\n",
    "print(np.argmax(val_iou_evolution_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/wenjian/Internship/DDPN_transfer/experiments/2019-08-17_21-13-41_3k_all-trainable_general-dict-mapping/process.dct\", \"rb\") as f:\n",
    "    loaded_process = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': [14.308952331542969,\n",
       "  14.47034764289856,\n",
       "  14.245407581329346,\n",
       "  14.061838865280151,\n",
       "  14.14346957206726,\n",
       "  14.259566068649292,\n",
       "  14.262677431106567,\n",
       "  14.299423694610596,\n",
       "  14.053919315338135,\n",
       "  14.558829545974731,\n",
       "  14.223828554153442,\n",
       "  14.105716466903687,\n",
       "  14.351279497146606,\n",
       "  14.558295726776123,\n",
       "  14.306871891021729,\n",
       "  14.42065691947937,\n",
       "  14.297110080718994,\n",
       "  14.387116193771362,\n",
       "  14.441229581832886,\n",
       "  14.656492710113525],\n",
       " 'train_average_losses_by_epoch': [1.1863258267875145,\n",
       "  0.9039005830167018,\n",
       "  0.7879152359417362,\n",
       "  0.7240410841642958,\n",
       "  0.6778976119555316,\n",
       "  0.649167752460408,\n",
       "  0.624294168983795,\n",
       "  0.6156659182229354,\n",
       "  0.605945559198488,\n",
       "  0.5963620048547865,\n",
       "  0.5924514750665434,\n",
       "  0.5899442195969843,\n",
       "  0.5818788112583898,\n",
       "  0.5840751589408565,\n",
       "  0.5847490874499713,\n",
       "  0.5815934303424392,\n",
       "  0.5791874635669128,\n",
       "  0.5827078555390998,\n",
       "  0.5799955002578638,\n",
       "  0.5779476364688511],\n",
       " 'val_average_losses_by_epoch': [1.321754810945043,\n",
       "  1.3328114722048423,\n",
       "  1.3608077873512345,\n",
       "  1.3764760288340951,\n",
       "  1.405288348177175,\n",
       "  1.4122723929248804,\n",
       "  1.420166441767932,\n",
       "  1.4370252591259074,\n",
       "  1.4296949318946706,\n",
       "  1.4463666061531477,\n",
       "  1.448408187041262,\n",
       "  1.4494445599042451,\n",
       "  1.4415429990592648,\n",
       "  1.4496477427953214,\n",
       "  1.4502835711477804,\n",
       "  1.4535500036095672,\n",
       "  1.4576318873030354,\n",
       "  1.4407729782456065,\n",
       "  1.4469391634831061,\n",
       "  1.447816793389175],\n",
       " 'train_IoU_acc_before_refinement': [tensor(0.6641),\n",
       "  tensor(0.7553),\n",
       "  tensor(0.7919),\n",
       "  tensor(0.8153),\n",
       "  tensor(0.8282),\n",
       "  tensor(0.8385),\n",
       "  tensor(0.8499),\n",
       "  tensor(0.8538),\n",
       "  tensor(0.8535),\n",
       "  tensor(0.8555),\n",
       "  tensor(0.8604),\n",
       "  tensor(0.8601),\n",
       "  tensor(0.8639),\n",
       "  tensor(0.8652),\n",
       "  tensor(0.8646),\n",
       "  tensor(0.8605),\n",
       "  tensor(0.8618),\n",
       "  tensor(0.8590),\n",
       "  tensor(0.8646),\n",
       "  tensor(0.8627)],\n",
       " 'val_IoU_acc_before_refinement': [tensor(0.6364),\n",
       "  tensor(0.6372),\n",
       "  tensor(0.6350),\n",
       "  tensor(0.6364),\n",
       "  tensor(0.6368),\n",
       "  tensor(0.6317),\n",
       "  tensor(0.6346),\n",
       "  tensor(0.6353),\n",
       "  tensor(0.6335),\n",
       "  tensor(0.6313),\n",
       "  tensor(0.6321),\n",
       "  tensor(0.6324),\n",
       "  tensor(0.6310),\n",
       "  tensor(0.6335),\n",
       "  tensor(0.6313),\n",
       "  tensor(0.6313),\n",
       "  tensor(0.6324),\n",
       "  tensor(0.6343),\n",
       "  tensor(0.6332),\n",
       "  tensor(0.6328)],\n",
       " 'configure': <__main__.CFG at 0x7f570bafb748>,\n",
       " 'train_losses': [[1.3565099239349365,\n",
       "   1.1673047542572021,\n",
       "   1.4217700958251953,\n",
       "   1.2453869581222534,\n",
       "   1.4343817234039307,\n",
       "   1.348339319229126,\n",
       "   1.305149793624878,\n",
       "   1.57369065284729,\n",
       "   1.6382259130477905,\n",
       "   1.4157564640045166,\n",
       "   1.2475478649139404,\n",
       "   1.2696213722229004,\n",
       "   1.7609633207321167,\n",
       "   1.3925297260284424,\n",
       "   1.1505451202392578,\n",
       "   1.290602684020996,\n",
       "   1.1809780597686768,\n",
       "   1.1526426076889038,\n",
       "   1.1585158109664917,\n",
       "   1.1519124507904053,\n",
       "   1.1909019947052002,\n",
       "   0.9793809056282043,\n",
       "   1.3770720958709717,\n",
       "   1.2904472351074219,\n",
       "   1.3761465549468994,\n",
       "   1.1345160007476807,\n",
       "   1.364692211151123,\n",
       "   1.4667690992355347,\n",
       "   1.3054777383804321,\n",
       "   1.1297152042388916,\n",
       "   1.0347684621810913,\n",
       "   1.111701250076294,\n",
       "   1.408057689666748,\n",
       "   1.200998306274414,\n",
       "   1.4061200618743896,\n",
       "   1.3167850971221924,\n",
       "   1.2126610279083252,\n",
       "   1.4158440828323364,\n",
       "   1.0052344799041748,\n",
       "   1.286211609840393,\n",
       "   1.4466843605041504,\n",
       "   0.946090817451477,\n",
       "   1.3136241436004639,\n",
       "   1.5836429595947266,\n",
       "   1.181746244430542,\n",
       "   1.3738126754760742,\n",
       "   1.3619120121002197,\n",
       "   1.1185098886489868,\n",
       "   0.9955419898033142,\n",
       "   1.3573551177978516,\n",
       "   1.0420199632644653,\n",
       "   1.339400053024292,\n",
       "   1.0601938962936401,\n",
       "   1.1167609691619873,\n",
       "   1.2136869430541992,\n",
       "   0.8342141509056091,\n",
       "   1.071885585784912,\n",
       "   1.1781827211380005,\n",
       "   1.2769887447357178,\n",
       "   1.3318763971328735,\n",
       "   1.0576629638671875,\n",
       "   1.323934555053711,\n",
       "   1.0043059587478638,\n",
       "   1.1195226907730103,\n",
       "   1.3592679500579834,\n",
       "   1.1413557529449463,\n",
       "   0.9960232973098755,\n",
       "   1.2320568561553955,\n",
       "   1.1181668043136597,\n",
       "   0.8913342952728271,\n",
       "   1.0079364776611328,\n",
       "   0.8702359199523926,\n",
       "   1.0285370349884033,\n",
       "   1.1931400299072266,\n",
       "   1.173967719078064,\n",
       "   0.9857779741287231,\n",
       "   0.9841720461845398,\n",
       "   1.2950010299682617,\n",
       "   0.965462327003479,\n",
       "   1.2548465728759766,\n",
       "   1.0358223915100098,\n",
       "   1.2223442792892456,\n",
       "   0.8585494160652161,\n",
       "   1.058823823928833,\n",
       "   1.1216118335723877,\n",
       "   1.111700177192688,\n",
       "   1.2375808954238892,\n",
       "   0.8676002621650696,\n",
       "   1.2836781740188599,\n",
       "   1.3231480121612549,\n",
       "   1.0058090686798096,\n",
       "   1.1814472675323486,\n",
       "   0.9602664113044739,\n",
       "   1.0083591938018799,\n",
       "   1.0560908317565918,\n",
       "   1.1291191577911377,\n",
       "   1.0310159921646118,\n",
       "   0.8683630228042603,\n",
       "   1.5289045572280884,\n",
       "   1.1725038290023804,\n",
       "   1.1932897567749023,\n",
       "   1.3134517669677734,\n",
       "   1.2098180055618286,\n",
       "   1.095116376876831,\n",
       "   1.262276291847229,\n",
       "   1.1319937705993652,\n",
       "   1.3179088830947876,\n",
       "   1.1706788539886475,\n",
       "   1.1499743461608887,\n",
       "   0.9746554493904114,\n",
       "   1.1246877908706665,\n",
       "   0.9819879531860352,\n",
       "   1.1216681003570557,\n",
       "   1.209757685661316,\n",
       "   1.21799635887146,\n",
       "   1.1100057363510132,\n",
       "   1.1158194541931152,\n",
       "   1.3772939443588257,\n",
       "   1.021645188331604,\n",
       "   0.9102351665496826,\n",
       "   0.9872338771820068,\n",
       "   1.0706883668899536,\n",
       "   1.0650627613067627,\n",
       "   1.1926238536834717,\n",
       "   1.2503666877746582,\n",
       "   1.0308213233947754,\n",
       "   1.346985101699829,\n",
       "   0.9062358140945435,\n",
       "   1.0812606811523438,\n",
       "   1.0693845748901367,\n",
       "   1.410187005996704,\n",
       "   1.2275781631469727,\n",
       "   1.5404659509658813],\n",
       "  [0.8749386072158813,\n",
       "   0.9169471859931946,\n",
       "   0.9032952189445496,\n",
       "   1.1616075038909912,\n",
       "   0.9161054491996765,\n",
       "   0.8342771530151367,\n",
       "   0.8985826373100281,\n",
       "   1.0288631916046143,\n",
       "   0.8376113176345825,\n",
       "   1.171217441558838,\n",
       "   0.9465939998626709,\n",
       "   0.7696060538291931,\n",
       "   0.9635116457939148,\n",
       "   0.875717043876648,\n",
       "   0.7328143119812012,\n",
       "   0.8134698271751404,\n",
       "   1.0428590774536133,\n",
       "   0.8780498504638672,\n",
       "   0.9153467416763306,\n",
       "   0.8100013136863708,\n",
       "   0.7728028297424316,\n",
       "   0.843207597732544,\n",
       "   0.7969863414764404,\n",
       "   0.7404879331588745,\n",
       "   0.8897075653076172,\n",
       "   0.906536340713501,\n",
       "   1.0229413509368896,\n",
       "   0.7624428868293762,\n",
       "   0.8742084503173828,\n",
       "   0.8606812357902527,\n",
       "   0.9329988956451416,\n",
       "   0.9343630075454712,\n",
       "   0.9559980034828186,\n",
       "   0.8120401501655579,\n",
       "   0.826482892036438,\n",
       "   0.9806289672851562,\n",
       "   0.8842445611953735,\n",
       "   0.8753683567047119,\n",
       "   1.0345096588134766,\n",
       "   0.9362797141075134,\n",
       "   0.9838721752166748,\n",
       "   1.1015043258666992,\n",
       "   0.7113192081451416,\n",
       "   0.7668329477310181,\n",
       "   0.8123725652694702,\n",
       "   0.8804033994674683,\n",
       "   0.8346593379974365,\n",
       "   0.89974045753479,\n",
       "   0.9072847366333008,\n",
       "   1.1688225269317627,\n",
       "   1.018416166305542,\n",
       "   0.8010719418525696,\n",
       "   0.944159984588623,\n",
       "   0.7688762545585632,\n",
       "   0.8600091338157654,\n",
       "   1.0134518146514893,\n",
       "   0.9277843236923218,\n",
       "   0.9810216426849365,\n",
       "   0.7777152061462402,\n",
       "   1.0430724620819092,\n",
       "   0.8346275091171265,\n",
       "   0.9272024631500244,\n",
       "   0.8331655859947205,\n",
       "   0.7634920477867126,\n",
       "   0.9677994847297668,\n",
       "   1.008715271949768,\n",
       "   0.9315300583839417,\n",
       "   0.800195574760437,\n",
       "   0.7448558807373047,\n",
       "   1.039856195449829,\n",
       "   0.8397519588470459,\n",
       "   0.7445239424705505,\n",
       "   0.6631551384925842,\n",
       "   0.8841469287872314,\n",
       "   0.858080267906189,\n",
       "   0.8946307301521301,\n",
       "   0.8895382285118103,\n",
       "   0.8374679088592529,\n",
       "   0.8265678882598877,\n",
       "   1.2613492012023926,\n",
       "   0.823142945766449,\n",
       "   0.9717342853546143,\n",
       "   0.8758273124694824,\n",
       "   1.0900039672851562,\n",
       "   0.9962096214294434,\n",
       "   0.9540324807167053,\n",
       "   0.9817838668823242,\n",
       "   0.8596861958503723,\n",
       "   0.8665955662727356,\n",
       "   0.8943440914154053,\n",
       "   0.9866585731506348,\n",
       "   0.9731484651565552,\n",
       "   0.8165181279182434,\n",
       "   0.9099613428115845,\n",
       "   0.8362002372741699,\n",
       "   1.0246238708496094,\n",
       "   0.8025686740875244,\n",
       "   0.8762389421463013,\n",
       "   0.9511725902557373,\n",
       "   0.8794149160385132,\n",
       "   0.8330755829811096,\n",
       "   0.8381254076957703,\n",
       "   0.7484884858131409,\n",
       "   0.8496408462524414,\n",
       "   0.8429858684539795,\n",
       "   1.1263864040374756,\n",
       "   0.9075857400894165,\n",
       "   1.0652806758880615,\n",
       "   1.0595439672470093,\n",
       "   0.8945925235748291,\n",
       "   1.07728910446167,\n",
       "   1.0666399002075195,\n",
       "   0.7866150140762329,\n",
       "   1.1978869438171387,\n",
       "   0.8130406141281128,\n",
       "   0.8501167297363281,\n",
       "   0.7388839721679688,\n",
       "   0.800365149974823,\n",
       "   1.0200780630111694,\n",
       "   0.8503577709197998,\n",
       "   0.7135753631591797,\n",
       "   0.9492497444152832,\n",
       "   0.7506534457206726,\n",
       "   1.110734224319458,\n",
       "   1.120184063911438,\n",
       "   0.9163908958435059,\n",
       "   1.0402947664260864,\n",
       "   0.6981328725814819,\n",
       "   0.7901291251182556,\n",
       "   0.9352549910545349,\n",
       "   0.9239680171012878,\n",
       "   0.8735116720199585,\n",
       "   1.3028984069824219],\n",
       "  [0.7088164687156677,\n",
       "   0.7005900144577026,\n",
       "   0.834323525428772,\n",
       "   0.915002703666687,\n",
       "   0.6388934850692749,\n",
       "   0.7610151171684265,\n",
       "   0.7453833818435669,\n",
       "   0.8265786170959473,\n",
       "   0.7892582416534424,\n",
       "   0.7736430168151855,\n",
       "   0.8058192729949951,\n",
       "   0.9463551044464111,\n",
       "   0.7837263345718384,\n",
       "   0.8773223161697388,\n",
       "   0.8198720812797546,\n",
       "   0.7780274152755737,\n",
       "   0.9780957698822021,\n",
       "   0.6978152990341187,\n",
       "   0.7684787511825562,\n",
       "   0.8346844911575317,\n",
       "   0.7095365524291992,\n",
       "   0.8180957436561584,\n",
       "   0.8957779407501221,\n",
       "   0.8385016918182373,\n",
       "   0.7881031036376953,\n",
       "   0.7958751916885376,\n",
       "   0.9621526002883911,\n",
       "   0.7262569665908813,\n",
       "   0.6666611433029175,\n",
       "   0.8172845244407654,\n",
       "   0.8979763984680176,\n",
       "   0.8707165718078613,\n",
       "   0.777864933013916,\n",
       "   0.7485510110855103,\n",
       "   0.6330742239952087,\n",
       "   0.7714610695838928,\n",
       "   0.7101084589958191,\n",
       "   0.6944878697395325,\n",
       "   0.8066089153289795,\n",
       "   0.7345503568649292,\n",
       "   0.7218741178512573,\n",
       "   0.8123107552528381,\n",
       "   0.7553070783615112,\n",
       "   0.7744214534759521,\n",
       "   0.8006129264831543,\n",
       "   0.8993304371833801,\n",
       "   0.7624399662017822,\n",
       "   0.8753179907798767,\n",
       "   0.8761242032051086,\n",
       "   0.8671104907989502,\n",
       "   0.7039711475372314,\n",
       "   0.9057998061180115,\n",
       "   0.6915091276168823,\n",
       "   1.0002319812774658,\n",
       "   0.8709009885787964,\n",
       "   0.8134650588035583,\n",
       "   0.7451068758964539,\n",
       "   0.8474566340446472,\n",
       "   0.6681971549987793,\n",
       "   0.9328096508979797,\n",
       "   0.7701008915901184,\n",
       "   0.8093492388725281,\n",
       "   0.9366955757141113,\n",
       "   0.8338132500648499,\n",
       "   0.8479090929031372,\n",
       "   0.7602865695953369,\n",
       "   0.8368154764175415,\n",
       "   0.7615606188774109,\n",
       "   0.8172985911369324,\n",
       "   0.6863833665847778,\n",
       "   0.7070599794387817,\n",
       "   0.8440277576446533,\n",
       "   0.7376338243484497,\n",
       "   1.0070468187332153,\n",
       "   0.7130429744720459,\n",
       "   0.7034457921981812,\n",
       "   0.6587298512458801,\n",
       "   0.634369969367981,\n",
       "   0.843086838722229,\n",
       "   0.6885808706283569,\n",
       "   0.7573830485343933,\n",
       "   0.7276456356048584,\n",
       "   0.771182656288147,\n",
       "   0.6957024335861206,\n",
       "   0.7548364400863647,\n",
       "   0.8513442873954773,\n",
       "   0.8683055639266968,\n",
       "   0.6451969146728516,\n",
       "   0.826852560043335,\n",
       "   0.7595721483230591,\n",
       "   0.8334184885025024,\n",
       "   0.7532399892807007,\n",
       "   0.7802736759185791,\n",
       "   0.7239346504211426,\n",
       "   0.6570698022842407,\n",
       "   0.6663155555725098,\n",
       "   0.7929115891456604,\n",
       "   0.7505954504013062,\n",
       "   0.8380612134933472,\n",
       "   0.8721286058425903,\n",
       "   0.7639870643615723,\n",
       "   0.6585709452629089,\n",
       "   0.7752640843391418,\n",
       "   0.7982821464538574,\n",
       "   0.8350165486335754,\n",
       "   0.7469370365142822,\n",
       "   0.7844604253768921,\n",
       "   0.8344664573669434,\n",
       "   0.8234232664108276,\n",
       "   0.872310996055603,\n",
       "   0.7620516419410706,\n",
       "   0.7552507519721985,\n",
       "   0.9071347117424011,\n",
       "   0.8459000587463379,\n",
       "   0.9427974224090576,\n",
       "   0.7084405422210693,\n",
       "   0.7218968868255615,\n",
       "   0.7407798767089844,\n",
       "   0.7176030278205872,\n",
       "   0.8467009663581848,\n",
       "   0.6887633204460144,\n",
       "   0.7556342482566833,\n",
       "   0.7179397940635681,\n",
       "   0.7203152179718018,\n",
       "   0.872652530670166,\n",
       "   0.7592671513557434,\n",
       "   0.7565138339996338,\n",
       "   0.8575695753097534,\n",
       "   0.7602145671844482,\n",
       "   0.7804679870605469,\n",
       "   0.7546758055686951,\n",
       "   0.8509095907211304,\n",
       "   0.751610279083252],\n",
       "  [0.8033178448677063,\n",
       "   0.6647012829780579,\n",
       "   0.7408885955810547,\n",
       "   0.6596425175666809,\n",
       "   0.7410653233528137,\n",
       "   0.8746885061264038,\n",
       "   0.7358916997909546,\n",
       "   0.5990232229232788,\n",
       "   0.7344282269477844,\n",
       "   0.8521634340286255,\n",
       "   0.6375364065170288,\n",
       "   0.7558084726333618,\n",
       "   0.7222872376441956,\n",
       "   0.8299310207366943,\n",
       "   0.6516353487968445,\n",
       "   0.5345613360404968,\n",
       "   0.816400408744812,\n",
       "   0.8041030168533325,\n",
       "   0.8115711212158203,\n",
       "   0.7746764421463013,\n",
       "   0.7400281429290771,\n",
       "   0.7787927985191345,\n",
       "   0.6606851816177368,\n",
       "   0.65779709815979,\n",
       "   0.8105255961418152,\n",
       "   0.6031551361083984,\n",
       "   0.9116189479827881,\n",
       "   0.8209068775177002,\n",
       "   0.800660252571106,\n",
       "   0.7059218883514404,\n",
       "   0.745803713798523,\n",
       "   0.7707095146179199,\n",
       "   0.691476583480835,\n",
       "   0.7811547517776489,\n",
       "   0.7438305020332336,\n",
       "   0.749783992767334,\n",
       "   0.6876590251922607,\n",
       "   0.827477216720581,\n",
       "   0.5961449146270752,\n",
       "   0.7125387191772461,\n",
       "   0.7939813733100891,\n",
       "   0.6629098057746887,\n",
       "   0.6434887647628784,\n",
       "   0.7243281602859497,\n",
       "   0.6565766930580139,\n",
       "   0.8079797625541687,\n",
       "   0.7097378969192505,\n",
       "   0.7157323956489563,\n",
       "   0.8548489212989807,\n",
       "   0.6327639818191528,\n",
       "   0.8132463693618774,\n",
       "   0.7088067531585693,\n",
       "   0.7926775813102722,\n",
       "   0.7452157735824585,\n",
       "   0.7575584650039673,\n",
       "   0.6630329489707947,\n",
       "   0.7245582938194275,\n",
       "   0.7089609503746033,\n",
       "   0.6007586121559143,\n",
       "   0.7482984066009521,\n",
       "   0.6673336029052734,\n",
       "   0.7995504140853882,\n",
       "   0.7255175113677979,\n",
       "   0.8299595713615417,\n",
       "   0.648149847984314,\n",
       "   0.6860978603363037,\n",
       "   0.7267615795135498,\n",
       "   0.6401562690734863,\n",
       "   0.7314919829368591,\n",
       "   0.6867897510528564,\n",
       "   0.8209623694419861,\n",
       "   0.6712403893470764,\n",
       "   0.7042284607887268,\n",
       "   0.7090147733688354,\n",
       "   0.8727681636810303,\n",
       "   0.6324571371078491,\n",
       "   0.7856021523475647,\n",
       "   0.9263123273849487,\n",
       "   0.6733185052871704,\n",
       "   0.6933339834213257,\n",
       "   0.6516523957252502,\n",
       "   0.6258851885795593,\n",
       "   0.7538912892341614,\n",
       "   0.7757747769355774,\n",
       "   0.8480894565582275,\n",
       "   0.6685876846313477,\n",
       "   0.5309837460517883,\n",
       "   0.67569899559021,\n",
       "   0.8546411395072937,\n",
       "   0.6525934934616089,\n",
       "   0.7282969355583191,\n",
       "   0.6692483425140381,\n",
       "   0.6686842441558838,\n",
       "   0.7110345363616943,\n",
       "   0.775551438331604,\n",
       "   0.6813739538192749,\n",
       "   0.72857666015625,\n",
       "   0.7741092443466187,\n",
       "   0.7504856586456299,\n",
       "   0.7472867369651794,\n",
       "   0.6766736507415771,\n",
       "   0.6932250261306763,\n",
       "   0.5908969044685364,\n",
       "   0.7385331392288208,\n",
       "   0.7822794914245605,\n",
       "   0.8409395217895508,\n",
       "   0.7145442366600037,\n",
       "   0.717522382736206,\n",
       "   0.7554914951324463,\n",
       "   0.6420996189117432,\n",
       "   0.7117211818695068,\n",
       "   0.6861552596092224,\n",
       "   0.6927430629730225,\n",
       "   0.7101849317550659,\n",
       "   0.687403678894043,\n",
       "   0.8212762475013733,\n",
       "   0.7111557126045227,\n",
       "   0.6448484659194946,\n",
       "   0.8174771666526794,\n",
       "   0.6880806088447571,\n",
       "   0.6224194765090942,\n",
       "   0.664781928062439,\n",
       "   0.7141788601875305,\n",
       "   0.7280542850494385,\n",
       "   0.6970163583755493,\n",
       "   0.5258697867393494,\n",
       "   0.7776530385017395,\n",
       "   0.7871795296669006,\n",
       "   0.7989593744277954,\n",
       "   0.6796177625656128,\n",
       "   0.7364418506622314,\n",
       "   0.6455142498016357,\n",
       "   0.5060805082321167],\n",
       "  [0.6856917142868042,\n",
       "   0.5825433731079102,\n",
       "   0.7139801979064941,\n",
       "   0.7457765340805054,\n",
       "   0.7406253814697266,\n",
       "   0.6943074464797974,\n",
       "   0.7184375524520874,\n",
       "   0.90328049659729,\n",
       "   0.6930875778198242,\n",
       "   0.578562319278717,\n",
       "   0.7358421683311462,\n",
       "   0.4934794306755066,\n",
       "   0.6565757989883423,\n",
       "   0.7480402588844299,\n",
       "   0.638982892036438,\n",
       "   0.7841297388076782,\n",
       "   0.640093982219696,\n",
       "   0.5639153718948364,\n",
       "   0.6165530681610107,\n",
       "   0.8554524779319763,\n",
       "   0.5852534770965576,\n",
       "   0.6413565278053284,\n",
       "   0.6896482110023499,\n",
       "   0.6383734345436096,\n",
       "   0.6514946222305298,\n",
       "   0.6219221353530884,\n",
       "   0.6681915521621704,\n",
       "   0.7483561038970947,\n",
       "   0.6408103108406067,\n",
       "   0.46987855434417725,\n",
       "   0.6999226808547974,\n",
       "   0.5987273454666138,\n",
       "   0.7604726552963257,\n",
       "   0.7883213758468628,\n",
       "   0.6030140519142151,\n",
       "   0.7195706963539124,\n",
       "   0.649499773979187,\n",
       "   0.6308265924453735,\n",
       "   0.7183946967124939,\n",
       "   0.6983270645141602,\n",
       "   0.5147702693939209,\n",
       "   0.5633691549301147,\n",
       "   0.6338604688644409,\n",
       "   0.6659698486328125,\n",
       "   0.5950750708580017,\n",
       "   0.8065656423568726,\n",
       "   0.6701756715774536,\n",
       "   0.8071712851524353,\n",
       "   0.6787389516830444,\n",
       "   0.7507327795028687,\n",
       "   0.6154545545578003,\n",
       "   0.6772421598434448,\n",
       "   0.7079362869262695,\n",
       "   0.6448428630828857,\n",
       "   0.6574020385742188,\n",
       "   0.70124751329422,\n",
       "   0.5419455766677856,\n",
       "   0.77946537733078,\n",
       "   0.6768391132354736,\n",
       "   0.6740106344223022,\n",
       "   0.6745762825012207,\n",
       "   0.5499248504638672,\n",
       "   0.6199968457221985,\n",
       "   0.6798110008239746,\n",
       "   0.762954831123352,\n",
       "   0.635592520236969,\n",
       "   0.7073832750320435,\n",
       "   0.7025717496871948,\n",
       "   0.736086905002594,\n",
       "   0.6538435220718384,\n",
       "   0.6472569704055786,\n",
       "   0.7786192893981934,\n",
       "   0.6869471073150635,\n",
       "   0.6614370942115784,\n",
       "   0.6290929317474365,\n",
       "   0.63548743724823,\n",
       "   0.652187168598175,\n",
       "   0.562174916267395,\n",
       "   0.6912057399749756,\n",
       "   0.5867487192153931,\n",
       "   0.7447566986083984,\n",
       "   0.7101092338562012,\n",
       "   0.672435462474823,\n",
       "   0.6610429286956787,\n",
       "   0.8112781047821045,\n",
       "   0.7183963060379028,\n",
       "   0.686745285987854,\n",
       "   0.5935570001602173,\n",
       "   0.5623500347137451,\n",
       "   0.8065066337585449,\n",
       "   0.7652850151062012,\n",
       "   0.7479888796806335,\n",
       "   0.583196759223938,\n",
       "   0.6261690855026245,\n",
       "   0.7773482203483582,\n",
       "   0.7127307653427124,\n",
       "   0.6044846177101135,\n",
       "   0.6320455074310303,\n",
       "   0.5797566175460815,\n",
       "   0.6708834767341614,\n",
       "   0.7244004607200623,\n",
       "   0.7605471611022949,\n",
       "   0.7752993106842041,\n",
       "   0.743247926235199,\n",
       "   0.5860109329223633,\n",
       "   0.6537004113197327,\n",
       "   0.7575981020927429,\n",
       "   0.8533643484115601,\n",
       "   0.5625400543212891,\n",
       "   0.7087095379829407,\n",
       "   0.5675919651985168,\n",
       "   0.6528204679489136,\n",
       "   0.620073139667511,\n",
       "   0.7066210508346558,\n",
       "   0.7562733292579651,\n",
       "   0.7093316912651062,\n",
       "   0.6157577037811279,\n",
       "   0.6749342679977417,\n",
       "   0.7617627382278442,\n",
       "   0.5654637813568115,\n",
       "   0.6884565353393555,\n",
       "   0.7155991792678833,\n",
       "   0.6927840709686279,\n",
       "   0.6086598634719849,\n",
       "   0.7015048861503601,\n",
       "   0.6246599555015564,\n",
       "   0.7451640367507935,\n",
       "   0.5923317074775696,\n",
       "   0.723320484161377,\n",
       "   0.5501747131347656,\n",
       "   0.8067699670791626,\n",
       "   0.98414546251297,\n",
       "   0.6625657677650452],\n",
       "  [0.6414834260940552,\n",
       "   0.6048067212104797,\n",
       "   0.7000689506530762,\n",
       "   0.6024866104125977,\n",
       "   0.6693613529205322,\n",
       "   0.6201629638671875,\n",
       "   0.59382164478302,\n",
       "   0.6709084510803223,\n",
       "   0.741937518119812,\n",
       "   0.7643568515777588,\n",
       "   0.5928148031234741,\n",
       "   0.7489809393882751,\n",
       "   0.5522683262825012,\n",
       "   0.562059760093689,\n",
       "   0.6279273629188538,\n",
       "   0.6118813753128052,\n",
       "   0.6065319180488586,\n",
       "   0.6339960694313049,\n",
       "   0.814637303352356,\n",
       "   0.6653150320053101,\n",
       "   0.6394906044006348,\n",
       "   0.6518214344978333,\n",
       "   0.634020209312439,\n",
       "   0.7096611857414246,\n",
       "   0.5940138697624207,\n",
       "   0.6203274130821228,\n",
       "   0.6516715288162231,\n",
       "   0.7296812534332275,\n",
       "   0.5799267888069153,\n",
       "   0.5129500031471252,\n",
       "   0.7547246217727661,\n",
       "   0.6436678767204285,\n",
       "   0.6476802825927734,\n",
       "   0.6433699727058411,\n",
       "   0.6387815475463867,\n",
       "   0.5842847228050232,\n",
       "   0.5818421840667725,\n",
       "   0.6551958322525024,\n",
       "   0.6891940832138062,\n",
       "   0.5742455720901489,\n",
       "   0.6712137460708618,\n",
       "   0.714693546295166,\n",
       "   0.6248273253440857,\n",
       "   0.5889987945556641,\n",
       "   0.6102386713027954,\n",
       "   0.6469282507896423,\n",
       "   0.7210193872451782,\n",
       "   0.6010168790817261,\n",
       "   0.5964099764823914,\n",
       "   0.699194073677063,\n",
       "   0.7635944485664368,\n",
       "   0.5816155672073364,\n",
       "   0.8049368858337402,\n",
       "   0.658585786819458,\n",
       "   0.5828156471252441,\n",
       "   0.6175716519355774,\n",
       "   0.5962477922439575,\n",
       "   0.6216904520988464,\n",
       "   0.7025086879730225,\n",
       "   0.5982955694198608,\n",
       "   0.5629475116729736,\n",
       "   0.5666630268096924,\n",
       "   0.5403774976730347,\n",
       "   0.5706811547279358,\n",
       "   0.6423469185829163,\n",
       "   0.5282912254333496,\n",
       "   0.6472275257110596,\n",
       "   0.6038447618484497,\n",
       "   0.696875274181366,\n",
       "   0.688666820526123,\n",
       "   0.5580782890319824,\n",
       "   0.5379199981689453,\n",
       "   0.674044668674469,\n",
       "   0.6271651983261108,\n",
       "   0.6024350523948669,\n",
       "   0.7063055038452148,\n",
       "   0.6693627834320068,\n",
       "   0.7709380388259888,\n",
       "   0.5487572550773621,\n",
       "   0.8240811228752136,\n",
       "   0.5870872735977173,\n",
       "   0.6065808534622192,\n",
       "   0.6773465871810913,\n",
       "   0.7030022144317627,\n",
       "   0.6982704401016235,\n",
       "   0.5924301147460938,\n",
       "   0.68072509765625,\n",
       "   0.7169172167778015,\n",
       "   0.7424938678741455,\n",
       "   0.630888819694519,\n",
       "   0.578344464302063,\n",
       "   0.5893594026565552,\n",
       "   0.6398046016693115,\n",
       "   0.6230708956718445,\n",
       "   0.74362713098526,\n",
       "   0.5795062780380249,\n",
       "   0.6771206855773926,\n",
       "   0.5941727161407471,\n",
       "   0.5970220565795898,\n",
       "   0.6190333366394043,\n",
       "   0.5670117139816284,\n",
       "   0.7569031715393066,\n",
       "   0.6171339750289917,\n",
       "   0.6007720232009888,\n",
       "   0.5676877498626709,\n",
       "   0.5745388269424438,\n",
       "   0.8724185228347778,\n",
       "   0.6465137004852295,\n",
       "   0.7287730574607849,\n",
       "   0.6447633504867554,\n",
       "   0.6578484177589417,\n",
       "   0.6479085683822632,\n",
       "   0.6787382364273071,\n",
       "   0.631069540977478,\n",
       "   0.5263113975524902,\n",
       "   0.6089751124382019,\n",
       "   0.648470401763916,\n",
       "   0.5708484053611755,\n",
       "   0.7250902652740479,\n",
       "   0.6825751066207886,\n",
       "   0.6733617782592773,\n",
       "   0.7150363922119141,\n",
       "   0.9837363958358765,\n",
       "   0.748127818107605,\n",
       "   0.5240297317504883,\n",
       "   0.7045807242393494,\n",
       "   0.8251782059669495,\n",
       "   0.6092479228973389,\n",
       "   0.7665297985076904,\n",
       "   0.7898439168930054,\n",
       "   0.6317235231399536,\n",
       "   0.5788824558258057,\n",
       "   0.5149884223937988],\n",
       "  [0.5339673757553101,\n",
       "   0.6711874008178711,\n",
       "   0.6337167024612427,\n",
       "   0.6787712574005127,\n",
       "   0.5872420072555542,\n",
       "   0.6684048175811768,\n",
       "   0.680280327796936,\n",
       "   0.7214454412460327,\n",
       "   0.7248289585113525,\n",
       "   0.5597655773162842,\n",
       "   0.5965790748596191,\n",
       "   0.687124490737915,\n",
       "   0.7438793182373047,\n",
       "   0.5927059650421143,\n",
       "   0.5783714056015015,\n",
       "   0.6737899780273438,\n",
       "   0.6208547353744507,\n",
       "   0.5001875162124634,\n",
       "   0.563116192817688,\n",
       "   0.5324332118034363,\n",
       "   0.7307620644569397,\n",
       "   0.7229050397872925,\n",
       "   0.595177173614502,\n",
       "   0.6806005239486694,\n",
       "   0.604939341545105,\n",
       "   0.6477293968200684,\n",
       "   0.6104772090911865,\n",
       "   0.7550090551376343,\n",
       "   0.5355406999588013,\n",
       "   0.5556280016899109,\n",
       "   0.5398924350738525,\n",
       "   0.5651789903640747,\n",
       "   0.530669093132019,\n",
       "   0.5369771718978882,\n",
       "   0.6644742488861084,\n",
       "   0.7477669715881348,\n",
       "   0.6344300508499146,\n",
       "   0.7347850799560547,\n",
       "   0.6054458022117615,\n",
       "   0.5444099307060242,\n",
       "   0.6427181959152222,\n",
       "   0.6958824396133423,\n",
       "   0.6456731557846069,\n",
       "   0.48460090160369873,\n",
       "   0.5434987545013428,\n",
       "   0.6620244979858398,\n",
       "   0.5720683336257935,\n",
       "   0.6659051775932312,\n",
       "   0.5607700347900391,\n",
       "   0.5462080240249634,\n",
       "   0.6190954446792603,\n",
       "   0.6005281209945679,\n",
       "   0.5135737657546997,\n",
       "   0.5572196245193481,\n",
       "   0.6127432584762573,\n",
       "   0.6670676469802856,\n",
       "   0.7271049618721008,\n",
       "   0.6274049282073975,\n",
       "   0.7013403177261353,\n",
       "   0.5623943209648132,\n",
       "   0.6362882852554321,\n",
       "   0.6458127498626709,\n",
       "   0.5573232769966125,\n",
       "   0.7037807703018188,\n",
       "   0.5989383459091187,\n",
       "   0.4896702170372009,\n",
       "   0.5888649821281433,\n",
       "   0.517429769039154,\n",
       "   0.6505216360092163,\n",
       "   0.7469899654388428,\n",
       "   0.5657370090484619,\n",
       "   0.5051062703132629,\n",
       "   0.5629689693450928,\n",
       "   0.7379910945892334,\n",
       "   0.6346107721328735,\n",
       "   0.567973256111145,\n",
       "   0.48109889030456543,\n",
       "   0.5225029587745667,\n",
       "   0.6587571501731873,\n",
       "   0.674152672290802,\n",
       "   0.6476872563362122,\n",
       "   0.7202070951461792,\n",
       "   0.5497363805770874,\n",
       "   0.7080419063568115,\n",
       "   0.762810230255127,\n",
       "   0.8545423150062561,\n",
       "   0.6085454225540161,\n",
       "   0.6493767499923706,\n",
       "   0.512721061706543,\n",
       "   0.6189213991165161,\n",
       "   0.792366623878479,\n",
       "   0.5790994167327881,\n",
       "   0.6501865386962891,\n",
       "   0.6421369314193726,\n",
       "   0.6524476408958435,\n",
       "   0.5810009837150574,\n",
       "   0.5931613445281982,\n",
       "   0.654184103012085,\n",
       "   0.6380720734596252,\n",
       "   0.5137344598770142,\n",
       "   0.6244364380836487,\n",
       "   0.6800264120101929,\n",
       "   0.6389509439468384,\n",
       "   0.5455646514892578,\n",
       "   0.5660227537155151,\n",
       "   0.6180158853530884,\n",
       "   0.7094978094100952,\n",
       "   0.5381735563278198,\n",
       "   0.5886244773864746,\n",
       "   0.6631922721862793,\n",
       "   0.5904121398925781,\n",
       "   0.6059541702270508,\n",
       "   0.6231207847595215,\n",
       "   0.6011233329772949,\n",
       "   0.7397221326828003,\n",
       "   0.6625493764877319,\n",
       "   0.685817539691925,\n",
       "   0.5734614729881287,\n",
       "   0.5923519134521484,\n",
       "   0.5685412287712097,\n",
       "   0.7087326049804688,\n",
       "   0.7074263095855713,\n",
       "   0.6699584722518921,\n",
       "   0.646636426448822,\n",
       "   0.6736896634101868,\n",
       "   0.5918877124786377,\n",
       "   0.44293415546417236,\n",
       "   0.6083678007125854,\n",
       "   0.620154857635498,\n",
       "   0.7598350048065186,\n",
       "   0.5953738689422607,\n",
       "   0.6392538547515869,\n",
       "   0.9282904863357544],\n",
       "  [0.627845287322998,\n",
       "   0.5962550044059753,\n",
       "   0.6068731546401978,\n",
       "   0.6070592403411865,\n",
       "   0.5407916307449341,\n",
       "   0.5870842933654785,\n",
       "   0.6201258897781372,\n",
       "   0.6651415824890137,\n",
       "   0.5965814590454102,\n",
       "   0.5398855209350586,\n",
       "   0.6471993923187256,\n",
       "   0.5975761413574219,\n",
       "   0.6619425415992737,\n",
       "   0.6414304971694946,\n",
       "   0.5077815055847168,\n",
       "   0.7422096729278564,\n",
       "   0.8177317976951599,\n",
       "   0.5820636749267578,\n",
       "   0.652225911617279,\n",
       "   0.6363267302513123,\n",
       "   0.6563385725021362,\n",
       "   0.573451578617096,\n",
       "   0.5110028982162476,\n",
       "   0.707760214805603,\n",
       "   0.5800158381462097,\n",
       "   0.5668355226516724,\n",
       "   0.5700105428695679,\n",
       "   0.6228426694869995,\n",
       "   0.5900492072105408,\n",
       "   0.6154409646987915,\n",
       "   0.6045112609863281,\n",
       "   0.6328109502792358,\n",
       "   0.6785213351249695,\n",
       "   0.5999760627746582,\n",
       "   0.49317601323127747,\n",
       "   0.6481696367263794,\n",
       "   0.6162227392196655,\n",
       "   0.6665985584259033,\n",
       "   0.6412100791931152,\n",
       "   0.6399320363998413,\n",
       "   0.6100585460662842,\n",
       "   0.48056381940841675,\n",
       "   0.6616511940956116,\n",
       "   0.6751164793968201,\n",
       "   0.6523283123970032,\n",
       "   0.6468498706817627,\n",
       "   0.617398202419281,\n",
       "   0.61686110496521,\n",
       "   0.6880325675010681,\n",
       "   0.5631619691848755,\n",
       "   0.5587311387062073,\n",
       "   0.6938744783401489,\n",
       "   0.5171047449111938,\n",
       "   0.5182524919509888,\n",
       "   0.5847055912017822,\n",
       "   0.5000545978546143,\n",
       "   0.6209134459495544,\n",
       "   0.594840407371521,\n",
       "   0.6877189874649048,\n",
       "   0.6838513612747192,\n",
       "   0.6247363090515137,\n",
       "   0.5560476779937744,\n",
       "   0.5493575930595398,\n",
       "   0.6898431777954102,\n",
       "   0.6081087589263916,\n",
       "   0.5020018815994263,\n",
       "   0.7212462425231934,\n",
       "   0.6613402962684631,\n",
       "   0.6797349452972412,\n",
       "   0.5259321928024292,\n",
       "   0.6999127864837646,\n",
       "   0.5786212682723999,\n",
       "   0.7002418637275696,\n",
       "   0.6759500503540039,\n",
       "   0.5425185561180115,\n",
       "   0.6213799715042114,\n",
       "   0.6981121301651001,\n",
       "   0.5760715007781982,\n",
       "   0.5429967641830444,\n",
       "   0.6732794046401978,\n",
       "   0.620172917842865,\n",
       "   0.593193531036377,\n",
       "   0.5669533014297485,\n",
       "   0.6828287839889526,\n",
       "   0.6461713314056396,\n",
       "   0.7448484897613525,\n",
       "   0.5997011661529541,\n",
       "   0.6401879787445068,\n",
       "   0.6444834470748901,\n",
       "   0.7381815910339355,\n",
       "   0.6199103593826294,\n",
       "   0.6871888637542725,\n",
       "   0.5672852993011475,\n",
       "   0.5367639660835266,\n",
       "   0.662340521812439,\n",
       "   0.624678373336792,\n",
       "   0.6170206069946289,\n",
       "   0.5973328351974487,\n",
       "   0.5314878225326538,\n",
       "   0.6916384696960449,\n",
       "   0.6166770458221436,\n",
       "   0.702989935874939,\n",
       "   0.6707354784011841,\n",
       "   0.5083041191101074,\n",
       "   0.5814794301986694,\n",
       "   0.5275605320930481,\n",
       "   0.49618545174598694,\n",
       "   0.7175459861755371,\n",
       "   0.5142062902450562,\n",
       "   0.5197700262069702,\n",
       "   0.624805748462677,\n",
       "   0.564716100692749,\n",
       "   0.5046961903572083,\n",
       "   0.5996005535125732,\n",
       "   0.537355363368988,\n",
       "   0.6610572338104248,\n",
       "   0.5720879435539246,\n",
       "   0.6263600587844849,\n",
       "   0.6206251978874207,\n",
       "   0.6666516065597534,\n",
       "   0.49528011679649353,\n",
       "   0.5779473781585693,\n",
       "   0.66741943359375,\n",
       "   0.6145312786102295,\n",
       "   0.6999375820159912,\n",
       "   0.570549726486206,\n",
       "   0.6908646821975708,\n",
       "   0.6208919286727905,\n",
       "   0.6968252062797546,\n",
       "   0.580018937587738,\n",
       "   0.5924665331840515,\n",
       "   0.6983975172042847,\n",
       "   0.7813714742660522],\n",
       "  [0.45721834897994995,\n",
       "   0.8930181264877319,\n",
       "   0.5670205354690552,\n",
       "   0.6506611108779907,\n",
       "   0.6134615540504456,\n",
       "   0.7174330353736877,\n",
       "   0.5919750332832336,\n",
       "   0.6124179363250732,\n",
       "   0.6523303985595703,\n",
       "   0.6517970561981201,\n",
       "   0.5171949863433838,\n",
       "   0.49381962418556213,\n",
       "   0.6112334132194519,\n",
       "   0.49679622054100037,\n",
       "   0.6569688320159912,\n",
       "   0.5443040132522583,\n",
       "   0.5534442067146301,\n",
       "   0.6254515647888184,\n",
       "   0.5722182989120483,\n",
       "   0.5735197067260742,\n",
       "   0.613498330116272,\n",
       "   0.4870705306529999,\n",
       "   0.6265530586242676,\n",
       "   0.5661581754684448,\n",
       "   0.5658601522445679,\n",
       "   0.6965939402580261,\n",
       "   0.5621494650840759,\n",
       "   0.7277361154556274,\n",
       "   0.5919983983039856,\n",
       "   0.6354441046714783,\n",
       "   0.5861902236938477,\n",
       "   0.5867235064506531,\n",
       "   0.7021497488021851,\n",
       "   0.6552059650421143,\n",
       "   0.641416609287262,\n",
       "   0.5970110297203064,\n",
       "   0.5508606433868408,\n",
       "   0.6090630292892456,\n",
       "   0.5361475348472595,\n",
       "   0.5956209897994995,\n",
       "   0.6265015602111816,\n",
       "   0.6203322410583496,\n",
       "   0.6753250360488892,\n",
       "   0.6541317701339722,\n",
       "   0.7720597982406616,\n",
       "   0.5286166071891785,\n",
       "   0.551328182220459,\n",
       "   0.5930216908454895,\n",
       "   0.5820120573043823,\n",
       "   0.6686105132102966,\n",
       "   0.7162631750106812,\n",
       "   0.6024618148803711,\n",
       "   0.5343844890594482,\n",
       "   0.6770506501197815,\n",
       "   0.6466609239578247,\n",
       "   0.6310219764709473,\n",
       "   0.6287204027175903,\n",
       "   0.5721390247344971,\n",
       "   0.6393797397613525,\n",
       "   0.5548819899559021,\n",
       "   0.765741229057312,\n",
       "   0.5730239152908325,\n",
       "   0.6818263530731201,\n",
       "   0.510074257850647,\n",
       "   0.4985159635543823,\n",
       "   0.5880895853042603,\n",
       "   0.5592159032821655,\n",
       "   0.6147975325584412,\n",
       "   0.6549431085586548,\n",
       "   0.5557399392127991,\n",
       "   0.7116228938102722,\n",
       "   0.5619906187057495,\n",
       "   0.6355385780334473,\n",
       "   0.5656490921974182,\n",
       "   0.7106694579124451,\n",
       "   0.5689045786857605,\n",
       "   0.5503443479537964,\n",
       "   0.5656071901321411,\n",
       "   0.5620666146278381,\n",
       "   0.5886823534965515,\n",
       "   0.6285233497619629,\n",
       "   0.6605994701385498,\n",
       "   0.7113164067268372,\n",
       "   0.5268210172653198,\n",
       "   0.5053839683532715,\n",
       "   0.5728359222412109,\n",
       "   0.5675511360168457,\n",
       "   0.5277714133262634,\n",
       "   0.6207218170166016,\n",
       "   0.769813060760498,\n",
       "   0.658840000629425,\n",
       "   0.6097954511642456,\n",
       "   0.5494993925094604,\n",
       "   0.583560585975647,\n",
       "   0.6047050952911377,\n",
       "   0.6933424472808838,\n",
       "   0.5884353518486023,\n",
       "   0.6147942543029785,\n",
       "   0.684855580329895,\n",
       "   0.48280489444732666,\n",
       "   0.5282728672027588,\n",
       "   0.582245409488678,\n",
       "   0.6106553077697754,\n",
       "   0.6936789751052856,\n",
       "   0.5623290538787842,\n",
       "   0.6891958117485046,\n",
       "   0.7514112591743469,\n",
       "   0.6388228535652161,\n",
       "   0.5627589821815491,\n",
       "   0.4949212074279785,\n",
       "   0.6541537046432495,\n",
       "   0.5589160919189453,\n",
       "   0.6235865950584412,\n",
       "   0.5553374290466309,\n",
       "   0.5808944702148438,\n",
       "   0.5543131232261658,\n",
       "   0.5394576191902161,\n",
       "   0.7362172603607178,\n",
       "   0.6403895616531372,\n",
       "   0.5245471000671387,\n",
       "   0.5716742873191833,\n",
       "   0.6237978935241699,\n",
       "   0.5582112669944763,\n",
       "   0.607069730758667,\n",
       "   0.6863141059875488,\n",
       "   0.43074044585227966,\n",
       "   0.5309911966323853,\n",
       "   0.6575624942779541,\n",
       "   0.6007052659988403,\n",
       "   0.6024719476699829,\n",
       "   0.6536935567855835,\n",
       "   0.5516691207885742,\n",
       "   0.5021171569824219],\n",
       "  [0.5372942686080933,\n",
       "   0.5954641699790955,\n",
       "   0.5200673937797546,\n",
       "   0.8329082727432251,\n",
       "   0.6032982468605042,\n",
       "   0.5978274941444397,\n",
       "   0.5967584848403931,\n",
       "   0.6572179794311523,\n",
       "   0.5301125049591064,\n",
       "   0.6403927803039551,\n",
       "   0.6948702931404114,\n",
       "   0.5607882738113403,\n",
       "   0.6882737874984741,\n",
       "   0.5260636806488037,\n",
       "   0.5651679039001465,\n",
       "   0.6277803778648376,\n",
       "   0.6476752161979675,\n",
       "   0.6624628305435181,\n",
       "   0.5882956981658936,\n",
       "   0.6841481328010559,\n",
       "   0.6312177181243896,\n",
       "   0.5426055192947388,\n",
       "   0.5906010866165161,\n",
       "   0.6837754845619202,\n",
       "   0.5886356830596924,\n",
       "   0.6608526706695557,\n",
       "   0.5176636576652527,\n",
       "   0.593395471572876,\n",
       "   0.5384928584098816,\n",
       "   0.48611903190612793,\n",
       "   0.7303956747055054,\n",
       "   0.54483962059021,\n",
       "   0.6527727842330933,\n",
       "   0.5444897413253784,\n",
       "   0.6047991514205933,\n",
       "   0.7218682169914246,\n",
       "   0.49239832162857056,\n",
       "   0.6025035381317139,\n",
       "   0.5553163290023804,\n",
       "   0.5972208976745605,\n",
       "   0.5127905011177063,\n",
       "   0.6009764671325684,\n",
       "   0.5285281538963318,\n",
       "   0.4932800233364105,\n",
       "   0.5134106874465942,\n",
       "   0.7429337501525879,\n",
       "   0.5387837886810303,\n",
       "   0.5062432289123535,\n",
       "   0.5562729835510254,\n",
       "   0.5016934871673584,\n",
       "   0.6700766682624817,\n",
       "   0.6155914068222046,\n",
       "   0.6471010446548462,\n",
       "   0.5785623788833618,\n",
       "   0.627440333366394,\n",
       "   0.6261709928512573,\n",
       "   0.6079052090644836,\n",
       "   0.8483906388282776,\n",
       "   0.6341127157211304,\n",
       "   0.5425254106521606,\n",
       "   0.49782365560531616,\n",
       "   0.553824782371521,\n",
       "   0.6298203468322754,\n",
       "   0.49141931533813477,\n",
       "   0.6154637932777405,\n",
       "   0.6645776033401489,\n",
       "   0.6366666555404663,\n",
       "   0.6273932456970215,\n",
       "   0.7832688689231873,\n",
       "   0.47665444016456604,\n",
       "   0.7192792892456055,\n",
       "   0.5785079002380371,\n",
       "   0.526208758354187,\n",
       "   0.5166816711425781,\n",
       "   0.5641298294067383,\n",
       "   0.6144354343414307,\n",
       "   0.6647467017173767,\n",
       "   0.718863844871521,\n",
       "   0.6033713817596436,\n",
       "   0.655673623085022,\n",
       "   0.5775831937789917,\n",
       "   0.5299878120422363,\n",
       "   0.5512590408325195,\n",
       "   0.610256552696228,\n",
       "   0.6254695653915405,\n",
       "   0.6589690446853638,\n",
       "   0.5800132751464844,\n",
       "   0.5445166826248169,\n",
       "   0.6132067441940308,\n",
       "   0.5268920660018921,\n",
       "   0.5769405961036682,\n",
       "   0.5008434057235718,\n",
       "   0.5092471837997437,\n",
       "   0.529057502746582,\n",
       "   0.5779327154159546,\n",
       "   0.5976818799972534,\n",
       "   0.5533913373947144,\n",
       "   0.4951200485229492,\n",
       "   0.5485770106315613,\n",
       "   0.5464267730712891,\n",
       "   0.6040120124816895,\n",
       "   0.5615522265434265,\n",
       "   0.5792241096496582,\n",
       "   0.47492045164108276,\n",
       "   0.5052242279052734,\n",
       "   0.5341859459877014,\n",
       "   0.5485905408859253,\n",
       "   0.5786815285682678,\n",
       "   0.5748080015182495,\n",
       "   0.6457409858703613,\n",
       "   0.5376538038253784,\n",
       "   0.6646014451980591,\n",
       "   0.5506751537322998,\n",
       "   0.6775009632110596,\n",
       "   0.6414121389389038,\n",
       "   0.7765451669692993,\n",
       "   0.6212915182113647,\n",
       "   0.5846661329269409,\n",
       "   0.6330022215843201,\n",
       "   0.5681809782981873,\n",
       "   0.5241767168045044,\n",
       "   0.6597706079483032,\n",
       "   0.7838031053543091,\n",
       "   0.6109545826911926,\n",
       "   0.6031956672668457,\n",
       "   0.5156666040420532,\n",
       "   0.6800345778465271,\n",
       "   0.6394506692886353,\n",
       "   0.6359589099884033,\n",
       "   0.6255805492401123,\n",
       "   0.4938752055168152,\n",
       "   0.5654430389404297,\n",
       "   0.582399308681488],\n",
       "  [0.5432080030441284,\n",
       "   0.7046297788619995,\n",
       "   0.605294406414032,\n",
       "   0.5130150318145752,\n",
       "   0.5985827445983887,\n",
       "   0.5240753293037415,\n",
       "   0.5744088888168335,\n",
       "   0.5416021347045898,\n",
       "   0.6369746327400208,\n",
       "   0.6127645969390869,\n",
       "   0.6686080694198608,\n",
       "   0.5506506562232971,\n",
       "   0.5818412899971008,\n",
       "   0.6938936710357666,\n",
       "   0.480776309967041,\n",
       "   0.5735704898834229,\n",
       "   0.5930359363555908,\n",
       "   0.5224241614341736,\n",
       "   0.5807451009750366,\n",
       "   0.6114427447319031,\n",
       "   0.49355435371398926,\n",
       "   0.5601224303245544,\n",
       "   0.5323259830474854,\n",
       "   0.48562100529670715,\n",
       "   0.5051363110542297,\n",
       "   0.6278603672981262,\n",
       "   0.5256880521774292,\n",
       "   0.6448877453804016,\n",
       "   0.653729259967804,\n",
       "   0.6487220525741577,\n",
       "   0.599089503288269,\n",
       "   0.5060579776763916,\n",
       "   0.5453956723213196,\n",
       "   0.6708380579948425,\n",
       "   0.5489883422851562,\n",
       "   0.44478875398635864,\n",
       "   0.4860954284667969,\n",
       "   0.5668094158172607,\n",
       "   0.6290860176086426,\n",
       "   0.5716407299041748,\n",
       "   0.6494145393371582,\n",
       "   0.5124998092651367,\n",
       "   0.5440533757209778,\n",
       "   0.628660261631012,\n",
       "   0.5853884220123291,\n",
       "   0.5842461585998535,\n",
       "   0.696997880935669,\n",
       "   0.5436139702796936,\n",
       "   0.6416164636611938,\n",
       "   0.48943400382995605,\n",
       "   0.5212766528129578,\n",
       "   0.5971424579620361,\n",
       "   0.5287212133407593,\n",
       "   0.7521462440490723,\n",
       "   0.5062980651855469,\n",
       "   0.6669806241989136,\n",
       "   0.5184491276741028,\n",
       "   0.6043781042098999,\n",
       "   0.5764718055725098,\n",
       "   0.5121375918388367,\n",
       "   0.6203361749649048,\n",
       "   0.6603326797485352,\n",
       "   0.6737402081489563,\n",
       "   0.5654956102371216,\n",
       "   0.7275364398956299,\n",
       "   0.6889554262161255,\n",
       "   0.6404222249984741,\n",
       "   0.6139734983444214,\n",
       "   0.5622258186340332,\n",
       "   0.5985174775123596,\n",
       "   0.5743157863616943,\n",
       "   0.6337206959724426,\n",
       "   0.5707646608352661,\n",
       "   0.6914693117141724,\n",
       "   0.4933033883571625,\n",
       "   0.5812274217605591,\n",
       "   0.686359167098999,\n",
       "   0.5839149355888367,\n",
       "   0.7086146473884583,\n",
       "   0.5214626789093018,\n",
       "   0.5738964080810547,\n",
       "   0.5733071565628052,\n",
       "   0.6824113130569458,\n",
       "   0.6650290489196777,\n",
       "   0.5604748129844666,\n",
       "   0.5524035096168518,\n",
       "   0.601077139377594,\n",
       "   0.7575875520706177,\n",
       "   0.5196816921234131,\n",
       "   0.6564303040504456,\n",
       "   0.620853841304779,\n",
       "   0.6380971670150757,\n",
       "   0.5501524209976196,\n",
       "   0.6374304294586182,\n",
       "   0.4807080328464508,\n",
       "   0.6223421096801758,\n",
       "   0.556598424911499,\n",
       "   0.6448572278022766,\n",
       "   0.5696027278900146,\n",
       "   0.47742509841918945,\n",
       "   0.6298346519470215,\n",
       "   0.5978870987892151,\n",
       "   0.5362453460693359,\n",
       "   0.5242255926132202,\n",
       "   0.5844287872314453,\n",
       "   0.7252493500709534,\n",
       "   0.4897022247314453,\n",
       "   0.5314845442771912,\n",
       "   0.5420302152633667,\n",
       "   0.6813545227050781,\n",
       "   0.6353013515472412,\n",
       "   0.5469757318496704,\n",
       "   0.6503656506538391,\n",
       "   0.4550419747829437,\n",
       "   0.6164662837982178,\n",
       "   0.5983145833015442,\n",
       "   0.6434769630432129,\n",
       "   0.6911328434944153,\n",
       "   0.6340720057487488,\n",
       "   0.5633013844490051,\n",
       "   0.6716267466545105,\n",
       "   0.6829416751861572,\n",
       "   0.6803615689277649,\n",
       "   0.6409283876419067,\n",
       "   0.6115015745162964,\n",
       "   0.5224388837814331,\n",
       "   0.587572455406189,\n",
       "   0.5304350852966309,\n",
       "   0.5871081948280334,\n",
       "   0.6358036398887634,\n",
       "   0.597219705581665,\n",
       "   0.6336891055107117,\n",
       "   0.5349311828613281],\n",
       "  [0.5798963308334351,\n",
       "   0.6146315336227417,\n",
       "   0.5808148384094238,\n",
       "   0.6093650460243225,\n",
       "   0.45034945011138916,\n",
       "   0.526883065700531,\n",
       "   0.6717841029167175,\n",
       "   0.6297036409378052,\n",
       "   0.6234345436096191,\n",
       "   0.5584092140197754,\n",
       "   0.5742809772491455,\n",
       "   0.47532790899276733,\n",
       "   0.5285857915878296,\n",
       "   0.6276850700378418,\n",
       "   0.7915065288543701,\n",
       "   0.5681247711181641,\n",
       "   0.4636157155036926,\n",
       "   0.5941051244735718,\n",
       "   0.5648685693740845,\n",
       "   0.5933431386947632,\n",
       "   0.5162249803543091,\n",
       "   0.6397745013237,\n",
       "   0.5744850039482117,\n",
       "   0.647874653339386,\n",
       "   0.5431534647941589,\n",
       "   0.5806107521057129,\n",
       "   0.562956690788269,\n",
       "   0.6273706555366516,\n",
       "   0.6064774990081787,\n",
       "   0.6084918975830078,\n",
       "   0.5972923040390015,\n",
       "   0.5658854842185974,\n",
       "   0.7346169948577881,\n",
       "   0.6725649833679199,\n",
       "   0.6260170936584473,\n",
       "   0.5864661931991577,\n",
       "   0.6666984558105469,\n",
       "   0.5538033246994019,\n",
       "   0.48466163873672485,\n",
       "   0.4804087281227112,\n",
       "   0.6606189608573914,\n",
       "   0.5118159055709839,\n",
       "   0.5517382621765137,\n",
       "   0.5064483880996704,\n",
       "   0.5870678424835205,\n",
       "   0.7314760684967041,\n",
       "   0.5747907161712646,\n",
       "   0.5927103161811829,\n",
       "   0.5062475800514221,\n",
       "   0.621732234954834,\n",
       "   0.6179280281066895,\n",
       "   0.6236997246742249,\n",
       "   0.6626936197280884,\n",
       "   0.4757996201515198,\n",
       "   0.6285041570663452,\n",
       "   0.5757063627243042,\n",
       "   0.83957439661026,\n",
       "   0.4913245439529419,\n",
       "   0.6930464506149292,\n",
       "   0.6192096471786499,\n",
       "   0.6366431713104248,\n",
       "   0.5738596320152283,\n",
       "   0.5389034748077393,\n",
       "   0.6410404443740845,\n",
       "   0.5031038522720337,\n",
       "   0.6302852630615234,\n",
       "   0.5137361288070679,\n",
       "   0.6709842085838318,\n",
       "   0.4510148763656616,\n",
       "   0.5752642154693604,\n",
       "   0.542127251625061,\n",
       "   0.7416658401489258,\n",
       "   0.5869589447975159,\n",
       "   0.6832908391952515,\n",
       "   0.5798734426498413,\n",
       "   0.608607292175293,\n",
       "   0.6909075975418091,\n",
       "   0.5211172103881836,\n",
       "   0.5984934568405151,\n",
       "   0.600506067276001,\n",
       "   0.5875265598297119,\n",
       "   0.5433764457702637,\n",
       "   0.5728293657302856,\n",
       "   0.7585471868515015,\n",
       "   0.5965712070465088,\n",
       "   0.5986601114273071,\n",
       "   0.6148408651351929,\n",
       "   0.552129864692688,\n",
       "   0.5310587882995605,\n",
       "   0.5302724838256836,\n",
       "   0.5698591470718384,\n",
       "   0.5387580394744873,\n",
       "   0.7549518346786499,\n",
       "   0.632043719291687,\n",
       "   0.6065958738327026,\n",
       "   0.587370753288269,\n",
       "   0.6048113107681274,\n",
       "   0.5747551918029785,\n",
       "   0.6458872556686401,\n",
       "   0.5804933905601501,\n",
       "   0.5718974471092224,\n",
       "   0.539384126663208,\n",
       "   0.5586428642272949,\n",
       "   0.613174557685852,\n",
       "   0.6666117310523987,\n",
       "   0.5827575922012329,\n",
       "   0.6533209681510925,\n",
       "   0.58255934715271,\n",
       "   0.6813024282455444,\n",
       "   0.5605242252349854,\n",
       "   0.5770602226257324,\n",
       "   0.5348148941993713,\n",
       "   0.5880391001701355,\n",
       "   0.5854496955871582,\n",
       "   0.49912258982658386,\n",
       "   0.5210724472999573,\n",
       "   0.5760473012924194,\n",
       "   0.5918785333633423,\n",
       "   0.47546422481536865,\n",
       "   0.5897403955459595,\n",
       "   0.6668103933334351,\n",
       "   0.5291633605957031,\n",
       "   0.6313779950141907,\n",
       "   0.5700218081474304,\n",
       "   0.5641236305236816,\n",
       "   0.5494810342788696,\n",
       "   0.5312343835830688,\n",
       "   0.6292701959609985,\n",
       "   0.5484106540679932,\n",
       "   0.4692501127719879,\n",
       "   0.6037840843200684,\n",
       "   0.6112980842590332,\n",
       "   0.4453069269657135],\n",
       "  [0.6194100379943848,\n",
       "   0.5206631422042847,\n",
       "   0.5170214176177979,\n",
       "   0.5217189788818359,\n",
       "   0.542462170124054,\n",
       "   0.55143803358078,\n",
       "   0.5933014154434204,\n",
       "   0.4590144753456116,\n",
       "   0.6566874384880066,\n",
       "   0.5213022232055664,\n",
       "   0.5926287174224854,\n",
       "   0.6467152833938599,\n",
       "   0.4916854798793793,\n",
       "   0.7004031538963318,\n",
       "   0.643362283706665,\n",
       "   0.46564942598342896,\n",
       "   0.5377367734909058,\n",
       "   0.46362176537513733,\n",
       "   0.5991598963737488,\n",
       "   0.4422685205936432,\n",
       "   0.47567570209503174,\n",
       "   0.6347821354866028,\n",
       "   0.5810002684593201,\n",
       "   0.589417576789856,\n",
       "   0.5848302245140076,\n",
       "   0.6714705228805542,\n",
       "   0.6477035284042358,\n",
       "   0.5184625387191772,\n",
       "   0.7140498161315918,\n",
       "   0.5743319392204285,\n",
       "   0.554641842842102,\n",
       "   0.5688254237174988,\n",
       "   0.6308286190032959,\n",
       "   0.5877922773361206,\n",
       "   0.6253530979156494,\n",
       "   0.496613085269928,\n",
       "   0.5553441047668457,\n",
       "   0.6425426602363586,\n",
       "   0.5970648527145386,\n",
       "   0.5721573233604431,\n",
       "   0.6760219931602478,\n",
       "   0.7197184562683105,\n",
       "   0.548172116279602,\n",
       "   0.5529732704162598,\n",
       "   0.5445553064346313,\n",
       "   0.5973072648048401,\n",
       "   0.5652686953544617,\n",
       "   0.6802844405174255,\n",
       "   0.5510685443878174,\n",
       "   0.5379549264907837,\n",
       "   0.5966736078262329,\n",
       "   0.5925308465957642,\n",
       "   0.6112951636314392,\n",
       "   0.5946423411369324,\n",
       "   0.5202053785324097,\n",
       "   0.5486384630203247,\n",
       "   0.6030710935592651,\n",
       "   0.6019376516342163,\n",
       "   0.5544365644454956,\n",
       "   0.6038349270820618,\n",
       "   0.5911418795585632,\n",
       "   0.5501660704612732,\n",
       "   0.6216650009155273,\n",
       "   0.6019899249076843,\n",
       "   0.5666664242744446,\n",
       "   0.4823753535747528,\n",
       "   0.46690696477890015,\n",
       "   0.530845582485199,\n",
       "   0.6178180575370789,\n",
       "   0.5576261878013611,\n",
       "   0.6616816520690918,\n",
       "   0.5277279019355774,\n",
       "   0.5495506525039673,\n",
       "   0.5390485525131226,\n",
       "   0.530983567237854,\n",
       "   0.6173142194747925,\n",
       "   0.5899773836135864,\n",
       "   0.5650059580802917,\n",
       "   0.5443620085716248,\n",
       "   0.5499061346054077,\n",
       "   0.631058394908905,\n",
       "   0.5550034046173096,\n",
       "   0.519184410572052,\n",
       "   0.5043131113052368,\n",
       "   0.6362717151641846,\n",
       "   0.5560839176177979,\n",
       "   0.630509614944458,\n",
       "   0.5322451591491699,\n",
       "   0.5170506238937378,\n",
       "   0.6182242631912231,\n",
       "   0.6022453308105469,\n",
       "   0.5064293146133423,\n",
       "   0.5348166227340698,\n",
       "   0.6672791242599487,\n",
       "   0.6474339962005615,\n",
       "   0.675132155418396,\n",
       "   0.4694384038448334,\n",
       "   0.5822371244430542,\n",
       "   0.5913222432136536,\n",
       "   0.7464274764060974,\n",
       "   0.6605945825576782,\n",
       "   0.5464382767677307,\n",
       "   0.5128731727600098,\n",
       "   0.5280134081840515,\n",
       "   0.7180554270744324,\n",
       "   0.550696074962616,\n",
       "   0.655084490776062,\n",
       "   0.7031835913658142,\n",
       "   0.6548129320144653,\n",
       "   0.5502352714538574,\n",
       "   0.5985331535339355,\n",
       "   0.5313570499420166,\n",
       "   0.5573472380638123,\n",
       "   0.5473899245262146,\n",
       "   0.5416223406791687,\n",
       "   0.5817239284515381,\n",
       "   0.6954628229141235,\n",
       "   0.631195604801178,\n",
       "   0.5924047231674194,\n",
       "   0.5471582412719727,\n",
       "   0.5817261934280396,\n",
       "   0.5402820110321045,\n",
       "   0.567552924156189,\n",
       "   0.6143559813499451,\n",
       "   0.5967940092086792,\n",
       "   0.5213598012924194,\n",
       "   0.7085162401199341,\n",
       "   0.5295827984809875,\n",
       "   0.7332788705825806,\n",
       "   0.5995239019393921,\n",
       "   0.5569930076599121,\n",
       "   0.6532697677612305,\n",
       "   0.6132400631904602],\n",
       "  [0.4932829737663269,\n",
       "   0.5840702652931213,\n",
       "   0.575192391872406,\n",
       "   0.6260576248168945,\n",
       "   0.46975064277648926,\n",
       "   0.648268461227417,\n",
       "   0.6619104146957397,\n",
       "   0.6085255146026611,\n",
       "   0.45098423957824707,\n",
       "   0.6003069877624512,\n",
       "   0.559496283531189,\n",
       "   0.5289490818977356,\n",
       "   0.5126293897628784,\n",
       "   0.6589913368225098,\n",
       "   0.6487675905227661,\n",
       "   0.6062071323394775,\n",
       "   0.7913985848426819,\n",
       "   0.5598587393760681,\n",
       "   0.6348146200180054,\n",
       "   0.6196973323822021,\n",
       "   0.570130467414856,\n",
       "   0.5375525951385498,\n",
       "   0.562915563583374,\n",
       "   0.513310968875885,\n",
       "   0.6677793860435486,\n",
       "   0.5469796657562256,\n",
       "   0.6670247316360474,\n",
       "   0.48912009596824646,\n",
       "   0.6702572703361511,\n",
       "   0.5714074373245239,\n",
       "   0.5107865929603577,\n",
       "   0.6302444338798523,\n",
       "   0.5745645761489868,\n",
       "   0.5602004528045654,\n",
       "   0.6003106832504272,\n",
       "   0.6374982595443726,\n",
       "   0.5934789180755615,\n",
       "   0.5610191822052002,\n",
       "   0.6179298758506775,\n",
       "   0.7401832342147827,\n",
       "   0.6304737329483032,\n",
       "   0.7159874439239502,\n",
       "   0.5195508003234863,\n",
       "   0.6599409580230713,\n",
       "   0.589984655380249,\n",
       "   0.612320601940155,\n",
       "   0.6445359587669373,\n",
       "   0.5416089296340942,\n",
       "   0.7622243762016296,\n",
       "   0.6501041650772095,\n",
       "   0.6801317930221558,\n",
       "   0.5045784711837769,\n",
       "   0.5515936017036438,\n",
       "   0.5493710041046143,\n",
       "   0.574838399887085,\n",
       "   0.5961498022079468,\n",
       "   0.5700209140777588,\n",
       "   0.5290079116821289,\n",
       "   0.5393487215042114,\n",
       "   0.6905971765518188,\n",
       "   0.5638808012008667,\n",
       "   0.5490871071815491,\n",
       "   0.5706263780593872,\n",
       "   0.5154662132263184,\n",
       "   0.4793713688850403,\n",
       "   0.5729696750640869,\n",
       "   0.6043322086334229,\n",
       "   0.6527180671691895,\n",
       "   0.6142935156822205,\n",
       "   0.520383358001709,\n",
       "   0.47139889001846313,\n",
       "   0.6741353273391724,\n",
       "   0.5017126798629761,\n",
       "   0.6417303085327148,\n",
       "   0.7042566537857056,\n",
       "   0.48862239718437195,\n",
       "   0.6233167052268982,\n",
       "   0.5932776927947998,\n",
       "   0.6624647974967957,\n",
       "   0.4869379997253418,\n",
       "   0.5234487652778625,\n",
       "   0.675348162651062,\n",
       "   0.4479827284812927,\n",
       "   0.542339563369751,\n",
       "   0.5842255353927612,\n",
       "   0.5132908821105957,\n",
       "   0.5509912371635437,\n",
       "   0.4972131848335266,\n",
       "   0.49477964639663696,\n",
       "   0.5505495071411133,\n",
       "   0.6038559675216675,\n",
       "   0.7779361605644226,\n",
       "   0.6209069490432739,\n",
       "   0.6647154092788696,\n",
       "   0.6033512949943542,\n",
       "   0.5077809691429138,\n",
       "   0.5005394220352173,\n",
       "   0.5983878374099731,\n",
       "   0.6103745698928833,\n",
       "   0.5907005071640015,\n",
       "   0.5888606309890747,\n",
       "   0.5130747556686401,\n",
       "   0.6124244928359985,\n",
       "   0.5536897778511047,\n",
       "   0.5952909588813782,\n",
       "   0.5610542297363281,\n",
       "   0.6786729097366333,\n",
       "   0.44406723976135254,\n",
       "   0.5132455825805664,\n",
       "   0.5505073070526123,\n",
       "   0.6071093082427979,\n",
       "   0.5585039854049683,\n",
       "   0.6232024431228638,\n",
       "   0.48767316341400146,\n",
       "   0.6791980266571045,\n",
       "   0.5215528011322021,\n",
       "   0.631659209728241,\n",
       "   0.5246923565864563,\n",
       "   0.7167707085609436,\n",
       "   0.5453178286552429,\n",
       "   0.5470360517501831,\n",
       "   0.524364173412323,\n",
       "   0.5466784834861755,\n",
       "   0.5195481777191162,\n",
       "   0.5501466989517212,\n",
       "   0.5590959787368774,\n",
       "   0.6190645098686218,\n",
       "   0.6594910621643066,\n",
       "   0.5438387989997864,\n",
       "   0.5127086639404297,\n",
       "   0.6545010805130005,\n",
       "   0.6225818395614624,\n",
       "   0.6327959299087524],\n",
       "  [0.6860249638557434,\n",
       "   0.5623663067817688,\n",
       "   0.42978695034980774,\n",
       "   0.524658203125,\n",
       "   0.4575881361961365,\n",
       "   0.6212899684906006,\n",
       "   0.6348121762275696,\n",
       "   0.6119237542152405,\n",
       "   0.5330982208251953,\n",
       "   0.6206655502319336,\n",
       "   0.5641661882400513,\n",
       "   0.5782198309898376,\n",
       "   0.6506508588790894,\n",
       "   0.5368191599845886,\n",
       "   0.6062976717948914,\n",
       "   0.571394681930542,\n",
       "   0.49765250086784363,\n",
       "   0.63246089220047,\n",
       "   0.5588934421539307,\n",
       "   0.6486968398094177,\n",
       "   0.6624517440795898,\n",
       "   0.5829801559448242,\n",
       "   0.5535436868667603,\n",
       "   0.5857990980148315,\n",
       "   0.5959899425506592,\n",
       "   0.6698893904685974,\n",
       "   0.6752426624298096,\n",
       "   0.6422528028488159,\n",
       "   0.6616194248199463,\n",
       "   0.6895742416381836,\n",
       "   0.6370484828948975,\n",
       "   0.6581579446792603,\n",
       "   0.5828123092651367,\n",
       "   0.6142192482948303,\n",
       "   0.5564333200454712,\n",
       "   0.580685555934906,\n",
       "   0.587267279624939,\n",
       "   0.5002365708351135,\n",
       "   0.6034279465675354,\n",
       "   0.6617607474327087,\n",
       "   0.5402275323867798,\n",
       "   0.5535449981689453,\n",
       "   0.5243848562240601,\n",
       "   0.5485578775405884,\n",
       "   0.6562238335609436,\n",
       "   0.5340157747268677,\n",
       "   0.6351515054702759,\n",
       "   0.563175618648529,\n",
       "   0.5933202505111694,\n",
       "   0.5446791648864746,\n",
       "   0.5182884335517883,\n",
       "   0.6051450967788696,\n",
       "   0.49995407462120056,\n",
       "   0.6754184365272522,\n",
       "   0.6631296873092651,\n",
       "   0.5933163166046143,\n",
       "   0.5888793468475342,\n",
       "   0.695683479309082,\n",
       "   0.5482618808746338,\n",
       "   0.5060702562332153,\n",
       "   0.6375941038131714,\n",
       "   0.5691044330596924,\n",
       "   0.6100943088531494,\n",
       "   0.5199707746505737,\n",
       "   0.5478589534759521,\n",
       "   0.5374497771263123,\n",
       "   0.5662385821342468,\n",
       "   0.5543993711471558,\n",
       "   0.5462392568588257,\n",
       "   0.6636518239974976,\n",
       "   0.5450627207756042,\n",
       "   0.49451324343681335,\n",
       "   0.5974820852279663,\n",
       "   0.580644965171814,\n",
       "   0.6600490212440491,\n",
       "   0.5315726399421692,\n",
       "   0.6027706265449524,\n",
       "   0.6536853313446045,\n",
       "   0.5511824488639832,\n",
       "   0.6177517771720886,\n",
       "   0.523714005947113,\n",
       "   0.589006781578064,\n",
       "   0.5332356691360474,\n",
       "   0.6312726736068726,\n",
       "   0.5597855448722839,\n",
       "   0.5831136703491211,\n",
       "   0.5472978949546814,\n",
       "   0.4857385754585266,\n",
       "   0.4843500554561615,\n",
       "   0.5802415609359741,\n",
       "   0.6555755138397217,\n",
       "   0.5544782280921936,\n",
       "   0.5770396590232849,\n",
       "   0.5512430667877197,\n",
       "   0.5896080732345581,\n",
       "   0.5626492500305176,\n",
       "   0.5525820255279541,\n",
       "   0.6014755368232727,\n",
       "   0.5068800449371338,\n",
       "   0.5873017311096191,\n",
       "   0.49821555614471436,\n",
       "   0.5932745337486267,\n",
       "   0.6491065621376038,\n",
       "   0.7672057747840881,\n",
       "   0.6048693060874939,\n",
       "   0.5806227922439575,\n",
       "   0.5607985258102417,\n",
       "   0.5837435722351074,\n",
       "   0.5240157842636108,\n",
       "   0.668462336063385,\n",
       "   0.5851988196372986,\n",
       "   0.6485133171081543,\n",
       "   0.5795964002609253,\n",
       "   0.5547391176223755,\n",
       "   0.495386004447937,\n",
       "   0.5170433521270752,\n",
       "   0.587182879447937,\n",
       "   0.6410467028617859,\n",
       "   0.4620838165283203,\n",
       "   0.6386603713035583,\n",
       "   0.5771099925041199,\n",
       "   0.639674961566925,\n",
       "   0.5624825954437256,\n",
       "   0.6169479489326477,\n",
       "   0.5766050219535828,\n",
       "   0.6496801376342773,\n",
       "   0.6490734815597534,\n",
       "   0.5738481283187866,\n",
       "   0.563921332359314,\n",
       "   0.6709179282188416,\n",
       "   0.5209625959396362,\n",
       "   0.5568892955780029,\n",
       "   0.7523564696311951],\n",
       "  [0.6428793668746948,\n",
       "   0.5429574847221375,\n",
       "   0.5064772367477417,\n",
       "   0.5945634245872498,\n",
       "   0.6338112354278564,\n",
       "   0.46199458837509155,\n",
       "   0.6352444887161255,\n",
       "   0.5037558674812317,\n",
       "   0.45131435990333557,\n",
       "   0.5591540336608887,\n",
       "   0.5793982148170471,\n",
       "   0.48009422421455383,\n",
       "   0.5718140006065369,\n",
       "   0.6521458625793457,\n",
       "   0.5196704268455505,\n",
       "   0.45477187633514404,\n",
       "   0.6600760221481323,\n",
       "   0.500164806842804,\n",
       "   0.5563697814941406,\n",
       "   0.5535726547241211,\n",
       "   0.5372835397720337,\n",
       "   0.557252049446106,\n",
       "   0.6445620059967041,\n",
       "   0.63639235496521,\n",
       "   0.5621356964111328,\n",
       "   0.5305178165435791,\n",
       "   0.6528079509735107,\n",
       "   0.6168192028999329,\n",
       "   0.5380153656005859,\n",
       "   0.49470704793930054,\n",
       "   0.7528097629547119,\n",
       "   0.5034498572349548,\n",
       "   0.5846089720726013,\n",
       "   0.6315834522247314,\n",
       "   0.6233236789703369,\n",
       "   0.5708521604537964,\n",
       "   0.6597082018852234,\n",
       "   0.6112770438194275,\n",
       "   0.6004166007041931,\n",
       "   0.5864350199699402,\n",
       "   0.8132262825965881,\n",
       "   0.5489022731781006,\n",
       "   0.7680750489234924,\n",
       "   0.5952333807945251,\n",
       "   0.5315382480621338,\n",
       "   0.5704820156097412,\n",
       "   0.4527435898780823,\n",
       "   0.6709071397781372,\n",
       "   0.6526616215705872,\n",
       "   0.4673702120780945,\n",
       "   0.5300620794296265,\n",
       "   0.5972163677215576,\n",
       "   0.5977286100387573,\n",
       "   0.7050047516822815,\n",
       "   0.6589453220367432,\n",
       "   0.6782793998718262,\n",
       "   0.541734516620636,\n",
       "   0.5163233280181885,\n",
       "   0.7330905199050903,\n",
       "   0.6399074792861938,\n",
       "   0.5144286751747131,\n",
       "   0.4639360308647156,\n",
       "   0.5759935975074768,\n",
       "   0.6308341026306152,\n",
       "   0.6928936243057251,\n",
       "   0.6554814577102661,\n",
       "   0.5180980563163757,\n",
       "   0.552420437335968,\n",
       "   0.5819976925849915,\n",
       "   0.6432192325592041,\n",
       "   0.5984162092208862,\n",
       "   0.6447694301605225,\n",
       "   0.5286426544189453,\n",
       "   0.6412019729614258,\n",
       "   0.5215866565704346,\n",
       "   0.5307698845863342,\n",
       "   0.5881166458129883,\n",
       "   0.569015383720398,\n",
       "   0.5803409814834595,\n",
       "   0.5955405831336975,\n",
       "   0.5339584350585938,\n",
       "   0.5297880172729492,\n",
       "   0.5703412294387817,\n",
       "   0.5811485052108765,\n",
       "   0.5696200132369995,\n",
       "   0.5759961605072021,\n",
       "   0.5714386701583862,\n",
       "   0.5274720191955566,\n",
       "   0.6722626686096191,\n",
       "   0.632117509841919,\n",
       "   0.548433780670166,\n",
       "   0.5945973992347717,\n",
       "   0.5108900666236877,\n",
       "   0.6311158537864685,\n",
       "   0.6516029834747314,\n",
       "   0.5681255459785461,\n",
       "   0.577101469039917,\n",
       "   0.689232349395752,\n",
       "   0.5923020839691162,\n",
       "   0.540631115436554,\n",
       "   0.6114094257354736,\n",
       "   0.6666256785392761,\n",
       "   0.5297999978065491,\n",
       "   0.48468855023384094,\n",
       "   0.45932579040527344,\n",
       "   0.7428011894226074,\n",
       "   0.568459689617157,\n",
       "   0.5750498175621033,\n",
       "   0.6159559488296509,\n",
       "   0.598922610282898,\n",
       "   0.5541679859161377,\n",
       "   0.4214048385620117,\n",
       "   0.5850688219070435,\n",
       "   0.5521789789199829,\n",
       "   0.5675662159919739,\n",
       "   0.5754038691520691,\n",
       "   0.5494006276130676,\n",
       "   0.5361486673355103,\n",
       "   0.5769535303115845,\n",
       "   0.5460360646247864,\n",
       "   0.5526351928710938,\n",
       "   0.5949407815933228,\n",
       "   0.6286009550094604,\n",
       "   0.6221910715103149,\n",
       "   0.535175085067749,\n",
       "   0.5349917411804199,\n",
       "   0.5848667025566101,\n",
       "   0.5857495069503784,\n",
       "   0.5552599430084229,\n",
       "   0.5859524011611938,\n",
       "   0.575114369392395,\n",
       "   0.5632593631744385,\n",
       "   0.6614670753479004],\n",
       "  [0.6332324743270874,\n",
       "   0.5302255153656006,\n",
       "   0.6089135408401489,\n",
       "   0.5351195335388184,\n",
       "   0.5139493942260742,\n",
       "   0.6557375192642212,\n",
       "   0.5175144672393799,\n",
       "   0.6052391529083252,\n",
       "   0.5378425121307373,\n",
       "   0.6631903648376465,\n",
       "   0.6477878093719482,\n",
       "   0.5030567646026611,\n",
       "   0.5811980366706848,\n",
       "   0.46190014481544495,\n",
       "   0.5474720597267151,\n",
       "   0.5852584838867188,\n",
       "   0.7053146958351135,\n",
       "   0.5483951568603516,\n",
       "   0.48077884316444397,\n",
       "   0.5707942247390747,\n",
       "   0.6236155033111572,\n",
       "   0.4694492816925049,\n",
       "   0.5769644975662231,\n",
       "   0.6245276927947998,\n",
       "   0.5884673595428467,\n",
       "   0.5522768497467041,\n",
       "   0.6044999957084656,\n",
       "   0.5253081917762756,\n",
       "   0.585773229598999,\n",
       "   0.6313132047653198,\n",
       "   0.6338518857955933,\n",
       "   0.5241321921348572,\n",
       "   0.5986089110374451,\n",
       "   0.5840020179748535,\n",
       "   0.5471228957176208,\n",
       "   0.4716276228427887,\n",
       "   0.6119117736816406,\n",
       "   0.6228776574134827,\n",
       "   0.554111123085022,\n",
       "   0.4764293432235718,\n",
       "   0.5955884456634521,\n",
       "   0.5159229636192322,\n",
       "   0.5589407682418823,\n",
       "   0.6056987047195435,\n",
       "   0.6081583499908447,\n",
       "   0.5270667672157288,\n",
       "   0.5996590852737427,\n",
       "   0.6797715425491333,\n",
       "   0.6525275111198425,\n",
       "   0.5752229690551758,\n",
       "   0.5275493860244751,\n",
       "   0.41988080739974976,\n",
       "   0.6695210337638855,\n",
       "   0.7010992169380188,\n",
       "   0.6179009675979614,\n",
       "   0.5090128183364868,\n",
       "   0.5778363347053528,\n",
       "   0.5584816932678223,\n",
       "   0.5702537894248962,\n",
       "   0.5979646444320679,\n",
       "   0.5330474972724915,\n",
       "   0.6253341436386108,\n",
       "   0.5633131265640259,\n",
       "   0.6378488540649414,\n",
       "   0.536592423915863,\n",
       "   0.5830288529396057,\n",
       "   0.7048959732055664,\n",
       "   0.5531198382377625,\n",
       "   0.6450706720352173,\n",
       "   0.5208368301391602,\n",
       "   0.5902140140533447,\n",
       "   0.591589093208313,\n",
       "   0.5631112456321716,\n",
       "   0.5902779698371887,\n",
       "   0.4916275143623352,\n",
       "   0.5884735584259033,\n",
       "   0.4808172583580017,\n",
       "   0.5144212245941162,\n",
       "   0.5828343629837036,\n",
       "   0.5952836275100708,\n",
       "   0.6086826920509338,\n",
       "   0.5440556406974792,\n",
       "   0.49751800298690796,\n",
       "   0.5477120280265808,\n",
       "   0.518362283706665,\n",
       "   0.7212905883789062,\n",
       "   0.6291025876998901,\n",
       "   0.5443376898765564,\n",
       "   0.6507396697998047,\n",
       "   0.6354761123657227,\n",
       "   0.5938924551010132,\n",
       "   0.6118819713592529,\n",
       "   0.5335217714309692,\n",
       "   0.5699790120124817,\n",
       "   0.6755458116531372,\n",
       "   0.6132825613021851,\n",
       "   0.6671143770217896,\n",
       "   0.6826660633087158,\n",
       "   0.5413507223129272,\n",
       "   0.5637684464454651,\n",
       "   0.6498452425003052,\n",
       "   0.630028247833252,\n",
       "   0.5499887466430664,\n",
       "   0.5776386260986328,\n",
       "   0.5615376830101013,\n",
       "   0.5204280614852905,\n",
       "   0.5032517910003662,\n",
       "   0.5983568429946899,\n",
       "   0.6406553387641907,\n",
       "   0.5022944211959839,\n",
       "   0.7072979211807251,\n",
       "   0.5515784025192261,\n",
       "   0.6308717727661133,\n",
       "   0.6898540258407593,\n",
       "   0.5796988010406494,\n",
       "   0.5615032911300659,\n",
       "   0.5081717371940613,\n",
       "   0.5306040048599243,\n",
       "   0.494846373796463,\n",
       "   0.48186570405960083,\n",
       "   0.5480929613113403,\n",
       "   0.6827116012573242,\n",
       "   0.5105420351028442,\n",
       "   0.5172718167304993,\n",
       "   0.5777925252914429,\n",
       "   0.5655975341796875,\n",
       "   0.696765661239624,\n",
       "   0.4967668056488037,\n",
       "   0.5901455879211426,\n",
       "   0.6397918462753296,\n",
       "   0.6098307371139526,\n",
       "   0.5500850677490234,\n",
       "   0.8536059856414795],\n",
       "  [0.6192615628242493,\n",
       "   0.5974959135055542,\n",
       "   0.7440381050109863,\n",
       "   0.5676703453063965,\n",
       "   0.610273003578186,\n",
       "   0.5569329261779785,\n",
       "   0.539709210395813,\n",
       "   0.558836817741394,\n",
       "   0.544252872467041,\n",
       "   0.6078360676765442,\n",
       "   0.5447560548782349,\n",
       "   0.6578469276428223,\n",
       "   0.5825351476669312,\n",
       "   0.4956446886062622,\n",
       "   0.513684868812561,\n",
       "   0.6106201410293579,\n",
       "   0.6348971128463745,\n",
       "   0.6427401304244995,\n",
       "   0.4500282108783722,\n",
       "   0.5014275908470154,\n",
       "   0.6520416736602783,\n",
       "   0.6274460554122925,\n",
       "   0.596203088760376,\n",
       "   0.6451190710067749,\n",
       "   0.5693159103393555,\n",
       "   0.5025840997695923,\n",
       "   0.45917797088623047,\n",
       "   0.4698284864425659,\n",
       "   0.5066132545471191,\n",
       "   0.4902198314666748,\n",
       "   0.5609496831893921,\n",
       "   0.640592098236084,\n",
       "   0.611295223236084,\n",
       "   0.4252893030643463,\n",
       "   0.7083681225776672,\n",
       "   0.5445103645324707,\n",
       "   0.7126308679580688,\n",
       "   0.5530030727386475,\n",
       "   0.49836987257003784,\n",
       "   0.5923547148704529,\n",
       "   0.5429867506027222,\n",
       "   0.5797942876815796,\n",
       "   0.5721771717071533,\n",
       "   0.5980564951896667,\n",
       "   0.6303392052650452,\n",
       "   0.5775905251502991,\n",
       "   0.5518107414245605,\n",
       "   0.6243166923522949,\n",
       "   0.5666108727455139,\n",
       "   0.5664083361625671,\n",
       "   0.735093355178833,\n",
       "   0.5233768224716187,\n",
       "   0.5039511322975159,\n",
       "   0.6136136054992676,\n",
       "   0.6859362721443176,\n",
       "   0.5832959413528442,\n",
       "   0.617969274520874,\n",
       "   0.5184721350669861,\n",
       "   0.5478212237358093,\n",
       "   0.5499500036239624,\n",
       "   0.6404054760932922,\n",
       "   0.574568510055542,\n",
       "   0.6928222179412842,\n",
       "   0.49877408146858215,\n",
       "   0.6210296154022217,\n",
       "   0.5255709886550903,\n",
       "   0.4904235005378723,\n",
       "   0.6063487529754639,\n",
       "   0.636878252029419,\n",
       "   0.5863345861434937,\n",
       "   0.5172456502914429,\n",
       "   0.5315154790878296,\n",
       "   0.5090763568878174,\n",
       "   0.5234453678131104,\n",
       "   0.6919951438903809,\n",
       "   0.6170291900634766,\n",
       "   0.5588416457176208,\n",
       "   0.6284836530685425,\n",
       "   0.6147669553756714,\n",
       "   0.5335904359817505,\n",
       "   0.5157720446586609,\n",
       "   0.5539671778678894,\n",
       "   0.5228402018547058,\n",
       "   0.5801728367805481,\n",
       "   0.5284532308578491,\n",
       "   0.5450522303581238,\n",
       "   0.6047149896621704,\n",
       "   0.4229169189929962,\n",
       "   0.6143953800201416,\n",
       "   0.7205959558486938,\n",
       "   0.6485843062400818,\n",
       "   0.5176504254341125,\n",
       "   0.6188904047012329,\n",
       "   0.499332994222641,\n",
       "   0.6489474773406982,\n",
       "   0.6571994423866272,\n",
       "   0.5716211795806885,\n",
       "   0.5918353199958801,\n",
       "   0.6570323705673218,\n",
       "   0.6283028721809387,\n",
       "   0.6215523481369019,\n",
       "   0.6349610090255737,\n",
       "   0.5543346405029297,\n",
       "   0.79273521900177,\n",
       "   0.6567151546478271,\n",
       "   0.6766538023948669,\n",
       "   0.7173985242843628,\n",
       "   0.48124074935913086,\n",
       "   0.5322660207748413,\n",
       "   0.5335754156112671,\n",
       "   0.6630508899688721,\n",
       "   0.7958637475967407,\n",
       "   0.6176230907440186,\n",
       "   0.5717273950576782,\n",
       "   0.5254414081573486,\n",
       "   0.6194438934326172,\n",
       "   0.591832160949707,\n",
       "   0.5682176351547241,\n",
       "   0.5573880672454834,\n",
       "   0.5073701739311218,\n",
       "   0.5273352265357971,\n",
       "   0.5106692314147949,\n",
       "   0.534832239151001,\n",
       "   0.5229599475860596,\n",
       "   0.6529072523117065,\n",
       "   0.5508776903152466,\n",
       "   0.4882220923900604,\n",
       "   0.6442616581916809,\n",
       "   0.501099169254303,\n",
       "   0.6923853158950806,\n",
       "   0.6011343002319336,\n",
       "   0.59269118309021,\n",
       "   0.5552189946174622],\n",
       "  [0.693202018737793,\n",
       "   0.5627002716064453,\n",
       "   0.4328727126121521,\n",
       "   0.5582365989685059,\n",
       "   0.6236151456832886,\n",
       "   0.5708655118942261,\n",
       "   0.5365794897079468,\n",
       "   0.6827951073646545,\n",
       "   0.6551897525787354,\n",
       "   0.5870462656021118,\n",
       "   0.5200818777084351,\n",
       "   0.5069860816001892,\n",
       "   0.5297675728797913,\n",
       "   0.5473318696022034,\n",
       "   0.5631319284439087,\n",
       "   0.6576297879219055,\n",
       "   0.5207446813583374,\n",
       "   0.4361392855644226,\n",
       "   0.6484960317611694,\n",
       "   0.6831963658332825,\n",
       "   0.6624456644058228,\n",
       "   0.5543691515922546,\n",
       "   0.6955900192260742,\n",
       "   0.4869156777858734,\n",
       "   0.5226870775222778,\n",
       "   0.6519396901130676,\n",
       "   0.6224911212921143,\n",
       "   0.6168375015258789,\n",
       "   0.5606831312179565,\n",
       "   0.612054705619812,\n",
       "   0.5562961101531982,\n",
       "   0.5468932390213013,\n",
       "   0.47515130043029785,\n",
       "   0.5745768547058105,\n",
       "   0.6174603700637817,\n",
       "   0.6481848359107971,\n",
       "   0.6339952349662781,\n",
       "   0.5798687934875488,\n",
       "   0.5594841837882996,\n",
       "   0.69229656457901,\n",
       "   0.5837574601173401,\n",
       "   0.51256263256073,\n",
       "   0.7763229012489319,\n",
       "   0.580815315246582,\n",
       "   0.6464064121246338,\n",
       "   0.46984124183654785,\n",
       "   0.5376827120780945,\n",
       "   0.5465105175971985,\n",
       "   0.5586156845092773,\n",
       "   0.5952954292297363,\n",
       "   0.5447790622711182,\n",
       "   0.5937299728393555,\n",
       "   0.5346460342407227,\n",
       "   0.5609328746795654,\n",
       "   0.5674332976341248,\n",
       "   0.782288670539856,\n",
       "   0.559887170791626,\n",
       "   0.5659390091896057,\n",
       "   0.6912046670913696,\n",
       "   0.5514876246452332,\n",
       "   0.6016696691513062,\n",
       "   0.5096623301506042,\n",
       "   0.6007046103477478,\n",
       "   0.6064820289611816,\n",
       "   0.5345081686973572,\n",
       "   0.6443435549736023,\n",
       "   0.620914101600647,\n",
       "   0.6775493621826172,\n",
       "   0.6096029281616211,\n",
       "   0.5903365015983582,\n",
       "   0.579315721988678,\n",
       "   0.5975905656814575,\n",
       "   0.47155362367630005,\n",
       "   0.49266916513442993,\n",
       "   0.7328915596008301,\n",
       "   0.6871792078018188,\n",
       "   0.5939285159111023,\n",
       "   0.5700815916061401,\n",
       "   0.483265221118927,\n",
       "   0.7141485810279846,\n",
       "   0.5086370706558228,\n",
       "   0.5736422538757324,\n",
       "   0.5241745114326477,\n",
       "   0.5624054670333862,\n",
       "   0.6181690692901611,\n",
       "   0.6468527317047119,\n",
       "   0.6458148956298828,\n",
       "   0.5173015594482422,\n",
       "   0.6046698689460754,\n",
       "   0.6255149245262146,\n",
       "   0.5321588516235352,\n",
       "   0.609993040561676,\n",
       "   0.5887032747268677,\n",
       "   0.5432014465332031,\n",
       "   0.588895857334137,\n",
       "   0.517959475517273,\n",
       "   0.5619871616363525,\n",
       "   0.5555341243743896,\n",
       "   0.4507497549057007,\n",
       "   0.6491076946258545,\n",
       "   0.5223566293716431,\n",
       "   0.5450950860977173,\n",
       "   0.5033092498779297,\n",
       "   0.562074601650238,\n",
       "   0.587356686592102,\n",
       "   0.5321094989776611,\n",
       "   0.5585295557975769,\n",
       "   0.6511616706848145,\n",
       "   0.520528256893158,\n",
       "   0.6840764284133911,\n",
       "   0.5468857288360596,\n",
       "   0.6267306804656982,\n",
       "   0.6069798469543457,\n",
       "   0.5106366872787476,\n",
       "   0.669584333896637,\n",
       "   0.5921797752380371,\n",
       "   0.4840400218963623,\n",
       "   0.5340970754623413,\n",
       "   0.4707333445549011,\n",
       "   0.6141887903213501,\n",
       "   0.5470650792121887,\n",
       "   0.4731387495994568,\n",
       "   0.6984431743621826,\n",
       "   0.5597320199012756,\n",
       "   0.680568516254425,\n",
       "   0.5414303541183472,\n",
       "   0.5511504411697388,\n",
       "   0.5428831577301025,\n",
       "   0.46124833822250366,\n",
       "   0.5795297026634216,\n",
       "   0.5666025876998901,\n",
       "   0.5131896734237671,\n",
       "   0.75996333360672],\n",
       "  [0.576003909111023,\n",
       "   0.594465970993042,\n",
       "   0.5563793778419495,\n",
       "   0.5431537628173828,\n",
       "   0.5080239772796631,\n",
       "   0.5980409383773804,\n",
       "   0.5410396456718445,\n",
       "   0.749992311000824,\n",
       "   0.47360071539878845,\n",
       "   0.6002874374389648,\n",
       "   0.7385611534118652,\n",
       "   0.5195968151092529,\n",
       "   0.5768536329269409,\n",
       "   0.599021315574646,\n",
       "   0.6108531951904297,\n",
       "   0.5767334699630737,\n",
       "   0.5457790493965149,\n",
       "   0.5836614966392517,\n",
       "   0.6906014084815979,\n",
       "   0.5142555236816406,\n",
       "   0.506248950958252,\n",
       "   0.5536326169967651,\n",
       "   0.4702668786048889,\n",
       "   0.5367708206176758,\n",
       "   0.6082360148429871,\n",
       "   0.6799113154411316,\n",
       "   0.5738704204559326,\n",
       "   0.6256300210952759,\n",
       "   0.6356062889099121,\n",
       "   0.5492537617683411,\n",
       "   0.6816710233688354,\n",
       "   0.5312327146530151,\n",
       "   0.4841004014015198,\n",
       "   0.46023786067962646,\n",
       "   0.5691957473754883,\n",
       "   0.498542457818985,\n",
       "   0.5703493356704712,\n",
       "   0.7644990682601929,\n",
       "   0.5879701972007751,\n",
       "   0.6704191565513611,\n",
       "   0.5663101673126221,\n",
       "   0.557466447353363,\n",
       "   0.6385790109634399,\n",
       "   0.45717012882232666,\n",
       "   0.5181465148925781,\n",
       "   0.586903989315033,\n",
       "   0.524673342704773,\n",
       "   0.7573434710502625,\n",
       "   0.568291187286377,\n",
       "   0.5845414400100708,\n",
       "   0.5258849859237671,\n",
       "   0.5131505727767944,\n",
       "   0.5295796990394592,\n",
       "   0.5477956533432007,\n",
       "   0.5032980442047119,\n",
       "   0.6402252316474915,\n",
       "   0.6279293298721313,\n",
       "   0.5455918312072754,\n",
       "   0.6865140199661255,\n",
       "   0.6590031385421753,\n",
       "   0.5875391960144043,\n",
       "   0.5719922184944153,\n",
       "   0.624142587184906,\n",
       "   0.5435742139816284,\n",
       "   0.5676542520523071,\n",
       "   0.682037353515625,\n",
       "   0.4819543659687042,\n",
       "   0.5225500464439392,\n",
       "   0.5872558355331421,\n",
       "   0.5068148374557495,\n",
       "   0.5080430507659912,\n",
       "   0.5833096504211426,\n",
       "   0.5689312219619751,\n",
       "   0.5335050821304321,\n",
       "   0.5397405624389648,\n",
       "   0.5424466133117676,\n",
       "   0.5960410833358765,\n",
       "   0.5645414590835571,\n",
       "   0.597557783126831,\n",
       "   0.6981444358825684,\n",
       "   0.5336392521858215,\n",
       "   0.6890310049057007,\n",
       "   0.5347227454185486,\n",
       "   0.4894787073135376,\n",
       "   0.6434940695762634,\n",
       "   0.5870082378387451,\n",
       "   0.5971498489379883,\n",
       "   0.6420717239379883,\n",
       "   0.6491348147392273,\n",
       "   0.5552989840507507,\n",
       "   0.5420557260513306,\n",
       "   0.6194157600402832,\n",
       "   0.614772379398346,\n",
       "   0.5300230979919434,\n",
       "   0.527026891708374,\n",
       "   0.6610268354415894,\n",
       "   0.5717067718505859,\n",
       "   0.5331023931503296,\n",
       "   0.5600794553756714,\n",
       "   0.5412527322769165,\n",
       "   0.5362077951431274,\n",
       "   0.6995539665222168,\n",
       "   0.7018136978149414,\n",
       "   0.5430324077606201,\n",
       "   0.5685238838195801,\n",
       "   0.5735811591148376,\n",
       "   0.4558838903903961,\n",
       "   0.4707188010215759,\n",
       "   0.5539143085479736,\n",
       "   0.6186140179634094,\n",
       "   0.5490114688873291,\n",
       "   0.5364464521408081,\n",
       "   0.6443058252334595,\n",
       "   0.6209036111831665,\n",
       "   0.4929042458534241,\n",
       "   0.5573937296867371,\n",
       "   0.5703245401382446,\n",
       "   0.5872377753257751,\n",
       "   0.5786522626876831,\n",
       "   0.5213873386383057,\n",
       "   0.6508151292800903,\n",
       "   0.5571385622024536,\n",
       "   0.5593016147613525,\n",
       "   0.6405797004699707,\n",
       "   0.5889713764190674,\n",
       "   0.7288342714309692,\n",
       "   0.5408488512039185,\n",
       "   0.5131475925445557,\n",
       "   0.6082741022109985,\n",
       "   0.5079481601715088,\n",
       "   0.5622251033782959,\n",
       "   0.6120026111602783,\n",
       "   0.6732152104377747]],\n",
       " 'val_losses': [[1.0344325304031372,\n",
       "   1.3304580450057983,\n",
       "   1.3316433429718018,\n",
       "   1.132706642150879,\n",
       "   1.270207166671753,\n",
       "   1.058262586593628,\n",
       "   1.2956368923187256,\n",
       "   0.9919421672821045,\n",
       "   1.249420404434204,\n",
       "   1.3022773265838623,\n",
       "   0.9983683228492737,\n",
       "   1.4120783805847168,\n",
       "   1.659024715423584,\n",
       "   1.4745986461639404,\n",
       "   1.1888670921325684,\n",
       "   1.5577049255371094,\n",
       "   1.458789587020874,\n",
       "   1.0237597227096558,\n",
       "   1.293191909790039,\n",
       "   1.5301344394683838,\n",
       "   1.167067527770996,\n",
       "   1.6461811065673828,\n",
       "   1.6969190835952759,\n",
       "   1.1660304069519043,\n",
       "   1.5104049444198608,\n",
       "   1.2023935317993164,\n",
       "   1.4172747135162354,\n",
       "   1.4598817825317383,\n",
       "   1.2022532224655151,\n",
       "   1.3179926872253418,\n",
       "   1.461890459060669,\n",
       "   1.2424412965774536,\n",
       "   1.2026499509811401,\n",
       "   1.3306617736816406,\n",
       "   1.2847235202789307,\n",
       "   0.9498664736747742,\n",
       "   1.5795626640319824,\n",
       "   1.328688144683838,\n",
       "   1.754934549331665,\n",
       "   1.129150629043579,\n",
       "   1.34218430519104,\n",
       "   1.5041254758834839,\n",
       "   1.3278515338897705,\n",
       "   1.5909106731414795],\n",
       "  [1.0456469058990479,\n",
       "   1.555894374847412,\n",
       "   1.483750581741333,\n",
       "   1.2367135286331177,\n",
       "   0.98271644115448,\n",
       "   1.463564157485962,\n",
       "   1.4715865850448608,\n",
       "   1.7582229375839233,\n",
       "   1.2584513425827026,\n",
       "   1.8027490377426147,\n",
       "   1.1558928489685059,\n",
       "   1.193203091621399,\n",
       "   1.3431789875030518,\n",
       "   1.2176899909973145,\n",
       "   1.498842477798462,\n",
       "   1.4150729179382324,\n",
       "   0.8901335000991821,\n",
       "   1.2452994585037231,\n",
       "   1.3215287923812866,\n",
       "   1.430945634841919,\n",
       "   1.319447636604309,\n",
       "   1.1533938646316528,\n",
       "   1.072107195854187,\n",
       "   1.288362979888916,\n",
       "   1.2982877492904663,\n",
       "   1.4704992771148682,\n",
       "   1.140702724456787,\n",
       "   1.3899738788604736,\n",
       "   1.340874433517456,\n",
       "   1.6788783073425293,\n",
       "   1.1774288415908813,\n",
       "   1.4596161842346191,\n",
       "   1.3273167610168457,\n",
       "   1.424598217010498,\n",
       "   1.3161684274673462,\n",
       "   1.5722322463989258,\n",
       "   0.9603735208511353,\n",
       "   1.5966269969940186,\n",
       "   1.4278346300125122,\n",
       "   1.4073944091796875,\n",
       "   1.0746023654937744,\n",
       "   1.3489866256713867,\n",
       "   1.3281350135803223,\n",
       "   0.78829026222229],\n",
       "  [1.5375990867614746,\n",
       "   1.5146009922027588,\n",
       "   1.592815637588501,\n",
       "   1.4969191551208496,\n",
       "   1.110614538192749,\n",
       "   1.5002694129943848,\n",
       "   1.1124699115753174,\n",
       "   1.4115557670593262,\n",
       "   1.2317569255828857,\n",
       "   1.5126891136169434,\n",
       "   1.4563648700714111,\n",
       "   1.4678516387939453,\n",
       "   1.2840296030044556,\n",
       "   1.0080807209014893,\n",
       "   1.0459513664245605,\n",
       "   1.4002703428268433,\n",
       "   1.4889678955078125,\n",
       "   1.1768782138824463,\n",
       "   1.5340824127197266,\n",
       "   1.3140428066253662,\n",
       "   1.409865140914917,\n",
       "   1.5965006351470947,\n",
       "   1.3811084032058716,\n",
       "   1.1359515190124512,\n",
       "   1.310589075088501,\n",
       "   1.2575933933258057,\n",
       "   1.195538878440857,\n",
       "   1.3426542282104492,\n",
       "   1.2136919498443604,\n",
       "   1.5121726989746094,\n",
       "   1.392303466796875,\n",
       "   1.1200149059295654,\n",
       "   0.9929441213607788,\n",
       "   1.654693841934204,\n",
       "   1.456913709640503,\n",
       "   1.460972785949707,\n",
       "   0.9796894192695618,\n",
       "   1.1996153593063354,\n",
       "   1.2870664596557617,\n",
       "   1.4588489532470703,\n",
       "   1.55458402633667,\n",
       "   1.7746813297271729,\n",
       "   1.604419231414795,\n",
       "   1.7529823780059814],\n",
       "  [1.4214389324188232,\n",
       "   1.4396531581878662,\n",
       "   1.2026262283325195,\n",
       "   1.6611607074737549,\n",
       "   0.8319546580314636,\n",
       "   1.1069841384887695,\n",
       "   1.1372272968292236,\n",
       "   1.4677679538726807,\n",
       "   1.3979135751724243,\n",
       "   0.948939859867096,\n",
       "   1.3720202445983887,\n",
       "   1.1128158569335938,\n",
       "   1.5247812271118164,\n",
       "   1.6905150413513184,\n",
       "   1.3232203722000122,\n",
       "   1.6878056526184082,\n",
       "   1.6075419187545776,\n",
       "   1.3202842473983765,\n",
       "   1.4861713647842407,\n",
       "   1.4435644149780273,\n",
       "   1.5298168659210205,\n",
       "   1.6965301036834717,\n",
       "   1.2013825178146362,\n",
       "   1.3567802906036377,\n",
       "   1.5044519901275635,\n",
       "   1.378598928451538,\n",
       "   1.4306683540344238,\n",
       "   1.3008744716644287,\n",
       "   1.6453542709350586,\n",
       "   1.1584264039993286,\n",
       "   1.4165549278259277,\n",
       "   1.2101547718048096,\n",
       "   0.9009091854095459,\n",
       "   1.5634379386901855,\n",
       "   1.4481146335601807,\n",
       "   1.3328864574432373,\n",
       "   1.388966679573059,\n",
       "   1.6480717658996582,\n",
       "   1.3054343461990356,\n",
       "   1.8038737773895264,\n",
       "   1.3497885465621948,\n",
       "   0.9685308337211609,\n",
       "   1.4669688940048218,\n",
       "   1.336562991142273],\n",
       "  [1.5783257484436035,\n",
       "   1.3362712860107422,\n",
       "   1.6488316059112549,\n",
       "   1.60036301612854,\n",
       "   1.3408887386322021,\n",
       "   1.2698379755020142,\n",
       "   1.212522029876709,\n",
       "   1.3927834033966064,\n",
       "   1.6148626804351807,\n",
       "   1.5507655143737793,\n",
       "   1.2107515335083008,\n",
       "   1.4159399271011353,\n",
       "   1.3794596195220947,\n",
       "   1.2045924663543701,\n",
       "   1.7901476621627808,\n",
       "   1.2903268337249756,\n",
       "   1.4633102416992188,\n",
       "   1.155676245689392,\n",
       "   1.3590550422668457,\n",
       "   1.5441944599151611,\n",
       "   1.1964075565338135,\n",
       "   1.7501925230026245,\n",
       "   1.3927230834960938,\n",
       "   1.0160505771636963,\n",
       "   1.1099302768707275,\n",
       "   1.4270468950271606,\n",
       "   1.6474826335906982,\n",
       "   1.0545337200164795,\n",
       "   1.7528748512268066,\n",
       "   1.2815189361572266,\n",
       "   1.1200729608535767,\n",
       "   1.352386713027954,\n",
       "   1.6558396816253662,\n",
       "   1.558576226234436,\n",
       "   1.3812220096588135,\n",
       "   1.280280351638794,\n",
       "   1.3834333419799805,\n",
       "   1.4804863929748535,\n",
       "   1.5133401155471802,\n",
       "   1.6736100912094116,\n",
       "   1.4532703161239624,\n",
       "   1.2828528881072998,\n",
       "   1.3028111457824707,\n",
       "   1.4300827980041504],\n",
       "  [1.0568385124206543,\n",
       "   1.7897238731384277,\n",
       "   1.0933082103729248,\n",
       "   1.3715589046478271,\n",
       "   1.5606789588928223,\n",
       "   1.7191652059555054,\n",
       "   1.4409303665161133,\n",
       "   1.3858036994934082,\n",
       "   1.828956127166748,\n",
       "   1.8929975032806396,\n",
       "   1.3590712547302246,\n",
       "   1.3614156246185303,\n",
       "   1.1679694652557373,\n",
       "   1.2694854736328125,\n",
       "   1.363463044166565,\n",
       "   1.1819477081298828,\n",
       "   1.760039210319519,\n",
       "   1.7275410890579224,\n",
       "   1.3556795120239258,\n",
       "   1.1178781986236572,\n",
       "   1.3717095851898193,\n",
       "   1.3802911043167114,\n",
       "   1.7705159187316895,\n",
       "   1.7116141319274902,\n",
       "   1.2403823137283325,\n",
       "   1.2726291418075562,\n",
       "   1.5868370532989502,\n",
       "   1.2107298374176025,\n",
       "   1.6138789653778076,\n",
       "   1.0824576616287231,\n",
       "   1.4219152927398682,\n",
       "   1.3140738010406494,\n",
       "   1.3441572189331055,\n",
       "   1.1178221702575684,\n",
       "   1.488020896911621,\n",
       "   1.647181749343872,\n",
       "   1.3532170057296753,\n",
       "   1.5073480606079102,\n",
       "   1.670314073562622,\n",
       "   1.1450495719909668,\n",
       "   1.3555364608764648,\n",
       "   1.0581896305084229,\n",
       "   1.2975976467132568,\n",
       "   0.8009389638900757],\n",
       "  [1.4138340950012207,\n",
       "   1.7255181074142456,\n",
       "   1.2211016416549683,\n",
       "   1.867048978805542,\n",
       "   1.4254975318908691,\n",
       "   1.4977383613586426,\n",
       "   1.3043019771575928,\n",
       "   1.532072901725769,\n",
       "   1.5272254943847656,\n",
       "   1.0171087980270386,\n",
       "   1.0873825550079346,\n",
       "   1.6617369651794434,\n",
       "   1.5759296417236328,\n",
       "   1.665449619293213,\n",
       "   1.8672711849212646,\n",
       "   1.3604657649993896,\n",
       "   1.225259780883789,\n",
       "   1.916728138923645,\n",
       "   1.3107414245605469,\n",
       "   1.2293076515197754,\n",
       "   1.335777759552002,\n",
       "   1.3900752067565918,\n",
       "   1.433164358139038,\n",
       "   1.611490249633789,\n",
       "   1.4774653911590576,\n",
       "   1.1558986902236938,\n",
       "   1.4301624298095703,\n",
       "   1.3314566612243652,\n",
       "   1.5498526096343994,\n",
       "   1.2132980823516846,\n",
       "   1.2603435516357422,\n",
       "   1.1388623714447021,\n",
       "   1.1994495391845703,\n",
       "   1.1359643936157227,\n",
       "   1.5434541702270508,\n",
       "   1.5792253017425537,\n",
       "   1.5591232776641846,\n",
       "   1.3972461223602295,\n",
       "   1.202880859375,\n",
       "   1.1452627182006836,\n",
       "   1.3556528091430664,\n",
       "   1.4799399375915527,\n",
       "   1.7436888217926025,\n",
       "   0.871383547782898],\n",
       "  [1.5423500537872314,\n",
       "   1.0556694269180298,\n",
       "   1.1269422769546509,\n",
       "   1.8347834348678589,\n",
       "   1.3652491569519043,\n",
       "   1.2535121440887451,\n",
       "   1.3965681791305542,\n",
       "   1.1408891677856445,\n",
       "   1.568028450012207,\n",
       "   1.598371982574463,\n",
       "   1.143691062927246,\n",
       "   1.7655693292617798,\n",
       "   1.4664709568023682,\n",
       "   1.3449702262878418,\n",
       "   1.3106982707977295,\n",
       "   1.409406065940857,\n",
       "   1.0628926753997803,\n",
       "   1.376413345336914,\n",
       "   1.5675995349884033,\n",
       "   1.1298236846923828,\n",
       "   1.3323218822479248,\n",
       "   1.2580674886703491,\n",
       "   1.8447915315628052,\n",
       "   1.6155871152877808,\n",
       "   1.221467137336731,\n",
       "   1.0635493993759155,\n",
       "   1.2880533933639526,\n",
       "   1.321624755859375,\n",
       "   1.5788742303848267,\n",
       "   1.7504642009735107,\n",
       "   1.6670273542404175,\n",
       "   1.3838865756988525,\n",
       "   1.8579180240631104,\n",
       "   1.6723031997680664,\n",
       "   1.5679395198822021,\n",
       "   1.7588773965835571,\n",
       "   1.5834074020385742,\n",
       "   1.435725212097168,\n",
       "   1.0030617713928223,\n",
       "   1.719512701034546,\n",
       "   1.413163423538208,\n",
       "   1.566912293434143,\n",
       "   1.3764595985412598,\n",
       "   2.2560830116271973],\n",
       "  [1.3736991882324219,\n",
       "   1.4710267782211304,\n",
       "   1.490366816520691,\n",
       "   1.5771093368530273,\n",
       "   1.2742273807525635,\n",
       "   1.3551356792449951,\n",
       "   1.2330551147460938,\n",
       "   1.997755765914917,\n",
       "   1.2099266052246094,\n",
       "   1.4544492959976196,\n",
       "   1.297126293182373,\n",
       "   1.6792268753051758,\n",
       "   1.4133098125457764,\n",
       "   1.7677431106567383,\n",
       "   1.2573227882385254,\n",
       "   1.3545562028884888,\n",
       "   1.3464224338531494,\n",
       "   1.2034353017807007,\n",
       "   1.4739899635314941,\n",
       "   1.6044957637786865,\n",
       "   1.2425570487976074,\n",
       "   1.6056632995605469,\n",
       "   0.9218177795410156,\n",
       "   1.3146066665649414,\n",
       "   1.325331211090088,\n",
       "   1.2560070753097534,\n",
       "   2.1691551208496094,\n",
       "   0.925312876701355,\n",
       "   1.7707537412643433,\n",
       "   1.460623860359192,\n",
       "   1.1014260053634644,\n",
       "   1.5748791694641113,\n",
       "   1.7288565635681152,\n",
       "   1.3615992069244385,\n",
       "   1.022983431816101,\n",
       "   1.317582130432129,\n",
       "   1.4049336910247803,\n",
       "   2.0192391872406006,\n",
       "   1.9271653890609741,\n",
       "   1.0721018314361572,\n",
       "   1.372352123260498,\n",
       "   1.4184882640838623,\n",
       "   1.3725214004516602,\n",
       "   0.7344067692756653],\n",
       "  [1.932620882987976,\n",
       "   1.4174131155014038,\n",
       "   1.3394768238067627,\n",
       "   1.4316164255142212,\n",
       "   1.097350001335144,\n",
       "   1.1702196598052979,\n",
       "   1.5319926738739014,\n",
       "   1.6906943321228027,\n",
       "   1.168806552886963,\n",
       "   1.5752413272857666,\n",
       "   1.3480514287948608,\n",
       "   1.5268725156784058,\n",
       "   1.6645747423171997,\n",
       "   1.3863004446029663,\n",
       "   1.446683406829834,\n",
       "   1.5444661378860474,\n",
       "   1.204313039779663,\n",
       "   1.2960236072540283,\n",
       "   1.4199678897857666,\n",
       "   0.9446477293968201,\n",
       "   1.690794825553894,\n",
       "   1.5018949508666992,\n",
       "   1.4687509536743164,\n",
       "   1.4530227184295654,\n",
       "   1.3594577312469482,\n",
       "   1.5652861595153809,\n",
       "   1.5031346082687378,\n",
       "   1.4719935655593872,\n",
       "   1.4169864654541016,\n",
       "   1.4192194938659668,\n",
       "   1.5223400592803955,\n",
       "   1.5586740970611572,\n",
       "   1.7717211246490479,\n",
       "   1.9281879663467407,\n",
       "   1.3465569019317627,\n",
       "   1.1865203380584717,\n",
       "   1.454075574874878,\n",
       "   1.4607458114624023,\n",
       "   1.299435019493103,\n",
       "   1.2490646839141846,\n",
       "   1.4879015684127808,\n",
       "   1.3817368745803833,\n",
       "   1.5813806056976318,\n",
       "   1.0871542692184448],\n",
       "  [1.4181782007217407,\n",
       "   1.5906175374984741,\n",
       "   1.2781895399093628,\n",
       "   1.303156852722168,\n",
       "   1.4057613611221313,\n",
       "   1.1646158695220947,\n",
       "   1.3016932010650635,\n",
       "   1.0884283781051636,\n",
       "   1.2483000755310059,\n",
       "   1.228996753692627,\n",
       "   1.3466715812683105,\n",
       "   1.5843653678894043,\n",
       "   1.177234411239624,\n",
       "   1.4462318420410156,\n",
       "   1.63927161693573,\n",
       "   1.3362298011779785,\n",
       "   1.6791250705718994,\n",
       "   1.491217017173767,\n",
       "   1.350935935974121,\n",
       "   1.4565401077270508,\n",
       "   1.526790976524353,\n",
       "   1.391974687576294,\n",
       "   1.1087465286254883,\n",
       "   1.634390115737915,\n",
       "   1.701377034187317,\n",
       "   1.0947152376174927,\n",
       "   1.3634843826293945,\n",
       "   1.7588688135147095,\n",
       "   1.8403356075286865,\n",
       "   1.3480942249298096,\n",
       "   1.3957096338272095,\n",
       "   1.8257696628570557,\n",
       "   1.940327763557434,\n",
       "   1.337762475013733,\n",
       "   1.742957592010498,\n",
       "   1.450758457183838,\n",
       "   1.3211286067962646,\n",
       "   1.3908851146697998,\n",
       "   1.3225882053375244,\n",
       "   1.3702738285064697,\n",
       "   1.8459198474884033,\n",
       "   1.7519975900650024,\n",
       "   1.2373361587524414,\n",
       "   2.145991802215576],\n",
       "  [1.4904589653015137,\n",
       "   1.572601318359375,\n",
       "   1.3440463542938232,\n",
       "   1.5270334482192993,\n",
       "   1.1840980052947998,\n",
       "   1.4837085008621216,\n",
       "   1.2548085451126099,\n",
       "   1.887906551361084,\n",
       "   1.450575828552246,\n",
       "   1.6614735126495361,\n",
       "   1.3755910396575928,\n",
       "   1.4337904453277588,\n",
       "   1.3537572622299194,\n",
       "   1.487572193145752,\n",
       "   1.5396971702575684,\n",
       "   1.4659041166305542,\n",
       "   1.397444725036621,\n",
       "   1.5228230953216553,\n",
       "   1.4606359004974365,\n",
       "   1.267612338066101,\n",
       "   1.6321552991867065,\n",
       "   1.3460285663604736,\n",
       "   1.0673613548278809,\n",
       "   1.6810448169708252,\n",
       "   1.4540669918060303,\n",
       "   1.1325173377990723,\n",
       "   1.5512139797210693,\n",
       "   1.4810007810592651,\n",
       "   1.5488176345825195,\n",
       "   1.4084959030151367,\n",
       "   1.5156258344650269,\n",
       "   1.1962177753448486,\n",
       "   1.5464917421340942,\n",
       "   1.4785339832305908,\n",
       "   1.4089453220367432,\n",
       "   1.4767627716064453,\n",
       "   1.0409338474273682,\n",
       "   1.6026067733764648,\n",
       "   1.7391834259033203,\n",
       "   1.7849595546722412,\n",
       "   1.3922021389007568,\n",
       "   1.1594901084899902,\n",
       "   1.5727019309997559,\n",
       "   0.6049467325210571],\n",
       "  [0.9795509576797485,\n",
       "   1.6482224464416504,\n",
       "   1.5806982517242432,\n",
       "   1.6091176271438599,\n",
       "   1.65664541721344,\n",
       "   1.2709541320800781,\n",
       "   1.444209337234497,\n",
       "   1.3466036319732666,\n",
       "   1.3786647319793701,\n",
       "   1.1552764177322388,\n",
       "   1.4290759563446045,\n",
       "   1.7580130100250244,\n",
       "   1.4124678373336792,\n",
       "   1.207049012184143,\n",
       "   1.9703123569488525,\n",
       "   1.7301280498504639,\n",
       "   1.5119582414627075,\n",
       "   1.882858157157898,\n",
       "   1.2978674173355103,\n",
       "   1.5636165142059326,\n",
       "   1.9280308485031128,\n",
       "   1.4605770111083984,\n",
       "   1.2190607786178589,\n",
       "   1.2388025522232056,\n",
       "   1.7036199569702148,\n",
       "   1.4766855239868164,\n",
       "   0.8553363084793091,\n",
       "   1.6131327152252197,\n",
       "   1.3621795177459717,\n",
       "   1.1475403308868408,\n",
       "   1.4915008544921875,\n",
       "   1.4754321575164795,\n",
       "   1.220055341720581,\n",
       "   1.3355666399002075,\n",
       "   0.9660454988479614,\n",
       "   1.483634352684021,\n",
       "   1.5527255535125732,\n",
       "   1.3341021537780762,\n",
       "   1.9293582439422607,\n",
       "   1.260325312614441,\n",
       "   1.3534166812896729,\n",
       "   1.357726812362671,\n",
       "   1.4356741905212402,\n",
       "   0.6820248961448669],\n",
       "  [1.1272222995758057,\n",
       "   1.4413702487945557,\n",
       "   1.2781713008880615,\n",
       "   1.468104600906372,\n",
       "   1.241887092590332,\n",
       "   1.069242238998413,\n",
       "   1.2694240808486938,\n",
       "   1.7218528985977173,\n",
       "   1.7796028852462769,\n",
       "   1.5762977600097656,\n",
       "   1.6620241403579712,\n",
       "   1.3478096723556519,\n",
       "   1.5540485382080078,\n",
       "   1.5618666410446167,\n",
       "   1.61391019821167,\n",
       "   1.3604716062545776,\n",
       "   1.249595046043396,\n",
       "   1.348713755607605,\n",
       "   1.40708589553833,\n",
       "   1.388944387435913,\n",
       "   1.8825557231903076,\n",
       "   1.3019306659698486,\n",
       "   1.7169469594955444,\n",
       "   1.15897536277771,\n",
       "   1.2817230224609375,\n",
       "   1.2566231489181519,\n",
       "   1.4596970081329346,\n",
       "   1.4676566123962402,\n",
       "   1.8409998416900635,\n",
       "   1.6655502319335938,\n",
       "   1.852280616760254,\n",
       "   1.2199662923812866,\n",
       "   1.067516803741455,\n",
       "   1.4077035188674927,\n",
       "   1.520737648010254,\n",
       "   1.2175164222717285,\n",
       "   1.2886474132537842,\n",
       "   1.7239301204681396,\n",
       "   1.4811599254608154,\n",
       "   1.4645359516143799,\n",
       "   1.6131291389465332,\n",
       "   1.581742286682129,\n",
       "   1.4345066547393799,\n",
       "   0.8284682631492615],\n",
       "  [1.4240210056304932,\n",
       "   1.5160276889801025,\n",
       "   1.013314127922058,\n",
       "   1.369802713394165,\n",
       "   1.5522727966308594,\n",
       "   1.1462719440460205,\n",
       "   1.130103349685669,\n",
       "   1.03111732006073,\n",
       "   1.543684720993042,\n",
       "   1.4482160806655884,\n",
       "   1.2805266380310059,\n",
       "   1.7911016941070557,\n",
       "   1.3737874031066895,\n",
       "   1.3385851383209229,\n",
       "   1.5880351066589355,\n",
       "   1.0833489894866943,\n",
       "   1.6645563840866089,\n",
       "   1.452034592628479,\n",
       "   1.5176767110824585,\n",
       "   1.5186814069747925,\n",
       "   1.5719900131225586,\n",
       "   1.6969366073608398,\n",
       "   1.6295409202575684,\n",
       "   1.558366060256958,\n",
       "   1.7361176013946533,\n",
       "   1.2259535789489746,\n",
       "   1.491317629814148,\n",
       "   2.1656711101531982,\n",
       "   1.2666953802108765,\n",
       "   1.2480814456939697,\n",
       "   1.4147100448608398,\n",
       "   1.708294153213501,\n",
       "   1.560312271118164,\n",
       "   1.6819486618041992,\n",
       "   1.5229883193969727,\n",
       "   1.0595678091049194,\n",
       "   1.8602931499481201,\n",
       "   1.3759310245513916,\n",
       "   1.0809829235076904,\n",
       "   1.7790517807006836,\n",
       "   1.3400654792785645,\n",
       "   1.1634156703948975,\n",
       "   1.4837266206741333,\n",
       "   0.7633954286575317],\n",
       "  [1.623263955116272,\n",
       "   1.7312254905700684,\n",
       "   1.3661389350891113,\n",
       "   1.6406142711639404,\n",
       "   1.666587471961975,\n",
       "   1.742067575454712,\n",
       "   1.4428118467330933,\n",
       "   1.6993000507354736,\n",
       "   1.7979152202606201,\n",
       "   1.3419957160949707,\n",
       "   1.0434560775756836,\n",
       "   1.2767770290374756,\n",
       "   1.3756659030914307,\n",
       "   1.560009241104126,\n",
       "   1.2885057926177979,\n",
       "   1.4044135808944702,\n",
       "   1.1985172033309937,\n",
       "   1.5535138845443726,\n",
       "   1.6136353015899658,\n",
       "   1.1048123836517334,\n",
       "   1.6082994937896729,\n",
       "   1.9694541692733765,\n",
       "   1.6091886758804321,\n",
       "   1.5534422397613525,\n",
       "   1.1999077796936035,\n",
       "   1.2763822078704834,\n",
       "   1.0484538078308105,\n",
       "   1.2310574054718018,\n",
       "   1.3788819313049316,\n",
       "   1.0668203830718994,\n",
       "   1.1239573955535889,\n",
       "   1.7843749523162842,\n",
       "   2.3214449882507324,\n",
       "   1.7045756578445435,\n",
       "   1.178672432899475,\n",
       "   1.4406203031539917,\n",
       "   1.3710620403289795,\n",
       "   1.020538091659546,\n",
       "   1.356520414352417,\n",
       "   1.530442237854004,\n",
       "   1.0273668766021729,\n",
       "   1.6214652061462402,\n",
       "   1.6368988752365112,\n",
       "   0.9990805387496948],\n",
       "  [1.4424201250076294,\n",
       "   1.7455518245697021,\n",
       "   1.3072853088378906,\n",
       "   1.551281452178955,\n",
       "   1.9200875759124756,\n",
       "   1.615639328956604,\n",
       "   1.36587655544281,\n",
       "   1.623533010482788,\n",
       "   1.2776590585708618,\n",
       "   1.758090615272522,\n",
       "   0.8696420192718506,\n",
       "   1.6055912971496582,\n",
       "   1.617005467414856,\n",
       "   1.3941954374313354,\n",
       "   1.3284201622009277,\n",
       "   1.753853440284729,\n",
       "   1.0979536771774292,\n",
       "   1.3909389972686768,\n",
       "   1.1016192436218262,\n",
       "   1.1593306064605713,\n",
       "   1.453279972076416,\n",
       "   1.3267394304275513,\n",
       "   1.8315613269805908,\n",
       "   1.719325065612793,\n",
       "   1.4536285400390625,\n",
       "   1.1231697797775269,\n",
       "   1.348433494567871,\n",
       "   1.0944650173187256,\n",
       "   1.4010958671569824,\n",
       "   1.4711973667144775,\n",
       "   1.3660613298416138,\n",
       "   1.463611125946045,\n",
       "   1.6039175987243652,\n",
       "   1.706520915031433,\n",
       "   1.4316661357879639,\n",
       "   1.7316157817840576,\n",
       "   1.3205502033233643,\n",
       "   1.4977973699569702,\n",
       "   1.2480008602142334,\n",
       "   1.6463546752929688,\n",
       "   1.5835316181182861,\n",
       "   1.5623753070831299,\n",
       "   1.4104723930358887,\n",
       "   0.7668282985687256],\n",
       "  [1.2632718086242676,\n",
       "   1.7611942291259766,\n",
       "   1.8265180587768555,\n",
       "   1.0397312641143799,\n",
       "   1.2397173643112183,\n",
       "   1.5256094932556152,\n",
       "   1.2444729804992676,\n",
       "   1.0861072540283203,\n",
       "   1.237333059310913,\n",
       "   1.2046573162078857,\n",
       "   1.5482170581817627,\n",
       "   1.2402631044387817,\n",
       "   1.6976337432861328,\n",
       "   1.2269127368927002,\n",
       "   1.3663330078125,\n",
       "   1.423713207244873,\n",
       "   1.2046048641204834,\n",
       "   1.0546822547912598,\n",
       "   1.8323040008544922,\n",
       "   1.5070785284042358,\n",
       "   1.3765780925750732,\n",
       "   1.0739678144454956,\n",
       "   1.5679527521133423,\n",
       "   1.6589909791946411,\n",
       "   1.7723181247711182,\n",
       "   0.9365332126617432,\n",
       "   1.6232128143310547,\n",
       "   1.4406156539916992,\n",
       "   1.9873051643371582,\n",
       "   1.5417466163635254,\n",
       "   1.2350597381591797,\n",
       "   1.5494803190231323,\n",
       "   1.7050237655639648,\n",
       "   1.6348211765289307,\n",
       "   1.5079150199890137,\n",
       "   1.325705885887146,\n",
       "   0.9895923137664795,\n",
       "   1.4103425741195679,\n",
       "   1.3752286434173584,\n",
       "   1.5642775297164917,\n",
       "   1.3950220346450806,\n",
       "   1.7753403186798096,\n",
       "   1.9829106330871582,\n",
       "   1.3278378248214722],\n",
       "  [1.6421610116958618,\n",
       "   1.8334672451019287,\n",
       "   1.8455123901367188,\n",
       "   1.359076738357544,\n",
       "   1.7810828685760498,\n",
       "   1.1929864883422852,\n",
       "   1.5695502758026123,\n",
       "   1.5137054920196533,\n",
       "   1.5048260688781738,\n",
       "   1.449232578277588,\n",
       "   1.266230583190918,\n",
       "   1.3559906482696533,\n",
       "   1.2649202346801758,\n",
       "   1.6981151103973389,\n",
       "   1.371364712715149,\n",
       "   1.4892208576202393,\n",
       "   1.453329086303711,\n",
       "   1.5364083051681519,\n",
       "   1.4464855194091797,\n",
       "   1.3524749279022217,\n",
       "   1.0774141550064087,\n",
       "   1.0870879888534546,\n",
       "   1.4040313959121704,\n",
       "   1.4797039031982422,\n",
       "   1.834079384803772,\n",
       "   1.7509350776672363,\n",
       "   1.474359154701233,\n",
       "   1.2515430450439453,\n",
       "   1.030455470085144,\n",
       "   1.4792859554290771,\n",
       "   1.8607114553451538,\n",
       "   1.1476231813430786,\n",
       "   1.5346894264221191,\n",
       "   1.3984503746032715,\n",
       "   1.1119216680526733,\n",
       "   1.3578264713287354,\n",
       "   1.4210087060928345,\n",
       "   1.49336576461792,\n",
       "   1.569441318511963,\n",
       "   1.3435287475585938,\n",
       "   1.1718744039535522,\n",
       "   1.5242222547531128,\n",
       "   1.5678393840789795,\n",
       "   0.18044635653495789],\n",
       "  [1.0690269470214844,\n",
       "   1.4500877857208252,\n",
       "   1.6463706493377686,\n",
       "   1.1533679962158203,\n",
       "   1.6302915811538696,\n",
       "   2.1750588417053223,\n",
       "   1.3960610628128052,\n",
       "   1.3206899166107178,\n",
       "   1.3710265159606934,\n",
       "   0.9773879647254944,\n",
       "   1.283235788345337,\n",
       "   1.5673680305480957,\n",
       "   1.2754528522491455,\n",
       "   1.6715123653411865,\n",
       "   1.7598509788513184,\n",
       "   1.3367483615875244,\n",
       "   1.0052812099456787,\n",
       "   1.4236880540847778,\n",
       "   1.4219392538070679,\n",
       "   1.688527226448059,\n",
       "   1.023492455482483,\n",
       "   1.7796831130981445,\n",
       "   1.5829472541809082,\n",
       "   1.3760241270065308,\n",
       "   1.0644190311431885,\n",
       "   1.1816855669021606,\n",
       "   1.610751748085022,\n",
       "   1.5946012735366821,\n",
       "   1.712254524230957,\n",
       "   1.4951056241989136,\n",
       "   1.5458228588104248,\n",
       "   1.7011141777038574,\n",
       "   1.38136887550354,\n",
       "   1.3514811992645264,\n",
       "   1.2786316871643066,\n",
       "   1.406675100326538,\n",
       "   1.25323486328125,\n",
       "   1.3163113594055176,\n",
       "   1.5847293138504028,\n",
       "   1.5554633140563965,\n",
       "   1.5057876110076904,\n",
       "   1.613629937171936,\n",
       "   1.556192398071289,\n",
       "   4.035677909851074]],\n",
       " 'total_time': 293.20370388031006}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3k all trainable, training from scratch\n",
    "train_iou_from_scratch = [tensor(0.4313),\n",
    "                          tensor(0.5460),\n",
    "                          tensor(0.6029),\n",
    "                          tensor(0.6465),\n",
    "                          tensor(0.6846),\n",
    "                          tensor(0.7150),\n",
    "                          tensor(0.7410),\n",
    "                          tensor(0.7501),\n",
    "                          tensor(0.7692),\n",
    "                          tensor(0.7743),\n",
    "                          tensor(0.7770),\n",
    "                          tensor(0.7876),\n",
    "                          tensor(0.7911),\n",
    "                          tensor(0.7850),\n",
    "                          tensor(0.7926),\n",
    "                          tensor(0.7929),\n",
    "                          tensor(0.7909),\n",
    "                          tensor(0.7970),\n",
    "                          tensor(0.7996),\n",
    "                          tensor(0.7926)]\n",
    "\n",
    "val_iou_from_scratch = [tensor(0.5294),\n",
    "                          tensor(0.5693),\n",
    "                          tensor(0.5849),\n",
    "                          tensor(0.5824),\n",
    "                          tensor(0.5860),\n",
    "                          tensor(0.5882),\n",
    "                          tensor(0.5900),\n",
    "                          tensor(0.5885),\n",
    "                          tensor(0.5893),\n",
    "                          tensor(0.5864),\n",
    "                          tensor(0.5867),\n",
    "                          tensor(0.5838),\n",
    "                          tensor(0.5878),\n",
    "                          tensor(0.5871),\n",
    "                          tensor(0.5882),\n",
    "                          tensor(0.5874),\n",
    "                          tensor(0.5878),\n",
    "                          tensor(0.5900),\n",
    "                          tensor(0.5885),\n",
    "                          tensor(0.5896)]\n",
    "\n",
    "# 3k all trainable, general dictioinary mapping\n",
    "train_iou_general_dict_mapping = [tensor(0.6641),\n",
    "                                  tensor(0.7553),\n",
    "                                  tensor(0.7919),\n",
    "                                  tensor(0.8153),\n",
    "                                  tensor(0.8282),\n",
    "                                  tensor(0.8385),\n",
    "                                  tensor(0.8499),\n",
    "                                  tensor(0.8538),\n",
    "                                  tensor(0.8535),\n",
    "                                  tensor(0.8555),\n",
    "                                  tensor(0.8604),\n",
    "                                  tensor(0.8601),\n",
    "                                  tensor(0.8639),\n",
    "                                  tensor(0.8652),\n",
    "                                  tensor(0.8646),\n",
    "                                  tensor(0.8605),\n",
    "                                  tensor(0.8618),\n",
    "                                  tensor(0.8590),\n",
    "                                  tensor(0.8646),\n",
    "                                  tensor(0.8627)]\n",
    "val_iou_general_dict_mapping = [tensor(0.6364),\n",
    "                                  tensor(0.6372),\n",
    "                                  tensor(0.6350),\n",
    "                                  tensor(0.6364),\n",
    "                                  tensor(0.6368),\n",
    "                                  tensor(0.6317),\n",
    "                                  tensor(0.6346),\n",
    "                                  tensor(0.6353),\n",
    "                                  tensor(0.6335),\n",
    "                                  tensor(0.6313),\n",
    "                                  tensor(0.6321),\n",
    "                                  tensor(0.6324),\n",
    "                                  tensor(0.6310),\n",
    "                                  tensor(0.6335),\n",
    "                                  tensor(0.6313),\n",
    "                                  tensor(0.6313),\n",
    "                                  tensor(0.6324),\n",
    "                                  tensor(0.6343),\n",
    "                                  tensor(0.6332),\n",
    "                                  tensor(0.6328)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5fe8176898>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs, train_iou_from_scratch, label='train from scratch: train', linestyle='--', marker='*')\n",
    "plt.plot(epochs, val_iou_from_scratch, label='train from scratch: val', marker='s')\n",
    "plt.plot(epochs, train_iou_general_dict_mapping, label='transfer with g.d.m.: train', linestyle='--', marker='+')\n",
    "plt.plot(epochs, val_iou_general_dict_mapping, label='transfer with g.d.m.: val', marker='D')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('IoU accuracy')\n",
    "plt.title('Learning curves of French model')\n",
    "plt.xticks(range(0,21,5))\n",
    "plt.ylim(0.35,0.9)\n",
    "plt.xlim(0,20)\n",
    "plt.hlines(y=0.69038, xmin=0, xmax=20, linewidth=0.5, label='English model')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5b36d4d978>]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('IoU accuracy')\n",
    "plt.title('gereral-dictionary-mapping_ranking-loss-only')\n",
    "plt.plot(loaded_process['val_IoU_acc_before_refinement'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f95e74eb978>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('IoU accuracy')\n",
    "plt.title('reg-on-chosen-box_smoothl1loss_lr-decay-0.1')\n",
    "plt.plot(process['val_IoU_acc_before_refinement'], label='val_IoU_acc_before_refinement')\n",
    "plt.plot(process['val_IoU_acc_after_refinement'], label='val_IoU_acc_after_refinement')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint: /home/wenjian/Internship/DDPN_transfer/experiments/2019-08-09_10-46-31_3k_specific-dictionary-mapping_all-trainable-testing/checkpoint_6.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DDPN(\n",
       "  (embedding): Embedding(2453, 300)\n",
       "  (lstm): LSTM(300, 1024)\n",
       "  (fc1): Linear(in_features=3077, out_features=512, bias=True)\n",
       "  (fc_rank): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_test = DDPN(cfg, vocab_size=fr_vocab)\n",
    "\n",
    "#model_en.load_state_dict(torch.load(english_pretrained_model_path, map_location=device))\n",
    "model_to_test_path = os.path.join(output_dir, \"checkpoint_6.tar\")\n",
    "checkpoint = torch.load(model_to_test_path, map_location=device)\n",
    "model_test.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(\"loaded checkpoint:\", model_to_test_path)\n",
    "model_test.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set: 2789 samples\n",
      "Test set: good bounding box based on original bounding box: 1785\n",
      "Test set: accuracy based on original bounding box: 0.6400143504142761\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For statistics of IoU score\n",
    "test_all_ious_original = []\n",
    "if cfg.regression_loss:\n",
    "    test_all_ious_refined = []\n",
    "    \n",
    "print(f\"Evaluating on test set: {len(test_set)} samples\" )\n",
    "with torch.no_grad():      \n",
    "    for test_batch_counter, (inputs, gt_bboxes, _) in enumerate(test_generator):\n",
    "        Xs, queries = inputs\n",
    "        #print(\"val_batch_counter\", val_batch_counter)\n",
    "        #print(\"Xs\", Xs.size())\n",
    "        #print(\"queries\", len(queries))\n",
    "        #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "\n",
    "        Qs, seq_lengths = preprocess_query(queries)\n",
    "\n",
    "        model_test.eval()\n",
    "\n",
    "        Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "        test_pred = model_test(Xs, Qs, seq_lengths)\n",
    "        test_targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "#         try:\n",
    "#             val_loss = loss_func(val_pred, val_targ)\n",
    "#         except AssertionError as e:\n",
    "#             print(f\"epoch {epoch}, val, batch: {val_batch_counter}\")\n",
    "#             with open(\"debug.log\", 'a') as log:\n",
    "#                 log.write(f\"epoch {epoch}, val, batch: {val_batch_counter}\\n\")\n",
    "#             raise e\n",
    "#         test_losses_by_epoch.append(val_loss.item())\n",
    "#         val_loss_average_by_epoch += val_loss.item()*Xs.size(0)\n",
    "        #logger.add_scalar('val_losses_all_batches', val_losses, val_batch_counter)\n",
    "\n",
    "#         print(f\"\\repoch {epoch}, validation phase, batch {val_batch_counter}/{len(validation_generator)}, val_loss={val_loss.item()}\", end='')\n",
    "#         logger.add_scalar(\"val_loss_by_batch\", val_loss.item(), val_batch_counter_total)\n",
    "\n",
    "        # Statistics of IoU score\n",
    "        if cfg.regression_loss:\n",
    "            ious_original, ious_refined = calculate_IoU_scores(Xs, test_pred, gt_bboxes)\n",
    "        else:\n",
    "            ious_original = calculate_IoU_scores(Xs, test_pred, gt_bboxes)\n",
    "        test_all_ious_original = test_all_ious_original + ious_original.tolist()\n",
    "        if cfg.regression_loss:\n",
    "            test_all_ious_refined = test_all_ious_refined + ious_refined.tolist()\n",
    "    \n",
    "    good_original = torch.tensor(test_all_ious_original) > 0.5     \n",
    "    print(\"Test set: good bounding box based on original bounding box:\", good_original.sum().item())\n",
    "    acc_original = good_original.sum().float()/len(test_set)\n",
    "    print(\"Test set: accuracy based on original bounding box:\", acc_original.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "\n",
    "def draw_bounding_box(filepath_sourceimage, bbox, color, output_dir=\"\", output_name=\"\"):\n",
    "    \"\"\"\n",
    "    Arguemnts:\n",
    "        filepath: the path to the image file.\n",
    "        bbox: a 4-element list to describe a bounding box; format: [x1,y1,x2,y2]\n",
    "        color: a 3-element tuple or a string to describe a color. Example(pure red): (255,0,0) or \"#ff0000\" or \"red\"\n",
    "    \"\"\"\n",
    "    img_name = os.path.basename(filepath_sourceimage)\n",
    "\n",
    "    if isinstance(color, str):\n",
    "        color = PIL.ImageColor.getrgb(color)\n",
    "\n",
    "    img = Image.open(filepath_sourceimage).convert(\"RGBA\")\n",
    "    tmp = Image.new('RGBA', img.size, (0,0,0,0))\n",
    "    draw = ImageDraw.Draw(tmp)\n",
    "    draw.rectangle(bbox, fill=color+(32,), outline=color, width=2)\n",
    "    img = Image.alpha_composite(img, tmp)\n",
    "    img = img.convert(\"RGB\") # Remove alpha for saving\n",
    "    if output_name == \"\":\n",
    "        out_img_name = 'bbox_' + img_name\n",
    "    else:\n",
    "        out_img_name = output_name\n",
    "    output_path = os.path.join(output_dir, out_img_name)\n",
    "    img.save(output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_multiple_bounding_boxes(filepath_sourceimage, bbox_color_tuple_list, output_dir=\"\", output_name=\"\"):\n",
    "    \"\"\"\n",
    "    Arguemnts:\n",
    "        filepath: the path to the image file.\n",
    "        bbox_color_tuple_list: a list of (bbox, color) tuple, where\n",
    "            bbox: a 4-element list to describe a bounding box; format: [x1,y1,x2,y2]\n",
    "            color: a 3-element tuple or a string to describe a color. Example(pure red): (255,0,0) or \"#ff0000\" or \"red\"\n",
    "    \"\"\"\n",
    "    img_name = os.path.basename(filepath_sourceimage)\n",
    "    \n",
    "    img = Image.open(filepath_sourceimage).convert(\"RGBA\")\n",
    "    \n",
    "    \n",
    "    for bbox, color in bbox_color_tuple_list:\n",
    "        if isinstance(color, str):\n",
    "            color = PIL.ImageColor.getrgb(color)\n",
    "        tmp = Image.new('RGBA', img.size, (0,0,0,0))\n",
    "        draw = ImageDraw.Draw(tmp)\n",
    "        draw.rectangle(bbox, fill=color+(32,), outline=color, width=2)\n",
    "        img = Image.alpha_composite(img, tmp)\n",
    "        \n",
    "    img = img.convert(\"RGB\") # Remove alpha for saving\n",
    "    if output_name == \"\":\n",
    "        out_img_name = 'bbox_' + img_name\n",
    "    else:\n",
    "        out_img_name = output_name     \n",
    "    output_path = os.path.join(output_dir, out_img_name)\n",
    "    img.save(output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate this function from loss_wrapper to print two losses separately \n",
    "# Don't forget to synchronize this function when the loss_wrapper is modified\n",
    "# Noted that no matter regularization loss is trained on chosen proposal or on all proposals, the loss in this function should always work on the chosen proposal. \n",
    "def loss_wrapper_testing(delta, epsilon):\n",
    "    def my_loss(predict, target):  # predict is expected to be (s,t), target their ground truth value\n",
    "        s, t = predict\n",
    "        gt_s, gt_t = target\n",
    "        #print(\"s\", s.size())   # --> s torch.Size([64, 100])\n",
    "        #print(\"gt_s\", gt_s.size())   # --> gt_s torch.Size([64, 100])\n",
    "        #print(\"t\", t.size())   # --> t torch.Size([64, 100, 4])\n",
    "        #print(\"gt_t\", gt_t.size())   # --> gt_t torch.Size([64, 4])\n",
    "        s = torch.add(s, torch.tensor(epsilon))  # In order to avoid 0 in the denominator\n",
    "        try:\n",
    "            assert not torch.isnan(s).any()\n",
    "            assert not torch.isinf(s).any()\n",
    "            assert not torch.isnan(t).any()\n",
    "            assert not torch.isinf(t).any()\n",
    "            assert not torch.isnan(gt_s).any()\n",
    "            assert not torch.isinf(gt_s).any()\n",
    "            assert not torch.isnan(gt_t).any()\n",
    "            assert not torch.isinf(gt_t).any()\n",
    "            loss_ranking = F.kl_div(torch.log(s), gt_s, reduction='batchmean') \n",
    "            assert not torch.isnan(loss_ranking).any()\n",
    "            assert not torch.isinf(loss_ranking).any()\n",
    "            N = t.size()[1]\n",
    "            #print('gt_t after repeat', gt_t.unsqueeze(1).repeat(1,N,1).size())\n",
    "            \n",
    "            \n",
    "            proposal_chosen = torch.argmax(s, dim=1)\n",
    "            batch_size = s.size()[0]\n",
    "            t_chosen = t[torch.arange(batch_size),proposal_chosen,:]  # t_chosen shape is expected to be (batch_size, 4)\n",
    "            #print(\"t_chosen\", t_chosen.size())\n",
    "            loss_regression = F.smooth_l1_loss(t_chosen, gt_t, reduction='none')\n",
    "            \n",
    "            #loss_regression = F.smooth_l1_loss(t, gt_t.unsqueeze(1).repeat(1,N,1), reduction='mean')\n",
    "            \n",
    "            \n",
    "            #print(\"loss_regression\", loss_regression)\n",
    "            assert not torch.isnan(loss_regression).any()\n",
    "            assert not torch.isinf(loss_regression).any()\n",
    "            \n",
    "            print(\"ranking_loss\", loss_ranking)\n",
    "            print(\"regression_loss\", loss_regression)\n",
    "            #my_loss.counter += 1 \n",
    "            \n",
    "        except AssertionError as e:\n",
    "            torch.set_printoptions(profile='full')\n",
    "            print('s\\n', s)\n",
    "            print('t\\n', t)\n",
    "            print('gt_s\\n', gt_s)\n",
    "            print('gt_t\\n', gt_t)\n",
    "            with open(\"debug.log\", 'w') as log:\n",
    "                log.write('s\\n')\n",
    "                log.write(str(s))\n",
    "                log.write('gt_s\\n')\n",
    "                log.write(str(gt_s))\n",
    "            torch.set_printoptions(profile='default')\n",
    "            raise e\n",
    "           \n",
    "        return delta*loss_ranking + torch.mean(loss_regression)  # Manual reduction\n",
    "        #return loss_ranking + gamma*loss_regression\n",
    "        #return loss_ranking \n",
    "    #my_loss.counter = 0\n",
    "    return my_loss\n",
    "loss_func_testing = loss_wrapper_testing(cfg.DELTA, cfg.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDPN(\n",
       "  (embedding): Embedding(2453, 300)\n",
       "  (lstm): LSTM(300, 1024)\n",
       "  (fc1): Linear(in_features=3077, out_features=512, bias=True)\n",
       "  (fc_rank): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase = \"test\"\n",
    "\n",
    "folder = \"./test-visualization/\"\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "if phase == 'val':\n",
    "    generator_for_visualization = data.DataLoader(validation_set, shuffle=False, batch_size=64)\n",
    "elif phase == 'test':\n",
    "    generator_for_visualization = data.DataLoader(test_set, shuffle=False, batch_size=64)\n",
    "\n",
    "    \n",
    "model_test = DDPN(cfg, vocab_size=fr_vocab)\n",
    "\n",
    "#model_en.load_state_dict(torch.load(english_pretrained_model_path, map_location=device))\n",
    "model_to_test_path = os.path.join(output_dir, \"checkpoint_1.tar\")\n",
    "checkpoint = torch.load(model_to_test_path, map_location=device)\n",
    "model_test.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model_test.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generator_for_visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint: /home/wenjian/Internship/DDPN_transfer/experiments/2019-08-21_20-17-40_3k_all-trainable_general-dict-mapping_for-visualization/checkpoint_1.tar\n",
      "1.2202752828598022\n",
      "960 3107059919 94067 une petite fille 0.5595679879188538\n",
      "961 3107059919 94069 bord d' une plage 0.8554666042327881\n",
      "962 3128856481 95489 des ailes 0.9155943989753723\n",
      "963 313385842 95785 deux hommes 0.37385568022727966\n",
      "964 313385842 95782 l' arrière d' un camion 0.6198970079421997\n",
      "965 313385842 95788 un objet métallique 0.44036829471588135\n",
      "966 313385842 95790 quatre personnes 0.4853997230529785\n",
      "967 3135317718 95915 une femme 0.6538425087928772\n",
      "968 3135317718 95921 jupe rose 0.6377099752426147\n",
      "969 3135317718 95916 un bébé 0.26449117064476013\n",
      "970 3138504165 96038 un joueur de hockey 0.6490362286567688\n",
      "971 3138504165 96040 maillot jaune 0.7010584473609924\n",
      "972 3138504165 96042 le but 0.7251001000404358\n",
      "973 314739483 96516 un homme 0.5830113291740417\n",
      "974 314739483 96519 un grand panneau 0.6782522797584534\n",
      "975 3148193539 96625 trois garçons 0.5106339454650879\n",
      "976 3148193539 96626 t-shirts verts 0.23654505610466003\n",
      "977 3148193539 96627 pantalons beiges 0.33929887413978577\n",
      "978 3148193539 96628 sommet d' un toboggan 0.3550538420677185\n",
      "979 3149894951 96739 un homme 0.6067847013473511\n",
      "980 3149894951 96743 un chien 0.020124517381191254\n",
      "981 3149894951 96744 ses jambes 0.28887298703193665\n",
      "982 3150380412 96775 le chien blanc 0.6788020730018616\n",
      "983 3150380412 96776 une eau peu profonde 0.7350318431854248\n",
      "984 3155400369 97090 des percussionnistes de l' oregon 0.1555284559726715\n",
      "985 3155400369 97091 la fanfare 0.767907440662384\n",
      "986 3155657768 97135 un groupe d' enfants 0.6552677154541016\n",
      "987 3155657768 97137 un adulte 0.9190549850463867\n",
      "988 3167453543 97752 un groupe de femmes 0.6037619709968567\n",
      "989 3167453543 97756 des instruments de musique 0.3138688802719116\n",
      "990 3168354472 97839 une petite fille 0.7181618213653564\n",
      "991 3168354472 97840 robe à carreaux violette 0.3805839717388153\n",
      "992 3168354472 97842 le sol 0.6395887732505798\n",
      "993 3171020648 98054 un homme 0.7097790837287903\n",
      "994 3171020648 98058 cheveux grisonnants 0.5962671041488647\n",
      "995 3171020648 98057 la barbe 0.3424394130706787\n",
      "996 317383917 98254 deux chiens noirs 0.600761890411377\n",
      "997 317383917 98256 un chiot noir 0.7415590882301331\n",
      "998 317383917 98257 un chien blanc 0.12086959928274155\n",
      "999 3178300150 98610 un homme 0.4909376800060272\n",
      "1000 3178300150 98612 basket-ball de miami 0.0\n",
      "1001 3182490771 99023 une femme 0.8325389623641968\n",
      "1002 3182490771 99026 sa maison 0.12467747926712036\n",
      "1003 3182490771 99024 une porte bleue 0.665736973285675\n",
      "1004 3182495095 99046 des enfants 0.6032693386077881\n",
      "1005 3182495095 99048 un homme 0.673258900642395\n",
      "1006 3182495095 99049 costume de banane 0.0925527811050415\n",
      "1007 319185571 99917 un chien gris et blanc 0.5810530781745911\n",
      "1008 319185571 99919 de l' eau stagnante 0.08900394290685654\n",
      "1009 319185571 99920 le sable 0.5156967639923096\n",
      "1010 3192267612 99970 une foule 0.32389742136001587\n",
      "1011 3192267612 99972 une fontaine dans un parc 0.095492884516716\n",
      "1012 319750026 100249 plusieurs hommes âgés 0.6648507118225098\n",
      "1013 319750026 100253 coiffes traditionnelles 0.0\n",
      "1014 3206999917 101076 un jeune chien 0.6782959699630737\n",
      "1015 3206999917 101076 lassie 0.5526113510131836\n",
      "1016 3206999917 101077 la neige 0.6043301820755005\n",
      "1017 3222702477 102310 le joueur de football 0.7559863924980164\n",
      "1018 3222702477 102312 le maillot doré 0.8931822180747986\n",
      "1019 3222702477 102316 le joueur de l' équipe adverse 0.10698670893907547\n",
      "1020 3222702477 102315 le ballon 0.7792208790779114\n",
      "1021 3223318401 102365 une femme 0.6738387942314148\n",
      "1022 3223318401 102367 t-shirt noir 0.63840651512146\n",
      "1023 3223318401 102369 la laine violette 0.42405563592910767\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"loaded checkpoint:\", model_to_test_path)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        \n",
    "    batch_number = 15 # batch_number begins by 0, until last batch in the data set\n",
    "\n",
    "    #for inputs, gt_bboxes in generator:\n",
    "    it = iter(generator_for_visualization)\n",
    "    for i in range(batch_number+1):\n",
    "        inputs, gt_bboxes, IDs = next(it)\n",
    "    Xs, queries = inputs\n",
    "    img_ids, obj_ids, img_ws, img_hs = IDs\n",
    "    #print(\"val_batch_counter\", val_batch_counter)\n",
    "    #print(\"Xs\", Xs.size())\n",
    "    #print(\"queries\", len(queries))\n",
    "    #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "\n",
    "    Qs, seq_lengths = preprocess_query(queries)\n",
    "\n",
    "    model_test.eval()\n",
    "\n",
    "    Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "    pred = model_test(Xs, Qs, seq_lengths)\n",
    "    targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "    #loss = loss_func_testing(pred, targ)\n",
    "    loss = loss_func(pred, targ)\n",
    "    print(loss.item())\n",
    "\n",
    "\n",
    "    # Statistics of IoU score\n",
    "\n",
    "    s, t = pred\n",
    "    proposal_chosen = torch.argmax(s, dim=1)\n",
    "    batch_size = Xs.size()[0]\n",
    "    gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "    bboxes_chosen_original = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "    #bboxes_chosen_refined = t[torch.arange(batch_size),proposal_chosen,:].unsqueeze(1)\n",
    "    #print(bboxes_chosen.size())\n",
    "    ious_original = IoU(bboxes_chosen_original, gt_bboxes).squeeze()  \n",
    "    #ious_refined = IoU(bboxes_chosen_refined, gt_bboxes).squeeze() \n",
    "    \n",
    "    \n",
    "    def get_bbox_in_original_scale(boxes, img_ws, img_hs, sample_in_batch):\n",
    "        box = boxes[sample_in_batch].tolist()[0]  # [0] is to remove a pair of []\n",
    "        #print(box)\n",
    "        #print(img_ws[sample_in_batch])\n",
    "        #print(img_hs[sample_in_batch])\n",
    "        #print(img_ws[sample_in_batch].data.cpu().numpy())\n",
    "        box[0] *= img_ws[sample_in_batch].item()\n",
    "        box[1] *= img_hs[sample_in_batch].item()\n",
    "        box[2] *= img_ws[sample_in_batch].item()\n",
    "        box[3] *= img_hs[sample_in_batch].item()\n",
    "        #print(\"box[0]\", box[0])\n",
    "        return box\n",
    "    \n",
    "    for sample_in_batch in range(0,64): # Change here to see different samples\n",
    "\n",
    "        gt_box = get_bbox_in_original_scale(gt_bboxes, img_ws, img_hs, sample_in_batch)\n",
    "        top_rank_box = get_bbox_in_original_scale(bboxes_chosen_original, img_ws, img_hs, sample_in_batch)\n",
    "        #refined_top_rank_box = get_bbox_in_original_scale(bboxes_chosen_refined, img_ws, img_hs, sample_in_batch)\n",
    "\n",
    "#         boxes_colors = [(gt_box, \"green\"),\n",
    "#                         (top_rank_box, \"yellow\"),\n",
    "#                         (refined_top_rank_box, \"red\")\n",
    "#                         ]\n",
    "\n",
    "        boxes_colors = [(gt_box, \"green\"),\n",
    "                        (top_rank_box, \"yellow\"),\n",
    "                        ]\n",
    "\n",
    "        img_path_source = os.path.join(img_dir, img_ids[sample_in_batch]+'.jpg')  \n",
    "        query_number = batch_number*batch_size+sample_in_batch\n",
    "        output_path = draw_multiple_bounding_boxes(img_path_source, boxes_colors, output_dir = folder,\n",
    "                output_name=str(query_number) + \"_\" + img_ids[sample_in_batch]+'_'+obj_ids[sample_in_batch]+'_'+queries[sample_in_batch]+'.jpg')\n",
    "        print(query_number, img_ids[sample_in_batch], obj_ids[sample_in_batch], queries[sample_in_batch], ious_original[sample_in_batch].item())\n",
    "\n",
    "#os.system(\"xdg-open \"+output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is to draw all bounding box proposals on one image.  \n",
    "\n",
    "visualization_dir = \"./visualization_gt2/\"\n",
    "\n",
    "\n",
    "if not os.path.exists(visualization_dir):\n",
    "    os.mkdir(visualization_dir)\n",
    "\n",
    "validation_generator_for_visualization = data.DataLoader(validation_set, shuffle=False, batch_size=64)\n",
    "\n",
    "\n",
    "batch_number = 1 # batch_number begins by 0, until last batch in validation set\n",
    "\n",
    "#for inputs, gt_bboxes in validation_generator:\n",
    "it = iter(validation_generator_for_visualization)\n",
    "for i in range(batch_number+1):\n",
    "    inputs, gt_bboxes, IDs = next(it)\n",
    "Xs, queries = inputs\n",
    "img_ids, obj_ids, img_ws, img_hs = IDs\n",
    "#print(\"val_batch_counter\", val_batch_counter)\n",
    "#print(\"Xs\", Xs.size())\n",
    "#print(\"queries\", len(queries))\n",
    "\n",
    "\n",
    "\n",
    "def get_bbox_in_original_scale_all_proposals(boxes, img_ws, img_hs, sample_in_batch):\n",
    "    #print(boxes)\n",
    "    box = boxes.clone()\n",
    "    #print(box[0])\n",
    "    #print(img_ws[sample_in_batch])\n",
    "    #print(img_hs[sample_in_batch])\n",
    "    #print(img_ws[sample_in_batch].data.cpu().numpy())\n",
    "    box[:,0] *= img_ws[sample_in_batch]\n",
    "    box[:,1] *= img_hs[sample_in_batch]\n",
    "    box[:,2] *= img_ws[sample_in_batch]\n",
    "    box[:,3] *= img_hs[sample_in_batch]\n",
    "    print(\"box\", box)\n",
    "    return box.tolist()\n",
    "\n",
    "for sample_in_batch in range(0,64): # Change here to see a different sample\n",
    "\n",
    "    sample_in_batch = 0\n",
    "\n",
    "    proposals = Xs[sample_in_batch,:,-5:-1]\n",
    "    proposal_list = get_bbox_in_original_scale_all_proposals(proposals, img_ws, img_hs, sample_in_batch)\n",
    "    \n",
    "     \n",
    "    #print(proposal_list[0])\n",
    "    \n",
    "    img_path_source = os.path.join(img_dir, img_ids[sample_in_batch]+'.jpg')  \n",
    "    im = Image.open(img_path_source)\n",
    "    \n",
    "    print(len(proposal_list[i]))\n",
    "    \n",
    "    for i in range(len(proposal_list)):\n",
    "        ImageDraw.ImageDraw(im).rectangle(proposal_list[i], outline=\"yellow\", width=0)\n",
    "        \n",
    "    query_number = batch_number*batch_size+sample_in_batch\n",
    "#     output_path = draw_multiple_bounding_boxes(img_path_source, boxes_colors, output_dir = visualization_dir,\n",
    "#             output_name=str(query_number) + \"_\" + img_ids[sample_in_batch]+'_'+obj_ids[sample_in_batch]+'_'+queries[sample_in_batch]+'.jpg')\n",
    "    im.save(os.path.join(visualization_dir, str(query_number) + \"_\" + img_ids[sample_in_batch]+'_'+obj_ids[sample_in_batch]+'_'+queries[sample_in_batch]+'.jpg'))\n",
    "    print(query_number, img_ids[sample_in_batch], obj_ids[sample_in_batch], queries[sample_in_batch])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(torch.tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,    0,    0,    0,    0,    0,   17,    0,    0,    0,\n",
       "            0,    0,    0,   17,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,  130,  239,    0,    0,\n",
       "            0,  239,    0,   31,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,   17,    0,    0,    0,    0,   71,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,   17,    0,    0,    0,\n",
       "           17,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,  186,  186,   17,    0,\n",
       "            0,  186,    0,   30,   44,    0,    0,    0,    3,    0,    0,    0,\n",
       "            0,   17,    0,    0,    0,   17,   87,    0,   17,    0,    0,   70,\n",
       "            3,    0,    0,   17,    0,    0,    0,    0,  943,    0,   17,    0,\n",
       "         8687,    0,    0,    0,   17,    0,   49,    0,   17,    0,    0,    0,\n",
       "           17,    0,    0,    0],\n",
       "        [   0,   71,   19,   17,   66,    0,   17,   17,   11,   11,  369,    0,\n",
       "           17,  277,   17, 5848,  298,   71,   17, 4364,    4,   17, 5537, 2607,\n",
       "           71,   48,   17,   17,    0,   63,   30,   17,    4,   17,    3,    3,\n",
       "           37,    0,    0,  237,   49,   17,   17,   17,  186,   17, 2553,   97,\n",
       "          446,   17,   49,    0,  446,   71,  240,    3, 2052,   17,   50,    0,\n",
       "          276,   17,    0,    0],\n",
       "        [ 971,  317,   59,   18,  547, 3571,   18,  452,  129, 8458,   39,   68,\n",
       "          223,   84, 1038,   29,   18,   69,  369,  139,  158,  297, 5538, 1321,\n",
       "          442,  223,   96,  444,  239,  129,   68,   96,  223,  247,  116, 1335,\n",
       "         1296,  702,   18,  624, 8449,  247,  369, 2331,  472,   96, 1574, 9564,\n",
       "          444,   90, 1448, 1391,  125,  221, 7594,   14, 1145,   54,  823,   68,\n",
       "           96,  166,  323,  222]], device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A blog on tips of deep learning debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pytorch_result_save_path+loss_filename, 'wb') as fp:\n",
    "    pickle.dump(process, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # Do this before saving the model when dropout or batch normalization is involved. https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "# Save model's learnable parameters\n",
    "torch.save(model.state_dict(), pytorch_model_save_path+pth_filename)\n",
    "# Save checkpoint\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "\n",
    "            }, pytorch_checkpoint_save_path+checkpoint_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Error: you are using non-pretraind embedding, and vocab_size is not an integer, but <__main__.CFG object at 0x7fb52806ee80>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e1617743e348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pretrained_word_embedding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_corpus_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pretrained_word_embedding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GloVe\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_corpus_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-1dc839866046>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, vocab_size, embedding_weights)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m#print(\"type(embedding_weights) equals to type(None)\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Error: you are using non-pretraind embedding, and vocab_size is not an integer, but {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORD_EMB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Error: you are using non-pretraind embedding, and vocab_size is not an integer, but <__main__.CFG object at 0x7fb52806ee80>."
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "if False:\n",
    "    if cfg.use_pretrained_word_embedding == None:\n",
    "        model = DDPN(len(training_corpus_dct.token2id), cfg)\n",
    "    elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "        model = DDPN(len(training_corpus_dct.token2id), cfg, glove.vectors)\n",
    "    model.load_state_dict(torch.load('/home/wenjian/Internship/DDPN_draft/model/ddpn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the validation set (14526 samples)...\n",
      "good bounding box based on original bounding box: tensor(9112)\n",
      "accuracy based on original bounding box: tensor(0.6273)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(f\"Evaluating the model on the validation set ({len(validation_set)} samples)...\")\n",
    "    all_ious_original = []\n",
    "    all_ious_refined = []\n",
    "    counter = 0\n",
    "    for inputs, gt_bboxes in validation_generator:\n",
    "        Xs, queries = inputs\n",
    "        batch_size = Xs.size()[0]\n",
    "        \"\"\"\n",
    "        indices = [training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)]) for q in queries]\n",
    "        #print(\"---aaa---\\n\", indices)\n",
    "        # Gensim assign -1 to unknown word in the dictionary. \n",
    "        # Pytorch embedding, however, don't support negative index. \n",
    "        # So we kept 1 for unknown word when building Gensim dictionary, and convert -1 to 1 now\n",
    "        indices = [[idx if idx!=-1 else 1 for idx in row] for row in indices]\n",
    "        #print(\"---bbb---\\n\", indices)\n",
    "\n",
    "        Qs_before_padding = [torch.tensor(row) for row in indices]\n",
    "        if cfg.use_pretrained_word_embedding == None:\n",
    "            padding_value = 0\n",
    "        elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "            padding_value = 1  # 1 is '.', since in GloVe there is no empty word token\n",
    "        #Qs = nn.utils.rnn.pad_sequence(Qs_before_padding, batch_first=False)\n",
    "        Qs = pad_sequence_right_alignment(Qs_before_padding, batch_first=False, padding_value=padding_value)\n",
    "        \"\"\"\n",
    "        Qs, seq_lengths = preprocess_query(queries)\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "        val_pred = model(Xs, Qs, seq_lengths)\n",
    "        \n",
    "        s, t = val_pred\n",
    "        \n",
    "        proposal_chosen = torch.argmax(s, dim=1)\n",
    "        \n",
    "        gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "        bboxes_chosen_original = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "#         bboxes_chosen_refined = t[torch.arange(batch_size),proposal_chosen,:].unsqueeze(1)\n",
    "        #print(bboxes_chosen.size())\n",
    "        ious_original = IoU(bboxes_chosen_original, gt_bboxes)  \n",
    "#         ious_refined = IoU(bboxes_chosen_refined, gt_bboxes) \n",
    "        \n",
    "        #print(ious.size())\n",
    "        all_ious_original = all_ious_original + ious_original.squeeze().tolist()\n",
    "#         all_ious_refined = all_ious_refined + ious_refined.squeeze().tolist()\n",
    "        \n",
    "        counter += 1\n",
    "        #if counter%10 == 0:\n",
    "        #    print(counter)\n",
    "\n",
    "good_original = torch.tensor(all_ious_original) > 0.5     \n",
    "print(\"good bounding box based on original bounding box:\", good_original.sum())\n",
    "acc_original = good_original.sum().float()/len(validation_set)\n",
    "print(\"accuracy based on original bounding box:\", acc_original)\n",
    "\n",
    "# good_refined = torch.tensor(all_ious_refined) > 0.5\n",
    "# print(\"good bounding box refined:\", good_refined.sum())\n",
    "# acc_refined = good_refined.sum().float()/len(validation_set)\n",
    "# print(\"accuracy of refined bounding box:\", acc_refined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without pretrained embedding:\n",
    "With Wenjian's feature:\n",
    "Epochs --> accuracy based on original bounding box --> accuracy of refined bounding box\n",
    "3 epochs --> 20.30% --> 21.56% <br>\n",
    "10 epochs --> 20.16% --> 21.70% <br>\n",
    "20 epochs --> 18.88% --> 23.67%\n",
    "\n",
    "With Otani's feature:\n",
    "3 epochs --> 24.15% --> 19.12% <br>\n",
    "\n",
    "Only consider ranking loss: <br>\n",
    "3 epochs --> 57.83% (before considering multiple bounding boxes) <br>\n",
    "3 epochs --> 62.73% (after considering multiple bounding boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Random selection test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2028)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(f\"Evaluating the model on the validation set ({len(validation_set)} samples)...\")\n",
    "all_ious_original = []\n",
    "all_ious_refined = []\n",
    "counter = 0\n",
    "random.seed()\n",
    "for inputs, gt_bboxes in validation_generator:\n",
    "    Xs, queries = inputs\n",
    "    batch_size = Xs.size()[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    proposal_chosen = [random.randint(0,99) for i in range(100)]\n",
    "\n",
    "    gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "    bboxes_chosen_original = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "    #print(bboxes_chosen.size())\n",
    "    ious_original = IoU(bboxes_chosen_original, gt_bboxes)  \n",
    "\n",
    "    #print(ious.size())\n",
    "    all_ious_original = all_ious_original + ious_original.squeeze().tolist()\n",
    "\n",
    "    counter += 1\n",
    "    #if counter%10 == 0:\n",
    "    #    print(counter)\n",
    "\n",
    "good_original = torch.tensor(all_ious_original) > 0.5     \n",
    "print(\"good bounding box based on original bounding box:\", good_original.sum())\n",
    "acc_original = good_original.sum().float()/len(validation_set)\n",
    "print(\"accuracy based on original bounding box:\", acc_original)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refined bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    all_ious = []\n",
    "    counter = 0\n",
    "    for inputs, gt_bboxes in validation_generator:\n",
    "        Xs, queries = inputs\n",
    "        batch_size = Xs.size()[0]\n",
    "        indices = [training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)]) for q in queries]\n",
    "        #print(\"---aaa---\\n\", indices)\n",
    "        # Gensim assign -1 to unknown word in the dictionary. \n",
    "        # Pytorch embedding, however, don't support negative index. \n",
    "        # So we kept 1 for unknown word when building Gensim dictionary, and convert -1 to 1 now\n",
    "        indices = [[idx if idx!=-1 else 1 for idx in row] for row in indices]\n",
    "        #print(\"---bbb---\\n\", indices)\n",
    "\n",
    "        Qs_before_padding = [torch.tensor(row) for row in indices]\n",
    "        Qs = nn.utils.rnn.pad_sequence(Qs_before_padding, batch_first=False)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "        val_pred = model(Xs, Qs)\n",
    "        \n",
    "        s, t = val_pred\n",
    "        #print(\"t\", t.size())\n",
    "        \n",
    "        proposal_chosen = torch.argmax(s, dim=1)\n",
    "        \n",
    "        gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "        bboxes_chosen_refined = t[torch.arange(batch_size),proposal_chosen,:].unsqueeze(1)\n",
    "        #print(bboxes_chosen.size())\n",
    "        ious = IoU(bboxes_chosen_refined, gt_bboxes)  \n",
    "        \n",
    "        #print(ious.size())\n",
    "        all_ious = all_ious + ious.squeeze().tolist()\n",
    "        \n",
    "        counter += 1\n",
    "        print(counter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3132)\n"
     ]
    }
   ],
   "source": [
    "good_refined = torch.tensor(all_ious) > 0.5\n",
    "print(good_refined.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2156)\n"
     ]
    }
   ],
   "source": [
    "print(good_refined.sum().float()/len(validation_set))\n",
    "# First try (3 epochs) --> 21.56%\n",
    "# Second try (20 epochs) --> 23.67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 , average= 1.0\n",
      "i= 100 , average= 4.554455445544554\n",
      "i= 200 , average= 4.3283582089552235\n",
      "i= 300 , average= 4.212624584717608\n",
      "i= 400 , average= 4.082294264339152\n",
      "i= 500 , average= 4.06187624750499\n",
      "i= 600 , average= 4.2579034941763725\n",
      "i= 700 , average= 4.272467902995721\n",
      "i= 800 , average= 4.253433208489389\n",
      "i= 900 , average= 4.314095449500555\n",
      "i= 1000 , average= 4.393606393606394\n",
      "i= 1100 , average= 4.464123524069028\n",
      "i= 1200 , average= 4.385512073272273\n",
      "i= 1300 , average= 4.467332820906995\n",
      "i= 1400 , average= 4.599571734475375\n",
      "i= 1500 , average= 4.574950033311126\n",
      "i= 1600 , average= 4.553404122423485\n",
      "i= 1700 , average= 4.577895355673133\n",
      "i= 1800 , average= 4.520821765685731\n",
      "i= 1900 , average= 4.52656496580747\n",
      "i= 2000 , average= 4.491754122938531\n",
      "i= 2100 , average= 4.488338886244645\n",
      "i= 2200 , average= 4.534756928668787\n",
      "i= 2300 , average= 4.515428074750108\n",
      "i= 2400 , average= 4.555601832569763\n",
      "i= 2500 , average= 4.591363454618152\n",
      "i= 2600 , average= 4.549404075355633\n",
      "i= 2700 , average= 4.611625323954091\n",
      "i= 2800 , average= 4.578364869689397\n",
      "i= 2900 , average= 4.566011720096518\n",
      "i= 3000 , average= 4.555814728423859\n",
      "i= 3100 , average= 4.547887778136085\n",
      "i= 3200 , average= 4.564511090284286\n",
      "i= 3300 , average= 4.60224174492578\n",
      "i= 3400 , average= 4.602763892972655\n",
      "i= 3500 , average= 4.592116538131962\n",
      "i= 3600 , average= 4.591502360455429\n",
      "i= 3700 , average= 4.593353147797893\n",
      "i= 3800 , average= 4.588529334385688\n",
      "i= 3900 , average= 4.589336067674955\n",
      "i= 4000 , average= 4.596600849787553\n",
      "i= 4100 , average= 4.574250182882224\n",
      "i= 4200 , average= 4.572482742204237\n",
      "i= 4300 , average= 4.564054870960242\n",
      "i= 4400 , average= 4.561463303794592\n",
      "i= 4500 , average= 4.584758942457232\n",
      "i= 4600 , average= 4.601173657900456\n",
      "i= 4700 , average= 4.610933843863008\n",
      "i= 4800 , average= 4.619870860237451\n",
      "i= 4900 , average= 4.640073454397061\n",
      "i= 5000 , average= 4.6374725054989\n",
      "i= 5100 , average= 4.627916094883356\n",
      "i= 5200 , average= 4.667179388579119\n",
      "i= 5300 , average= 4.680249009620827\n",
      "i= 5400 , average= 4.690798000370302\n",
      "i= 5500 , average= 4.710779858207599\n",
      "i= 5600 , average= 4.702731655061596\n",
      "i= 5700 , average= 4.696895281529557\n",
      "i= 5800 , average= 4.697810722289261\n",
      "i= 5900 , average= 4.687680054228097\n",
      "i= 6000 , average= 4.704715880686552\n",
      "i= 6100 , average= 4.710703163415833\n",
      "i= 6200 , average= 4.699564586357039\n",
      "i= 6300 , average= 4.701475956197429\n",
      "i= 6400 , average= 4.709889079831276\n",
      "i= 6500 , average= 4.7260421473619445\n",
      "i= 6600 , average= 4.732616270262081\n",
      "i= 6700 , average= 4.7361587822713025\n",
      "i= 6800 , average= 4.7368034112630495\n",
      "i= 6900 , average= 4.720475293435734\n",
      "i= 7000 , average= 4.72146836166262\n",
      "i= 7100 , average= 4.739332488381918\n",
      "i= 7200 , average= 4.751006804610471\n",
      "i= 7300 , average= 4.742227092179154\n",
      "i= 7400 , average= 4.734360221591677\n",
      "i= 7500 , average= 4.726169844020797\n",
      "i= 7600 , average= 4.714116563610052\n",
      "i= 7700 , average= 4.727827554863005\n",
      "i= 7800 , average= 4.717600307652865\n",
      "i= 7900 , average= 4.725730920136692\n",
      "i= 8000 , average= 4.7390326209223845\n",
      "i= 8100 , average= 4.745586964572275\n",
      "i= 8200 , average= 4.737836849164736\n",
      "i= 8300 , average= 4.738344777737622\n",
      "i= 8400 , average= 4.729317938340674\n",
      "i= 8500 , average= 4.73120809316551\n",
      "i= 8600 , average= 4.730380188350192\n",
      "i= 8700 , average= 4.7309504654637395\n",
      "i= 8800 , average= 4.723667765026701\n",
      "i= 8900 , average= 4.7346365576901475\n",
      "i= 9000 , average= 4.735473836240418\n",
      "i= 9100 , average= 4.7368421052631575\n",
      "i= 9200 , average= 4.72513857189436\n",
      "i= 9300 , average= 4.724438232448124\n",
      "i= 9400 , average= 4.725880225507924\n",
      "i= 9500 , average= 4.7276076202505\n",
      "i= 9600 , average= 4.719404228726174\n",
      "i= 9700 , average= 4.72270899907226\n",
      "i= 9800 , average= 4.723191511070299\n",
      "i= 9900 , average= 4.714877285122715\n",
      "i= 10000 , average= 4.714728527147285\n",
      "i= 10100 , average= 4.7076527076527075\n",
      "i= 10200 , average= 4.703166356239584\n",
      "i= 10300 , average= 4.696437239103\n",
      "i= 10400 , average= 4.697721372944909\n",
      "i= 10500 , average= 4.6917436434625275\n",
      "i= 10600 , average= 4.688142628053957\n",
      "i= 10700 , average= 4.678815064012709\n",
      "i= 10800 , average= 4.665586519766689\n",
      "i= 10900 , average= 4.659847720392625\n",
      "i= 11000 , average= 4.654667757476593\n",
      "i= 11100 , average= 4.654355463471759\n",
      "i= 11200 , average= 4.659048299258995\n",
      "i= 11300 , average= 4.6603840368109015\n",
      "i= 11400 , average= 4.652574335584598\n",
      "i= 11500 , average= 4.653595339535692\n",
      "i= 11600 , average= 4.641324023791053\n",
      "i= 11700 , average= 4.637808734296214\n",
      "i= 11800 , average= 4.64181001610033\n",
      "i= 11900 , average= 4.632972019158054\n",
      "i= 12000 , average= 4.634863761353221\n",
      "i= 12100 , average= 4.641434592182464\n",
      "i= 12200 , average= 4.653716908450127\n",
      "i= 12300 , average= 4.6503536297861965\n",
      "i= 12400 , average= 4.650189500846706\n",
      "i= 12500 , average= 4.649308055355571\n",
      "i= 12600 , average= 4.652567256566939\n",
      "i= 12700 , average= 4.653334383119439\n",
      "i= 12800 , average= 4.64963674712913\n",
      "i= 12900 , average= 4.656305712735447\n",
      "i= 13000 , average= 4.6581801399892315\n",
      "i= 13100 , average= 4.65346156781925\n",
      "i= 13200 , average= 4.644648132717219\n",
      "i= 13300 , average= 4.647470115028945\n",
      "i= 13400 , average= 4.64204163868368\n",
      "i= 13500 , average= 4.634249314865565\n",
      "i= 13600 , average= 4.6351738842732155\n",
      "i= 13700 , average= 4.6328005255090865\n",
      "i= 13800 , average= 4.633287442938918\n",
      "i= 13900 , average= 4.630098554060859\n",
      "i= 14000 , average= 4.6258124419684306\n",
      "i= 14100 , average= 4.628324232323949\n",
      "i= 14200 , average= 4.630237307231885\n",
      "i= 14300 , average= 4.626669463673869\n",
      "i= 14400 , average= 4.625026039858343\n",
      "i= 14500 , average= 4.626301634370043\n"
     ]
    }
   ],
   "source": [
    "# Attention! this function only work on CPU. Relaod the oringal version after using this version\n",
    "def intersect(box_a, box_b):  # Tackle with N (like 100) box pairs at the same time\n",
    "    #print(box_a.type())\n",
    "    #print(box_b.type())\n",
    "    inter_xmin=torch.max(box_a[:,:,0], box_b[:,:,0])\n",
    "    inter_xmax=torch.min(box_a[:,:,2], box_b[:,:,2])\n",
    "    inter_ymin=torch.max(box_a[:,:,1], box_b[:,:,1])\n",
    "    inter_ymax=torch.min(box_a[:,:,3], box_b[:,:,3])\n",
    "    inter = torch.max((inter_xmax-inter_xmin).float(), torch.tensor(0).float().to('cpu')) * torch.max((inter_ymax-inter_ymin).float(), torch.tensor(0).float().to('cpu'))\n",
    "    return inter\n",
    "thre = 0.5\n",
    "good_proposal = []\n",
    "for i in range(len(validation_set)):\n",
    "    iou = iou_pass_threshold(validation_set[i][0][0].unsqueeze(0),validation_set[i][1], thre)\n",
    "    \n",
    "    good_proposal.append(iou.sum())\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(\"i=\", i, \", average=\", np.array(good_proposal).mean())\n",
    "#print(\"Finally,\", counter, \"examples pass the threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05281045751633987"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.04/76.5  # There are 76.5 proposals per image on average for the whole Flickr30k dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    all_ious = []\n",
    "    counter = 0\n",
    "    for inputs, gt_bboxes in validation_generator:\n",
    "        Xs, queries = inputs\n",
    "        batch_size = Xs.size()[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "        bboxes_chosen = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "        #print(bboxes_chosen.size())\n",
    "        ious = IoU(bboxes_chosen, gt_bboxes)  \n",
    "        \n",
    "        #print(ious.size())\n",
    "        all_ious = all_ious + ious.squeeze().tolist()\n",
    "        \n",
    "        counter += 1\n",
    "        print(counter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities: for obtaining the general dictionary by google translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./dictionary/FrenchWordList{fr_dataset_volume}.txt\", \"w\") as f:\n",
    "    for key in training_corpus_dct.token2id:\n",
    "        f.write(key+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./dictionary/FrenchWordList{fr_dataset_volume}.txt\", \"r\") as f_fr:\n",
    "    fr_words = f_fr.readlines()\n",
    "    fr_words = [item.strip() for item in fr_words]  \n",
    "with open(f\"./dictionary/Fr-En-GoogleTrans{fr_dataset_volume}.txt\", \"r\") as f_en:\n",
    "    en_words = f_en.readlines()\n",
    "    en_words = [item.strip() for item in en_words]  \n",
    "    en_words = [item.split(' ')[-1] for item in en_words]  # When it is a phrase, just choose the last word\n",
    "with open(f\"./dictionary/Fr-En-GoogleTrans_dictionary{fr_dataset_volume}.txt\", \"w\") as f_fr2en:\n",
    "    for i in range(len(fr_words)):\n",
    "        f_fr2en.write(f\"{fr_words[i]} {en_words[i]}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7500, 1.2500])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3,5]).float() / torch.tensor(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a>1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*(a>1.5).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array((1,2,3))\n",
    "b = np.array((4,5,6))\n",
    "c = np.array((7,8,9))\n",
    "d = np.array((10,11,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.column_stack((a,b))\n",
    "B = np.column_stack((c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB = np.column_stack((A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABA = np.column_stack((AB,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4,  7, 10,  1,  4],\n",
       "       [ 2,  5,  8, 11,  2,  5],\n",
       "       [ 3,  6,  9, 12,  3,  6]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-e23de71598de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mABA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "ABA[[1,2,3],[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],[15,16,17]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14],\n",
       "        [15, 16, 17]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0,2,1,0,2,0])\n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5,  7,  9, 14, 15])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[torch.arange(6), y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f06cc5108d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/wenjian/.local/lib/python2.7/site-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "np.stack((AB,A), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ManglingTest:\n",
    "    def __init__(self):\n",
    "        self.__mangled = 'hello'\n",
    "\n",
    "    def get_mangled(self):\n",
    "        return self.__mangled\n",
    "\n",
    "ManglingTest().get_mangled()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ManglingTest instance has no attribute '__mangled'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-0bb3c4f8d3a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mManglingTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mangled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: ManglingTest instance has no attribute '__mangled'"
     ]
    }
   ],
   "source": [
    "ManglingTest().__mangled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.repeat((4,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(4, 2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [1, 2, 3]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(4, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(4, 2, 1).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-0ed8aeb7c585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "C.a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 2 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-e2c3e9e6a185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 2 values to unpack"
     ]
    }
   ],
   "source": [
    "def myfunc():\n",
    "    a = 1\n",
    "    b = 2\n",
    "    c = 3\n",
    "    return (a,b), c\n",
    "d,e,f = myfunc()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = a.repeat(1,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4],\n",
       "         [1, 2],\n",
       "         [3, 4]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.device(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_cached(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], device='cuda:0')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard.summary.writer'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-247a8ab0a07a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     raise ImportError('TensorBoard logging requires TensorBoard with Python summary writer installed. '\n\u001b[0m\u001b[1;32m      5\u001b[0m                       'This should be available in 1.14 or above.')\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy (from torch)\n",
      "  Using cached https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Installing collected packages: numpy, torch\n",
      "Successfully installed numpy-1.16.4 torch-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -U torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "m = gensim.models.KeyedVectors.load_word2vec_format('./word2vec/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectors',\n",
       " 'vocab',\n",
       " 'vector_size',\n",
       " 'index2word',\n",
       " 'vectors_norm',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " 'save_word2vec_format',\n",
       " 'load_word2vec_format',\n",
       " 'get_keras_embedding',\n",
       " 'load',\n",
       " '__init__',\n",
       " 'wv',\n",
       " 'index2entity',\n",
       " 'syn0',\n",
       " 'syn0norm',\n",
       " '__contains__',\n",
       " 'save',\n",
       " 'word_vec',\n",
       " 'get_vector',\n",
       " 'words_closer_than',\n",
       " 'most_similar',\n",
       " 'similar_by_word',\n",
       " 'similar_by_vector',\n",
       " 'similarity_matrix',\n",
       " 'wmdistance',\n",
       " 'most_similar_cosmul',\n",
       " 'doesnt_match',\n",
       " 'cosine_similarities',\n",
       " 'distances',\n",
       " 'distance',\n",
       " 'similarity',\n",
       " 'n_similarity',\n",
       " '_log_evaluate_word_analogies',\n",
       " 'evaluate_word_analogies',\n",
       " 'log_accuracy',\n",
       " 'accuracy',\n",
       " 'log_evaluate_word_pairs',\n",
       " 'evaluate_word_pairs',\n",
       " 'init_sims',\n",
       " 'relative_cosine_similarity',\n",
       " 'add',\n",
       " '__setitem__',\n",
       " '__getitem__',\n",
       " 'most_similar_to_given',\n",
       " 'closer_than',\n",
       " 'rank',\n",
       " '_load_specials',\n",
       " '_adapt_by_suffix',\n",
       " '_smart_save',\n",
       " '_save_specials',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__new__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gen():\n",
    "    for i in range(5):\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object my_gen at 0x7efc78480150>\n"
     ]
    }
   ],
   "source": [
    "print(my_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[0,0,0],[0,0,0]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3895,  0.0679, -0.1960],\n",
       "        [ 0.2881, -0.3075,  0.6298]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.xavier_uniform_(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
