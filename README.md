# Multi-Lingual-Visual-Grounding

Visual grounding, as an extension to object detection, is the task to locate objects in an image based on queries in natural language. It is a fundamental task in various multi-modal learning tasks. This project gives a benchmark for visual grounding in French language. For more details, please refer to [our paper](https://ieeexplore.ieee.org/document/9305199).

The French dataset that we annotated is in the folder French-data. 

More descriptions will be added to this Github page in the future. 

If you use the dataset in this repository, please cite our paper: 

    @ARTICLE{9305199,  author={W. {Dong} and M. {Otani} and N. {Garcia} and Y. {Nakashima} and C. {Chu}},
    journal={IEEE Access},   
    title={Cross-Lingual Visual Grounding},   
    year={2021},  volume={9},  number={},  pages={349-358},  
    doi={10.1109/ACCESS.2020.3046719}}
