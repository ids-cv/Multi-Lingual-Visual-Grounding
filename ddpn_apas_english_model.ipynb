{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dongwenjian-ThinkPad-E460'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.uname()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongwenjian-ThinkPad-E460\n"
     ]
    }
   ],
   "source": [
    "computer_name = os.uname()[1]\n",
    "if computer_name == \"wenjian-desktop\":\n",
    "    img_dir = \"/home/wenjian/Internship/data/flickr30kentities/flickr30k-images/\"  # For visualization\n",
    "    \n",
    "    features_dir = \"/home/wenjian/Internship/data/flickr30kentities/flickr30k-feats-otani/bottom-up-feats/\"\n",
    "    #features_dir = \"/home/wenjian/Internship/GitHubCloned/DDPN/data/flickr30k/features/bottom-up-feats-resnet101/\"\n",
    "\n",
    "    #train_image_list_filepath = \"/home/wenjian/Internship/data/flickr30kentities/Multi30k/task1/image_splits/train.txt\"\n",
    "    #train_triple_filepath = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries_fr_1000-images.csv\"\n",
    "    train_triple_filepath = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries_fr_3000-images.csv\"\n",
    "    train_triple_filepath_en = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries.csv\"\n",
    "\n",
    "    val_triple_filepath = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/val_queries_fr.csv\"\n",
    "    test_triple_filepath = \"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/test_2016_flickr_queries_fr.csv\"\n",
    "    \n",
    "    xml_dirpath = \"/home/wenjian/Internship/data/flickr30kentities/annotations/Annotations/\"\n",
    "\n",
    "    project_root = \"/home/wenjian/Internship/DDPN_transfer/\"\n",
    "    \n",
    "    english_pretrained_model_path = \"/home/wenjian/Internship/DDPN_transfer/pretrained-models/2019-08-07_10-36-3_rank-loss-only_adam-beta2-0.999_dropout-batchnorm-later_checkpoint_9_67.76.tar\"\n",
    "    specific_dictionary_file = \"/home/wenjian/Internship/data/word_allignment/lex.e2f\"  # The file name is e2f, but in fact it is f2e\n",
    "    general_dictionary_file = \"/home/wenjian/Internship/DDPN_transfer/dictionary/Fr-En-GoogleTrans_dictionary.txt\"\n",
    "    \n",
    "\n",
    "elif computer_name == \"apas\":\n",
    "    img_dir = \"/home/wenjian/data/flickr30kentities/flickr30k-images/\"  # For visualization\n",
    "    \n",
    "    features_dir = \"/home/wenjian/data/flickr30kentities/bottom-up-feats/\"\n",
    "    \n",
    "    #train_image_list_filepath = \"/home/wenjian/data/flickr30kentities/Multi30k/task1/image_splits/train.txt\"\n",
    "    train_triple_filepath = \"/home/wenjian/data/flickr30kentities/queries_extracted/train_queries.csv\"\n",
    "\n",
    "    val_triple_filepath = \"/home/wenjian/data/flickr30kentities/queries_extracted/val_queries.csv\"\n",
    "    \n",
    "    test_triple_filepath = \"/home/wenjian/data/flickr30kentities/queries_extracted/test_2016_flickr_queries.csv\"\n",
    "\n",
    "    xml_dirpath = \"/home/wenjian/data/flickr30kentities/annotations/Annotations/\"\n",
    "\n",
    "    project_root = \"/home/wenjian/code/\"\n",
    "    \n",
    "    pretrained_model_path = None\n",
    "\n",
    "elif computer_name == \"dongwenjian-ThinkPad-E460\":\n",
    "    fr_dataset_volume = \"3k\"\n",
    "    \n",
    "    features_dir = \"/media/dongwenjian/SSDBACKUP/Internship/data/flickr30kentities/flickr30k-feats-otani/bottom-up-feats/\"\n",
    "    \n",
    "    #train_image_list_filepath = \"/home/wenjian/data/flickr30kentities/Multi30k/task1/image_splits/train.txt\"\n",
    "    train_triple_filepath = \"/media/dongwenjian/SSDBACKUP/Internship/data/flickr30kentities/queries_extracted/train_queries.csv\"\n",
    "\n",
    "    val_triple_filepath = \"/media/dongwenjian/SSDBACKUP/Internship/data/flickr30kentities/queries_extracted/val_queries.csv\"\n",
    "    \n",
    "    test_triple_filepath = \"/media/dongwenjian/SSDBACKUP/Internship/data/flickr30kentities/queries_extracted/test_2016_flickr_queries.csv\"\n",
    "\n",
    "    xml_dirpath = \"/media/dongwenjian/SSDBACKUP/Internship/data/flickr30kentities/annotations/Annotations/\"\n",
    "\n",
    "    project_root = \"/media/dongwenjian/SSDBACKUP/newly_added/new_experiments/word2word_test_set/\"\n",
    "    \n",
    "    pretrained_model_path = \"/media/dongwenjian/SSDBACKUP/Internship/DDPN_transfer/pretrained-models/2019-08-17_19-26-48_L1-gt-softlabel_drop0.5_checkpoint_4_69.30.tar\"\n",
    "    \n",
    "else:\n",
    "    raise Exception(\"Failed to initialize paths: computer not recognized\")\n",
    "print(computer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing the following idea:\n",
    "# French test set translated into English by Google Translate, then run with English model\n",
    "# On apas:\n",
    "#test_triple_filepath = \"/home/wenjian/data/flickr30kentities/queries_extracted/test_2016_flickr_queries_fr_translated_into_en.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing the following idea:\n",
    "# French test set translated into English by word2word manner, then run with English model\n",
    "# On dongwenjian-ThinkPad-E460\n",
    "test_triple_filepath = \"/media/dongwenjian/SSDBACKUP/newly_added/new_experiments/test-set_word2word_translation/test_2016_flickr_queries_fr_word2word_into_en.csv\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self):\n",
    "        # cfg_path for future use\n",
    "        self.xml_dirpath = xml_dirpath\n",
    "        self.triple_filepaths = {'train': train_triple_filepath,\n",
    "                                 'val': val_triple_filepath,\n",
    "                                 'test': test_triple_filepath\n",
    "                                }\n",
    "        self.RPN_TOPN = 100\n",
    "        \n",
    "        # Configure for network\n",
    "        self.WORD_EMB_SIZE = 300\n",
    "        self.RNN_DIM = 1024\n",
    "        self.VISUAL_FEATURES = 2048  # For resnet\n",
    "        self.SPATIAL_FEATURES = 5\n",
    "        self.SOFTLABEL_THRESHOLD = 0.5 # 0.5 in paper\n",
    "        self.GAMMA = 1\n",
    "        self.DELTA = 1\n",
    "        self.STEMMING = False\n",
    "        self.epsilon = 1e-7\n",
    "        self.dropout_rate = 0.5\n",
    "        self.lr_decay_rate = 0.7\n",
    "        self.initial_lr = 0.001\n",
    "        self.use_pretrained_word_embedding = None  # candidate: None, \"GloVe\"\n",
    "        self.use_pretrained_model = False\n",
    "        self.regression_loss = False\n",
    "        \n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_imageID_list = []\n",
    "# with open(train_image_list_filepath, 'r') as f:\n",
    "#     l = f.readline()\n",
    "#     while l :\n",
    "#         train_imageID_list.append(l.split('.')[0])\n",
    "#         l = f.readline()\n",
    "# print(len(train_imageID_list))\n",
    "# print(train_imageID_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish vocabulary dictionary from training set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_triple_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMPTYWORDTOKEN',\n",
       " 'UNKNOWNWORD',\n",
       " 'Two young guys',\n",
       " 'shaggy hair',\n",
       " 'their hands',\n",
       " 'Two young , White males',\n",
       " 'many bushes',\n",
       " 'Two men',\n",
       " 'green shirts',\n",
       " 'A man',\n",
       " 'a blue shirt',\n",
       " 'Two friends',\n",
       " 'Several men',\n",
       " 'hard hats',\n",
       " 'a giant pulley system',\n",
       " 'Workers',\n",
       " 'a piece of equipment',\n",
       " 'Two men',\n",
       " 'a machine',\n",
       " 'hard hats',\n",
       " 'Four men',\n",
       " 'a tall structure',\n",
       " 'Three men',\n",
       " 'a large rig',\n",
       " 'A child',\n",
       " 'a pink dress',\n",
       " 'a set of stairs',\n",
       " 'an entry way',\n",
       " 'A little girl',\n",
       " 'a pink dress',\n",
       " 'A little girl',\n",
       " 'the stairs',\n",
       " 'her playhouse',\n",
       " 'A little girl',\n",
       " 'a wooden playhouse',\n",
       " 'A girl',\n",
       " 'Someone',\n",
       " 'a blue shirt',\n",
       " 'hat',\n",
       " 'stair',\n",
       " 'a window',\n",
       " 'A man',\n",
       " 'a blue shirt',\n",
       " 'a ladder',\n",
       " 'a window',\n",
       " 'A man',\n",
       " 'a ladder',\n",
       " 'the window of a tall building',\n",
       " 'man',\n",
       " 'blue shirt',\n",
       " 'jeans',\n",
       " 'ladder',\n",
       " 'windows',\n",
       " 'a man',\n",
       " 'a ladder',\n",
       " 'a window',\n",
       " 'Two men',\n",
       " 'one',\n",
       " 'a gray shirt',\n",
       " 'one',\n",
       " 'a black shirt',\n",
       " 'a stove',\n",
       " 'Two guy',\n",
       " 'Two men',\n",
       " 'food',\n",
       " 'a stove',\n",
       " 'Two men',\n",
       " 'the stove',\n",
       " 'food',\n",
       " 'Two men',\n",
       " 'a meal',\n",
       " 'Two people',\n",
       " 'the guitar',\n",
       " 'the other',\n",
       " 'A man',\n",
       " 'green',\n",
       " 'a guitar',\n",
       " 'the other man',\n",
       " 'his shirt',\n",
       " 'A man',\n",
       " 'the guitar players costume',\n",
       " 'a guy',\n",
       " \"another man 's coat\",\n",
       " 'the two boys',\n",
       " 'guitar',\n",
       " 'A man',\n",
       " 'a chair',\n",
       " 'a large stuffed animal of a lion',\n",
       " 'A man',\n",
       " 'a chair',\n",
       " 'a large stuffed animal',\n",
       " 'A man',\n",
       " 'the finishing touches',\n",
       " 'a stuffed lion',\n",
       " 'A man',\n",
       " 'a large stuffed lion toy',\n",
       " 'A man',\n",
       " 'a stuffed lion',\n",
       " 'A girl',\n",
       " 'rollerskates',\n",
       " 'her cellphone',\n",
       " 'a parking lot',\n",
       " 'A trendy girl',\n",
       " 'her cellphone',\n",
       " 'the street',\n",
       " 'A young adult',\n",
       " 'rollerblades',\n",
       " 'a cellular phone',\n",
       " 'a young girl',\n",
       " 'her cellphone',\n",
       " 'skating',\n",
       " 'Woman',\n",
       " 'cellphone',\n",
       " 'rollerskates',\n",
       " 'An asian man',\n",
       " 'a black suit',\n",
       " 'a dark-haired woman',\n",
       " 'a brown-haired woman',\n",
       " 'Three people',\n",
       " 'large pipes',\n",
       " 'a metal railing',\n",
       " 'A young woman',\n",
       " 'two young people',\n",
       " 'hip black outfits',\n",
       " 'A woman',\n",
       " 'a large purse',\n",
       " 'a gate',\n",
       " 'Several people',\n",
       " 'a building',\n",
       " 'Two men',\n",
       " 'a rail',\n",
       " 'shirts',\n",
       " 'Two youths',\n",
       " 'a roadside railing',\n",
       " 'Boys',\n",
       " 'poles',\n",
       " 'Two men',\n",
       " 'no shirts',\n",
       " 'a rail',\n",
       " 'two guys',\n",
       " 'a gate',\n",
       " 'Five ballet dancers',\n",
       " 'a window',\n",
       " 'Ballet dancers',\n",
       " 'Five girls',\n",
       " 'Five girls',\n",
       " 'feet',\n",
       " 'A ballet class of five girls',\n",
       " 'Three young men',\n",
       " 'a young woman',\n",
       " 'sneakers',\n",
       " 'the top of a flight',\n",
       " 'Four casually dressed guys',\n",
       " 'a stone wall',\n",
       " 'Four guys',\n",
       " 'hats',\n",
       " 'one',\n",
       " 'the top of a staircase',\n",
       " 'Four men',\n",
       " 'excited faces',\n",
       " 'the top of stairs',\n",
       " 'Four people',\n",
       " 'A black dog',\n",
       " 'a white dog',\n",
       " 'brown spots',\n",
       " 'the street',\n",
       " 'A black dog',\n",
       " 'a tri-colored dog',\n",
       " 'the road',\n",
       " 'Two dogs of different breeds',\n",
       " 'the road',\n",
       " 'Two dogs',\n",
       " 'pavement',\n",
       " 'A black dog',\n",
       " 'a spotted dog',\n",
       " 'A man',\n",
       " 'reflective safety clothes',\n",
       " 'ear protection',\n",
       " 'a John Deere tractor',\n",
       " 'a road',\n",
       " 'John Deere',\n",
       " 'a street',\n",
       " 'the driver',\n",
       " 'easy to see clothing',\n",
       " 'A man',\n",
       " 'orange uniform',\n",
       " 'a green tractor',\n",
       " 'A man',\n",
       " 'headphones',\n",
       " 'a paved street',\n",
       " 'A man',\n",
       " 'a John Deere tractor',\n",
       " 'a main road',\n",
       " 'Some women',\n",
       " 'buildings',\n",
       " 'Several women',\n",
       " 'tall buildings',\n",
       " 'A group of women',\n",
       " 'Several women',\n",
       " 'Women',\n",
       " 'A young woman',\n",
       " 'dark hair',\n",
       " 'glasses',\n",
       " 'white powder',\n",
       " 'a cake',\n",
       " 'a sifter',\n",
       " 'A lady',\n",
       " 'a black top',\n",
       " 'glasses',\n",
       " 'powdered sugar',\n",
       " 'a bundt cake',\n",
       " 'A woman',\n",
       " 'glasses sprinkles',\n",
       " 'sugar',\n",
       " 'her bundt cake',\n",
       " 'Girl',\n",
       " 'black jacket',\n",
       " 'powdered sugar',\n",
       " 'a chocolate cake',\n",
       " 'A standing woman',\n",
       " 'a pan',\n",
       " 'a cake',\n",
       " 'A small girl',\n",
       " 'the grass',\n",
       " 'fingerpaints',\n",
       " 'a white canvas',\n",
       " 'a rainbow',\n",
       " 'A little girl',\n",
       " 'paint',\n",
       " 'a painted rainbow',\n",
       " 'her hands',\n",
       " 'a bowl',\n",
       " 'a girl',\n",
       " 'pigtails',\n",
       " 'a rainbow painting',\n",
       " 'A little girl',\n",
       " 'a large painted rainbow',\n",
       " 'Young girl',\n",
       " 'pigtails',\n",
       " 'the grass',\n",
       " 'a man',\n",
       " 'a bench',\n",
       " 'a white and black dog',\n",
       " 'A man',\n",
       " 'the bench',\n",
       " 'a white dog',\n",
       " 'man',\n",
       " 'bench',\n",
       " 'leash of dog',\n",
       " 'A shirtless man',\n",
       " 'a park bench',\n",
       " 'his dog',\n",
       " 'A man',\n",
       " 'a bench',\n",
       " 'his dog',\n",
       " 'A group of adults',\n",
       " 'chairs',\n",
       " 'a circle',\n",
       " 'a type of musical instruments',\n",
       " 'Five musicians',\n",
       " 'a man',\n",
       " 'four women',\n",
       " 'sheet music',\n",
       " 'flutes',\n",
       " 'People',\n",
       " 'a circle',\n",
       " 'some',\n",
       " 'musical instruments',\n",
       " 'People',\n",
       " 'Five people',\n",
       " 'a circle',\n",
       " 'instruments',\n",
       " 'Two women',\n",
       " 'glasses',\n",
       " 'clarinets',\n",
       " 'an elderly woman',\n",
       " 'a stringed instrument',\n",
       " 'At least four instrumentalists',\n",
       " 'clarinets',\n",
       " 'other instruments',\n",
       " 'Four women',\n",
       " 'a musical instrument',\n",
       " 'A bunch of elderly women',\n",
       " 'their clarinets',\n",
       " 'sheet music',\n",
       " 'A group of four women',\n",
       " 'their instruments',\n",
       " 'A person',\n",
       " 'gray',\n",
       " 'a structure',\n",
       " 'A large structure',\n",
       " 'a roadway',\n",
       " 'A man',\n",
       " 'a gray coat',\n",
       " 'a washed out bridge',\n",
       " 'A man',\n",
       " 'wooden supports',\n",
       " 'A man',\n",
       " 'a jacket',\n",
       " 'jeans',\n",
       " 'a bridge',\n",
       " 'A man',\n",
       " 'a white t-shirt',\n",
       " 'a crowd',\n",
       " 'A large crowd of people',\n",
       " 'A group of people',\n",
       " 'A crowd',\n",
       " 'Crowd',\n",
       " 'A man',\n",
       " 'a goatee',\n",
       " 'a black shirt',\n",
       " 'white latex gloves',\n",
       " 'a tattoo gun',\n",
       " 'a tattoo',\n",
       " \"someone 's back\",\n",
       " 'A man',\n",
       " 'a tattoo',\n",
       " \"a another 's man\",\n",
       " 'A man',\n",
       " 'a black shirt',\n",
       " 'another man',\n",
       " 'a tattoo',\n",
       " 'A man',\n",
       " 'tattoo',\n",
       " 'his back',\n",
       " 'A man',\n",
       " 'a tattoo',\n",
       " 'his back',\n",
       " 'two children',\n",
       " 'a girl',\n",
       " 'a boy',\n",
       " 'Two children',\n",
       " 'a small seesaw',\n",
       " 'the sand',\n",
       " 'Two children',\n",
       " 'a teeter totter',\n",
       " '2 kids',\n",
       " 'a seesaw',\n",
       " 'Two kids',\n",
       " 'a seesaw',\n",
       " 'A man',\n",
       " 'a blue hard hat',\n",
       " 'orange safety vest',\n",
       " 'an intersection',\n",
       " 'a flag',\n",
       " 'A man',\n",
       " 'a hard hat',\n",
       " 'a caution vest',\n",
       " 'the street',\n",
       " 'an orange flag',\n",
       " 'A man',\n",
       " 'bright vest',\n",
       " 'hard hat',\n",
       " 'a flag',\n",
       " 'a street corner',\n",
       " 'spray paint',\n",
       " 'A construction worker',\n",
       " 'the street',\n",
       " 'a red flag',\n",
       " 'A man',\n",
       " 'a reflective vest',\n",
       " 'a hard hat',\n",
       " 'a flag',\n",
       " 'the road',\n",
       " 'A person',\n",
       " 'long gray hair',\n",
       " 'a beret',\n",
       " 'beige and white',\n",
       " 'a blue raincoat',\n",
       " 'other artists',\n",
       " 'paintings',\n",
       " 'A person',\n",
       " 'a blue coat',\n",
       " 'a busy sidewalk',\n",
       " 'painting of a street scene',\n",
       " 'A person',\n",
       " 'gray hair',\n",
       " 'a public place',\n",
       " 'others',\n",
       " 'Lady',\n",
       " 'blue coat',\n",
       " 'white and brown hat',\n",
       " 'a painting',\n",
       " 'Passerby',\n",
       " 'painting',\n",
       " 'an outdoor art fair',\n",
       " 'A man',\n",
       " 'one foot',\n",
       " 'a waste basket',\n",
       " 'A man',\n",
       " 'green pants',\n",
       " 'blue shirt',\n",
       " 'a cart',\n",
       " 'Janitor',\n",
       " 'dolly',\n",
       " 'janitor tools',\n",
       " 'A man',\n",
       " 'green pants',\n",
       " 'the road',\n",
       " 'A man',\n",
       " 'bright pants',\n",
       " 'a cart',\n",
       " 'A small child',\n",
       " 'the red ropes',\n",
       " 'A little girl',\n",
       " 'pink',\n",
       " 'a rope bridge',\n",
       " 'The small child',\n",
       " 'a red',\n",
       " 'A little girl',\n",
       " 'red roping',\n",
       " 'A child',\n",
       " 'a rope net',\n",
       " 'Young man',\n",
       " 'jacket',\n",
       " 'a toothpick',\n",
       " 'something',\n",
       " 'A young man',\n",
       " 'a piece of flower',\n",
       " 'his hands',\n",
       " 'A teen',\n",
       " 'an unknown object',\n",
       " 'A young man',\n",
       " 'an origami crane',\n",
       " 'Young blond man',\n",
       " 'a blue and yellow jacket',\n",
       " 'a net',\n",
       " 'A young man',\n",
       " 'a black and yellow jacket',\n",
       " 'A young man',\n",
       " 'a pole vault',\n",
       " 'A man',\n",
       " 'a pole',\n",
       " 'A smiling man',\n",
       " 'the sky',\n",
       " 'A man',\n",
       " 'a baseball cap',\n",
       " 'black jacket',\n",
       " 'a coffee mug',\n",
       " 'A man',\n",
       " 'a ball cap',\n",
       " 'a coffee cup',\n",
       " 'urinals',\n",
       " 'a man',\n",
       " 'a urinal',\n",
       " 'a cup of coffee',\n",
       " 'A man',\n",
       " 'a coffee cup',\n",
       " 'A man',\n",
       " 'a urinal',\n",
       " 'a coffee cup',\n",
       " 'Five people',\n",
       " 'Four people',\n",
       " 'clear blue skies',\n",
       " 'Four people',\n",
       " 'the sun',\n",
       " 'Four silhouettes',\n",
       " 'A group of people',\n",
       " 'the sun',\n",
       " 'A man',\n",
       " 'black hair',\n",
       " 'a glass of beer',\n",
       " 'A man',\n",
       " 'a table',\n",
       " 'a drink',\n",
       " 'A man',\n",
       " 'a table',\n",
       " 'a beer',\n",
       " 'A dark-haired man',\n",
       " 'A old man',\n",
       " 'a beer',\n",
       " 'An officer',\n",
       " 'a reflective vest',\n",
       " 'the front of his van',\n",
       " 'his dog',\n",
       " 'A trained police dog',\n",
       " 'his handler',\n",
       " 'the police van',\n",
       " 'A security man',\n",
       " 'his watch dog',\n",
       " 'A policeman',\n",
       " 'a German Shepherd dog',\n",
       " 'A policeman',\n",
       " 'a street',\n",
       " 'a search dog',\n",
       " 'The \" white out \" conditions of snow',\n",
       " 'the details of a man',\n",
       " 'a heavy jacket',\n",
       " 'red hat',\n",
       " 'a bicycle',\n",
       " 'A young boy',\n",
       " 'a bike',\n",
       " 'a snow',\n",
       " 'A boy',\n",
       " 'the snow',\n",
       " 'his bike',\n",
       " 'A person',\n",
       " 'a bike',\n",
       " 'a snowy road',\n",
       " 'A person',\n",
       " 'a bike',\n",
       " 'snow',\n",
       " 'Five men',\n",
       " 'white shirts',\n",
       " 'tie',\n",
       " 'black slacks',\n",
       " 'the back of an open van',\n",
       " 'small group of 5 white males',\n",
       " 'white suits',\n",
       " 'the back of a van',\n",
       " 'a parking lot',\n",
       " 'Five men',\n",
       " 'white short-sleeved shirts',\n",
       " 'ties',\n",
       " 'a parking lot',\n",
       " 'A group of men',\n",
       " 'ties',\n",
       " 'the street',\n",
       " 'Colleges stop',\n",
       " 'A tan man',\n",
       " 'hat',\n",
       " 'Older man',\n",
       " 'A man',\n",
       " 'a white shirt',\n",
       " 'black camp',\n",
       " 'many machines',\n",
       " 'A man',\n",
       " 'hat',\n",
       " 'machinery',\n",
       " 'A man',\n",
       " 'a backwards cap',\n",
       " 'A caucasian man',\n",
       " 'a short-sleeved black shirt',\n",
       " 'a dark-skinned woman',\n",
       " 'a sleeveless dress',\n",
       " 'a conveyor',\n",
       " 'A black woman',\n",
       " 'a white man',\n",
       " 'packing jars',\n",
       " 'candles',\n",
       " 'boxes',\n",
       " 'A woman',\n",
       " 'white tall candles',\n",
       " 'a man',\n",
       " 'a green shirt',\n",
       " 'A warehouse manager',\n",
       " 'an employee',\n",
       " 'Two people',\n",
       " 'an assembly line',\n",
       " 'Man',\n",
       " 'a blue and white outfit',\n",
       " 'a broom',\n",
       " 'a traditional Asian architecture',\n",
       " 'A Asian man',\n",
       " 'a white top',\n",
       " 'baby blue bottoms',\n",
       " 'a broom',\n",
       " 'the dirt of the pavement',\n",
       " 'A man',\n",
       " 'a white and blue kimono',\n",
       " 'a broom',\n",
       " 'pavement',\n",
       " 'Man',\n",
       " 'the street',\n",
       " 'Asian man',\n",
       " 'the walkway',\n",
       " 'two men',\n",
       " 'florescent vests',\n",
       " 'parked cars',\n",
       " 'a small building',\n",
       " 'a driver',\n",
       " 'a woman',\n",
       " 'a bike',\n",
       " 'A man',\n",
       " 'a car',\n",
       " 'the driver',\n",
       " 'a man',\n",
       " 'a bicycle',\n",
       " 'A man',\n",
       " 'a bicycle',\n",
       " 'a row of cars',\n",
       " 'a checkpoint',\n",
       " 'A park ranger',\n",
       " 'a tourist',\n",
       " 'Two cars',\n",
       " 'A little girl',\n",
       " 'a pink shirt',\n",
       " 'a little girl',\n",
       " 'an orange shirt',\n",
       " 'Two young children',\n",
       " 'a snack',\n",
       " 'Two young toddlers',\n",
       " 'Two infants',\n",
       " '2 female babies',\n",
       " 'chips',\n",
       " 'A person',\n",
       " 'tan pants',\n",
       " 'a silver mobile object',\n",
       " 'people',\n",
       " 'People',\n",
       " 'a person',\n",
       " 'a weird vehicle',\n",
       " 'A man',\n",
       " 'a blue shirt',\n",
       " 'a Segway type vehicle',\n",
       " 'a showing of product',\n",
       " 'A crowd',\n",
       " 'modern art',\n",
       " 'A man',\n",
       " 'a strange silver object',\n",
       " 'a person',\n",
       " 'many onlookers',\n",
       " 'a roped off barrier',\n",
       " 'A person',\n",
       " 'a futuristic looking vehicle',\n",
       " 'a man',\n",
       " 'a crowd',\n",
       " 'A person',\n",
       " 'a futuristic single-person vehicle',\n",
       " 'man',\n",
       " 'silver 4-wheeled chair',\n",
       " 'A man',\n",
       " 'a silver vehicle',\n",
       " 'bride',\n",
       " 'groom',\n",
       " 'pathway',\n",
       " 'brick building',\n",
       " 'A beautiful bride',\n",
       " 'a sidewalk',\n",
       " 'her new husband',\n",
       " 'A recently married couple',\n",
       " 'A groom',\n",
       " 'bride',\n",
       " 'A couple',\n",
       " 'A little boy',\n",
       " 'a Nintendo GameCube controller',\n",
       " 'a McDonald',\n",
       " 'A young boy',\n",
       " 'a video game',\n",
       " 'A young boy',\n",
       " 'a GameCube kiosk',\n",
       " 'McDonald',\n",
       " 'A little boy',\n",
       " 'GameCube',\n",
       " 'a McDonald',\n",
       " 'A little kid',\n",
       " 'GameCube',\n",
       " 'McDonald',\n",
       " 'White dog',\n",
       " 'brown ears',\n",
       " 'water',\n",
       " 'head',\n",
       " 'Dog',\n",
       " 'orange ball',\n",
       " 'feet',\n",
       " 'shore',\n",
       " 'water',\n",
       " 'A white dog',\n",
       " 'the edge of a beach',\n",
       " 'an orange ball',\n",
       " 'White dog',\n",
       " 'a red ball',\n",
       " 'the shore',\n",
       " 'the water',\n",
       " 'A dog',\n",
       " 'its head',\n",
       " 'the shore',\n",
       " 'a red ball',\n",
       " 'A group of people',\n",
       " 'picnic tables',\n",
       " 'A group of people',\n",
       " 'A group of people',\n",
       " 'The reunion',\n",
       " 'a moon bounce',\n",
       " 'A group of people',\n",
       " 'Two asian or spanish people',\n",
       " 'a woman',\n",
       " 'a man',\n",
       " 'a glass window',\n",
       " 'cars',\n",
       " 'A man',\n",
       " 'sunglasses',\n",
       " 'a woman',\n",
       " 'a black and white blouse',\n",
       " 'A man',\n",
       " 'sunglasses',\n",
       " 'a woman',\n",
       " 'A man',\n",
       " 'woman',\n",
       " 'An Asian couple',\n",
       " 'the bench',\n",
       " 'Women',\n",
       " 'a picnic table',\n",
       " 'a man',\n",
       " 'a white t-shirt',\n",
       " 'a yellow and orange balloon design',\n",
       " 'his head',\n",
       " 'An elderly woman',\n",
       " 'a burger',\n",
       " 'the man',\n",
       " 'his hat',\n",
       " 'A man',\n",
       " 'a balloon hat',\n",
       " 'people',\n",
       " 'picnic tables',\n",
       " 'Two older women',\n",
       " 'a table',\n",
       " 'two coolers',\n",
       " 'A gray-haired person',\n",
       " 'glasses',\n",
       " 'a sandwich',\n",
       " 'Two people',\n",
       " 'a crowd',\n",
       " 'three youngsters',\n",
       " 'the mat',\n",
       " 'A boy',\n",
       " 'three kids',\n",
       " 'wood',\n",
       " 'A boy',\n",
       " 'three other students',\n",
       " 'A crowd',\n",
       " 'a group of five martial artists',\n",
       " 'A crowd of people',\n",
       " 'People',\n",
       " 'two balconies',\n",
       " 'a man',\n",
       " 'a pipe',\n",
       " 'the lower balcony',\n",
       " 'liquid',\n",
       " 'A kid',\n",
       " 'a red sweatshirt',\n",
       " 'something',\n",
       " 'a man',\n",
       " 'a white shirt',\n",
       " 'A young boy',\n",
       " 'a bottle',\n",
       " 'the railing of a balcony',\n",
       " 'the man',\n",
       " 'a boy',\n",
       " 'a red jacket',\n",
       " 'water',\n",
       " 'a man',\n",
       " 'a white shirt',\n",
       " 'A young man',\n",
       " 'the contents of a bottle',\n",
       " 'A man',\n",
       " 'a red jacket',\n",
       " 'a piece of paper',\n",
       " 'a man',\n",
       " 'a red coat',\n",
       " 'his hand',\n",
       " 'his head',\n",
       " 'A man',\n",
       " 'a red jacket',\n",
       " 'his eyes',\n",
       " 'a busy street',\n",
       " 'An elderly man',\n",
       " 'a red jacket',\n",
       " 'his face',\n",
       " 'Man',\n",
       " 'red jacket',\n",
       " 'face',\n",
       " 'Two men',\n",
       " 'children',\n",
       " 'the street',\n",
       " 'Two men',\n",
       " 'each',\n",
       " 'a small child',\n",
       " 'a paved road',\n",
       " 'Two men',\n",
       " 'their two young children',\n",
       " 'Men',\n",
       " 'a street',\n",
       " 'children',\n",
       " 'Two men',\n",
       " 'children',\n",
       " 'Smiling boy',\n",
       " 'white shirt',\n",
       " 'blue jeans',\n",
       " 'rock wall',\n",
       " 'man',\n",
       " 'overalls',\n",
       " 'A little boy',\n",
       " 'the street',\n",
       " 'a man',\n",
       " 'overalls',\n",
       " 'a stone wall',\n",
       " 'A young child',\n",
       " 'a stone paved street',\n",
       " 'a metal pole',\n",
       " 'a man',\n",
       " 'A boy',\n",
       " 'a stony wall',\n",
       " 'A young boy',\n",
       " 'the street',\n",
       " 'A mottled black and gray dog',\n",
       " 'a blue collar',\n",
       " 'a fallen tree',\n",
       " 'A gray dog',\n",
       " 'a fallen tree',\n",
       " 'A large black dog',\n",
       " 'a fallen log',\n",
       " 'The black dog',\n",
       " 'the tree stump',\n",
       " 'A black dog',\n",
       " 'a log',\n",
       " 'Men',\n",
       " 'the business suits',\n",
       " 'the street',\n",
       " 'people',\n",
       " 'placards',\n",
       " 'the street',\n",
       " 'A man',\n",
       " 'a suit',\n",
       " 'an intersection',\n",
       " 'a large group of people assembles',\n",
       " 'A man',\n",
       " 'a suit',\n",
       " 'two other gentleman',\n",
       " 'a suit',\n",
       " 'A man',\n",
       " 'a suit',\n",
       " 'the street',\n",
       " 'A man',\n",
       " 'a suit',\n",
       " 'the street',\n",
       " 'A man',\n",
       " 'a red long-sleeved shirt',\n",
       " 'a body of water',\n",
       " 'a bridge',\n",
       " 'A man',\n",
       " 'his bike',\n",
       " 'the bridge',\n",
       " 'the river',\n",
       " 'A man',\n",
       " 'red',\n",
       " 'a bicycle',\n",
       " 'a glass structure',\n",
       " 'Man',\n",
       " 'a red shirt',\n",
       " 'his bicycle',\n",
       " 'water',\n",
       " 'A man',\n",
       " 'a red shirt',\n",
       " 'his bicycle',\n",
       " 'A barefooted man',\n",
       " 'olive green shorts',\n",
       " 'hotdogs',\n",
       " 'a small propane grill',\n",
       " 'a blue plastic cup',\n",
       " 'A guy',\n",
       " 'shorts',\n",
       " 'a white t-shirt',\n",
       " 'a grill',\n",
       " 'hotdogs',\n",
       " 'A young man',\n",
       " 'sunglasses',\n",
       " 'a blue cup',\n",
       " 'a grill',\n",
       " 'sausages',\n",
       " 'A young man',\n",
       " 'a white shirt',\n",
       " 'hotdogs',\n",
       " 'a small grill',\n",
       " 'A man',\n",
       " 'his cup',\n",
       " 'hotdogs',\n",
       " 'The white and brown dog',\n",
       " 'the surface of the snow',\n",
       " 'a white and brown dog',\n",
       " 'a snow covered field',\n",
       " 'A brown and white dog',\n",
       " 'the snow',\n",
       " 'A dog',\n",
       " 'snow',\n",
       " 'A dog',\n",
       " 'the snow',\n",
       " 'Man',\n",
       " 'scooter',\n",
       " 'some of those',\n",
       " 'large crowd',\n",
       " 'A crowd',\n",
       " 'People',\n",
       " 'an older woman',\n",
       " 'A crowd of people',\n",
       " 'A crowd of people',\n",
       " 'A person',\n",
       " 'skis',\n",
       " 'framed pictures',\n",
       " 'the snow',\n",
       " 'A man',\n",
       " 'a hat',\n",
       " 'pictures',\n",
       " 'a skier',\n",
       " 'a blue hat',\n",
       " 'A man',\n",
       " 'another man',\n",
       " 'paintings',\n",
       " 'the snow',\n",
       " 'A skier',\n",
       " 'framed pictures',\n",
       " 'the snow',\n",
       " 'trees',\n",
       " 'Man',\n",
       " 'skis',\n",
       " 'artwork',\n",
       " 'the snow',\n",
       " 'Several climbers',\n",
       " 'the rock',\n",
       " 'the man',\n",
       " 'red',\n",
       " 'the line',\n",
       " 'Seven climbers',\n",
       " 'a rock face',\n",
       " 'another man',\n",
       " 'the rope',\n",
       " 'A group of people',\n",
       " 'a rock climbing wall',\n",
       " 'A group of people',\n",
       " 'a rock',\n",
       " 'one man',\n",
       " 'A collage of one person',\n",
       " 'a cliff',\n",
       " 'A young gymnast',\n",
       " 'a balance beam',\n",
       " 'A woman',\n",
       " 'an orange leotard',\n",
       " 'gymnastics',\n",
       " 'an audience',\n",
       " 'A gymnast',\n",
       " 'the balance beam',\n",
       " 'an audience',\n",
       " \"The young gymnast 's supple body\",\n",
       " 'the balance beam',\n",
       " 'A gymnast',\n",
       " 'the balance beam',\n",
       " 'a boy',\n",
       " 'a black t-shirt',\n",
       " 'blue jeans',\n",
       " 'a toy',\n",
       " 'three wheeler',\n",
       " 'a small pool',\n",
       " 'A young boy',\n",
       " 'a toy ATV',\n",
       " 'a rubber pool',\n",
       " 'a boy',\n",
       " 'a red toy',\n",
       " 'a pool',\n",
       " 'A boy',\n",
       " 'a miniature car',\n",
       " 'a lawn',\n",
       " 'A young boy',\n",
       " 'his toy quad',\n",
       " 'a woman',\n",
       " 'a red jacket',\n",
       " 'headscarf',\n",
       " 'over a scenic view of a bay',\n",
       " 'a set of pay binoculars',\n",
       " 'A woman',\n",
       " 'a headscarf',\n",
       " 'a window',\n",
       " 'a mounted telescope',\n",
       " 'Woman',\n",
       " 'red windbreaker',\n",
       " 'a rooftop',\n",
       " 'A woman',\n",
       " 'a headscarf',\n",
       " 'a telescope',\n",
       " 'bay',\n",
       " 'A Woman',\n",
       " 'a telescope',\n",
       " 'a red coat',\n",
       " 'A man',\n",
       " 'a black coat',\n",
       " 'a red spaceship',\n",
       " 'a parking ticket',\n",
       " 'its window',\n",
       " 'A man',\n",
       " 'a small red object',\n",
       " 'a plane',\n",
       " 'A man',\n",
       " 'a black jacket',\n",
       " 'the street',\n",
       " 'A man',\n",
       " 'a black jacket',\n",
       " 'a street',\n",
       " 'Man',\n",
       " 'black coat',\n",
       " 'airplane nose',\n",
       " 'Large brown dog',\n",
       " 'the sprinkler',\n",
       " 'the grass',\n",
       " 'A brown dog',\n",
       " 'the water',\n",
       " 'a sprinkler',\n",
       " 'a lawn',\n",
       " 'A brown dog',\n",
       " 'a lawn',\n",
       " 'a garden hose',\n",
       " 'a brown dog',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "corpus_list = train_df[\"entity_content\"].values.tolist()\n",
    "corpus_list = ['EMPTYWORDTOKEN', 'UNKNOWNWORD'] + corpus_list  # 'EMPTYWORDTOKEN' is the token for empty word. It is needed because the input data for word embedding layer require padding. \n",
    "corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.STEMMING:\n",
    "    corpus = [[stemmer.stem(w) for w in word_tokenize(q)] for q in corpus_list]\n",
    "else: \n",
    "    corpus = [[w.lower() for w in word_tokenize(q)] for q in corpus_list]\n",
    "# corpus is a list of list of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413629"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emptywordtoken']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknownword']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus_dct = gensim.corpora.Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token2id': {'emptywordtoken': 0,\n",
       "  'unknownword': 1,\n",
       "  'guys': 2,\n",
       "  'two': 3,\n",
       "  'young': 4,\n",
       "  'hair': 5,\n",
       "  'shaggy': 6,\n",
       "  'hands': 7,\n",
       "  'their': 8,\n",
       "  ',': 9,\n",
       "  'males': 10,\n",
       "  'white': 11,\n",
       "  'bushes': 12,\n",
       "  'many': 13,\n",
       "  'men': 14,\n",
       "  'green': 15,\n",
       "  'shirts': 16,\n",
       "  'a': 17,\n",
       "  'man': 18,\n",
       "  'blue': 19,\n",
       "  'shirt': 20,\n",
       "  'friends': 21,\n",
       "  'several': 22,\n",
       "  'hard': 23,\n",
       "  'hats': 24,\n",
       "  'giant': 25,\n",
       "  'pulley': 26,\n",
       "  'system': 27,\n",
       "  'workers': 28,\n",
       "  'equipment': 29,\n",
       "  'of': 30,\n",
       "  'piece': 31,\n",
       "  'machine': 32,\n",
       "  'four': 33,\n",
       "  'structure': 34,\n",
       "  'tall': 35,\n",
       "  'three': 36,\n",
       "  'large': 37,\n",
       "  'rig': 38,\n",
       "  'child': 39,\n",
       "  'dress': 40,\n",
       "  'pink': 41,\n",
       "  'set': 42,\n",
       "  'stairs': 43,\n",
       "  'an': 44,\n",
       "  'entry': 45,\n",
       "  'way': 46,\n",
       "  'girl': 47,\n",
       "  'little': 48,\n",
       "  'the': 49,\n",
       "  'her': 50,\n",
       "  'playhouse': 51,\n",
       "  'wooden': 52,\n",
       "  'someone': 53,\n",
       "  'hat': 54,\n",
       "  'stair': 55,\n",
       "  'window': 56,\n",
       "  'ladder': 57,\n",
       "  'building': 58,\n",
       "  'jeans': 59,\n",
       "  'windows': 60,\n",
       "  'one': 61,\n",
       "  'gray': 62,\n",
       "  'black': 63,\n",
       "  'stove': 64,\n",
       "  'guy': 65,\n",
       "  'food': 66,\n",
       "  'meal': 67,\n",
       "  'people': 68,\n",
       "  'guitar': 69,\n",
       "  'other': 70,\n",
       "  'his': 71,\n",
       "  'costume': 72,\n",
       "  'players': 73,\n",
       "  \"'s\": 74,\n",
       "  'another': 75,\n",
       "  'coat': 76,\n",
       "  'boys': 77,\n",
       "  'chair': 78,\n",
       "  'animal': 79,\n",
       "  'lion': 80,\n",
       "  'stuffed': 81,\n",
       "  'finishing': 82,\n",
       "  'touches': 83,\n",
       "  'toy': 84,\n",
       "  'rollerskates': 85,\n",
       "  'cellphone': 86,\n",
       "  'lot': 87,\n",
       "  'parking': 88,\n",
       "  'trendy': 89,\n",
       "  'street': 90,\n",
       "  'adult': 91,\n",
       "  'rollerblades': 92,\n",
       "  'cellular': 93,\n",
       "  'phone': 94,\n",
       "  'skating': 95,\n",
       "  'woman': 96,\n",
       "  'asian': 97,\n",
       "  'suit': 98,\n",
       "  'dark-haired': 99,\n",
       "  'brown-haired': 100,\n",
       "  'pipes': 101,\n",
       "  'metal': 102,\n",
       "  'railing': 103,\n",
       "  'hip': 104,\n",
       "  'outfits': 105,\n",
       "  'purse': 106,\n",
       "  'gate': 107,\n",
       "  'rail': 108,\n",
       "  'youths': 109,\n",
       "  'roadside': 110,\n",
       "  'poles': 111,\n",
       "  'no': 112,\n",
       "  'ballet': 113,\n",
       "  'dancers': 114,\n",
       "  'five': 115,\n",
       "  'girls': 116,\n",
       "  'feet': 117,\n",
       "  'class': 118,\n",
       "  'sneakers': 119,\n",
       "  'flight': 120,\n",
       "  'top': 121,\n",
       "  'casually': 122,\n",
       "  'dressed': 123,\n",
       "  'stone': 124,\n",
       "  'wall': 125,\n",
       "  'staircase': 126,\n",
       "  'excited': 127,\n",
       "  'faces': 128,\n",
       "  'dog': 129,\n",
       "  'brown': 130,\n",
       "  'spots': 131,\n",
       "  'tri-colored': 132,\n",
       "  'road': 133,\n",
       "  'breeds': 134,\n",
       "  'different': 135,\n",
       "  'dogs': 136,\n",
       "  'pavement': 137,\n",
       "  'spotted': 138,\n",
       "  'clothes': 139,\n",
       "  'reflective': 140,\n",
       "  'safety': 141,\n",
       "  'ear': 142,\n",
       "  'protection': 143,\n",
       "  'deere': 144,\n",
       "  'john': 145,\n",
       "  'tractor': 146,\n",
       "  'driver': 147,\n",
       "  'clothing': 148,\n",
       "  'easy': 149,\n",
       "  'see': 150,\n",
       "  'to': 151,\n",
       "  'orange': 152,\n",
       "  'uniform': 153,\n",
       "  'headphones': 154,\n",
       "  'paved': 155,\n",
       "  'main': 156,\n",
       "  'some': 157,\n",
       "  'women': 158,\n",
       "  'buildings': 159,\n",
       "  'group': 160,\n",
       "  'dark': 161,\n",
       "  'glasses': 162,\n",
       "  'powder': 163,\n",
       "  'cake': 164,\n",
       "  'sifter': 165,\n",
       "  'lady': 166,\n",
       "  'powdered': 167,\n",
       "  'sugar': 168,\n",
       "  'bundt': 169,\n",
       "  'sprinkles': 170,\n",
       "  'jacket': 171,\n",
       "  'chocolate': 172,\n",
       "  'standing': 173,\n",
       "  'pan': 174,\n",
       "  'small': 175,\n",
       "  'grass': 176,\n",
       "  'fingerpaints': 177,\n",
       "  'canvas': 178,\n",
       "  'rainbow': 179,\n",
       "  'paint': 180,\n",
       "  'painted': 181,\n",
       "  'bowl': 182,\n",
       "  'pigtails': 183,\n",
       "  'painting': 184,\n",
       "  'bench': 185,\n",
       "  'and': 186,\n",
       "  'leash': 187,\n",
       "  'shirtless': 188,\n",
       "  'park': 189,\n",
       "  'adults': 190,\n",
       "  'chairs': 191,\n",
       "  'circle': 192,\n",
       "  'instruments': 193,\n",
       "  'musical': 194,\n",
       "  'type': 195,\n",
       "  'musicians': 196,\n",
       "  'music': 197,\n",
       "  'sheet': 198,\n",
       "  'flutes': 199,\n",
       "  'clarinets': 200,\n",
       "  'elderly': 201,\n",
       "  'instrument': 202,\n",
       "  'stringed': 203,\n",
       "  'at': 204,\n",
       "  'instrumentalists': 205,\n",
       "  'least': 206,\n",
       "  'bunch': 207,\n",
       "  'person': 208,\n",
       "  'roadway': 209,\n",
       "  'bridge': 210,\n",
       "  'out': 211,\n",
       "  'washed': 212,\n",
       "  'supports': 213,\n",
       "  't-shirt': 214,\n",
       "  'crowd': 215,\n",
       "  'goatee': 216,\n",
       "  'gloves': 217,\n",
       "  'latex': 218,\n",
       "  'gun': 219,\n",
       "  'tattoo': 220,\n",
       "  'back': 221,\n",
       "  'children': 222,\n",
       "  'boy': 223,\n",
       "  'seesaw': 224,\n",
       "  'sand': 225,\n",
       "  'teeter': 226,\n",
       "  'totter': 227,\n",
       "  '2': 228,\n",
       "  'kids': 229,\n",
       "  'vest': 230,\n",
       "  'intersection': 231,\n",
       "  'flag': 232,\n",
       "  'caution': 233,\n",
       "  'bright': 234,\n",
       "  'corner': 235,\n",
       "  'spray': 236,\n",
       "  'construction': 237,\n",
       "  'worker': 238,\n",
       "  'red': 239,\n",
       "  'long': 240,\n",
       "  'beret': 241,\n",
       "  'beige': 242,\n",
       "  'raincoat': 243,\n",
       "  'artists': 244,\n",
       "  'paintings': 245,\n",
       "  'busy': 246,\n",
       "  'sidewalk': 247,\n",
       "  'scene': 248,\n",
       "  'place': 249,\n",
       "  'public': 250,\n",
       "  'others': 251,\n",
       "  'passerby': 252,\n",
       "  'art': 253,\n",
       "  'fair': 254,\n",
       "  'outdoor': 255,\n",
       "  'foot': 256,\n",
       "  'basket': 257,\n",
       "  'waste': 258,\n",
       "  'pants': 259,\n",
       "  'cart': 260,\n",
       "  'janitor': 261,\n",
       "  'dolly': 262,\n",
       "  'tools': 263,\n",
       "  'ropes': 264,\n",
       "  'rope': 265,\n",
       "  'roping': 266,\n",
       "  'net': 267,\n",
       "  'toothpick': 268,\n",
       "  'something': 269,\n",
       "  'flower': 270,\n",
       "  'teen': 271,\n",
       "  'object': 272,\n",
       "  'unknown': 273,\n",
       "  'crane': 274,\n",
       "  'origami': 275,\n",
       "  'blond': 276,\n",
       "  'yellow': 277,\n",
       "  'pole': 278,\n",
       "  'vault': 279,\n",
       "  'smiling': 280,\n",
       "  'sky': 281,\n",
       "  'baseball': 282,\n",
       "  'cap': 283,\n",
       "  'coffee': 284,\n",
       "  'mug': 285,\n",
       "  'ball': 286,\n",
       "  'cup': 287,\n",
       "  'urinals': 288,\n",
       "  'urinal': 289,\n",
       "  'clear': 290,\n",
       "  'skies': 291,\n",
       "  'sun': 292,\n",
       "  'silhouettes': 293,\n",
       "  'beer': 294,\n",
       "  'glass': 295,\n",
       "  'table': 296,\n",
       "  'drink': 297,\n",
       "  'old': 298,\n",
       "  'officer': 299,\n",
       "  'front': 300,\n",
       "  'van': 301,\n",
       "  'police': 302,\n",
       "  'trained': 303,\n",
       "  'handler': 304,\n",
       "  'security': 305,\n",
       "  'watch': 306,\n",
       "  'policeman': 307,\n",
       "  'german': 308,\n",
       "  'shepherd': 309,\n",
       "  'search': 310,\n",
       "  '``': 311,\n",
       "  'conditions': 312,\n",
       "  'snow': 313,\n",
       "  'details': 314,\n",
       "  'heavy': 315,\n",
       "  'bicycle': 316,\n",
       "  'bike': 317,\n",
       "  'snowy': 318,\n",
       "  'tie': 319,\n",
       "  'slacks': 320,\n",
       "  'open': 321,\n",
       "  '5': 322,\n",
       "  'suits': 323,\n",
       "  'short-sleeved': 324,\n",
       "  'ties': 325,\n",
       "  'colleges': 326,\n",
       "  'stop': 327,\n",
       "  'tan': 328,\n",
       "  'older': 329,\n",
       "  'camp': 330,\n",
       "  'machines': 331,\n",
       "  'machinery': 332,\n",
       "  'backwards': 333,\n",
       "  'caucasian': 334,\n",
       "  'dark-skinned': 335,\n",
       "  'sleeveless': 336,\n",
       "  'conveyor': 337,\n",
       "  'jars': 338,\n",
       "  'packing': 339,\n",
       "  'candles': 340,\n",
       "  'boxes': 341,\n",
       "  'manager': 342,\n",
       "  'warehouse': 343,\n",
       "  'employee': 344,\n",
       "  'assembly': 345,\n",
       "  'line': 346,\n",
       "  'outfit': 347,\n",
       "  'broom': 348,\n",
       "  'architecture': 349,\n",
       "  'traditional': 350,\n",
       "  'baby': 351,\n",
       "  'bottoms': 352,\n",
       "  'dirt': 353,\n",
       "  'kimono': 354,\n",
       "  'walkway': 355,\n",
       "  'florescent': 356,\n",
       "  'vests': 357,\n",
       "  'cars': 358,\n",
       "  'parked': 359,\n",
       "  'car': 360,\n",
       "  'row': 361,\n",
       "  'checkpoint': 362,\n",
       "  'ranger': 363,\n",
       "  'tourist': 364,\n",
       "  'snack': 365,\n",
       "  'toddlers': 366,\n",
       "  'infants': 367,\n",
       "  'babies': 368,\n",
       "  'female': 369,\n",
       "  'chips': 370,\n",
       "  'mobile': 371,\n",
       "  'silver': 372,\n",
       "  'vehicle': 373,\n",
       "  'weird': 374,\n",
       "  'segway': 375,\n",
       "  'product': 376,\n",
       "  'showing': 377,\n",
       "  'modern': 378,\n",
       "  'strange': 379,\n",
       "  'onlookers': 380,\n",
       "  'barrier': 381,\n",
       "  'off': 382,\n",
       "  'roped': 383,\n",
       "  'futuristic': 384,\n",
       "  'looking': 385,\n",
       "  'single-person': 386,\n",
       "  '4-wheeled': 387,\n",
       "  'bride': 388,\n",
       "  'groom': 389,\n",
       "  'pathway': 390,\n",
       "  'brick': 391,\n",
       "  'beautiful': 392,\n",
       "  'husband': 393,\n",
       "  'new': 394,\n",
       "  'couple': 395,\n",
       "  'married': 396,\n",
       "  'recently': 397,\n",
       "  'controller': 398,\n",
       "  'gamecube': 399,\n",
       "  'nintendo': 400,\n",
       "  'mcdonald': 401,\n",
       "  'game': 402,\n",
       "  'video': 403,\n",
       "  'kiosk': 404,\n",
       "  'kid': 405,\n",
       "  'ears': 406,\n",
       "  'water': 407,\n",
       "  'head': 408,\n",
       "  'shore': 409,\n",
       "  'beach': 410,\n",
       "  'edge': 411,\n",
       "  'its': 412,\n",
       "  'picnic': 413,\n",
       "  'tables': 414,\n",
       "  'reunion': 415,\n",
       "  'bounce': 416,\n",
       "  'moon': 417,\n",
       "  'or': 418,\n",
       "  'spanish': 419,\n",
       "  'sunglasses': 420,\n",
       "  'blouse': 421,\n",
       "  'balloon': 422,\n",
       "  'design': 423,\n",
       "  'burger': 424,\n",
       "  'coolers': 425,\n",
       "  'gray-haired': 426,\n",
       "  'sandwich': 427,\n",
       "  'youngsters': 428,\n",
       "  'mat': 429,\n",
       "  'wood': 430,\n",
       "  'students': 431,\n",
       "  'martial': 432,\n",
       "  'balconies': 433,\n",
       "  'pipe': 434,\n",
       "  'balcony': 435,\n",
       "  'lower': 436,\n",
       "  'liquid': 437,\n",
       "  'sweatshirt': 438,\n",
       "  'bottle': 439,\n",
       "  'contents': 440,\n",
       "  'paper': 441,\n",
       "  'hand': 442,\n",
       "  'eyes': 443,\n",
       "  'face': 444,\n",
       "  'each': 445,\n",
       "  'rock': 446,\n",
       "  'overalls': 447,\n",
       "  'stony': 448,\n",
       "  'mottled': 449,\n",
       "  'collar': 450,\n",
       "  'fallen': 451,\n",
       "  'tree': 452,\n",
       "  'log': 453,\n",
       "  'stump': 454,\n",
       "  'business': 455,\n",
       "  'placards': 456,\n",
       "  'assembles': 457,\n",
       "  'gentleman': 458,\n",
       "  'long-sleeved': 459,\n",
       "  'body': 460,\n",
       "  'river': 461,\n",
       "  'barefooted': 462,\n",
       "  'olive': 463,\n",
       "  'shorts': 464,\n",
       "  'hotdogs': 465,\n",
       "  'grill': 466,\n",
       "  'propane': 467,\n",
       "  'plastic': 468,\n",
       "  'sausages': 469,\n",
       "  'surface': 470,\n",
       "  'covered': 471,\n",
       "  'field': 472,\n",
       "  'scooter': 473,\n",
       "  'those': 474,\n",
       "  'skis': 475,\n",
       "  'framed': 476,\n",
       "  'pictures': 477,\n",
       "  'skier': 478,\n",
       "  'trees': 479,\n",
       "  'artwork': 480,\n",
       "  'climbers': 481,\n",
       "  'seven': 482,\n",
       "  'climbing': 483,\n",
       "  'collage': 484,\n",
       "  'cliff': 485,\n",
       "  'gymnast': 486,\n",
       "  'balance': 487,\n",
       "  'beam': 488,\n",
       "  'leotard': 489,\n",
       "  'gymnastics': 490,\n",
       "  'audience': 491,\n",
       "  'supple': 492,\n",
       "  'wheeler': 493,\n",
       "  'pool': 494,\n",
       "  'atv': 495,\n",
       "  'rubber': 496,\n",
       "  'miniature': 497,\n",
       "  'lawn': 498,\n",
       "  'quad': 499,\n",
       "  'headscarf': 500,\n",
       "  'bay': 501,\n",
       "  'over': 502,\n",
       "  'scenic': 503,\n",
       "  'view': 504,\n",
       "  'binoculars': 505,\n",
       "  'pay': 506,\n",
       "  'mounted': 507,\n",
       "  'telescope': 508,\n",
       "  'windbreaker': 509,\n",
       "  'rooftop': 510,\n",
       "  'spaceship': 511,\n",
       "  'ticket': 512,\n",
       "  'plane': 513,\n",
       "  'airplane': 514,\n",
       "  'nose': 515,\n",
       "  'sprinkler': 516,\n",
       "  'garden': 517,\n",
       "  'hose': 518,\n",
       "  'daughter': 519,\n",
       "  'stroller': 520,\n",
       "  'thrown': 521,\n",
       "  'nearby': 522,\n",
       "  'mouth': 523,\n",
       "  'colored': 524,\n",
       "  'part': 525,\n",
       "  'booth': 526,\n",
       "  'restaurant': 527,\n",
       "  'sweater': 528,\n",
       "  'grassy': 529,\n",
       "  'hikers': 530,\n",
       "  'patch': 531,\n",
       "  'facial': 532,\n",
       "  'cabinet': 533,\n",
       "  'hutch': 534,\n",
       "  'doors': 535,\n",
       "  'long-sleeve': 536,\n",
       "  'middle-aged': 537,\n",
       "  'beard': 538,\n",
       "  'handmade': 539,\n",
       "  'creation': 540,\n",
       "  'floor': 541,\n",
       "  'father': 542,\n",
       "  'grown': 543,\n",
       "  'son': 544,\n",
       "  'camping': 545,\n",
       "  'living': 546,\n",
       "  'items': 547,\n",
       "  'bearded': 548,\n",
       "  'map': 549,\n",
       "  'traveler': 550,\n",
       "  'lake': 551,\n",
       "  'duck': 552,\n",
       "  'lone': 553,\n",
       "  'city': 554,\n",
       "  'skyline': 555,\n",
       "  'waters': 556,\n",
       "  'infant': 557,\n",
       "  'male': 558,\n",
       "  'pond': 559,\n",
       "  'side': 560,\n",
       "  'newborn': 561,\n",
       "  'shelter': 562,\n",
       "  'bicycles': 563,\n",
       "  'bikes': 564,\n",
       "  'curved': 565,\n",
       "  'roof': 566,\n",
       "  'tonight': 567,\n",
       "  'wagon': 568,\n",
       "  'dome': 569,\n",
       "  'station': 570,\n",
       "  'frolicks': 571,\n",
       "  'tags': 572,\n",
       "  'frozen': 573,\n",
       "  'ice': 574,\n",
       "  'hole': 575,\n",
       "  'soft': 576,\n",
       "  'sandy': 577,\n",
       "  'climber': 578,\n",
       "  'picks': 579,\n",
       "  'crampons': 580,\n",
       "  'waterfall': 581,\n",
       "  'ocean': 582,\n",
       "  'path': 583,\n",
       "  'attire': 584,\n",
       "  'shovels': 585,\n",
       "  'roads': 586,\n",
       "  'sidewalks': 587,\n",
       "  'slush': 588,\n",
       "  'wedding': 589,\n",
       "  'flowers': 590,\n",
       "  'wet': 591,\n",
       "  'item': 592,\n",
       "  'rows': 593,\n",
       "  'vegetables': 594,\n",
       "  'harvest': 595,\n",
       "  'vegetable': 596,\n",
       "  'blankets': 597,\n",
       "  'villagers': 598,\n",
       "  'crops': 599,\n",
       "  'onions': 600,\n",
       "  'very': 601,\n",
       "  'band': 602,\n",
       "  'singer': 603,\n",
       "  'tattoos': 604,\n",
       "  'microphone': 605,\n",
       "  'sign': 606,\n",
       "  '13': 607,\n",
       "  'lucky': 608,\n",
       "  'punk': 609,\n",
       "  'rocker': 610,\n",
       "  'blond-hair': 611,\n",
       "  'short': 612,\n",
       "  'striped': 613,\n",
       "  'skateboard': 614,\n",
       "  'this': 615,\n",
       "  'jackets': 616,\n",
       "  'life': 617,\n",
       "  'canoe': 618,\n",
       "  'kayak': 619,\n",
       "  'gentle': 620,\n",
       "  'big': 621,\n",
       "  'smile': 622,\n",
       "  'ladies': 623,\n",
       "  'site': 624,\n",
       "  'area': 625,\n",
       "  'light': 626,\n",
       "  'post': 627,\n",
       "  'younger': 628,\n",
       "  'luggage': 629,\n",
       "  'billboard': 630,\n",
       "  'suitcase': 631,\n",
       "  'prescription': 632,\n",
       "  'advertisement': 633,\n",
       "  'picture': 634,\n",
       "  'flags': 635,\n",
       "  'oriental': 636,\n",
       "  'outside': 637,\n",
       "  'waving': 638,\n",
       "  'cleaning': 639,\n",
       "  'fish': 640,\n",
       "  'cigarette': 641,\n",
       "  'match': 642,\n",
       "  'vendor': 643,\n",
       "  'sellers': 644,\n",
       "  'stock': 645,\n",
       "  'red-hair': 646,\n",
       "  'red-haired': 647,\n",
       "  'skirt': 648,\n",
       "  'tank': 649,\n",
       "  'college-aged': 650,\n",
       "  'individuals': 651,\n",
       "  'females': 652,\n",
       "  'concrete': 653,\n",
       "  'steps': 654,\n",
       "  'entrance': 655,\n",
       "  'outdoors': 656,\n",
       "  'multiple': 657,\n",
       "  'school': 658,\n",
       "  'snaps': 659,\n",
       "  'goal': 660,\n",
       "  'hockey': 661,\n",
       "  'stick': 662,\n",
       "  'right': 663,\n",
       "  'goalie': 664,\n",
       "  'rink': 665,\n",
       "  'backpack': 666,\n",
       "  'courtyard': 667,\n",
       "  'sculpture': 668,\n",
       "  'newspaper': 669,\n",
       "  'office': 670,\n",
       "  'statue': 671,\n",
       "  'toddler': 672,\n",
       "  'fenced': 673,\n",
       "  'patio': 674,\n",
       "  'bars': 675,\n",
       "  'me': 676,\n",
       "  'jail': 677,\n",
       "  'railings': 678,\n",
       "  'fence': 679,\n",
       "  'hill': 680,\n",
       "  'skyscraper': 681,\n",
       "  'matching': 682,\n",
       "  'turban': 683,\n",
       "  'african': 684,\n",
       "  'grocery': 685,\n",
       "  'stand': 686,\n",
       "  'fruits': 687,\n",
       "  'fruit': 688,\n",
       "  'produce': 689,\n",
       "  'band-aid': 690,\n",
       "  'plate': 691,\n",
       "  'blond-haired': 692,\n",
       "  'both': 693,\n",
       "  'treat': 694,\n",
       "  'pizza': 695,\n",
       "  'dish': 696,\n",
       "  'tin': 697,\n",
       "  'baked': 698,\n",
       "  'good': 699,\n",
       "  'wild': 700,\n",
       "  'center': 701,\n",
       "  'stage': 702,\n",
       "  'electric': 703,\n",
       "  'helmet': 704,\n",
       "  'bat': 705,\n",
       "  'tennis': 706,\n",
       "  'softball': 707,\n",
       "  'batter': 708,\n",
       "  'stickers': 709,\n",
       "  'long-haired': 710,\n",
       "  'musician': 711,\n",
       "  'artist': 712,\n",
       "  'black-colored': 713,\n",
       "  'dirty': 714,\n",
       "  'unfinished': 715,\n",
       "  'cement': 716,\n",
       "  'tape': 717,\n",
       "  'filler': 718,\n",
       "  'trench': 719,\n",
       "  'smoothing': 720,\n",
       "  'hooded': 721,\n",
       "  'dinner': 722,\n",
       "  'entrees': 723,\n",
       "  'martini': 724,\n",
       "  'dining': 725,\n",
       "  'fancy': 726,\n",
       "  'blanket': 727,\n",
       "  'cloudy': 728,\n",
       "  'solitary': 729,\n",
       "  'expression': 730,\n",
       "  'sad': 731,\n",
       "  'beans': 732,\n",
       "  'hilltop': 733,\n",
       "  'valley': 734,\n",
       "  'mountainside': 735,\n",
       "  'ledge': 736,\n",
       "  'moutains': 737,\n",
       "  'tourists': 738,\n",
       "  'walking': 739,\n",
       "  'footbridge': 740,\n",
       "  'tree-covered': 741,\n",
       "  'arched': 742,\n",
       "  'jersey': 743,\n",
       "  'rafts': 744,\n",
       "  'kayakers': 745,\n",
       "  'corn': 746,\n",
       "  'elder': 747,\n",
       "  'multiracial': 748,\n",
       "  'oboe': 749,\n",
       "  'purple': 750,\n",
       "  'percussion': 751,\n",
       "  'spectators': 752,\n",
       "  'bamboo': 753,\n",
       "  'bassoon': 754,\n",
       "  'wind': 755,\n",
       "  'bus': 756,\n",
       "  'material': 757,\n",
       "  'blank': 758,\n",
       "  'earphones': 759,\n",
       "  '30': 760,\n",
       "  'somethings': 761,\n",
       "  'bags': 762,\n",
       "  'shopping': 763,\n",
       "  'betty': 764,\n",
       "  'boop': 765,\n",
       "  'crosswalk': 766,\n",
       "  'numerous': 767,\n",
       "  'chinese': 768,\n",
       "  'six': 769,\n",
       "  'noddles': 770,\n",
       "  'asians': 771,\n",
       "  'assorted': 772,\n",
       "  'pineapples': 773,\n",
       "  'bananas': 774,\n",
       "  'papayas': 775,\n",
       "  'work': 776,\n",
       "  'shovel': 777,\n",
       "  'deep': 778,\n",
       "  'whole': 779,\n",
       "  'septic': 780,\n",
       "  '3': 781,\n",
       "  'american': 782,\n",
       "  'peers': 783,\n",
       "  'all': 784,\n",
       "  'bandanna': 785,\n",
       "  'graphic': 786,\n",
       "  'oblong': 787,\n",
       "  'smoke': 788,\n",
       "  'handkerchief': 789,\n",
       "  'tub': 790,\n",
       "  'steam': 791,\n",
       "  'vat': 792,\n",
       "  'pantaloons': 793,\n",
       "  'sleepy': 794,\n",
       "  'sleeping': 795,\n",
       "  'individual': 796,\n",
       "  'beads': 797,\n",
       "  'decorations': 798,\n",
       "  'native': 799,\n",
       "  'cobs': 800,\n",
       "  'necklaces': 801,\n",
       "  'shells': 802,\n",
       "  'member': 803,\n",
       "  'tribe': 804,\n",
       "  'tribal': 805,\n",
       "  'piercings': 806,\n",
       "  'lots': 807,\n",
       "  'jewelry': 808,\n",
       "  'samurai': 809,\n",
       "  'warrior': 810,\n",
       "  'full': 811,\n",
       "  'sword': 812,\n",
       "  'sheath': 813,\n",
       "  'training': 814,\n",
       "  'arts': 815,\n",
       "  'fighting': 816,\n",
       "  'gear': 817,\n",
       "  'wields': 818,\n",
       "  'hills': 819,\n",
       "  'rolling': 820,\n",
       "  'karate': 821,\n",
       "  'teens': 822,\n",
       "  'bed': 823,\n",
       "  'dried': 824,\n",
       "  'up': 825,\n",
       "  'rocks': 826,\n",
       "  'rocky': 827,\n",
       "  'walls': 828,\n",
       "  'dense': 829,\n",
       "  'forest': 830,\n",
       "  'riverbed': 831,\n",
       "  'creek': 832,\n",
       "  'cool': 833,\n",
       "  'scenery': 834,\n",
       "  'strewn': 835,\n",
       "  'stream': 836,\n",
       "  'badge': 837,\n",
       "  'guard': 838,\n",
       "  'white-haired': 839,\n",
       "  'colorful': 840,\n",
       "  'dresses': 841,\n",
       "  'indian': 842,\n",
       "  'saris': 843,\n",
       "  'separate': 844,\n",
       "  'flip-flops': 845,\n",
       "  'pair': 846,\n",
       "  'plants': 847,\n",
       "  'sandals': 848,\n",
       "  'phones': 849,\n",
       "  'shrubbery': 850,\n",
       "  'multicolored': 851,\n",
       "  'house': 852,\n",
       "  'home': 853,\n",
       "  'yard': 854,\n",
       "  'soccer': 855,\n",
       "  'backyard': 856,\n",
       "  'black-haired': 857,\n",
       "  'tile': 858,\n",
       "  'legos': 859,\n",
       "  'skateboarder': 860,\n",
       "  'board': 861,\n",
       "  'platform': 862,\n",
       "  'skateboarders': 863,\n",
       "  'teenager': 864,\n",
       "  'trolley': 865,\n",
       "  'mass': 866,\n",
       "  'transit': 867,\n",
       "  'talkie': 868,\n",
       "  'walkie': 869,\n",
       "  'family': 870,\n",
       "  'paddle': 871,\n",
       "  'splashes': 872,\n",
       "  'shallow': 873,\n",
       "  'surf': 874,\n",
       "  'sweaters': 875,\n",
       "  'khaki': 876,\n",
       "  'wine': 877,\n",
       "  'appetizers': 878,\n",
       "  'plates': 879,\n",
       "  'wineglasses': 880,\n",
       "  'rack': 881,\n",
       "  'elegant': 882,\n",
       "  'constructions': 883,\n",
       "  'seat': 884,\n",
       "  'steel': 885,\n",
       "  'i-beam': 886,\n",
       "  'mixer': 887,\n",
       "  'blender': 888,\n",
       "  'mud': 889,\n",
       "  'puddle': 890,\n",
       "  'pamphlet': 891,\n",
       "  'train': 892,\n",
       "  'book': 893,\n",
       "  'rides': 894,\n",
       "  'brochure': 895,\n",
       "  'ride': 896,\n",
       "  'magizine': 897,\n",
       "  'marathon': 898,\n",
       "  'joggers': 899,\n",
       "  'diving': 900,\n",
       "  'swimming': 901,\n",
       "  'high': 902,\n",
       "  'dive': 903,\n",
       "  'end': 904,\n",
       "  'light-colored': 905,\n",
       "  'only': 906,\n",
       "  'pale': 907,\n",
       "  'basin': 908,\n",
       "  'huge': 909,\n",
       "  'plaid': 910,\n",
       "  'about': 911,\n",
       "  'branches': 912,\n",
       "  'soldier': 913,\n",
       "  'belt': 914,\n",
       "  'pancake': 915,\n",
       "  'omelet': 916,\n",
       "  'skillet': 917,\n",
       "  'firefighters': 918,\n",
       "  'uniforms': 919,\n",
       "  'reflections': 920,\n",
       "  'firemen': 921,\n",
       "  'few': 922,\n",
       "  'firetruck': 923,\n",
       "  'firetrucks': 924,\n",
       "  'lights': 925,\n",
       "  'on-duty': 926,\n",
       "  'ceiling': 927,\n",
       "  'stripe': 928,\n",
       "  'yellow-and-black': 929,\n",
       "  'warning': 930,\n",
       "  'boots': 931,\n",
       "  'magazines': 932,\n",
       "  'candy': 933,\n",
       "  'coke-a-cola': 934,\n",
       "  'products': 935,\n",
       "  'counter': 936,\n",
       "  'magazine': 937,\n",
       "  'clerk': 938,\n",
       "  'newsstand': 939,\n",
       "  'merchandise': 940,\n",
       "  'earth': 941,\n",
       "  'moving': 942,\n",
       "  'track': 943,\n",
       "  'surveying': 944,\n",
       "  'dry': 945,\n",
       "  'jean': 946,\n",
       "  'fists': 947,\n",
       "  'dough': 948,\n",
       "  'bakery': 949,\n",
       "  'apprentice': 950,\n",
       "  'photo': 951,\n",
       "  'tired': 952,\n",
       "  'bread': 953,\n",
       "  'shade': 954,\n",
       "  'tropical': 955,\n",
       "  'trunks': 956,\n",
       "  'arms': 957,\n",
       "  'swim': 958,\n",
       "  'landscape': 959,\n",
       "  'hiker': 960,\n",
       "  'bluff': 961,\n",
       "  'mountains': 962,\n",
       "  'mountain': 963,\n",
       "  'snow-covered': 964,\n",
       "  'mountaintop': 965,\n",
       "  'mound': 966,\n",
       "  'hovel': 967,\n",
       "  'backhoe': 968,\n",
       "  'pile': 969,\n",
       "  'racing': 970,\n",
       "  'helmets': 971,\n",
       "  'puddles': 972,\n",
       "  'bicyclers': 973,\n",
       "  'wheels': 974,\n",
       "  'bikers': 975,\n",
       "  'riders': 976,\n",
       "  'middle': 977,\n",
       "  'cane': 978,\n",
       "  'bush': 979,\n",
       "  'short-sleeve': 980,\n",
       "  'surgeon': 981,\n",
       "  'scrubs': 982,\n",
       "  'teal': 983,\n",
       "  'doctor': 984,\n",
       "  'nurses': 985,\n",
       "  'staff': 986,\n",
       "  'surgical': 987,\n",
       "  'assistants': 988,\n",
       "  'team': 989,\n",
       "  'frisbee': 990,\n",
       "  'woolly': 991,\n",
       "  'doberman': 992,\n",
       "  'bowling': 993,\n",
       "  'lane': 994,\n",
       "  'pins': 995,\n",
       "  'balls': 996,\n",
       "  'cosmic': 997,\n",
       "  'imagery': 998,\n",
       "  'including': 999,\n",
       "  ...},\n",
       " 'id2token': {},\n",
       " 'dfs': {0: 1,\n",
       "  1: 1,\n",
       "  3: 19353,\n",
       "  4: 11942,\n",
       "  2: 601,\n",
       "  6: 45,\n",
       "  5: 1995,\n",
       "  8: 2776,\n",
       "  7: 1330,\n",
       "  9: 1322,\n",
       "  11: 11620,\n",
       "  10: 233,\n",
       "  13: 1110,\n",
       "  12: 81,\n",
       "  14: 8629,\n",
       "  15: 4470,\n",
       "  16: 839,\n",
       "  17: 214432,\n",
       "  18: 38854,\n",
       "  19: 10014,\n",
       "  20: 11839,\n",
       "  21: 364,\n",
       "  22: 1881,\n",
       "  23: 449,\n",
       "  24: 763,\n",
       "  25: 184,\n",
       "  26: 18,\n",
       "  27: 23,\n",
       "  28: 1015,\n",
       "  31: 643,\n",
       "  30: 20460,\n",
       "  29: 402,\n",
       "  32: 483,\n",
       "  33: 1972,\n",
       "  35: 381,\n",
       "  34: 296,\n",
       "  36: 5163,\n",
       "  37: 3988,\n",
       "  38: 9,\n",
       "  39: 4557,\n",
       "  41: 2555,\n",
       "  40: 1963,\n",
       "  42: 224,\n",
       "  43: 401,\n",
       "  44: 11746,\n",
       "  45: 8,\n",
       "  46: 40,\n",
       "  48: 4230,\n",
       "  47: 8601,\n",
       "  49: 34427,\n",
       "  50: 4901,\n",
       "  51: 16,\n",
       "  52: 887,\n",
       "  53: 626,\n",
       "  54: 3645,\n",
       "  55: 27,\n",
       "  56: 853,\n",
       "  57: 298,\n",
       "  58: 2436,\n",
       "  59: 1741,\n",
       "  60: 158,\n",
       "  61: 5034,\n",
       "  62: 1876,\n",
       "  63: 11030,\n",
       "  64: 83,\n",
       "  65: 1332,\n",
       "  66: 1363,\n",
       "  67: 202,\n",
       "  68: 15591,\n",
       "  69: 1816,\n",
       "  70: 2305,\n",
       "  71: 8939,\n",
       "  73: 1026,\n",
       "  72: 490,\n",
       "  75: 2315,\n",
       "  74: 1415,\n",
       "  76: 1192,\n",
       "  77: 1787,\n",
       "  78: 937,\n",
       "  81: 177,\n",
       "  79: 254,\n",
       "  80: 40,\n",
       "  82: 2,\n",
       "  83: 2,\n",
       "  84: 951,\n",
       "  85: 52,\n",
       "  86: 679,\n",
       "  88: 152,\n",
       "  87: 352,\n",
       "  89: 9,\n",
       "  90: 4224,\n",
       "  91: 438,\n",
       "  92: 64,\n",
       "  93: 15,\n",
       "  94: 506,\n",
       "  95: 16,\n",
       "  96: 20165,\n",
       "  97: 1961,\n",
       "  98: 1192,\n",
       "  99: 253,\n",
       "  100: 119,\n",
       "  101: 34,\n",
       "  102: 573,\n",
       "  103: 276,\n",
       "  104: 22,\n",
       "  105: 261,\n",
       "  106: 272,\n",
       "  107: 128,\n",
       "  108: 238,\n",
       "  109: 35,\n",
       "  110: 24,\n",
       "  111: 123,\n",
       "  112: 251,\n",
       "  115: 788,\n",
       "  113: 51,\n",
       "  114: 195,\n",
       "  116: 2291,\n",
       "  117: 248,\n",
       "  118: 123,\n",
       "  119: 105,\n",
       "  121: 1564,\n",
       "  120: 67,\n",
       "  122: 31,\n",
       "  123: 253,\n",
       "  124: 550,\n",
       "  125: 1935,\n",
       "  126: 120,\n",
       "  127: 41,\n",
       "  128: 189,\n",
       "  129: 8099,\n",
       "  130: 3951,\n",
       "  131: 27,\n",
       "  132: 10,\n",
       "  133: 1166,\n",
       "  136: 2080,\n",
       "  135: 231,\n",
       "  134: 4,\n",
       "  137: 128,\n",
       "  138: 44,\n",
       "  140: 99,\n",
       "  141: 346,\n",
       "  139: 674,\n",
       "  142: 107,\n",
       "  143: 29,\n",
       "  145: 25,\n",
       "  144: 16,\n",
       "  146: 129,\n",
       "  147: 118,\n",
       "  149: 2,\n",
       "  151: 25,\n",
       "  150: 2,\n",
       "  148: 897,\n",
       "  152: 2745,\n",
       "  153: 1025,\n",
       "  154: 208,\n",
       "  155: 103,\n",
       "  156: 23,\n",
       "  157: 2529,\n",
       "  158: 4853,\n",
       "  159: 361,\n",
       "  160: 7095,\n",
       "  161: 1061,\n",
       "  162: 1483,\n",
       "  163: 16,\n",
       "  164: 247,\n",
       "  165: 3,\n",
       "  166: 1870,\n",
       "  167: 4,\n",
       "  168: 5,\n",
       "  169: 2,\n",
       "  170: 3,\n",
       "  171: 3043,\n",
       "  172: 53,\n",
       "  173: 72,\n",
       "  174: 78,\n",
       "  175: 3140,\n",
       "  176: 1720,\n",
       "  177: 2,\n",
       "  178: 56,\n",
       "  179: 87,\n",
       "  180: 238,\n",
       "  181: 152,\n",
       "  182: 255,\n",
       "  183: 59,\n",
       "  184: 204,\n",
       "  185: 1547,\n",
       "  186: 5318,\n",
       "  187: 193,\n",
       "  188: 475,\n",
       "  189: 665,\n",
       "  190: 573,\n",
       "  191: 448,\n",
       "  192: 71,\n",
       "  195: 133,\n",
       "  194: 215,\n",
       "  193: 462,\n",
       "  196: 233,\n",
       "  198: 118,\n",
       "  197: 136,\n",
       "  199: 9,\n",
       "  200: 5,\n",
       "  201: 936,\n",
       "  203: 46,\n",
       "  202: 366,\n",
       "  204: 36,\n",
       "  206: 26,\n",
       "  205: 2,\n",
       "  207: 306,\n",
       "  208: 4008,\n",
       "  209: 21,\n",
       "  212: 2,\n",
       "  211: 19,\n",
       "  210: 460,\n",
       "  213: 5,\n",
       "  214: 1194,\n",
       "  215: 2549,\n",
       "  216: 32,\n",
       "  218: 13,\n",
       "  217: 336,\n",
       "  220: 180,\n",
       "  219: 176,\n",
       "  221: 632,\n",
       "  222: 3927,\n",
       "  223: 8383,\n",
       "  224: 21,\n",
       "  225: 820,\n",
       "  226: 10,\n",
       "  227: 10,\n",
       "  228: 394,\n",
       "  229: 1062,\n",
       "  230: 669,\n",
       "  231: 31,\n",
       "  232: 487,\n",
       "  233: 29,\n",
       "  234: 645,\n",
       "  235: 185,\n",
       "  236: 83,\n",
       "  237: 944,\n",
       "  238: 620,\n",
       "  239: 8808,\n",
       "  240: 1069,\n",
       "  241: 45,\n",
       "  242: 183,\n",
       "  243: 39,\n",
       "  244: 44,\n",
       "  245: 35,\n",
       "  246: 290,\n",
       "  247: 1880,\n",
       "  248: 67,\n",
       "  250: 156,\n",
       "  249: 33,\n",
       "  251: 592,\n",
       "  252: 13,\n",
       "  255: 371,\n",
       "  253: 239,\n",
       "  254: 27,\n",
       "  256: 191,\n",
       "  258: 3,\n",
       "  257: 270,\n",
       "  259: 1795,\n",
       "  260: 720,\n",
       "  261: 18,\n",
       "  262: 13,\n",
       "  263: 111,\n",
       "  264: 76,\n",
       "  265: 490,\n",
       "  266: 2,\n",
       "  267: 332,\n",
       "  268: 3,\n",
       "  269: 676,\n",
       "  270: 260,\n",
       "  271: 70,\n",
       "  273: 19,\n",
       "  272: 387,\n",
       "  275: 2,\n",
       "  274: 77,\n",
       "  276: 1437,\n",
       "  277: 3976,\n",
       "  278: 522,\n",
       "  279: 9,\n",
       "  280: 478,\n",
       "  281: 259,\n",
       "  282: 1102,\n",
       "  283: 950,\n",
       "  284: 235,\n",
       "  285: 40,\n",
       "  286: 3206,\n",
       "  287: 321,\n",
       "  288: 1,\n",
       "  289: 4,\n",
       "  290: 122,\n",
       "  291: 23,\n",
       "  292: 135,\n",
       "  293: 10,\n",
       "  295: 433,\n",
       "  294: 341,\n",
       "  296: 2422,\n",
       "  297: 371,\n",
       "  298: 1367,\n",
       "  299: 212,\n",
       "  300: 207,\n",
       "  301: 163,\n",
       "  303: 1,\n",
       "  302: 436,\n",
       "  304: 6,\n",
       "  305: 82,\n",
       "  306: 50,\n",
       "  307: 92,\n",
       "  308: 37,\n",
       "  309: 26,\n",
       "  310: 4,\n",
       "  311: 307,\n",
       "  312: 3,\n",
       "  313: 1719,\n",
       "  314: 2,\n",
       "  315: 158,\n",
       "  316: 1334,\n",
       "  317: 2172,\n",
       "  318: 318,\n",
       "  319: 213,\n",
       "  320: 68,\n",
       "  321: 372,\n",
       "  322: 120,\n",
       "  323: 309,\n",
       "  324: 52,\n",
       "  325: 22,\n",
       "  326: 1,\n",
       "  327: 110,\n",
       "  328: 792,\n",
       "  329: 2047,\n",
       "  330: 22,\n",
       "  331: 54,\n",
       "  332: 116,\n",
       "  333: 34,\n",
       "  334: 116,\n",
       "  335: 130,\n",
       "  336: 87,\n",
       "  337: 19,\n",
       "  339: 2,\n",
       "  338: 13,\n",
       "  340: 74,\n",
       "  341: 125,\n",
       "  343: 22,\n",
       "  342: 4,\n",
       "  344: 42,\n",
       "  345: 3,\n",
       "  346: 463,\n",
       "  347: 644,\n",
       "  348: 99,\n",
       "  350: 188,\n",
       "  349: 12,\n",
       "  351: 1491,\n",
       "  352: 42,\n",
       "  353: 1008,\n",
       "  354: 27,\n",
       "  355: 178,\n",
       "  356: 8,\n",
       "  357: 316,\n",
       "  359: 86,\n",
       "  358: 339,\n",
       "  360: 1450,\n",
       "  361: 139,\n",
       "  362: 2,\n",
       "  363: 6,\n",
       "  364: 64,\n",
       "  365: 68,\n",
       "  366: 58,\n",
       "  367: 10,\n",
       "  369: 1265,\n",
       "  368: 42,\n",
       "  370: 32,\n",
       "  372: 269,\n",
       "  371: 64,\n",
       "  374: 24,\n",
       "  373: 335,\n",
       "  375: 14,\n",
       "  377: 4,\n",
       "  376: 35,\n",
       "  378: 34,\n",
       "  379: 66,\n",
       "  380: 312,\n",
       "  383: 3,\n",
       "  382: 22,\n",
       "  381: 71,\n",
       "  384: 4,\n",
       "  385: 159,\n",
       "  386: 2,\n",
       "  387: 1,\n",
       "  388: 254,\n",
       "  389: 148,\n",
       "  390: 52,\n",
       "  391: 668,\n",
       "  392: 280,\n",
       "  394: 161,\n",
       "  393: 20,\n",
       "  397: 9,\n",
       "  396: 42,\n",
       "  395: 1358,\n",
       "  400: 9,\n",
       "  399: 4,\n",
       "  398: 8,\n",
       "  401: 33,\n",
       "  403: 149,\n",
       "  402: 462,\n",
       "  404: 31,\n",
       "  405: 550,\n",
       "  406: 112,\n",
       "  407: 4264,\n",
       "  408: 1394,\n",
       "  409: 223,\n",
       "  411: 297,\n",
       "  410: 1579,\n",
       "  412: 899,\n",
       "  413: 117,\n",
       "  414: 251,\n",
       "  415: 6,\n",
       "  417: 15,\n",
       "  416: 25,\n",
       "  418: 342,\n",
       "  419: 22,\n",
       "  420: 1143,\n",
       "  421: 158,\n",
       "  422: 250,\n",
       "  423: 47,\n",
       "  424: 9,\n",
       "  425: 11,\n",
       "  426: 76,\n",
       "  427: 64,\n",
       "  428: 17,\n",
       "  429: 130,\n",
       "  430: 436,\n",
       "  431: 296,\n",
       "  432: 143,\n",
       "  433: 13,\n",
       "  434: 122,\n",
       "  436: 19,\n",
       "  435: 139,\n",
       "  437: 82,\n",
       "  438: 450,\n",
       "  439: 335,\n",
       "  440: 28,\n",
       "  441: 593,\n",
       "  442: 1697,\n",
       "  443: 333,\n",
       "  444: 1296,\n",
       "  445: 179,\n",
       "  446: 1066,\n",
       "  447: 144,\n",
       "  448: 8,\n",
       "  449: 3,\n",
       "  450: 213,\n",
       "  451: 80,\n",
       "  452: 1290,\n",
       "  453: 133,\n",
       "  454: 49,\n",
       "  455: 176,\n",
       "  456: 3,\n",
       "  457: 2,\n",
       "  458: 360,\n",
       "  459: 127,\n",
       "  460: 556,\n",
       "  461: 515,\n",
       "  462: 29,\n",
       "  463: 31,\n",
       "  464: 1848,\n",
       "  465: 37,\n",
       "  467: 7,\n",
       "  466: 275,\n",
       "  468: 450,\n",
       "  469: 20,\n",
       "  470: 117,\n",
       "  471: 213,\n",
       "  472: 1653,\n",
       "  473: 216,\n",
       "  474: 13,\n",
       "  475: 102,\n",
       "  476: 31,\n",
       "  477: 135,\n",
       "  478: 262,\n",
       "  479: 781,\n",
       "  480: 74,\n",
       "  481: 34,\n",
       "  482: 153,\n",
       "  483: 61,\n",
       "  484: 4,\n",
       "  485: 229,\n",
       "  486: 142,\n",
       "  487: 46,\n",
       "  488: 106,\n",
       "  489: 52,\n",
       "  490: 23,\n",
       "  491: 348,\n",
       "  492: 1,\n",
       "  493: 32,\n",
       "  494: 1051,\n",
       "  495: 66,\n",
       "  496: 81,\n",
       "  497: 33,\n",
       "  498: 315,\n",
       "  499: 22,\n",
       "  500: 86,\n",
       "  502: 18,\n",
       "  503: 26,\n",
       "  504: 149,\n",
       "  501: 26,\n",
       "  506: 34,\n",
       "  505: 53,\n",
       "  507: 15,\n",
       "  508: 179,\n",
       "  509: 19,\n",
       "  510: 40,\n",
       "  511: 1,\n",
       "  512: 24,\n",
       "  513: 108,\n",
       "  514: 131,\n",
       "  515: 160,\n",
       "  516: 46,\n",
       "  517: 126,\n",
       "  518: 141,\n",
       "  519: 158,\n",
       "  520: 238,\n",
       "  521: 3,\n",
       "  522: 62,\n",
       "  523: 1124,\n",
       "  524: 632,\n",
       "  525: 70,\n",
       "  527: 304,\n",
       "  526: 152,\n",
       "  528: 741,\n",
       "  529: 440,\n",
       "  530: 116,\n",
       "  531: 50,\n",
       "  532: 40,\n",
       "  534: 1,\n",
       "  533: 21,\n",
       "  535: 75,\n",
       "  536: 88,\n",
       "  537: 323,\n",
       "  538: 417,\n",
       "  539: 14,\n",
       "  540: 8,\n",
       "  541: 792,\n",
       "  542: 231,\n",
       "  543: 15,\n",
       "  544: 220,\n",
       "  545: 24,\n",
       "  546: 34,\n",
       "  547: 250,\n",
       "  548: 267,\n",
       "  549: 96,\n",
       "  550: 9,\n",
       "  551: 559,\n",
       "  553: 159,\n",
       "  552: 63,\n",
       "  554: 785,\n",
       "  555: 32,\n",
       "  556: 88,\n",
       "  557: 149,\n",
       "  558: 1354,\n",
       "  559: 157,\n",
       "  560: 513,\n",
       "  561: 98,\n",
       "  562: 15,\n",
       "  563: 242,\n",
       "  564: 370,\n",
       "  565: 26,\n",
       "  566: 321,\n",
       "  567: 1,\n",
       "  568: 115,\n",
       "  569: 10,\n",
       "  570: 142,\n",
       "  572: 28,\n",
       "  571: 1,\n",
       "  573: 41,\n",
       "  574: 636,\n",
       "  575: 167,\n",
       "  576: 24,\n",
       "  577: 152,\n",
       "  578: 149,\n",
       "  579: 4,\n",
       "  580: 2,\n",
       "  581: 113,\n",
       "  582: 702,\n",
       "  583: 539,\n",
       "  584: 279,\n",
       "  585: 50,\n",
       "  586: 4,\n",
       "  587: 10,\n",
       "  588: 3,\n",
       "  589: 145,\n",
       "  590: 520,\n",
       "  591: 239,\n",
       "  592: 75,\n",
       "  593: 45,\n",
       "  594: 244,\n",
       "  596: 60,\n",
       "  595: 6,\n",
       "  597: 53,\n",
       "  598: 19,\n",
       "  599: 26,\n",
       "  601: 479,\n",
       "  600: 10,\n",
       "  602: 1029,\n",
       "  603: 182,\n",
       "  604: 103,\n",
       "  605: 1049,\n",
       "  606: 1075,\n",
       "  608: 2,\n",
       "  607: 18,\n",
       "  609: 19,\n",
       "  610: 12,\n",
       "  612: 371,\n",
       "  611: 339,\n",
       "  613: 1204,\n",
       "  614: 642,\n",
       "  615: 523,\n",
       "  617: 212,\n",
       "  616: 318,\n",
       "  618: 163,\n",
       "  619: 128,\n",
       "  620: 3,\n",
       "  621: 639,\n",
       "  622: 114,\n",
       "  623: 412,\n",
       "  624: 70,\n",
       "  625: 449,\n",
       "  626: 672,\n",
       "  627: 121,\n",
       "  628: 264,\n",
       "  629: 128,\n",
       "  630: 69,\n",
       "  631: 82,\n",
       "  632: 2,\n",
       "  633: 107,\n",
       "  634: 556,\n",
       "  635: 280,\n",
       "  636: 157,\n",
       "  637: 485,\n",
       "  638: 5,\n",
       "  639: 39,\n",
       "  640: 331,\n",
       "  641: 373,\n",
       "  642: 21,\n",
       "  643: 284,\n",
       "  644: 2,\n",
       "  645: 8,\n",
       "  646: 167,\n",
       "  647: 111,\n",
       "  648: 520,\n",
       "  649: 642,\n",
       "  650: 5,\n",
       "  651: 184,\n",
       "  652: 156,\n",
       "  653: 403,\n",
       "  654: 462,\n",
       "  655: 77,\n",
       "  656: 129,\n",
       "  657: 141,\n",
       "  658: 217,\n",
       "  659: 2,\n",
       "  661: 384,\n",
       "  660: 134,\n",
       "  662: 628,\n",
       "  663: 237,\n",
       "  664: 133,\n",
       "  665: 53,\n",
       "  666: 565,\n",
       "  667: 43,\n",
       "  668: 175,\n",
       "  669: 323,\n",
       "  670: 76,\n",
       "  671: 357,\n",
       "  672: 585,\n",
       "  673: 58,\n",
       "  674: 64,\n",
       "  675: 90,\n",
       "  676: 12,\n",
       "  677: 1,\n",
       "  678: 24,\n",
       "  679: 754,\n",
       "  680: 483,\n",
       "  681: 13,\n",
       "  682: 95,\n",
       "  683: 57,\n",
       "  684: 488,\n",
       "  685: 115,\n",
       "  686: 362,\n",
       "  687: 83,\n",
       "  688: 290,\n",
       "  689: 142,\n",
       "  690: 1,\n",
       "  691: 193,\n",
       "  692: 165,\n",
       "  693: 142,\n",
       "  694: 30,\n",
       "  695: 80,\n",
       "  697: 13,\n",
       "  696: 67,\n",
       "  698: 27,\n",
       "  699: 32,\n",
       "  700: 35,\n",
       "  701: 57,\n",
       "  702: 660,\n",
       "  703: 244,\n",
       "  704: 1051,\n",
       "  705: 156,\n",
       "  706: 801,\n",
       "  707: 77,\n",
       "  708: 56,\n",
       "  709: 7,\n",
       "  710: 105,\n",
       "  711: 179,\n",
       "  712: 215,\n",
       "  713: 2,\n",
       "  714: 163,\n",
       "  715: 21,\n",
       "  716: 238,\n",
       "  717: 57,\n",
       "  718: 1,\n",
       "  719: 49,\n",
       "  720: 2,\n",
       "  721: 150,\n",
       "  722: 104,\n",
       "  723: 1,\n",
       "  724: 10,\n",
       "  725: 35,\n",
       "  726: 61,\n",
       "  727: 278,\n",
       "  728: 42,\n",
       "  729: 15,\n",
       "  731: 22,\n",
       "  730: 37,\n",
       "  732: 18,\n",
       "  733: 5,\n",
       "  734: 29,\n",
       "  735: 22,\n",
       "  736: 215,\n",
       "  737: 1,\n",
       "  738: 111,\n",
       "  739: 59,\n",
       "  740: 15,\n",
       "  741: 1,\n",
       "  742: 14,\n",
       "  743: 371,\n",
       "  744: 21,\n",
       "  745: 18,\n",
       "  746: 67,\n",
       "  747: 30,\n",
       "  748: 1,\n",
       "  749: 6,\n",
       "  750: 1153,\n",
       "  751: 13,\n",
       "  752: 298,\n",
       "  753: 48,\n",
       "  754: 1,\n",
       "  755: 26,\n",
       "  756: 103,\n",
       "  757: 65,\n",
       "  758: 11,\n",
       "  759: 36,\n",
       "  760: 7,\n",
       "  761: 1,\n",
       "  763: 332,\n",
       "  762: 434,\n",
       "  764: 2,\n",
       "  765: 2,\n",
       "  766: 119,\n",
       "  767: 55,\n",
       "  768: 206,\n",
       "  769: 363,\n",
       "  770: 1,\n",
       "  771: 50,\n",
       "  772: 18,\n",
       "  773: 11,\n",
       "  774: 39,\n",
       "  775: 1,\n",
       "  776: 219,\n",
       "  777: 183,\n",
       "  778: 83,\n",
       "  779: 24,\n",
       "  780: 1,\n",
       "  781: 274,\n",
       "  782: 521,\n",
       "  783: 16,\n",
       "  784: 635,\n",
       "  785: 143,\n",
       "  786: 19,\n",
       "  787: 3,\n",
       "  788: 85,\n",
       "  789: 13,\n",
       "  790: 96,\n",
       "  791: 26,\n",
       "  792: 6,\n",
       "  793: 1,\n",
       "  794: 7,\n",
       "  795: 89,\n",
       "  796: 108,\n",
       "  797: 47,\n",
       "  798: 38,\n",
       "  799: 106,\n",
       "  800: 1,\n",
       "  801: 32,\n",
       "  802: 9,\n",
       "  803: 105,\n",
       "  804: 13,\n",
       "  805: 34,\n",
       "  806: 11,\n",
       "  807: 141,\n",
       "  808: 84,\n",
       "  809: 3,\n",
       "  810: 10,\n",
       "  811: 249,\n",
       "  812: 62,\n",
       "  813: 1,\n",
       "  814: 22,\n",
       "  815: 125,\n",
       "  816: 3,\n",
       "  817: 487,\n",
       "  818: 1,\n",
       "  820: 35,\n",
       "  819: 40,\n",
       "  821: 88,\n",
       "  822: 48,\n",
       "  824: 16,\n",
       "  825: 67,\n",
       "  823: 377,\n",
       "  826: 499,\n",
       "  827: 235,\n",
       "  828: 121,\n",
       "  829: 3,\n",
       "  830: 162,\n",
       "  831: 2,\n",
       "  832: 57,\n",
       "  833: 15,\n",
       "  834: 15,\n",
       "  835: 4,\n",
       "  836: 141,\n",
       "  837: 13,\n",
       "  838: 111,\n",
       "  839: 43,\n",
       "  840: 823,\n",
       "  841: 288,\n",
       "  842: 284,\n",
       "  843: 18,\n",
       "  844: 22,\n",
       "  846: 165,\n",
       "  845: 85,\n",
       "  847: 147,\n",
       "  848: 210,\n",
       "  849: 24,\n",
       "  850: 13,\n",
       "  851: 178,\n",
       "  852: 408,\n",
       "  853: 112,\n",
       "  854: 192,\n",
       "  855: 1324,\n",
       "  856: 60,\n",
       "  857: 49,\n",
       "  858: 77,\n",
       "  859: 19,\n",
       "  860: 387,\n",
       "  861: 494,\n",
       "  862: 189,\n",
       "  863: 26,\n",
       "  864: 106,\n",
       "  865: 48,\n",
       "  866: 11,\n",
       "  867: 13,\n",
       "  869: 8,\n",
       "  868: 8,\n",
       "  870: 506,\n",
       "  871: 63,\n",
       "  872: 10,\n",
       "  873: 152,\n",
       "  874: 88,\n",
       "  875: 34,\n",
       "  876: 166,\n",
       "  877: 116,\n",
       "  878: 1,\n",
       "  879: 86,\n",
       "  880: 21,\n",
       "  881: 48,\n",
       "  882: 13,\n",
       "  883: 10,\n",
       "  884: 167,\n",
       "  885: 73,\n",
       "  886: 2,\n",
       "  887: 32,\n",
       "  888: 3,\n",
       "  889: 155,\n",
       "  890: 111,\n",
       "  892: 224,\n",
       "  891: 11,\n",
       "  893: 670,\n",
       "  894: 8,\n",
       "  895: 11,\n",
       "  896: 223,\n",
       "  897: 1,\n",
       "  898: 59,\n",
       "  899: 17,\n",
       "  900: 81,\n",
       "  901: 351,\n",
       "  902: 259,\n",
       "  903: 30,\n",
       "  904: 106,\n",
       "  905: 9,\n",
       "  906: 88,\n",
       "  907: 63,\n",
       "  908: 9,\n",
       "  909: 195,\n",
       "  910: 468,\n",
       "  911: 31,\n",
       "  912: 56,\n",
       "  913: 124,\n",
       "  914: 127,\n",
       "  915: 19,\n",
       "  916: 2,\n",
       "  917: 15,\n",
       "  918: 100,\n",
       "  919: 627,\n",
       "  920: 8,\n",
       "  921: 80,\n",
       "  922: 328,\n",
       "  923: 106,\n",
       "  924: 10,\n",
       "  925: 183,\n",
       "  926: 1,\n",
       "  927: 57,\n",
       "  929: 2,\n",
       "  928: 56,\n",
       "  930: 6,\n",
       "  931: 418,\n",
       "  932: 37,\n",
       "  933: 102,\n",
       "  934: 1,\n",
       "  935: 51,\n",
       "  936: 266,\n",
       "  937: 95,\n",
       "  939: 13,\n",
       "  938: 12,\n",
       "  940: 46,\n",
       "  941: 16,\n",
       "  942: 32,\n",
       "  943: 484,\n",
       "  944: 2,\n",
       "  945: 57,\n",
       "  946: 153,\n",
       "  947: 14,\n",
       "  948: 50,\n",
       "  949: 16,\n",
       "  950: 1,\n",
       "  951: 138,\n",
       "  952: 21,\n",
       "  953: 114,\n",
       "  954: 64,\n",
       "  955: 30,\n",
       "  956: 220,\n",
       "  957: 666,\n",
       "  958: 185,\n",
       "  959: 66,\n",
       "  960: 132,\n",
       "  961: 4,\n",
       "  962: 292,\n",
       "  964: 59,\n",
       "  963: 672,\n",
       "  965: 23,\n",
       "  966: 96,\n",
       "  967: 1,\n",
       "  968: 16,\n",
       "  969: 279,\n",
       "  970: 142,\n",
       "  971: 248,\n",
       "  972: 13,\n",
       "  973: 11,\n",
       "  974: 73,\n",
       "  975: 109,\n",
       "  976: 127,\n",
       "  977: 296,\n",
       "  978: 163,\n",
       "  979: 44,\n",
       "  980: 30,\n",
       "  981: 17,\n",
       "  983: 94,\n",
       "  982: 50,\n",
       "  984: 79,\n",
       "  985: 29,\n",
       "  987: 31,\n",
       "  986: 37,\n",
       "  988: 2,\n",
       "  989: 860,\n",
       "  990: 411,\n",
       "  991: 1,\n",
       "  992: 17,\n",
       "  993: 172,\n",
       "  994: 102,\n",
       "  995: 63,\n",
       "  997: 1,\n",
       "  998: 3,\n",
       "  999: 1,\n",
       "  996: 186,\n",
       "  ...},\n",
       " 'num_docs': 413629,\n",
       " 'num_pos': 978824,\n",
       " 'num_nnz': 976849}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus_dct.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_corpus_dct.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['token2id',\n",
       " 'id2token',\n",
       " 'dfs',\n",
       " 'num_docs',\n",
       " 'num_pos',\n",
       " 'num_nnz',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " '__init__',\n",
       " '__getitem__',\n",
       " '__iter__',\n",
       " 'iterkeys',\n",
       " 'iteritems',\n",
       " 'itervalues',\n",
       " 'keys',\n",
       " '__len__',\n",
       " '__str__',\n",
       " 'from_documents',\n",
       " 'add_documents',\n",
       " 'doc2bow',\n",
       " 'doc2idx',\n",
       " 'filter_extremes',\n",
       " 'filter_n_most_frequent',\n",
       " 'filter_tokens',\n",
       " 'compactify',\n",
       " 'save_as_text',\n",
       " 'merge_with',\n",
       " 'patch_with_special_tokens',\n",
       " 'load_from_text',\n",
       " 'from_corpus',\n",
       " '__abstractmethods__',\n",
       " '_abc_registry',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " 'load',\n",
       " '_load_specials',\n",
       " '_adapt_by_suffix',\n",
       " '_smart_save',\n",
       " '_save_specials',\n",
       " 'save',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__new__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__',\n",
       " '__slots__',\n",
       " 'get',\n",
       " '__contains__',\n",
       " 'items',\n",
       " 'values',\n",
       " '__reversed__']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus_dct.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 1,\n",
       " 3: 19353,\n",
       " 4: 11942,\n",
       " 2: 601,\n",
       " 6: 45,\n",
       " 5: 1995,\n",
       " 8: 2776,\n",
       " 7: 1330,\n",
       " 9: 1322,\n",
       " 11: 11620,\n",
       " 10: 233,\n",
       " 13: 1110,\n",
       " 12: 81,\n",
       " 14: 8629,\n",
       " 15: 4470,\n",
       " 16: 839,\n",
       " 17: 214432,\n",
       " 18: 38854,\n",
       " 19: 10014,\n",
       " 20: 11839,\n",
       " 21: 364,\n",
       " 22: 1881,\n",
       " 23: 449,\n",
       " 24: 763,\n",
       " 25: 184,\n",
       " 26: 18,\n",
       " 27: 23,\n",
       " 28: 1015,\n",
       " 31: 643,\n",
       " 30: 20460,\n",
       " 29: 402,\n",
       " 32: 483,\n",
       " 33: 1972,\n",
       " 35: 381,\n",
       " 34: 296,\n",
       " 36: 5163,\n",
       " 37: 3988,\n",
       " 38: 9,\n",
       " 39: 4557,\n",
       " 41: 2555,\n",
       " 40: 1963,\n",
       " 42: 224,\n",
       " 43: 401,\n",
       " 44: 11746,\n",
       " 45: 8,\n",
       " 46: 40,\n",
       " 48: 4230,\n",
       " 47: 8601,\n",
       " 49: 34427,\n",
       " 50: 4901,\n",
       " 51: 16,\n",
       " 52: 887,\n",
       " 53: 626,\n",
       " 54: 3645,\n",
       " 55: 27,\n",
       " 56: 853,\n",
       " 57: 298,\n",
       " 58: 2436,\n",
       " 59: 1741,\n",
       " 60: 158,\n",
       " 61: 5034,\n",
       " 62: 1876,\n",
       " 63: 11030,\n",
       " 64: 83,\n",
       " 65: 1332,\n",
       " 66: 1363,\n",
       " 67: 202,\n",
       " 68: 15591,\n",
       " 69: 1816,\n",
       " 70: 2305,\n",
       " 71: 8939,\n",
       " 73: 1026,\n",
       " 72: 490,\n",
       " 75: 2315,\n",
       " 74: 1415,\n",
       " 76: 1192,\n",
       " 77: 1787,\n",
       " 78: 937,\n",
       " 81: 177,\n",
       " 79: 254,\n",
       " 80: 40,\n",
       " 82: 2,\n",
       " 83: 2,\n",
       " 84: 951,\n",
       " 85: 52,\n",
       " 86: 679,\n",
       " 88: 152,\n",
       " 87: 352,\n",
       " 89: 9,\n",
       " 90: 4224,\n",
       " 91: 438,\n",
       " 92: 64,\n",
       " 93: 15,\n",
       " 94: 506,\n",
       " 95: 16,\n",
       " 96: 20165,\n",
       " 97: 1961,\n",
       " 98: 1192,\n",
       " 99: 253,\n",
       " 100: 119,\n",
       " 101: 34,\n",
       " 102: 573,\n",
       " 103: 276,\n",
       " 104: 22,\n",
       " 105: 261,\n",
       " 106: 272,\n",
       " 107: 128,\n",
       " 108: 238,\n",
       " 109: 35,\n",
       " 110: 24,\n",
       " 111: 123,\n",
       " 112: 251,\n",
       " 115: 788,\n",
       " 113: 51,\n",
       " 114: 195,\n",
       " 116: 2291,\n",
       " 117: 248,\n",
       " 118: 123,\n",
       " 119: 105,\n",
       " 121: 1564,\n",
       " 120: 67,\n",
       " 122: 31,\n",
       " 123: 253,\n",
       " 124: 550,\n",
       " 125: 1935,\n",
       " 126: 120,\n",
       " 127: 41,\n",
       " 128: 189,\n",
       " 129: 8099,\n",
       " 130: 3951,\n",
       " 131: 27,\n",
       " 132: 10,\n",
       " 133: 1166,\n",
       " 136: 2080,\n",
       " 135: 231,\n",
       " 134: 4,\n",
       " 137: 128,\n",
       " 138: 44,\n",
       " 140: 99,\n",
       " 141: 346,\n",
       " 139: 674,\n",
       " 142: 107,\n",
       " 143: 29,\n",
       " 145: 25,\n",
       " 144: 16,\n",
       " 146: 129,\n",
       " 147: 118,\n",
       " 149: 2,\n",
       " 151: 25,\n",
       " 150: 2,\n",
       " 148: 897,\n",
       " 152: 2745,\n",
       " 153: 1025,\n",
       " 154: 208,\n",
       " 155: 103,\n",
       " 156: 23,\n",
       " 157: 2529,\n",
       " 158: 4853,\n",
       " 159: 361,\n",
       " 160: 7095,\n",
       " 161: 1061,\n",
       " 162: 1483,\n",
       " 163: 16,\n",
       " 164: 247,\n",
       " 165: 3,\n",
       " 166: 1870,\n",
       " 167: 4,\n",
       " 168: 5,\n",
       " 169: 2,\n",
       " 170: 3,\n",
       " 171: 3043,\n",
       " 172: 53,\n",
       " 173: 72,\n",
       " 174: 78,\n",
       " 175: 3140,\n",
       " 176: 1720,\n",
       " 177: 2,\n",
       " 178: 56,\n",
       " 179: 87,\n",
       " 180: 238,\n",
       " 181: 152,\n",
       " 182: 255,\n",
       " 183: 59,\n",
       " 184: 204,\n",
       " 185: 1547,\n",
       " 186: 5318,\n",
       " 187: 193,\n",
       " 188: 475,\n",
       " 189: 665,\n",
       " 190: 573,\n",
       " 191: 448,\n",
       " 192: 71,\n",
       " 195: 133,\n",
       " 194: 215,\n",
       " 193: 462,\n",
       " 196: 233,\n",
       " 198: 118,\n",
       " 197: 136,\n",
       " 199: 9,\n",
       " 200: 5,\n",
       " 201: 936,\n",
       " 203: 46,\n",
       " 202: 366,\n",
       " 204: 36,\n",
       " 206: 26,\n",
       " 205: 2,\n",
       " 207: 306,\n",
       " 208: 4008,\n",
       " 209: 21,\n",
       " 212: 2,\n",
       " 211: 19,\n",
       " 210: 460,\n",
       " 213: 5,\n",
       " 214: 1194,\n",
       " 215: 2549,\n",
       " 216: 32,\n",
       " 218: 13,\n",
       " 217: 336,\n",
       " 220: 180,\n",
       " 219: 176,\n",
       " 221: 632,\n",
       " 222: 3927,\n",
       " 223: 8383,\n",
       " 224: 21,\n",
       " 225: 820,\n",
       " 226: 10,\n",
       " 227: 10,\n",
       " 228: 394,\n",
       " 229: 1062,\n",
       " 230: 669,\n",
       " 231: 31,\n",
       " 232: 487,\n",
       " 233: 29,\n",
       " 234: 645,\n",
       " 235: 185,\n",
       " 236: 83,\n",
       " 237: 944,\n",
       " 238: 620,\n",
       " 239: 8808,\n",
       " 240: 1069,\n",
       " 241: 45,\n",
       " 242: 183,\n",
       " 243: 39,\n",
       " 244: 44,\n",
       " 245: 35,\n",
       " 246: 290,\n",
       " 247: 1880,\n",
       " 248: 67,\n",
       " 250: 156,\n",
       " 249: 33,\n",
       " 251: 592,\n",
       " 252: 13,\n",
       " 255: 371,\n",
       " 253: 239,\n",
       " 254: 27,\n",
       " 256: 191,\n",
       " 258: 3,\n",
       " 257: 270,\n",
       " 259: 1795,\n",
       " 260: 720,\n",
       " 261: 18,\n",
       " 262: 13,\n",
       " 263: 111,\n",
       " 264: 76,\n",
       " 265: 490,\n",
       " 266: 2,\n",
       " 267: 332,\n",
       " 268: 3,\n",
       " 269: 676,\n",
       " 270: 260,\n",
       " 271: 70,\n",
       " 273: 19,\n",
       " 272: 387,\n",
       " 275: 2,\n",
       " 274: 77,\n",
       " 276: 1437,\n",
       " 277: 3976,\n",
       " 278: 522,\n",
       " 279: 9,\n",
       " 280: 478,\n",
       " 281: 259,\n",
       " 282: 1102,\n",
       " 283: 950,\n",
       " 284: 235,\n",
       " 285: 40,\n",
       " 286: 3206,\n",
       " 287: 321,\n",
       " 288: 1,\n",
       " 289: 4,\n",
       " 290: 122,\n",
       " 291: 23,\n",
       " 292: 135,\n",
       " 293: 10,\n",
       " 295: 433,\n",
       " 294: 341,\n",
       " 296: 2422,\n",
       " 297: 371,\n",
       " 298: 1367,\n",
       " 299: 212,\n",
       " 300: 207,\n",
       " 301: 163,\n",
       " 303: 1,\n",
       " 302: 436,\n",
       " 304: 6,\n",
       " 305: 82,\n",
       " 306: 50,\n",
       " 307: 92,\n",
       " 308: 37,\n",
       " 309: 26,\n",
       " 310: 4,\n",
       " 311: 307,\n",
       " 312: 3,\n",
       " 313: 1719,\n",
       " 314: 2,\n",
       " 315: 158,\n",
       " 316: 1334,\n",
       " 317: 2172,\n",
       " 318: 318,\n",
       " 319: 213,\n",
       " 320: 68,\n",
       " 321: 372,\n",
       " 322: 120,\n",
       " 323: 309,\n",
       " 324: 52,\n",
       " 325: 22,\n",
       " 326: 1,\n",
       " 327: 110,\n",
       " 328: 792,\n",
       " 329: 2047,\n",
       " 330: 22,\n",
       " 331: 54,\n",
       " 332: 116,\n",
       " 333: 34,\n",
       " 334: 116,\n",
       " 335: 130,\n",
       " 336: 87,\n",
       " 337: 19,\n",
       " 339: 2,\n",
       " 338: 13,\n",
       " 340: 74,\n",
       " 341: 125,\n",
       " 343: 22,\n",
       " 342: 4,\n",
       " 344: 42,\n",
       " 345: 3,\n",
       " 346: 463,\n",
       " 347: 644,\n",
       " 348: 99,\n",
       " 350: 188,\n",
       " 349: 12,\n",
       " 351: 1491,\n",
       " 352: 42,\n",
       " 353: 1008,\n",
       " 354: 27,\n",
       " 355: 178,\n",
       " 356: 8,\n",
       " 357: 316,\n",
       " 359: 86,\n",
       " 358: 339,\n",
       " 360: 1450,\n",
       " 361: 139,\n",
       " 362: 2,\n",
       " 363: 6,\n",
       " 364: 64,\n",
       " 365: 68,\n",
       " 366: 58,\n",
       " 367: 10,\n",
       " 369: 1265,\n",
       " 368: 42,\n",
       " 370: 32,\n",
       " 372: 269,\n",
       " 371: 64,\n",
       " 374: 24,\n",
       " 373: 335,\n",
       " 375: 14,\n",
       " 377: 4,\n",
       " 376: 35,\n",
       " 378: 34,\n",
       " 379: 66,\n",
       " 380: 312,\n",
       " 383: 3,\n",
       " 382: 22,\n",
       " 381: 71,\n",
       " 384: 4,\n",
       " 385: 159,\n",
       " 386: 2,\n",
       " 387: 1,\n",
       " 388: 254,\n",
       " 389: 148,\n",
       " 390: 52,\n",
       " 391: 668,\n",
       " 392: 280,\n",
       " 394: 161,\n",
       " 393: 20,\n",
       " 397: 9,\n",
       " 396: 42,\n",
       " 395: 1358,\n",
       " 400: 9,\n",
       " 399: 4,\n",
       " 398: 8,\n",
       " 401: 33,\n",
       " 403: 149,\n",
       " 402: 462,\n",
       " 404: 31,\n",
       " 405: 550,\n",
       " 406: 112,\n",
       " 407: 4264,\n",
       " 408: 1394,\n",
       " 409: 223,\n",
       " 411: 297,\n",
       " 410: 1579,\n",
       " 412: 899,\n",
       " 413: 117,\n",
       " 414: 251,\n",
       " 415: 6,\n",
       " 417: 15,\n",
       " 416: 25,\n",
       " 418: 342,\n",
       " 419: 22,\n",
       " 420: 1143,\n",
       " 421: 158,\n",
       " 422: 250,\n",
       " 423: 47,\n",
       " 424: 9,\n",
       " 425: 11,\n",
       " 426: 76,\n",
       " 427: 64,\n",
       " 428: 17,\n",
       " 429: 130,\n",
       " 430: 436,\n",
       " 431: 296,\n",
       " 432: 143,\n",
       " 433: 13,\n",
       " 434: 122,\n",
       " 436: 19,\n",
       " 435: 139,\n",
       " 437: 82,\n",
       " 438: 450,\n",
       " 439: 335,\n",
       " 440: 28,\n",
       " 441: 593,\n",
       " 442: 1697,\n",
       " 443: 333,\n",
       " 444: 1296,\n",
       " 445: 179,\n",
       " 446: 1066,\n",
       " 447: 144,\n",
       " 448: 8,\n",
       " 449: 3,\n",
       " 450: 213,\n",
       " 451: 80,\n",
       " 452: 1290,\n",
       " 453: 133,\n",
       " 454: 49,\n",
       " 455: 176,\n",
       " 456: 3,\n",
       " 457: 2,\n",
       " 458: 360,\n",
       " 459: 127,\n",
       " 460: 556,\n",
       " 461: 515,\n",
       " 462: 29,\n",
       " 463: 31,\n",
       " 464: 1848,\n",
       " 465: 37,\n",
       " 467: 7,\n",
       " 466: 275,\n",
       " 468: 450,\n",
       " 469: 20,\n",
       " 470: 117,\n",
       " 471: 213,\n",
       " 472: 1653,\n",
       " 473: 216,\n",
       " 474: 13,\n",
       " 475: 102,\n",
       " 476: 31,\n",
       " 477: 135,\n",
       " 478: 262,\n",
       " 479: 781,\n",
       " 480: 74,\n",
       " 481: 34,\n",
       " 482: 153,\n",
       " 483: 61,\n",
       " 484: 4,\n",
       " 485: 229,\n",
       " 486: 142,\n",
       " 487: 46,\n",
       " 488: 106,\n",
       " 489: 52,\n",
       " 490: 23,\n",
       " 491: 348,\n",
       " 492: 1,\n",
       " 493: 32,\n",
       " 494: 1051,\n",
       " 495: 66,\n",
       " 496: 81,\n",
       " 497: 33,\n",
       " 498: 315,\n",
       " 499: 22,\n",
       " 500: 86,\n",
       " 502: 18,\n",
       " 503: 26,\n",
       " 504: 149,\n",
       " 501: 26,\n",
       " 506: 34,\n",
       " 505: 53,\n",
       " 507: 15,\n",
       " 508: 179,\n",
       " 509: 19,\n",
       " 510: 40,\n",
       " 511: 1,\n",
       " 512: 24,\n",
       " 513: 108,\n",
       " 514: 131,\n",
       " 515: 160,\n",
       " 516: 46,\n",
       " 517: 126,\n",
       " 518: 141,\n",
       " 519: 158,\n",
       " 520: 238,\n",
       " 521: 3,\n",
       " 522: 62,\n",
       " 523: 1124,\n",
       " 524: 632,\n",
       " 525: 70,\n",
       " 527: 304,\n",
       " 526: 152,\n",
       " 528: 741,\n",
       " 529: 440,\n",
       " 530: 116,\n",
       " 531: 50,\n",
       " 532: 40,\n",
       " 534: 1,\n",
       " 533: 21,\n",
       " 535: 75,\n",
       " 536: 88,\n",
       " 537: 323,\n",
       " 538: 417,\n",
       " 539: 14,\n",
       " 540: 8,\n",
       " 541: 792,\n",
       " 542: 231,\n",
       " 543: 15,\n",
       " 544: 220,\n",
       " 545: 24,\n",
       " 546: 34,\n",
       " 547: 250,\n",
       " 548: 267,\n",
       " 549: 96,\n",
       " 550: 9,\n",
       " 551: 559,\n",
       " 553: 159,\n",
       " 552: 63,\n",
       " 554: 785,\n",
       " 555: 32,\n",
       " 556: 88,\n",
       " 557: 149,\n",
       " 558: 1354,\n",
       " 559: 157,\n",
       " 560: 513,\n",
       " 561: 98,\n",
       " 562: 15,\n",
       " 563: 242,\n",
       " 564: 370,\n",
       " 565: 26,\n",
       " 566: 321,\n",
       " 567: 1,\n",
       " 568: 115,\n",
       " 569: 10,\n",
       " 570: 142,\n",
       " 572: 28,\n",
       " 571: 1,\n",
       " 573: 41,\n",
       " 574: 636,\n",
       " 575: 167,\n",
       " 576: 24,\n",
       " 577: 152,\n",
       " 578: 149,\n",
       " 579: 4,\n",
       " 580: 2,\n",
       " 581: 113,\n",
       " 582: 702,\n",
       " 583: 539,\n",
       " 584: 279,\n",
       " 585: 50,\n",
       " 586: 4,\n",
       " 587: 10,\n",
       " 588: 3,\n",
       " 589: 145,\n",
       " 590: 520,\n",
       " 591: 239,\n",
       " 592: 75,\n",
       " 593: 45,\n",
       " 594: 244,\n",
       " 596: 60,\n",
       " 595: 6,\n",
       " 597: 53,\n",
       " 598: 19,\n",
       " 599: 26,\n",
       " 601: 479,\n",
       " 600: 10,\n",
       " 602: 1029,\n",
       " 603: 182,\n",
       " 604: 103,\n",
       " 605: 1049,\n",
       " 606: 1075,\n",
       " 608: 2,\n",
       " 607: 18,\n",
       " 609: 19,\n",
       " 610: 12,\n",
       " 612: 371,\n",
       " 611: 339,\n",
       " 613: 1204,\n",
       " 614: 642,\n",
       " 615: 523,\n",
       " 617: 212,\n",
       " 616: 318,\n",
       " 618: 163,\n",
       " 619: 128,\n",
       " 620: 3,\n",
       " 621: 639,\n",
       " 622: 114,\n",
       " 623: 412,\n",
       " 624: 70,\n",
       " 625: 449,\n",
       " 626: 672,\n",
       " 627: 121,\n",
       " 628: 264,\n",
       " 629: 128,\n",
       " 630: 69,\n",
       " 631: 82,\n",
       " 632: 2,\n",
       " 633: 107,\n",
       " 634: 556,\n",
       " 635: 280,\n",
       " 636: 157,\n",
       " 637: 485,\n",
       " 638: 5,\n",
       " 639: 39,\n",
       " 640: 331,\n",
       " 641: 373,\n",
       " 642: 21,\n",
       " 643: 284,\n",
       " 644: 2,\n",
       " 645: 8,\n",
       " 646: 167,\n",
       " 647: 111,\n",
       " 648: 520,\n",
       " 649: 642,\n",
       " 650: 5,\n",
       " 651: 184,\n",
       " 652: 156,\n",
       " 653: 403,\n",
       " 654: 462,\n",
       " 655: 77,\n",
       " 656: 129,\n",
       " 657: 141,\n",
       " 658: 217,\n",
       " 659: 2,\n",
       " 661: 384,\n",
       " 660: 134,\n",
       " 662: 628,\n",
       " 663: 237,\n",
       " 664: 133,\n",
       " 665: 53,\n",
       " 666: 565,\n",
       " 667: 43,\n",
       " 668: 175,\n",
       " 669: 323,\n",
       " 670: 76,\n",
       " 671: 357,\n",
       " 672: 585,\n",
       " 673: 58,\n",
       " 674: 64,\n",
       " 675: 90,\n",
       " 676: 12,\n",
       " 677: 1,\n",
       " 678: 24,\n",
       " 679: 754,\n",
       " 680: 483,\n",
       " 681: 13,\n",
       " 682: 95,\n",
       " 683: 57,\n",
       " 684: 488,\n",
       " 685: 115,\n",
       " 686: 362,\n",
       " 687: 83,\n",
       " 688: 290,\n",
       " 689: 142,\n",
       " 690: 1,\n",
       " 691: 193,\n",
       " 692: 165,\n",
       " 693: 142,\n",
       " 694: 30,\n",
       " 695: 80,\n",
       " 697: 13,\n",
       " 696: 67,\n",
       " 698: 27,\n",
       " 699: 32,\n",
       " 700: 35,\n",
       " 701: 57,\n",
       " 702: 660,\n",
       " 703: 244,\n",
       " 704: 1051,\n",
       " 705: 156,\n",
       " 706: 801,\n",
       " 707: 77,\n",
       " 708: 56,\n",
       " 709: 7,\n",
       " 710: 105,\n",
       " 711: 179,\n",
       " 712: 215,\n",
       " 713: 2,\n",
       " 714: 163,\n",
       " 715: 21,\n",
       " 716: 238,\n",
       " 717: 57,\n",
       " 718: 1,\n",
       " 719: 49,\n",
       " 720: 2,\n",
       " 721: 150,\n",
       " 722: 104,\n",
       " 723: 1,\n",
       " 724: 10,\n",
       " 725: 35,\n",
       " 726: 61,\n",
       " 727: 278,\n",
       " 728: 42,\n",
       " 729: 15,\n",
       " 731: 22,\n",
       " 730: 37,\n",
       " 732: 18,\n",
       " 733: 5,\n",
       " 734: 29,\n",
       " 735: 22,\n",
       " 736: 215,\n",
       " 737: 1,\n",
       " 738: 111,\n",
       " 739: 59,\n",
       " 740: 15,\n",
       " 741: 1,\n",
       " 742: 14,\n",
       " 743: 371,\n",
       " 744: 21,\n",
       " 745: 18,\n",
       " 746: 67,\n",
       " 747: 30,\n",
       " 748: 1,\n",
       " 749: 6,\n",
       " 750: 1153,\n",
       " 751: 13,\n",
       " 752: 298,\n",
       " 753: 48,\n",
       " 754: 1,\n",
       " 755: 26,\n",
       " 756: 103,\n",
       " 757: 65,\n",
       " 758: 11,\n",
       " 759: 36,\n",
       " 760: 7,\n",
       " 761: 1,\n",
       " 763: 332,\n",
       " 762: 434,\n",
       " 764: 2,\n",
       " 765: 2,\n",
       " 766: 119,\n",
       " 767: 55,\n",
       " 768: 206,\n",
       " 769: 363,\n",
       " 770: 1,\n",
       " 771: 50,\n",
       " 772: 18,\n",
       " 773: 11,\n",
       " 774: 39,\n",
       " 775: 1,\n",
       " 776: 219,\n",
       " 777: 183,\n",
       " 778: 83,\n",
       " 779: 24,\n",
       " 780: 1,\n",
       " 781: 274,\n",
       " 782: 521,\n",
       " 783: 16,\n",
       " 784: 635,\n",
       " 785: 143,\n",
       " 786: 19,\n",
       " 787: 3,\n",
       " 788: 85,\n",
       " 789: 13,\n",
       " 790: 96,\n",
       " 791: 26,\n",
       " 792: 6,\n",
       " 793: 1,\n",
       " 794: 7,\n",
       " 795: 89,\n",
       " 796: 108,\n",
       " 797: 47,\n",
       " 798: 38,\n",
       " 799: 106,\n",
       " 800: 1,\n",
       " 801: 32,\n",
       " 802: 9,\n",
       " 803: 105,\n",
       " 804: 13,\n",
       " 805: 34,\n",
       " 806: 11,\n",
       " 807: 141,\n",
       " 808: 84,\n",
       " 809: 3,\n",
       " 810: 10,\n",
       " 811: 249,\n",
       " 812: 62,\n",
       " 813: 1,\n",
       " 814: 22,\n",
       " 815: 125,\n",
       " 816: 3,\n",
       " 817: 487,\n",
       " 818: 1,\n",
       " 820: 35,\n",
       " 819: 40,\n",
       " 821: 88,\n",
       " 822: 48,\n",
       " 824: 16,\n",
       " 825: 67,\n",
       " 823: 377,\n",
       " 826: 499,\n",
       " 827: 235,\n",
       " 828: 121,\n",
       " 829: 3,\n",
       " 830: 162,\n",
       " 831: 2,\n",
       " 832: 57,\n",
       " 833: 15,\n",
       " 834: 15,\n",
       " 835: 4,\n",
       " 836: 141,\n",
       " 837: 13,\n",
       " 838: 111,\n",
       " 839: 43,\n",
       " 840: 823,\n",
       " 841: 288,\n",
       " 842: 284,\n",
       " 843: 18,\n",
       " 844: 22,\n",
       " 846: 165,\n",
       " 845: 85,\n",
       " 847: 147,\n",
       " 848: 210,\n",
       " 849: 24,\n",
       " 850: 13,\n",
       " 851: 178,\n",
       " 852: 408,\n",
       " 853: 112,\n",
       " 854: 192,\n",
       " 855: 1324,\n",
       " 856: 60,\n",
       " 857: 49,\n",
       " 858: 77,\n",
       " 859: 19,\n",
       " 860: 387,\n",
       " 861: 494,\n",
       " 862: 189,\n",
       " 863: 26,\n",
       " 864: 106,\n",
       " 865: 48,\n",
       " 866: 11,\n",
       " 867: 13,\n",
       " 869: 8,\n",
       " 868: 8,\n",
       " 870: 506,\n",
       " 871: 63,\n",
       " 872: 10,\n",
       " 873: 152,\n",
       " 874: 88,\n",
       " 875: 34,\n",
       " 876: 166,\n",
       " 877: 116,\n",
       " 878: 1,\n",
       " 879: 86,\n",
       " 880: 21,\n",
       " 881: 48,\n",
       " 882: 13,\n",
       " 883: 10,\n",
       " 884: 167,\n",
       " 885: 73,\n",
       " 886: 2,\n",
       " 887: 32,\n",
       " 888: 3,\n",
       " 889: 155,\n",
       " 890: 111,\n",
       " 892: 224,\n",
       " 891: 11,\n",
       " 893: 670,\n",
       " 894: 8,\n",
       " 895: 11,\n",
       " 896: 223,\n",
       " 897: 1,\n",
       " 898: 59,\n",
       " 899: 17,\n",
       " 900: 81,\n",
       " 901: 351,\n",
       " 902: 259,\n",
       " 903: 30,\n",
       " 904: 106,\n",
       " 905: 9,\n",
       " 906: 88,\n",
       " 907: 63,\n",
       " 908: 9,\n",
       " 909: 195,\n",
       " 910: 468,\n",
       " 911: 31,\n",
       " 912: 56,\n",
       " 913: 124,\n",
       " 914: 127,\n",
       " 915: 19,\n",
       " 916: 2,\n",
       " 917: 15,\n",
       " 918: 100,\n",
       " 919: 627,\n",
       " 920: 8,\n",
       " 921: 80,\n",
       " 922: 328,\n",
       " 923: 106,\n",
       " 924: 10,\n",
       " 925: 183,\n",
       " 926: 1,\n",
       " 927: 57,\n",
       " 929: 2,\n",
       " 928: 56,\n",
       " 930: 6,\n",
       " 931: 418,\n",
       " 932: 37,\n",
       " 933: 102,\n",
       " 934: 1,\n",
       " 935: 51,\n",
       " 936: 266,\n",
       " 937: 95,\n",
       " 939: 13,\n",
       " 938: 12,\n",
       " 940: 46,\n",
       " 941: 16,\n",
       " 942: 32,\n",
       " 943: 484,\n",
       " 944: 2,\n",
       " 945: 57,\n",
       " 946: 153,\n",
       " 947: 14,\n",
       " 948: 50,\n",
       " 949: 16,\n",
       " 950: 1,\n",
       " 951: 138,\n",
       " 952: 21,\n",
       " 953: 114,\n",
       " 954: 64,\n",
       " 955: 30,\n",
       " 956: 220,\n",
       " 957: 666,\n",
       " 958: 185,\n",
       " 959: 66,\n",
       " 960: 132,\n",
       " 961: 4,\n",
       " 962: 292,\n",
       " 964: 59,\n",
       " 963: 672,\n",
       " 965: 23,\n",
       " 966: 96,\n",
       " 967: 1,\n",
       " 968: 16,\n",
       " 969: 279,\n",
       " 970: 142,\n",
       " 971: 248,\n",
       " 972: 13,\n",
       " 973: 11,\n",
       " 974: 73,\n",
       " 975: 109,\n",
       " 976: 127,\n",
       " 977: 296,\n",
       " 978: 163,\n",
       " 979: 44,\n",
       " 980: 30,\n",
       " 981: 17,\n",
       " 983: 94,\n",
       " 982: 50,\n",
       " 984: 79,\n",
       " 985: 29,\n",
       " 987: 31,\n",
       " 986: 37,\n",
       " 988: 2,\n",
       " 989: 860,\n",
       " 990: 411,\n",
       " 991: 1,\n",
       " 992: 17,\n",
       " 993: 172,\n",
       " 994: 102,\n",
       " 995: 63,\n",
       " 997: 1,\n",
       " 998: 3,\n",
       " 999: 1,\n",
       " 996: 186,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus_dct.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 19353, 11942, 601, 45, 1995, 2776, 1330, 1322, 11620, 233, 1110, 81, 8629, 4470, 839, 214432, 38854, 10014, 11839, 364, 1881, 449, 763, 184, 18, 23, 1015, 643, 20460, 402, 483, 1972, 381, 296, 5163, 3988, 9, 4557, 2555, 1963, 224, 401, 11746, 8, 40, 4230, 8601, 34427, 4901, 16, 887, 626, 3645, 27, 853, 298, 2436, 1741, 158, 5034, 1876, 11030, 83, 1332, 1363, 202, 15591, 1816, 2305, 8939, 1026, 490, 2315, 1415, 1192, 1787, 937, 177, 254, 40, 2, 2, 951, 52, 679, 152, 352, 9, 4224, 438, 64, 15, 506, 16, 20165, 1961, 1192, 253, 119, 34, 573, 276, 22, 261, 272, 128, 238, 35, 24, 123, 251, 788, 51, 195, 2291, 248, 123, 105, 1564, 67, 31, 253, 550, 1935, 120, 41, 189, 8099, 3951, 27, 10, 1166, 2080, 231, 4, 128, 44, 99, 346, 674, 107, 29, 25, 16, 129, 118, 2, 25, 2, 897, 2745, 1025, 208, 103, 23, 2529, 4853, 361, 7095, 1061, 1483, 16, 247, 3, 1870, 4, 5, 2, 3, 3043, 53, 72, 78, 3140, 1720, 2, 56, 87, 238, 152, 255, 59, 204, 1547, 5318, 193, 475, 665, 573, 448, 71, 133, 215, 462, 233, 118, 136, 9, 5, 936, 46, 366, 36, 26, 2, 306, 4008, 21, 2, 19, 460, 5, 1194, 2549, 32, 13, 336, 180, 176, 632, 3927, 8383, 21, 820, 10, 10, 394, 1062, 669, 31, 487, 29, 645, 185, 83, 944, 620, 8808, 1069, 45, 183, 39, 44, 35, 290, 1880, 67, 156, 33, 592, 13, 371, 239, 27, 191, 3, 270, 1795, 720, 18, 13, 111, 76, 490, 2, 332, 3, 676, 260, 70, 19, 387, 2, 77, 1437, 3976, 522, 9, 478, 259, 1102, 950, 235, 40, 3206, 321, 1, 4, 122, 23, 135, 10, 433, 341, 2422, 371, 1367, 212, 207, 163, 1, 436, 6, 82, 50, 92, 37, 26, 4, 307, 3, 1719, 2, 158, 1334, 2172, 318, 213, 68, 372, 120, 309, 52, 22, 1, 110, 792, 2047, 22, 54, 116, 34, 116, 130, 87, 19, 2, 13, 74, 125, 22, 4, 42, 3, 463, 644, 99, 188, 12, 1491, 42, 1008, 27, 178, 8, 316, 86, 339, 1450, 139, 2, 6, 64, 68, 58, 10, 1265, 42, 32, 269, 64, 24, 335, 14, 4, 35, 34, 66, 312, 3, 22, 71, 4, 159, 2, 1, 254, 148, 52, 668, 280, 161, 20, 9, 42, 1358, 9, 4, 8, 33, 149, 462, 31, 550, 112, 4264, 1394, 223, 297, 1579, 899, 117, 251, 6, 15, 25, 342, 22, 1143, 158, 250, 47, 9, 11, 76, 64, 17, 130, 436, 296, 143, 13, 122, 19, 139, 82, 450, 335, 28, 593, 1697, 333, 1296, 179, 1066, 144, 8, 3, 213, 80, 1290, 133, 49, 176, 3, 2, 360, 127, 556, 515, 29, 31, 1848, 37, 7, 275, 450, 20, 117, 213, 1653, 216, 13, 102, 31, 135, 262, 781, 74, 34, 153, 61, 4, 229, 142, 46, 106, 52, 23, 348, 1, 32, 1051, 66, 81, 33, 315, 22, 86, 18, 26, 149, 26, 34, 53, 15, 179, 19, 40, 1, 24, 108, 131, 160, 46, 126, 141, 158, 238, 3, 62, 1124, 632, 70, 304, 152, 741, 440, 116, 50, 40, 1, 21, 75, 88, 323, 417, 14, 8, 792, 231, 15, 220, 24, 34, 250, 267, 96, 9, 559, 159, 63, 785, 32, 88, 149, 1354, 157, 513, 98, 15, 242, 370, 26, 321, 1, 115, 10, 142, 28, 1, 41, 636, 167, 24, 152, 149, 4, 2, 113, 702, 539, 279, 50, 4, 10, 3, 145, 520, 239, 75, 45, 244, 60, 6, 53, 19, 26, 479, 10, 1029, 182, 103, 1049, 1075, 2, 18, 19, 12, 371, 339, 1204, 642, 523, 212, 318, 163, 128, 3, 639, 114, 412, 70, 449, 672, 121, 264, 128, 69, 82, 2, 107, 556, 280, 157, 485, 5, 39, 331, 373, 21, 284, 2, 8, 167, 111, 520, 642, 5, 184, 156, 403, 462, 77, 129, 141, 217, 2, 384, 134, 628, 237, 133, 53, 565, 43, 175, 323, 76, 357, 585, 58, 64, 90, 12, 1, 24, 754, 483, 13, 95, 57, 488, 115, 362, 83, 290, 142, 1, 193, 165, 142, 30, 80, 13, 67, 27, 32, 35, 57, 660, 244, 1051, 156, 801, 77, 56, 7, 105, 179, 215, 2, 163, 21, 238, 57, 1, 49, 2, 150, 104, 1, 10, 35, 61, 278, 42, 15, 22, 37, 18, 5, 29, 22, 215, 1, 111, 59, 15, 1, 14, 371, 21, 18, 67, 30, 1, 6, 1153, 13, 298, 48, 1, 26, 103, 65, 11, 36, 7, 1, 332, 434, 2, 2, 119, 55, 206, 363, 1, 50, 18, 11, 39, 1, 219, 183, 83, 24, 1, 274, 521, 16, 635, 143, 19, 3, 85, 13, 96, 26, 6, 1, 7, 89, 108, 47, 38, 106, 1, 32, 9, 105, 13, 34, 11, 141, 84, 3, 10, 249, 62, 1, 22, 125, 3, 487, 1, 35, 40, 88, 48, 16, 67, 377, 499, 235, 121, 3, 162, 2, 57, 15, 15, 4, 141, 13, 111, 43, 823, 288, 284, 18, 22, 165, 85, 147, 210, 24, 13, 178, 408, 112, 192, 1324, 60, 49, 77, 19, 387, 494, 189, 26, 106, 48, 11, 13, 8, 8, 506, 63, 10, 152, 88, 34, 166, 116, 1, 86, 21, 48, 13, 10, 167, 73, 2, 32, 3, 155, 111, 224, 11, 670, 8, 11, 223, 1, 59, 17, 81, 351, 259, 30, 106, 9, 88, 63, 9, 195, 468, 31, 56, 124, 127, 19, 2, 15, 100, 627, 8, 80, 328, 106, 10, 183, 1, 57, 2, 56, 6, 418, 37, 102, 1, 51, 266, 95, 13, 12, 46, 16, 32, 484, 2, 57, 153, 14, 50, 16, 1, 138, 21, 114, 64, 30, 220, 666, 185, 66, 132, 4, 292, 59, 672, 23, 96, 1, 16, 279, 142, 248, 13, 11, 73, 109, 127, 296, 163, 44, 30, 17, 94, 50, 79, 29, 31, 37, 2, 860, 411, 1, 17, 172, 102, 63, 1, 3, 1, 186, 16, 19, 5, 92, 10, 72, 1048, 2, 424, 1, 23, 24, 214, 227, 167, 115, 231, 128, 306, 40, 21, 33, 2, 30, 5, 80, 7, 322, 30, 113, 384, 9, 13, 215, 114, 284, 52, 26, 114, 14, 122, 235, 186, 498, 149, 349, 11, 190, 18, 165, 8, 10, 23, 667, 41, 7, 49, 29, 241, 24, 17, 55, 15, 152, 39, 38, 15, 117, 42, 60, 48, 19, 137, 4, 25, 179, 38, 448, 77, 369, 2, 37, 13, 24, 5, 101, 102, 69, 6, 6, 8, 25, 11, 10, 5, 157, 78, 19, 46, 78, 38, 12, 30, 1, 57, 83, 9, 10, 50, 275, 9, 128, 276, 3, 109, 30, 297, 2, 2, 13, 15, 28, 5, 1, 41, 99, 28, 66, 18, 119, 75, 176, 51, 49, 89, 135, 1, 53, 3, 134, 46, 39, 6, 29, 310, 94, 110, 21, 1, 4, 4, 110, 18, 17, 14, 5, 19, 1, 8, 34, 57, 7, 2, 54, 4, 39, 356, 37, 52, 24, 174, 5, 45, 22, 2, 180, 20, 94, 47, 67, 108, 206, 166, 327, 20, 6, 74, 23, 80, 27, 20, 7, 103, 18, 4, 13, 1, 31, 170, 15, 103, 170, 48, 23, 82, 20, 12, 65, 35, 1, 40, 3, 35, 1, 46, 116, 141, 140, 9, 73, 6, 2, 14, 87, 4, 28, 59, 111, 708, 12, 8, 38, 178, 10, 8, 61, 80, 13, 70, 123, 1, 19, 396, 92, 6, 102, 128, 50, 66, 9, 34, 98, 244, 24, 4, 311, 1, 49, 2, 2, 26, 74, 37, 71, 246, 2, 49, 1, 9, 120, 7, 15, 4, 4, 201, 188, 46, 4, 3, 13, 122, 73, 116, 20, 25, 61, 6, 1, 148, 12, 18, 1, 22, 250, 69, 89, 128, 83, 21, 1, 15, 1, 21, 156, 35, 1, 8, 1, 3, 45, 2, 35, 23, 2, 54, 4, 58, 112, 18, 235, 24, 123, 65, 3, 15, 12, 45, 184, 294, 150, 6, 28, 19, 104, 90, 57, 19, 2074, 25, 183, 25, 101, 5, 82, 23, 11, 35, 103, 1, 598, 11, 873, 11, 13, 71, 55, 30, 638, 1, 2, 29, 42, 9, 1, 71, 7, 8, 1, 428, 65, 14, 97, 17, 1, 7, 290, 6, 1, 196, 330, 25, 116, 15, 30, 3, 156, 1, 1, 19, 13, 186, 119, 9, 40, 87, 545, 12, 16, 101, 347, 131, 21, 74, 9, 106, 349, 18, 112, 94, 2, 31, 58, 45, 26, 7, 9, 26, 35, 6, 80, 1, 14, 12, 1, 4, 102, 17, 295, 5, 16, 129, 60, 4, 20, 1, 1, 64, 8, 3, 1, 165, 15, 91, 9, 35, 20, 6, 17, 65, 21, 25, 91, 52, 6, 101, 107, 26, 300, 115, 36, 121, 9, 1, 55, 120, 80, 119, 261, 3, 100, 37, 43, 48, 144, 117, 1, 31, 2, 16, 84, 7, 19, 9, 17, 86, 35, 4, 82, 71, 32, 76, 10, 2, 23, 1, 112, 882, 1, 445, 17, 21, 64, 114, 6, 25, 4, 10, 51, 11, 48, 15, 7, 12, 1, 45, 74, 73, 51, 80, 12, 35, 9, 69, 92, 23, 30, 1, 1, 78, 3, 17, 5, 75, 4, 13, 1, 33, 107, 38, 13, 10, 13, 56, 68, 170, 121, 9, 94, 3, 5, 15, 191, 22, 1, 61, 321, 100, 2, 18, 11, 60, 6, 1, 13, 28, 71, 161, 32, 14, 40, 73, 79, 66, 1, 84, 59, 5, 77, 86, 172, 1, 16, 32, 47, 171, 1, 33, 54, 21, 17, 385, 58, 12, 19, 42, 21, 17, 19, 1, 4, 317, 1, 25, 90, 26, 8, 14, 6, 1, 3, 278, 96, 1, 174, 17, 4, 83, 20, 39, 69, 11, 46, 45, 9, 8, 7, 151, 93, 2, 132, 27, 32, 1, 21, 57, 7, 10, 170, 62, 3, 12, 33, 118, 51, 18, 60, 53, 42, 2, 2, 14, 4, 9, 491, 69, 4, 156, 21, 4, 54, 8, 50, 8, 4, 1, 9, 29, 9, 3, 20, 13, 37, 62, 62, 55, 68, 18, 44, 74, 14, 51, 6, 49, 22, 1, 163, 20, 55, 6, 3, 4, 40, 37, 8, 8, 5, 23, 44, 9, 3, 48, 3, 2, 161, 96, 5, 104, 5, 23, 5, 42, 55, 1, 4, 117, 3, 14, 2, 225, 10, 65, 1, 1, 71, 176, 23, 102, 70, 25, 29, 6, 39, 53, 18, 17, 22, 93, 71, 1, 50, 244, 64, 79, 3, 3, 4, 82, 137, 45, 27, 267, 15, 79, 33, 46, 104, 51, 63, 55, 2, 15, 122, 5, 7, 230, 7, 114, 20, 78, 99, 1, 6, 8, 3, 5, 10, 31, 1, 47, 3, 36, 18, 2, 12, 10, 58, 39, 13, 4, 3, 3, 7, 12, 143, 24, 3, 16, 1, 6, 76, 5, 1, 19, 27, 2, 36, 40, 12, 19, 3, 96, 14, 120, 6, 88, 10, 11, 16, 7, 11, 13, 34, 92, 1, 3, 8, 67, 395, 2, 17, 40, 45, 1, 26, 32, 4, 21, 8, 49, 30, 12, 19, 27, 70, 149, 129, 10, 1, 10, 2, 16, 8, 23, 2, 32, 19, 37, 9, 254, 87, 62, 199, 11, 42, 315, 50, 86, 61, 3, 28, 75, 26, 14, 103, 5, 100, 197, 69, 200, 64, 2, 40, 32, 6, 34, 32, 9, 13, 234, 68, 11, 5, 9, 15, 688, 1, 11, 6, 143, 389, 283, 1, 25, 39, 94, 1, 58, 85, 69, 22, 6, 83, 14, 19, 2, 1, 23, 7, 11, 2, 4, 222, 21, 1, 1, 28, 27, 36, 42, 42, 12, 67, 104, 200, 81, 22, 41, 17, 5, 18, 67, 87, 44, 7, 11, 12, 46, 36, 68, 4, 3, 31, 132, 7, 2, 1, 134, 128, 35, 26, 27, 120, 30, 56, 54, 6, 16, 1, 7, 2, 40, 44, 1, 5, 83, 29, 52, 5, 2, 14, 41, 10, 1, 87, 1, 4, 4, 12, 72, 8, 1, 7, 24, 1, 3, 234, 7, 33, 54, 82, 4, 16, 32, 104, 18, 6, 34, 43, 9, 68, 25, 49, 7, 26, 101, 11, 6, 50, 162, 17, 63, 6, 3, 4, 3, 66, 21, 1, 33, 63, 46, 115, 108, 109, 24, 17, 84, 59, 22, 1, 34, 7, 59, 24, 61, 41, 5, 10, 19, 1, 1, 3, 7, 13, 24, 2, 15, 48, 17, 53, 37, 34, 119, 29, 99, 1, 28, 1, 13, 30, 7, 23, 64, 16, 3, 2, 61, 5, 19, 17, 30, 21, 20, 6, 2, 69, 12, 17, 10, 8, 24, 268, 5, 132, 10, 144, 1, 40, 29, 6, 63, 3, 4, 72, 25, 40, 12, 7, 78, 5, 50, 7, 2, 120, 22, 3, 40, 77, 1, 5, 28, 5, 1, 79, 20, 2, 10, 113, 34, 38, 226, 84, 49, 30, 192, 44, 70, 7, 1, 2, 2, 29, 17, 1, 33, 15, 74, 132, 9, 51, 11, 2, 7, 10, 8, 36, 7, 43, 2, 13, 11, 39, 82, 64, 1, 42, 1, 35, 32, 29, 11, 67, 27, 162, 121, 7, 8, 138, 65, 7, 4, 2, 84, 43, 1, 5, 16, 1, 3, 194, 1, 2, 3, 45, 6, 1, 43, 53, 18, 2, 56, 1, 62, 16, 1, 43, 8, 3, 91, 19, 91, 35, 10, 9, 5, 2, 20, 1, 54, 3, 1, 4, 1, 11, 1, 27, 1, 2, 2, 46, 10, 1, 8, 44, 13, 84, 3, 2, 1, 3, 3, 42, 7, 45, 1, 126, 2, 17, 35, 8, 35, 194, 23, 60, 1, 3, 15, 3, 8, 205, 60, 177, 169, 12, 3, 46, 4, 84, 1, 41, 28, 8, 110, 88, 12, 7, 11, 2, 40, 78, 93, 36, 6, 19, 2, 45, 97, 21, 18, 14, 8, 16, 39, 37, 30, 11, 1, 6, 121, 18, 111, 11, 84, 16, 5, 78, 15, 14, 34, 1, 48, 18, 1, 15, 29, 32, 10, 41, 28, 82, 27, 20, 9, 30, 32, 25, 16, 5, 28, 239, 35, 478, 101, 41, 15, 3, 29, 7, 9, 1, 1, 1, 1, 1, 1, 3, 44, 7, 6, 7, 15, 18, 8, 54, 30, 7, 12, 2, 24, 1, 29, 2, 3, 23, 26, 9, 22, 1, 1, 46, 18, 44, 3, 2, 2, 5, 1, 10, 1, 38, 6, 1, 1, 22, 12, 18, 18, 8, 38, 2, 39, 1, 1, 1, 3, 4, 96, 15, 21, 1, 1, 18, 8, 2, 7, 299, 123, 7, 20, 1, 1, 112, 19, 21, 100, 8, 9, 142, 12, 1, 127, 15, 22, 1, 1, 3, 9, 110, 40, 16, 15, 25, 6, 16, 50, 10, 1, 21, 7, 5, 8, 8, 44, 6, 10, 15, 2, 15, 11, 185, 34, 5, 4, 29, 49, 1, 16, 3, 11, 29, 3, 27, 6, 3, 2, 6, 8, 2, 26, 6, 28, 1, 8, 6, 3, 13, 14, 28, 8, 1, 1, 18, 55, 11, 2, 11, 31, 27, 1, 10, 6, 7, 24, 46, 3, 7, 50, 24, 47, 10, 6, 14, 2, 4, 13, 172, 203, 9, 14, 10, 126, 119, 33, 97, 40, 101, 35, 2, 1, 35, 70, 8, 21, 38, 11, 3, 5, 23, 75, 13, 45, 1, 1, 4, 1, 1, 1, 1, 7, 21, 35, 22, 159, 58, 7, 1, 192, 10, 1, 8, 2, 41, 134, 45, 2, 2, 374, 57, 5, 80, 30, 3, 3, 10, 1, 10, 12, 23, 1, 7, 1, 161, 46, 4, 22, 6, 10, 60, 1, 75, 63, 121, 1, 3, 9, 7, 2, 1, 18, 20, 1, 50, 3, 3, 11, 52, 3, 5, 4, 6, 3, 2, 11, 1, 44, 95, 48, 34, 8, 17, 24, 13, 12, 141, 9, 22, 24, 3, 5, 1, 83, 52, 21, 15, 41, 71, 6, 6, 16, 48, 18, 1, 14, 11, 3, 36, 53, 14, 18, 20, 3, 19, 54, 120, 1, 32, 105, 5, 28, 12, 3, 21, 4, 40, 2, 2, 7, 6, 6, 1, 16, 55, 8, 8, 19, 5, 9, 16, 30, 61, 71, 10, 76, 1, 5, 2, 2, 12, 8, 3, 18, 3, 8, 3, 1, 14, 42, 20, 13, 9, 33, 21, 3, 12, 8, 51, 13, 32, 20, 20, 2, 8, 6, 4, 98, 1, 35, 13, 52, 65, 126, 107, 40, 4, 36, 15, 19, 20, 25, 2, 1, 13, 1, 13, 2, 6, 31, 12, 137, 2, 4, 9, 1, 1, 2, 2, 61, 38, 8, 1, 20, 27, 4, 7, 81, 17, 62, 4, 21, 18, 57, 191, 29, 58, 14, 18, 21, 103, 1, 1, 26, 17, 23, 149, 35, 75, 1, 115, 2, 21, 51, 1, 5, 4, 1, 10, 8, 1, 1, 11, 7, 15, 32, 17, 12, 8, 4, 81, 35, 7, 8, 12, 27, 19, 36, 73, 32, 31, 1, 4, 41, 17, 4, 10, 57, 3, 6, 3, 8, 10, 32, 3, 8, 36, 17, 19, 130, 6, 4, 134, 6, 10, 8, 22, 6, 11, 20, 9, 113, 5, 83, 23, 2, 1, 1, 25, 44, 14, 9, 17, 49, 9, 48, 12, 17, 3, 18, 9, 1, 16, 4, 38, 21, 3, 1, 5, 14, 4, 18, 1, 19, 93, 6, 2, 2, 1, 29, 1, 34, 4, 5, 3, 1, 1, 1, 10, 1, 38, 19, 12, 11, 1, 7, 52, 49, 48, 4, 4, 43, 20, 45, 2, 5, 19, 1, 3, 30, 1, 1, 42, 44, 33, 38, 18, 14, 13, 5, 11, 31, 1, 1, 3, 1, 31, 2, 27, 17, 4, 11, 41, 12, 1, 4, 53, 20, 5, 4, 1, 6, 3, 4, 10, 3, 5, 43, 3, 1, 17, 2, 13, 41, 3, 5, 126, 3, 10, 12, 13, 14, 2, 62, 48, 11, 1, 91, 6, 8, 7, 10, 1, 1, 72, 7, 27, 1, 12, 46, 10, 16, 63, 69, 127, 64, 40, 68, 9, 5, 1, 27, 18, 1, 5, 3, 2, 18, 114, 23, 3, 13, 1, 33, 12, 13, 21, 9, 1, 11, 9, 17, 10, 32, 72, 2, 46, 9, 2, 20, 14, 50, 3, 8, 4, 40, 69, 1, 15, 5, 1, 4, 2, 1, 26, 120, 1, 11, 43, 2, 21, 7, 2, 23, 13, 4, 4, 17, 1, 3, 11, 10, 2, 14, 34, 8, 5, 15, 14, 60, 16, 12, 53, 1, 20, 52, 14, 3, 3, 58, 1, 75, 5, 32, 9, 1, 27, 19, 57, 16, 3, 14, 21, 8, 7, 1, 8, 20, 2, 14, 17, 5, 1, 3, 7, 5, 1, 9, 18, 4, 6, 2, 35, 17, 11, 22, 3, 33, 1, 24, 22, 31, 11, 88, 23, 13, 18, 1, 10, 3, 24, 1, 1, 1, 9, 4, 26, 1, 3, 1, 9, 11, 25, 11, 4, 1, 16, 11, 9, 13, 4, 11, 10, 23, 45, 7, 77, 1, 3, 6, 6, 2, 34, 4, 89, 327, 50, 1, 1, 15, 16, 2, 2, 1, 3, 3, 17, 1, 2, 107, 46, 9, 16, 9, 3, 5, 90, 1, 18, 2, 44, 7, 99, 16, 1, 66, 52, 9, 15, 3, 56, 19, 21, 15, 12, 5, 3, 3, 4, 8, 177, 3, 1, 3, 52, 16, 5, 1, 9, 40, 2, 11, 22, 9, 8, 64, 4, 52, 41, 13, 110, 5, 42, 1, 2, 11, 1, 32, 5, 1, 10, 16, 21, 32, 17, 3, 5, 1, 15, 2, 2, 1, 6, 16, 155, 1, 22, 5, 7, 21, 15, 86, 23, 20, 5, 3, 3, 12, 1, 34, 18, 38, 3, 2, 2, 12, 7, 23, 26, 2, 26, 53, 19, 1, 1, 19, 10, 34, 1, 3, 1, 2, 1, 28, 1, 9, 14, 6, 59, 69, 5, 11, 2, 10, 7, 155, 10, 8, 6, 4, 1, 37, 13, 18, 2, 1, 71, 3, 2, 1, 21, 1, 14, 14, 68, 3, 5, 9, 24, 32, 18, 9, 1, 9, 1, 47, 39, 1, 17, 740, 111, 1, 17, 33, 54, 4, 15, 12, 6, 19, 31, 38, 3, 2, 32, 10, 3, 1, 2, 20, 37, 5, 21, 1, 1, 26, 9, 2, 1, 13, 42, 26, 6, 16, 2, 1, 4, 10, 15, 2, 4, 1, 7, 4, 16, 11, 19, 60, 21, 5, 1, 23, 41, 3, 1, 4, 1, 157, 1, 5, 22, 4, 1, 1, 4, 11, 6, 41, 9, 57, 11, 2, 7, 24, 2, 1, 19, 9, 4, 20, 5, 18, 4, 20, 15, 4, 112, 13, 2, 71, 4, 1, 2, 17, 2, 4, 3, 28, 12, 1, 11, 8, 6, 118, 16, 12, 24, 14, 6, 24, 8, 1, 13, 12, 3, 2, 7, 5, 11, 7, 8, 47, 1, 21, 38, 53, 3, 16, 14, 18, 5, 7, 2, 6, 2, 1, 18, 8, 3, 1, 15, 7, 3, 1, 5, 13, 1, 42, 47, 4, 2, 1, 22, 13, 25, 4, 1, 14, 6, 1, 1, 17, 5, 1, 16, 6, 15, 1, 8, 11, 7, 3, 23, 21, 3, 20, 1, 9, 17, 9, 3, 21, 14, 27, 2, 9, 3, 5, 1, 11, 1, 1, 16, 48, 1, 21, 46, 6, 14, 15, 16, 10, 4, 319, 2, 9, 3, 1, 1, 2, 1, 15, 1, 12, 2, 15, 12, 5, 3, 17, 12, 8, 13, 9, 2, 113, 1, 2, 2, 23, 9, 28, 53, 2, 9, 3, 54, 12, 9, 2, 32, 17, 5, 2, 1, 24, 4, 1, 7, 36, 1, 8, 17, 6, 44, 20, 2, 1, 46, 1, 10, 11, 23, 8, 35, 20, 11, 28, 25, 1, 3, 29, 3, 1, 4, 2, 9, 25, 8, 9, 1, 7, 6, 1, 21, 3, 28, 42, 18, 4, 15, 18, 4, 23, 3, 7, 9, 2, 1, 36, 8, 59, 35, 10, 11, 1, 19, 43, 18, 29, 25, 1, 4, 21, 25, 33, 4, 5, 46, 11, 2, 26, 1, 41, 1, 10, 37, 8, 7, 11, 12, 23, 2, 14, 2, 1, 17, 14, 1, 49, 6, 1, 1, 1, 23, 10, 1, 11, 39, 2, 21, 26, 2, 14, 16, 3, 9, 4, 14, 2, 6, 30, 105, 28, 1, 2, 10, 25, 3, 71, 2, 4, 4, 18, 12, 1, 10, 2, 1, 2, 1, 41, 1, 13, 2, 5, 4, 1, 38, 6, 42, 3, 23, 6, 44, 1, 2, 10, 2, 6, 2, 10, 7, 7, 9, 13, 51, 8, 3, 19, 3, 1, 230, 7, 2, 11, 37, 2, 2, 3, 6, 12, 32, 32, 7, 4, 2, 2, 1, 1, 6, 49, 3, 2, 69, 3, 1, 3, 6, 30, 19, 1, 6, 3, 82, 52, 18, 76, 1, 6, 116, 1, 2, 1, 2, 5, 2, 1, 13, 1, 4, 45, 2, 8, 28, 7, 6, 1, 4, 21, 1, 10, 10, 229, 28, 1, 3, 1, 6, 36, 1, 2, 5, 47, 7, 16, 19, 2, 3, 2, 2, 4, 15, 5, 13, 54, 1, 1, 2, 6, 1, 2, 5, 50, 14, 6, 7, 9, 7, 50, 1, 49, 1, 53, 4, 8, 2, 10, 3, 6, 6, 66, 11, 5, 1, 3, 6, 35, 4, 40, 2, 11, 5, 1, 4, 5, 3, 26, 6, 2, 4, 6, 1, 6, 2, 1, 5, 2, 1, 12, 3, 2, 2, 8, 44, 8, 4, 34, 2, 1, 1, 4, 1, 4, 11, 1, 1, 1, 4, 14, 1, 19, 7, 1, 31, 1, 18, 18, 22, 10, 51, 17, 2, 5, 6, 20, 14, 2, 7, 6, 289, 9, 3, 19, 17, 14, 5, 19, 19, 11, 14, 17, 1, 6, 3, 6, 1, 11, 1, 21, 18, 1, 7, 14, 9, 1, 5, 2, 1, 9, 10, 1, 46, 5, 29, 1, 23, 8, 3, 14, 14, 2, 1, 4, 4, 5, 1, 7, 18, 1, 13, 2, 18, 10, 13, 15, 12, 38, 90, 4, 108, 1, 16, 5, 4, 6, 8, 4, 16, 8, 6, 10, 11, 4, 14, 3, 1, 4, 2, 7, 5, 4, 13, 22, 7, 10, 12, 3, 7, 17, 1, 1, 5, 4, 1, 8, 42, 10, 2, 12, 13, 5, 7, 17, 29, 1, 1, 72, 32, 30, 7, 135, 37, 3, 3, 6, 10, 7, 28, 22, 12, 12, 5, 1, 3, 1, 26, 9, 19, 67, 1, 10, 1, 24, 10, 47, 5, 6, 23, 6, 9, 8, 13, 4, 1, 9, 59, 1, 1, 6, 18, 1, 4, 3, 1, 11, 1, 2, 4, 6, 3, 1, 2, 1, 3, 14, 17, 29, 16, 1, 2, 2, 7, 99, 2, 11, 73, 6, 1, 11, 3, 16, 7, 1, 10, 23, 11, 15, 26, 54, 6, 1, 53, 1, 29, 11, 42, 20, 138, 4, 28, 4, 1, 1, 34, 7, 47, 16, 17, 16, 7, 35, 1, 1, 11, 13, 11, 5, 30, 9, 3, 9, 2, 3, 8, 5, 1, 13, 3, 4, 6, 2, 13, 2, 49, 24, 1, 21, 5, 1, 6, 2, 9, 10, 11, 16, 13, 1, 1, 3, 1, 38, 5, 20, 3, 4, 2, 25, 1, 2, 1, 42, 3, 12, 10, 6, 4, 29, 1, 3, 5, 11, 1, 3, 1, 7, 13, 10, 10, 1, 7, 8, 1, 25, 2, 35, 18, 3, 7, 3, 41, 1, 4, 3, 10, 11, 3, 6, 11, 13, 12, 1, 24, 7, 18, 1, 26, 4, 10, 3, 4, 2, 1, 1, 6, 22, 5, 23, 1, 3, 13, 1, 1, 7, 63, 15, 3, 5, 2, 14, 11, 11, 1, 12, 5, 4, 14, 4, 2, 1, 10, 3, 5, 13, 13, 1, 1, 16, 17, 28, 1, 3, 4, 41, 9, 26, 1, 11, 3, 1, 14, 1, 8, 8, 4, 3, 2, 1, 7, 2, 10, 1, 1, 6, 2, 2, 33, 4, 18, 26, 3, 24, 4, 3, 7, 1, 19, 5, 10, 41, 11, 3, 2, 4, 2, 1, 34, 14, 13, 1, 12, 4, 10, 2, 41, 1, 2, 2, 3, 1, 3, 10, 20, 2, 7, 1, 8, 7, 16, 5, 4, 51, 16, 1, 29, 25, 14, 8, 18, 12, 4, 1, 12, 2, 10, 19, 2, 9, 2, 5, 5, 8, 9, 12, 2, 25, 16, 13, 10, 4, 16, 10, 30, 12, 38, 2, 3, 56, 2, 1, 9, 7, 1, 1, 2, 14, 3, 34, 7, 6, 7, 7, 11, 6, 1, 3, 6, 3, 4, 1, 1, 4, 2, 34, 27, 5, 4, 4, 19, 7, 1, 1, 26, 4, 3, 15, 2, 8, 1, 4, 6, 5, 1, 21, 11, 7, 1, 9, 2, 1, 59, 1, 10, 1, 10, 2, 9, 1, 11, 6, 2, 1, 1, 4, 18, 6, 2, 2, 20, 1, 12, 32, 1, 2, 8, 7, 2, 1, 1, 1, 2, 27, 13, 14, 36, 26, 47, 12, 13, 3, 30, 8, 6, 11, 6, 11, 1, 1, 27, 1, 77, 29, 3, 4, 1, 5, 1, 1, 5, 76, 1, 10, 15, 4, 1, 9, 27, 1, 10, 3, 1, 2, 1, 2, 8, 4, 3, 38, 10, 18, 11, 1, 3, 16, 2, 18, 1, 4, 10, 30, 1, 23, 11, 31, 7, 7, 1, 1, 7, 27, 10, 1, 1, 2, 3, 21, 1, 4, 5, 31, 31, 3, 1, 7, 7, 3, 4, 7, 2, 4, 1, 2, 1, 2, 1, 1, 39, 12, 15, 1, 5, 14, 2, 8, 3, 2, 10, 8, 1, 1, 12, 2, 5, 3, 8, 1, 10, 5, 2, 76, 1, 7, 1, 6, 1, 6, 10, 1, 1, 9, 3, 2, 2, 2, 2, 1, 1, 10, 3, 11, 37, 1, 3, 7, 2, 14, 1, 7, 22, 10, 15, 1, 2, 27, 31, 1, 6, 13, 25, 6, 1, 24, 8, 1, 1, 51, 5, 7, 4, 6, 2, 1, 2, 4, 8, 22, 17, 3, 3, 3, 7, 7, 4, 28, 3, 21, 10, 7, 3, 3, 3, 10, 10, 39, 8, 4, 11, 1, 2, 13, 5, 3, 9, 6, 14, 10, 18, 8, 1, 16, 2, 8, 2, 2, 10, 5, 5, 44, 6, 7, 1, 1, 18, 3, 9, 1, 2, 1, 1, 1, 7, 5, 6, 25, 1, 19, 6, 2, 24, 11, 26, 11, 7, 1, 9, 6, 2, 1, 28, 17, 6, 2, 14, 16, 36, 23, 18, 11, 2, 7, 12, 5, 4, 12, 37, 16, 1, 1, 4, 11, 1, 20, 2, 1, 17, 5, 23, 5, 2, 9, 15, 4, 2, 1, 20, 1, 2, 3, 15, 1, 5, 1, 2, 1, 3, 2, 3, 9, 1, 2, 1, 26, 4, 8, 6, 19, 2, 16, 9, 6, 1, 1, 18, 12, 12, 2, 4, 1, 15, 4, 5, 5, 57, 5, 2, 5, 10, 6, 1, 7, 28, 6, 7, 2, 5, 51, 24, 9, 1, 21, 20, 24, 36, 57, 6, 3, 6, 13, 2, 2, 1, 3, 7, 2, 10, 1, 4, 12, 32, 15, 10, 2, 1, 1, 10, 1, 42, 10, 44, 23, 3, 2, 2, 19, 1, 26, 4, 15, 12, 6, 13, 3, 5, 2, 5, 3, 3, 1, 4, 1, 44, 3, 16, 5, 8, 5, 4, 1, 8, 5, 17, 2, 9, 12, 2, 3, 12, 19, 2, 5, 12, 4, 2, 3, 4, 9, 3, 12, 2, 1, 29, 1, 14, 13, 1, 1, 4, 3, 24, 2, 4, 9, 7, 3, 1, 1, 1, 25, 1, 4, 1, 4, 1, 7, 6, 3, 1, 1, 1, 1, 11, 6, 4, 1, 10, 15, 1, 1, 1, 7, 1, 1, 2, 15, 16, 7, 1, 1, 7, 1, 78, 37, 8, 6, 6, 16, 1, 1, 1, 5, 8, 1, 4, 12, 26, 4, 2, 5, 1, 12, 4, 15, 1, 3, 10, 2, 3, 14, 12, 4, 12, 3, 1, 11, 73, 5, 1, 12, 25, 15, 23, 31, 3, 30, 40, 49, 25, 1, 1, 3, 14, 1, 18, 2, 9, 13, 16, 1, 1, 1, 10, 8, 11, 3, 61, 1, 1, 11, 7, 1, 11, 12, 6, 1, 1, 8, 2, 1, 8, 6, 41, 31, 1, 45, 10, 2, 9, 13, 13, 5, 24, 20, 1, 19, 23, 15, 37, 7, 4, 1, 11, 1, 1, 7, 1, 4, 7, 1, 1, 1, 2, 1, 1, 1, 10, 2, 2, 2, 1, 3, 3, 6, 19, 5, 2, 22, 2, 11, 37, 3, 2, 9, 1, 12, 1, 4, 19, 3, 1, 6, 4, 3, 1, 1, 8, 1, 1, 14, 5, 3, 12, 6, 29, 1, 29, 6, 14, 8, 7, 25, 2, 9, 17, 8, 1, 10, 35, 2, 7, 9, 14, 1, 4, 1, 1, 5, 14, 20, 4, 12, 14, 2, 3, 16, 1, 1, 11, 2, 19, 1, 1, 15, 8, 1, 7, 2, 6, 1, 14, 1, 11, 45, 27, 7, 2, 3, 1, 24, 2, 1, 1, 1, 13, 10, 3, 28, 3, 11, 1, 1, 17, 8, 1, 6, 3, 29, 8, 6, 4, 1, 1, 5, 4, 1, 33, 1, 55, 6, 1, 4, 9, 3, 6, 1, 6, 2, 13, 7, 10, 6, 22, 72, 4, 2, 2, 4, 1, 4, 10, 3, 23, 6, 4, 1, 13, 7, 8, 7, 15, 1, 2, 2, 1, 3, 3, 8, 1, 2, 2, 2, 1, 22, 11, 26, 8, 4, 8, 18, 7, 7, 1, 3, 3, 1, 2, 2, 6, 8, 1, 4, 113, 6, 17, 1, 2, 3, 27, 9, 2, 1, 10, 1, 22, 1, 1, 1, 6, 1, 15, 6, 11, 4, 3, 3, 12, 1, 16, 4, 1, 1, 35, 2, 3, 5, 6, 1, 5, 4, 7, 7, 1, 7, 7, 3, 43, 15, 5, 4, 2, 4, 3, 1, 5, 1, 3, 6, 14, 16, 2, 1, 2, 7, 1, 2, 10, 3, 6, 17, 3, 35, 1, 17, 3, 6, 1, 2, 5, 4, 16, 5, 1, 6, 3, 7, 2, 3, 1, 19, 2, 34, 21, 3, 1, 8, 1, 1, 4, 3, 1, 9, 7, 1, 1, 7, 1, 1, 13, 15, 2, 5, 5, 34, 1, 3, 7, 41, 13, 21, 3, 2, 2, 1, 4, 4, 11, 1, 8, 12, 2, 14, 1, 2, 1, 1, 2, 1, 14, 2, 1, 7, 13, 35, 2, 3, 1, 12, 21, 1, 6, 27, 4, 1, 11, 2, 23, 17, 7, 4, 2, 5, 7, 3, 2, 14, 1, 4, 33, 2, 17, 3, 4, 7, 3, 7, 2, 2, 1, 3, 12, 1, 22, 14, 7, 2, 5, 31, 2, 2, 3, 1, 16, 22, 1, 5, 5, 3, 1, 1, 29, 1, 1, 1, 3, 1, 2, 3, 2, 11, 32, 8, 14, 2, 5, 11, 20, 8, 5, 21, 3, 11, 25, 1, 3, 4, 1, 5, 6, 2, 3, 9, 4, 4, 24, 1, 22, 23, 4, 2, 2, 25, 1, 41, 14, 1, 7, 5, 11, 6, 6, 2, 3, 1, 3, 1, 5, 16, 1, 3, 10, 2, 27, 1, 7, 1, 3, 1, 9, 14, 6, 8, 27, 9, 13, 1, 15, 1, 1, 24, 1, 1, 13, 5, 17, 1, 1, 2, 1, 10, 11, 5, 1, 2, 2, 27, 19, 1, 3, 14, 2, 2, 1, 3, 8, 7, 2, 8, 2, 7, 1, 1, 1, 1, 5, 4, 5, 2, 9, 5, 10, 2, 1, 6, 1, 41, 3, 1, 1, 1, 4, 4, 4, 2, 3, 7, 2, 3, 3, 4, 5, 1, 13, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 11, 1, 1, 28, 2, 4, 1, 3, 3, 1, 11, 1, 6, 22, 4, 2, 2, 4, 5, 2, 1, 11, 3, 13, 5, 4, 1, 1, 4, 24, 1, 31, 4, 2, 2, 3, 1, 6, 12, 3, 18, 10, 18, 1, 2, 23, 1, 1, 7, 1, 1, 1, 3, 1, 6, 11, 6, 1, 1, 5, 7, 4, 21, 1, 22, 1, 3, 5, 3, 2, 1, 6, 7, 1, 1, 4, 4, 1, 5, 2, 1, 14, 18, 17, 1, 1, 3, 1, 10, 3, 1, 1, 11, 1, 4, 11, 1, 2, 10, 6, 4, 1, 1, 15, 11, 9, 1, 2, 11, 14, 2, 3, 10, 4, 1, 1, 2, 1, 10, 5, 72, 1, 4, 15, 3, 33, 3, 2, 3, 1, 1, 18, 1, 1, 1, 2, 21, 1, 2, 19, 1, 12, 1, 14, 22, 7, 28, 1, 5, 1, 5, 15, 1, 5, 4, 1, 2, 17, 5, 1, 3, 1, 1, 1, 2, 4, 19, 27, 3, 14, 4, 4, 5, 13, 16, 20, 15, 1, 2, 8, 11, 1, 18, 2, 1, 5, 3, 1, 13, 2, 13, 11, 1, 2, 4, 4, 15, 9, 1, 1, 11, 8, 13, 2, 10, 1, 1, 4, 2, 2, 6, 1, 12, 1, 2, 15, 1, 3, 1, 17, 1, 4, 12, 6, 3, 2, 1, 1, 1, 1, 5, 1, 1, 2, 12, 13, 23, 2, 1, 7, 4, 1, 2, 8, 1, 24, 1, 7, 14, 6, 3, 3, 1, 2, 18, 1, 1, 1, 24, 7, 9, 2, 1, 4, 2, 2, 4, 3, 1, 12, 9, 1, 8, 2, 8, 7, 1, 1, 1, 1, 2, 1, 5, 11, 1, 2, 1, 3, 6, 1, 4, 4, 6, 1, 2, 1, 1, 1, 2, 6, 3, 1, 9, 7, 13, 6, 1, 3, 9, 27, 10, 6, 2, 1, 2, 2, 1, 2, 19, 16, 3, 1, 2, 1, 2, 5, 2, 1, 1, 24, 2, 1, 2, 1, 53, 3, 5, 10, 17, 1, 4, 2, 2, 2, 25, 6, 10, 4, 1, 10, 2, 11, 6, 1, 1, 2, 12, 9, 5, 3, 2, 15, 3, 18, 1, 5, 2, 2, 1, 2, 3, 8, 1, 2, 2, 1, 4, 1, 2, 7, 5, 1, 56, 2, 1, 5, 1, 4, 1, 3, 3, 5, 9, 10, 23, 7, 1, 1, 4, 1, 1, 1, 6, 10, 1, 3, 1, 2, 11, 24, 21, 1, 9, 15, 3, 2, 4, 2, 6, 4, 3, 1, 1, 9, 3, 3, 5, 2, 3, 4, 10, 3, 1, 1, 2, 11, 5, 6, 1, 10, 5, 22, 2, 1, 1, 7, 2, 11, 9, 6, 22, 1, 4, 2, 13, 15, 1, 4, 1, 9, 3, 1, 9, 3, 3, 1, 1, 9, 1, 3, 2, 8, 5, 13, 26, 10, 7, 1, 34, 11, 5, 5, 1, 29, 3, 13, 1, 6, 4, 4, 3, 7, 4, 2, 1, 15, 1, 17, 1, 7, 18, 2, 2, 7, 20, 18, 75, 5, 1, 12, 2, 19, 1, 1, 2, 1, 9, 8, 1, 12, 2, 2, 1, 3, 4, 1, 4, 2, 4, 10, 1, 6, 5, 4, 3, 3, 1, 6, 1, 1, 2, 4, 1, 2, 14, 2, 2, 7, 4, 1, 2, 4, 2, 2, 18, 5, 4, 3, 15, 4, 9, 3, 15, 3, 6, 1, 1, 14, 3, 1, 3, 15, 11, 3, 2, 3, 1, 5, 8, 2, 2, 22, 2, 4, 3, 1, 9, 3, 1, 4, 2, 1, 2, 4, 4, 13, 8, 13, 10, 2, 1, 4, 1, 4, 2, 3, 1, 2, 45, 1, 12, 3, 12, 1, 1, 5, 13, 7, 7, 5, 5, 8, 17, 6, 3, 5, 2, 4, 1, 12, 1, 1, 3, 1, 1, 1, 15, 17, 3, 5, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 2, 11, 2, 2, 9, 14, 21, 16, 22, 2, 4, 10, 2, 2, 1, 3, 6, 1, 1, 1, 7, 3, 12, 6, 1, 1, 4, 5, 1, 5, 1, 1, 3, 1, 1, 1, 2, 1, 13, 5, 3, 7, 2, 1, 4, 9, 1, 39, 14, 2, 1, 1, 1, 1, 6, 4, 24, 4, 1, 1, 3, 6, 18, 3, 13, 9, 1, 1, 1, 3, 1, 1, 1, 4, 1, 2, 5, 5, 1, 1, 7, 5, 1, 9, 1, 2, 4, 2, 4, 1, 7, 6, 4, 1, 3, 1, 17, 4, 3, 7, 13, 7, 6, 1, 1, 5, 5, 1, 3, 11, 4, 15, 1, 1, 1, 5, 3, 11, 6, 3, 1, 37, 1, 1, 3, 6, 7, 1, 1, 11, 3, 1, 5, 3, 1, 8, 6, 1, 1, 3, 4, 7, 6, 12, 5, 2, 2, 1, 2, 1, 2, 1, 1, 2, 3, 9, 22, 15, 2, 5, 2, 4, 7, 2, 21, 1, 27, 11, 4, 1, 2, 1, 6, 4, 4, 2, 6, 1, 5, 25, 8, 2, 3, 1, 4, 1, 7, 5, 12, 1, 13, 1, 4, 8, 9, 1, 1, 7, 1, 2, 5, 5, 3, 1, 1, 2, 18, 2, 1, 1, 21, 1, 6, 1, 5, 8, 2, 5, 1, 1, 2, 6, 1, 2, 6, 3, 2, 4, 5, 1, 19, 5, 1, 15, 1, 1, 2, 1, 2, 18, 12, 3, 3, 2, 2, 1, 4, 1, 7, 5, 2, 1, 5, 4, 2, 1, 14, 11, 1, 7, 2, 11, 3, 1, 16, 3, 10, 2, 5, 31, 1, 5, 1, 6, 3, 1, 1, 9, 1, 1, 2, 3, 8, 2, 2, 12, 1, 6, 1, 1, 1, 21, 4, 1, 3, 1, 6, 19, 6, 1, 3, 4, 9, 7, 13, 2, 4, 1, 1, 38, 1, 1, 1, 6, 6, 5, 1, 3, 18, 21, 1, 2, 2, 1, 3, 1, 2, 1, 1, 3, 1, 4, 6, 1, 1, 2, 5, 2, 2, 2, 3, 21, 37, 6, 1, 1, 2, 3, 3, 1, 1, 3, 1, 4, 1, 1, 1, 3, 25, 1, 3, 4, 2, 9, 13, 5, 8, 12, 7, 1, 8, 1, 8, 2, 1, 2, 1, 4, 1, 4, 1, 1, 1, 3, 15, 37, 2, 7, 1, 7, 2, 6, 12, 8, 3, 2, 1, 19, 4, 1, 3, 2, 1, 1, 10, 13, 2, 11, 9, 2, 2, 2, 2, 2, 1, 3, 2, 12, 18, 15, 1, 1, 4, 1, 2, 6, 7, 1, 4, 4, 1, 1, 1, 1, 3, 1, 4, 10, 3, 4, 4, 2, 1, 2, 33, 1, 5, 2, 4, 21, 1, 3, 3, 1, 7, 5, 1, 4, 4, 1, 4, 1, 1, 10, 2, 1, 2, 7, 5, 2, 3, 9, 1, 9, 1, 15, 9, 1, 1, 3, 16, 4, 1, 1, 1, 9, 1, 7, 1, 2, 1, 1, 5, 2, 8, 2, 19, 5, 4, 1, 3, 7, 3, 4, 1, 10, 1, 7, 1, 10, 10, 3, 1, 3, 3, 1, 3, 1, 12, 4, 1, 1, 1, 5, 2, 8, 5, 2, 17, 1, 5, 1, 2, 5, 3, 1, 2, 2, 2, 12, 3, 4, 9, 6, 1, 14, 5, 2, 4, 2, 2, 1, 15, 38, 1, 5, 3, 3, 6, 3, 6, 1, 1, 5, 2, 2, 3, 1, 1, 3, 3, 1, 3, 1, 5, 1, 3, 1, 3, 2, 1, 1, 7, 1, 3, 5, 5, 1, 1, 9, 1, 3, 1, 5, 1, 2, 2, 1, 7, 2, 2, 2, 13, 4, 6, 1, 21, 3, 6, 2, 5, 1, 2, 1, 7, 1, 4, 2, 3, 14, 1, 6, 1, 2, 8, 7, 1, 1, 8, 1, 11, 1, 1, 8, 1, 1, 1, 1, 2, 2, 3, 3, 2, 4, 1, 3, 1, 1, 1, 1, 1, 3, 1, 7, 1, 8, 5, 2, 9, 13, 2, 4, 1, 1, 1, 13, 3, 5, 3, 4, 1, 7, 5, 8, 3, 4, 1, 31, 23, 10, 3, 1, 1, 2, 1, 1, 1, 5, 3, 2, 3, 1, 2, 4, 1, 3, 2, 9, 2, 6, 4, 3, 1, 4, 1, 5, 4, 1, 1, 3, 2, 1, 1, 2, 6, 1, 1, 1, 5, 2, 1, 2, 5, 1, 2, 6, 13, 1, 1, 2, 15, 3, 3, 1, 5, 1, 3, 13, 1, 6, 1, 4, 4, 1, 3, 3, 1, 3, 3, 2, 1, 4, 15, 2, 1, 1, 1, 23, 1, 1, 8, 3, 4, 2, 1, 4, 6, 4, 21, 1, 7, 3, 3, 11, 6, 1, 1, 2, 4, 7, 2, 9, 13, 3, 2, 8, 6, 2, 2, 3, 9, 3, 2, 1, 2, 3, 5, 1, 2, 1, 3, 5, 1, 8, 10, 1, 1, 4, 1, 3, 1, 1, 3, 2, 1, 2, 1, 11, 5, 12, 1, 3, 1, 1, 8, 1, 1, 5, 6, 1, 2, 13, 2, 2, 1, 8, 1, 4, 1, 1, 4, 2, 7, 2, 3, 4, 1, 3, 24, 3, 11, 4, 1, 1, 3, 2, 2, 1, 20, 21, 2, 4, 2, 2, 9, 5, 3, 4, 1, 1, 3, 1, 5, 2, 1, 5, 2, 1, 1, 16, 7, 3, 6, 1, 16, 6, 1, 8, 2, 2, 8, 5, 3, 3, 1, 4, 2, 1, 1, 2, 1, 1, 3, 2, 7, 1, 13, 1, 1, 1, 51, 3, 2, 1, 2, 1, 12, 1, 1, 2, 14, 1, 1, 1, 1, 2, 1, 1, 7, 1, 1, 4, 1, 16, 4, 22, 3, 3, 10, 1, 1, 10, 1, 4, 16, 11, 6, 2, 1, 1, 1, 9, 2, 1, 1, 1, 3, 1, 2, 4, 2, 3, 1, 1, 1, 3, 2, 4, 9, 5, 4, 4, 6, 5, 1, 8, 1, 24, 3, 1, 1, 1, 1, 1, 4, 5, 3, 2, 2, 5, 1, 3, 14, 1, 10, 11, 1, 1, 1, 1, 1, 1, 6, 1, 2, 2, 2, 1, 2, 3, 15, 1, 1, 1, 2, 3, 10, 15, 2, 1, 17, 12, 12, 11, 2, 21, 2, 5, 1, 13, 1, 1, 4, 2, 1, 19, 2, 5, 1, 1, 6, 6, 3, 3, 1, 1, 6, 2, 3, 2, 5, 3, 2, 1, 1, 1, 39, 1, 5, 2, 1, 2, 1, 1, 1, 2, 2, 1, 3, 2, 1, 4, 1, 2, 4, 1, 1, 1, 3, 5, 17, 1, 3, 3, 3, 1, 5, 2, 2, 5, 11, 1, 4, 1, 5, 2, 4, 4, 1, 3, 1, 1, 1, 2, 1, 3, 2, 1, 5, 6, 1, 2, 1, 1, 3, 1, 1, 1, 3, 1, 18, 6, 2, 1, 6, 1, 6, 1, 1, 1, 1, 8, 6, 1, 6, 1, 12, 4, 1, 1, 1, 2, 4, 4, 11, 2, 2, 1, 8, 1, 1, 1, 1, 1, 1, 1, 13, 13, 3, 1, 3, 1, 5, 3, 3, 2, 2, 3, 1, 2, 5, 2, 5, 1, 1, 1, 9, 5, 2, 1, 1, 3, 1, 26, 1, 1, 4, 1, 2, 1, 1, 3, 8, 22, 3, 4, 5, 1, 3, 1, 1, 2, 7, 3, 16, 5, 3, 3, 11, 3, 1, 12, 1, 1, 6, 5, 15, 6, 2, 2, 2, 7, 1, 1, 1, 2, 12, 4, 3, 5, 8, 11, 3, 1, 7, 4, 1, 1, 1, 11, 2, 1, 1, 4, 3, 6, 1, 1, 1, 4, 2, 3, 7, 3, 2, 2, 1, 5, 3, 3, 1, 7, 6, 13, 3, 1, 1, 4, 2, 1, 3, 15, 3, 1, 10, 8, 1, 1, 3, 1, 1, 4, 15, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 5, 4, 4, 4, 1, 2, 5, 2, 3, 3, 1, 2, 2, 2, 4, 5, 1, 5, 1, 6, 2, 2, 1, 13, 4, 2, 1, 1, 7, 1, 2, 3, 4, 1, 2, 4, 7, 18, 12, 1, 1, 1, 3, 4, 13, 1, 1, 2, 20, 1, 4, 1, 11, 18, 1, 2, 2, 3, 1, 6, 1, 6, 3, 2, 1, 1, 26, 2, 1, 6, 10, 1, 2, 1, 5, 10, 5, 4, 5, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 4, 2, 1, 5, 2, 3, 1, 3, 8, 4, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 9, 1, 1, 1, 2, 7, 1, 2, 6, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 6, 2, 1, 9, 1, 2, 1, 1, 5, 1, 8, 1, 2, 3, 5, 6, 2, 2, 2, 2, 1, 1, 1, 2, 1, 3, 6, 1, 14, 2, 3, 5, 6, 1, 5, 4, 4, 1, 7, 1, 1, 7, 15, 7, 1, 2, 2, 2, 3, 1, 5, 7, 1, 1, 3, 1, 1, 1, 4, 6, 1, 1, 5, 4, 3, 1, 2, 5, 1, 1, 4, 8, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 4, 6, 1, 2, 2, 3, 3, 10, 3, 1, 9, 1, 8, 3, 8, 2, 1, 1, 9, 10, 1, 16, 4, 3, 3, 1, 1, 8, 11, 12, 1, 1, 8, 6, 4, 3, 3, 3, 1, 1, 4, 13, 1, 2, 1, 38, 1, 1, 2, 1, 1, 2, 3, 5, 1, 1, 4, 1, 3, 2, 4, 1, 6, 2, 2, 1, 1, 1, 3, 1, 3, 1, 8, 1, 3, 5, 2, 1, 2, 1, 3, 1, 1, 3, 1, 3, 5, 1, 3, 2, 6, 1, 3, 3, 2, 6, 1, 1, 5, 1, 2, 3, 6, 1, 2, 1, 1, 3, 1, 5, 8, 10, 1, 4, 1, 1, 2, 3, 4, 1, 8, 2, 2, 2, 2, 1, 3, 6, 1, 1, 3, 2, 2, 12, 1, 1, 6, 2, 3, 3, 1, 7, 10, 4, 19, 8, 2, 2, 1, 2, 1, 1, 1, 1, 5, 3, 1, 11, 1, 1, 2, 1, 1, 6, 1, 2, 3, 1, 1, 1, 1, 1, 3, 1, 2, 4, 1, 1, 6, 1, 4, 1, 4, 4, 1, 1, 2, 1, 4, 1, 6, 3, 6, 1, 1, 1, 3, 2, 6, 2, 4, 2, 1, 1, 3, 7, 3, 10, 1, 1, 1, 1, 2, 1, 12, 1, 1, 2, 2, 2, 4, 1, 3, 3, 1, 5, 4, 1, 1, 1, 1, 1, 1, 6, 2, 13, 1, 1, 1, 1, 1, 3, 2, 37, 5, 1, 4, 1, 7, 1, 4, 9, 3, 1, 1, 1, 1, 1, 6, 1, 1, 2, 10, 5, 3, 12, 1, 1, 1, 8, 1, 1, 3, 1, 1, 1, 1, 2, 1, 6, 1, 1, 1, 1, 1, 1, 7, 1, 1, 4, 3, 2, 3, 1, 2, 1, 2, 4, 1, 1, 3, 1, 10, 1, 15, 2, 6, 1, 10, 4, 1, 2, 1, 11, 2, 1, 2, 7, 1, 4, 2, 1, 2, 2, 4, 4, 1, 1, 1, 2, 1, 2, 1, 1, 1, 5, 2, 4, 3, 2, 2, 2, 2, 12, 26, 2, 1, 1, 2, 5, 3, 1, 1, 1, 1, 3, 8, 13, 1, 4, 1, 8, 3, 15, 3, 9, 3, 2, 10, 1, 1, 1, 1, 10, 8, 4, 1, 5, 2, 2, 1, 1, 1, 12, 3, 6, 1, 3, 1, 2, 1, 1, 12, 1, 4, 1, 1, 2, 1, 3, 2, 1, 8, 5, 9, 4, 2, 3, 2, 1, 1, 2, 3, 1, 3, 2, 1, 1, 1, 2, 2, 1, 1, 2, 3, 1, 1, 1, 2, 1, 2, 4, 1, 1, 5, 1, 2, 3, 3, 1, 3, 3, 1, 5, 2, 4, 1, 7, 1, 1, 2, 3, 2, 1, 3, 6, 5, 2, 4, 4, 4, 1, 7, 2, 1, 1, 2, 4, 2, 1, 1, 5, 4, 1, 1, 2, 4, 5, 2, 5, 1, 3, 2, 1, 1, 1, 9, 6, 8, 3, 5, 3, 2, 2, 11, 1, 1, 1, 3, 1, 5, 4, 2, 1, 5, 5, 2, 6, 7, 1, 1, 10, 3, 1, 2, 1, 3, 1, 5, 1, 1, 6, 1, 3, 1, 1, 1, 2, 1, 8, 2, 2, 1, 2, 4, 6, 5, 1, 1, 1, 6, 3, 1, 3, 2, 3, 6, 20, 2, 1, 3, 3, 1, 2, 1, 1, 1, 7, 2, 2, 3, 2, 9, 1, 5, 3, 1, 5, 17, 1, 1, 1, 1, 1, 1, 2, 1, 3, 2, 1, 1, 3, 3, 2, 1, 10, 9, 1, 3, 5, 1, 2, 3, 7, 2, 3, 3, 1, 1, 4, 7, 1, 3, 3, 3, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 3, 7, 1, 1, 3, 3, 1, 1, 1, 1, 2, 2, 1, 1, 4, 1, 4, 1, 4, 14, 2, 3, 5, 1, 1, 1, 1, 11, 1, 1, 1, 1, 2, 1, 9, 3, 4, 1, 6, 1, 5, 5, 1, 1, 2, 2, 1, 1, 1, 8, 11, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1, 15, 2, 1, 1, 8, 9, 1, 1, 1, 1, 1, 1, 3, 1, 6, 3, 1, 1, 1, 5, 1, 3, 3, 2, 5, 5, 3, 1, 2, 3, 3, 18, 1, 1, 7, 11, 3, 1, 1, 1, 6, 6, 1, 8, 6, 1, 1, 5, 1, 1, 4, 4, 1, 5, 1, 8, 1, 7, 1, 1, 3, 2, 1, 7, 1, 2, 1, 1, 18, 3, 2, 1, 1, 1, 2, 2, 1, 6, 1, 1, 2, 1, 11, 1, 2, 2, 1, 1, 3, 1, 2, 4, 1, 2, 1, 7, 1, 35, 1, 7, 7, 3, 1, 1, 1, 8, 6, 1, 2, 1, 1, 2, 1, 1, 2, 1, 4, 1, 10, 1, 1, 1, 1, 1, 1, 6, 1, 2, 3, 1, 3, 2, 2, 14, 3, 1, 1, 3, 1, 1, 1, 7, 10, 1, 2, 2, 1, 2, 1, 3, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 6, 1, 8, 1, 1, 1, 1, 1, 1, 1, 14, 1, 1, 17, 10, 3, 7, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 26, 2, 3, 3, 4, 2, 1, 6, 2, 1, 1, 1, 1, 2, 1, 1, 1, 4, 2, 1, 4, 1, 1, 1, 1, 6, 4, 6, 3, 1, 1, 1, 3, 1, 4, 1, 1, 8, 1, 11, 1, 1, 2, 3, 2, 2, 2, 2, 1, 1, 4, 2, 1, 1, 2, 2, 1, 1, 1, 5, 6, 2, 17, 3, 1, 1, 5, 1, 3, 1, 1, 4, 1, 1, 2, 1, 2, 9, 4, 1, 1, 1, 11, 26, 2, 4, 2, 1, 2, 1, 2, 1, 1, 2, 1, 4, 1, 5, 7, 9, 5, 1, 1, 1, 2, 1, 3, 1, 1, 1, 3, 1, 1, 22, 3, 1, 2, 1, 1, 4, 1, 1, 1, 2, 1, 2, 4, 9, 1, 1, 31, 1, 11, 1, 2, 1, 1, 1, 1, 3, 4, 7, 1, 2, 3, 2, 11, 3, 6, 3, 4, 10, 3, 3, 2, 3, 1, 1, 1, 4, 3, 1, 1, 3, 4, 1, 4, 4, 8, 4, 1, 2, 1, 1, 1, 2, 5, 1, 1, 1, 4, 7, 13, 2, 3, 2, 1, 1, 4, 2, 3, 5, 3, 1, 1, 9, 1, 4, 5, 1, 1, 4, 3, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 2, 1, 9, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 6, 1, 1, 1, 3, 1, 1, 7, 1, 4, 2, 3, 12, 1, 3, 1, 1, 8, 1, 7, 3, 1, 5, 2, 1, 1, 1, 3, 3, 1, 2, 5, 4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 6, 3, 2, 1, 1, 4, 1, 3, 1, 1, 2, 2, 2, 1, 13, 3, 3, 1, 18, 1, 3, 4, 1, 4, 1, 2, 1, 5, 1, 2, 1, 3, 3, 1, 1, 1, 1, 1, 1, 2, 1, 3, 2, 1, 2, 1, 3, 2, 1, 6, 1, 1, 1, 3, 3, 1, 1, 3, 12, 3, 1, 1, 5, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 2, 1, 3, 1, 1, 4, 1, 3, 2, 1, 8, 1, 1, 4, 6, 9, 1, 1, 29, 7, 3, 1, 1, 1, 2, 1, 1, 1, 5, 14, 3, 1, 3, 1, 1, 1, 4, 1, 5, 2, 1, 1, 4, 4, 3, 1, 1, 1, 1, 4, 5, 1, 8, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 28, 4, 1, 16, 1, 4, 1, 9, 3, 1, 2, 1, 1, 6, 2, 8, 2, 1, 2, 1, 1, 1, 3, 2, 1, 1, 7, 1, 5, 4, 2, 1, 4, 1, 3, 1, 1, 1, 1, 1, 4, 2, 5, 2, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 5, 1, 2, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 3, 1, 2, 4, 2, 3, 1, 2, 2, 7, 3, 1, 1, 2, 2, 1, 1, 3, 7, 1, 1, 3, 2, 1, 1, 2, 3, 2, 1, 1, 6, 8, 3, 3, 1, 1, 1, 1, 2, 6, 2, 1, 1, 4, 3, 2, 7, 2, 1, 3, 8, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 7, 1, 2, 8, 7, 1, 1, 2, 1, 3, 1, 4, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 3, 1, 11, 2, 5, 1, 2, 1, 1, 1, 1, 1, 2, 7, 1, 1, 1, 2, 4, 1, 2, 1, 1, 1, 1, 1, 7, 2, 1, 1, 3, 1, 2, 2, 3, 2, 1, 1, 1, 1, 1, 6, 8, 4, 1, 4, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 3, 2, 3, 4, 2, 1, 1, 1, 5, 1, 4, 1, 1, 2, 1, 9, 1, 4, 1, 2, 1, 1, 3, 6, 2, 1, 1, 5, 1, 1, 1, 1, 2, 4, 1, 1, 2, 1, 2, 6, 2, 3, 1, 1, 1, 1, 5, 1, 1, 3, 7, 3, 1, 9, 1, 3, 6, 1, 1, 3, 3, 5, 1, 1, 2, 1, 1, 1, 3, 2, 2, 1, 3, 1, 1, 1, 1, 1, 4, 3, 1, 2, 2, 4, 21, 3, 2, 4, 4, 2, 1, 3, 7, 3, 3, 3, 1, 11, 1, 1, 1, 6, 1, 1, 1, 4, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 7, 4, 4, 1, 1, 9, 4, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 2, 1, 2, 6, 4, 2, 1, 6, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 4, 1, 1, 1, 1, 1, 1, 4, 5, 2, 1, 1, 3, 3, 2, 2, 1, 1, 2, 2, 2, 1, 4, 1, 1, 2, 3, 1, 5, 1, 5, 1, 5, 3, 1, 3, 1, 1, 4, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 2, 5, 1, 1, 1, 3, 1, 2, 2, 1, 3, 2, 1, 1, 5, 3, 1, 3, 1, 2, 4, 1, 15, 1, 1, 1, 4, 1, 7, 2, 2, 1, 3, 4, 1, 1, 1, 4, 1, 1, 3, 2, 8, 1, 2, 1, 3, 1, 1, 1, 1, 1, 3, 1, 2, 3, 1, 1, 1, 2, 2, 1, 3, 2, 1, 1, 2, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 2, 1, 4, 3, 1, 1, 1, 2, 3, 2, 2, 8, 2, 1, 1, 1, 2, 3, 5, 2, 2, 4, 1, 2, 2, 3, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 5, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 8, 3, 3, 2, 1, 1, 1, 1, 11, 1, 2, 1, 1, 4, 2, 9, 2, 1, 1, 2, 1, 6, 2, 1, 1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 9, 2, 15, 1, 1, 3, 10, 3, 1, 2, 1, 1, 2, 6, 1, 2, 1, 1, 1, 1, 1, 1, 4, 1, 2, 2, 1, 1, 1, 1, 1, 2, 5, 1, 2, 3, 2, 1, 2, 3, 1, 1, 1, 7, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 5, 1, 1, 2, 2, 1, 2, 1, 2, 1, 3, 2, 1, 1, 1, 5, 2, 5, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 4, 1, 3, 1, 1, 2, 4, 1, 3, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 2, 1, 2, 3, 1, 1, 1, 1, 1, 2, 1, 3, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 6, 1, 7, 2, 2, 3, 1, 7, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 3, 3, 1, 1, 13, 1, 1, 1, 1, 3, 1, 2, 1, 2, 3, 1, 1, 1, 2, 2, 1, 1, 5, 2, 1, 1, 1, 2, 1, 3, 1, 1, 6, 1, 1, 1, 1, 2, 1, 1, 1, 4, 1, 1, 1, 1, 2, 3, 4, 3, 1, 4, 1, 9, 3, 1, 6, 1, 1, 3, 3, 1, 2, 1, 1, 1, 4, 1, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 5, 1, 2, 4, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 7, 1, 2, 5, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 2, 6, 1, 1, 1, 1, 3, 1, 1, 3, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 4, 2, 2, 1, 1, 2, 2, 2, 5, 1, 1, 3, 1, 4, 1, 1, 2, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 6, 2, 7, 1, 1, 1, 1, 5, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 5, 1, 10, 3, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 4, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 2, 1, 1, 6, 4, 10, 1, 5, 1, 2, 1, 2, 2, 3, 1, 1, 1, 3, 1, 1, 1, 1, 4, 1, 1, 1, 2, 2, 1, 2, 7, 1, 1, 1, 1, 5, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 4, 2, 1, 3, 3, 5, 4, 10, 3, 1, 1, 2, 9, 1, 1, 1, 2, 2, 5, 2, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 2, 1, 1, 5, 1, 1, 1, 1, 1, 1, 3, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 5, 2, 1, 2, 9, 1, 2, 1, 3, 1, 1, 3, 1, 2, 3, 2, 3, 2, 1, 1, 1, 1, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 5, 3, 3, 7, 1, 2, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 6, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 2, 2, 1, 1, 1, 3, 2, 1, 2, 3, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 3, 1, 1, 1, 1, 3, 1, 3, 2, 1, 4, 3, 1, 2, 1, 1, 2, 1, 2, 5, 6, 1, 1, 1, 3, 1, 6, 3, 1, 3, 3, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 3, 2, 5, 1, 1, 1, 1, 1, 4, 4, 3, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 3, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 3, 1, 1, 4, 1, 1, 3, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 4, 1, 1, 2, 4, 2, 1, 1, 2, 1, 2, 1, 3, 2, 1, 7, 1, 2, 2, 1, 1, 2, 1, 1, 1, 5, 1, 1, 1, 2, 1, 3, 2, 2, 3, 4, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 3, 4, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 3, 4, 2, 1, 1, 1, 2, 2, 1, 2, 1, 4, 1, 1, 4, 2, 1, 1, 2, 1, 1, 1, 1, 3, 1, 5, 1, 1, 1, 1, 2, 4, 1, 2, 1, 6, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 2, 1, 4, 1, 1, 3, 1, 1, 1, 7, 1, 1, 1, 3, 1, 6, 1, 2, 3, 3, 1, 3, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 11, 1, 1, 1, 2, 2, 1, 3, 1, 1, 9, 1, 1, 1, 3, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 4, 1, 1, 2, 2, 3, 1, 2, 1, 1, 4, 3, 4, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 2, 3, 2, 1, 1, 5, 1, 9, 1, 1, 4, 2, 3, 7, 3, 1, 2, 1, 3, 3, 2, 1, 10, 2, 1, 4, 1, 3, 1, 2, 1, 3, 1, 1, 3, 1, 1, 3, 3, 4, 2, 5, 1, 2, 1, 1, 1, 5, 1, 2, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 2, 2, 8, 10, 2, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 4, 3, 1, 2, 2, 1, 4, 1, 4, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 4, 1, 1, 1, 1, 4, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 3, 11, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 5, 6, 1, 1, 1, 3, 1, 2, 4, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 6, 1, 2, 1, 4, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 7, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 10, 5, 2, 3, 1, 1, 2, 1, 5, 2, 1, 6, 4, 2, 1, 2, 5, 1, 1, 2, 5, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 1, 1, 8, 1, 5, 1, 1, 2, 1, 2, 2, 1, 2, 1, 3, 1, 1, 5, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 6, 4, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 6, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 5, 2, 2, 1, 2, 3, 5, 7, 2, 3, 3, 1, 7, 1, 1, 1, 1, 3, 1, 1, 3, 3, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 2, 1, 1, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 5, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 5, 2, 2, 13, 2, 1, 1, 1, 5, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 6, 1, 1, 1, 8, 1, 1, 5, 6, 1, 2, 2, 3, 2, 1, 4, 1, 5, 2, 1, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 5, 1, 1, 2, 1, 3, 2, 1, 1, 3, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 3, 1, 3, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 3, 1, 1, 3, 1, 1, 5, 1, 3, 1, 1, 1, 3, 4, 1, 1, 1, 2, 4, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 3, 3, 3, 2, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 2, 2, 1, 3, 1, 2, 3, 1, 1, 3, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 4, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 1, 1, 5, 1, 1, 1, 2, 2, 2, 1, 2, 1, 4, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 4, 3, 1, 1, 1, 3, 1, 3, 2, 3, 2, 4, 1, 1, 3, 1, 4, 2, 1, 12, 3, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 3, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 3, 3, 2, 2, 1, 1, 7, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 6, 2, 3, 2, 3, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 5, 3, 1, 1, 3, 3, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 1, 2, 1, 3, 2, 1, 3, 1, 3, 4, 1, 4, 2, 2, 3, 2, 3, 4, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 4, 3, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 5, 2, 1, 1, 2, 1, 1, 1, 2, 1, 9, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 3, 1, 1, 4, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 3, 1, 4, 3, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 6, 5, 4, 1, 1, 9, 3, 2, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 5, 1, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 2, 1, 4, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 4, 2, 3, 1, 3, 3, 1, 1, 1, 5, 1, 2, 2, 1, 1, 1, 2, 1, 4, 1, 1, 3, 1, 3, 1, 1, 1, 1, 5, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 5, 1, 1, 1, 2, 1, 1, 2, 2, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 4, 2, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 3, 1, 1, 1, 2, 8, 3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, 2, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 4, 3, 3, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 2, 1, 1, 1, 1, 3, 1, 3, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 4, 5, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 5, 3, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 5, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 2, 1, 3, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 4, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 3, 1, 4, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 5, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 4, 2, 1, 1, 1, 2, 1, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 5, 6, 1, 2, 1, 2, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 4, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 13, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 4, 4, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 3, 3, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "freq = list(training_corpus_dct.dfs.values())\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6709)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.tensor(freq) >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4990)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.tensor(freq) >= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The man',\n",
       " 'pierced ears',\n",
       " 'glasses',\n",
       " 'an orange hat',\n",
       " 'A man',\n",
       " 'glasses',\n",
       " 'a beer can crocheted hat',\n",
       " 'A man',\n",
       " 'gauges',\n",
       " 'glasses',\n",
       " 'a Blitz hat',\n",
       " 'A man',\n",
       " 'an orange hat',\n",
       " 'A man',\n",
       " 'an orange hat',\n",
       " 'glasses',\n",
       " 'A black and white dog',\n",
       " 'a grassy garden',\n",
       " 'a white fence',\n",
       " 'A Boston Terrier',\n",
       " 'lush green grass',\n",
       " 'a white fence',\n",
       " 'A black and white dog',\n",
       " 'the grass',\n",
       " 'A dog',\n",
       " 'the green grass',\n",
       " 'a wooden fence',\n",
       " 'A Boston terrier',\n",
       " 'the grass',\n",
       " 'A young female student',\n",
       " 'a board',\n",
       " 'her Karate instructor',\n",
       " 'Girl',\n",
       " 'a piece of wood',\n",
       " 'karate instructor',\n",
       " 'A girl',\n",
       " 'a stick',\n",
       " 'a man',\n",
       " 'A girl',\n",
       " 'karate uniform',\n",
       " 'a stick',\n",
       " 'A girl',\n",
       " 'boards',\n",
       " 'Five snowmobile riders',\n",
       " 'all',\n",
       " 'helmets',\n",
       " 'goggles',\n",
       " 'a snowy clearing',\n",
       " 'a forest',\n",
       " 'their snowmobiles',\n",
       " 'black snow pants',\n",
       " 'a black coat',\n",
       " 'white coat',\n",
       " 'red coat',\n",
       " 'blue coat',\n",
       " 'black coat',\n",
       " 'Five people',\n",
       " 'winter jackets',\n",
       " 'helmets',\n",
       " 'the snow',\n",
       " 'snowmobiles',\n",
       " 'Five people',\n",
       " 'winter clothing',\n",
       " 'helmets',\n",
       " 'ski goggles',\n",
       " 'the snow',\n",
       " 'A group of snowmobile riders',\n",
       " 'the snow',\n",
       " 'Group',\n",
       " 'Two men',\n",
       " 'the roof of a house',\n",
       " 'another one',\n",
       " 'a ladder',\n",
       " 'Two men',\n",
       " 'a rooftop',\n",
       " 'another man',\n",
       " 'a ladder',\n",
       " 'Three men',\n",
       " 'one',\n",
       " 'a ladder',\n",
       " 'a roof',\n",
       " 'People',\n",
       " 'the roof of a house',\n",
       " 'Three men',\n",
       " 'a roof',\n",
       " 'A bride',\n",
       " 'a light pink dress',\n",
       " 'a picture',\n",
       " 'male relatives',\n",
       " 'a man',\n",
       " 'a cream shirt',\n",
       " 'white pants',\n",
       " 'A man',\n",
       " 'light colored clothing photographs',\n",
       " 'a group of men',\n",
       " 'dark suits',\n",
       " 'hats',\n",
       " 'a woman',\n",
       " 'a strapless gown',\n",
       " 'A photographer',\n",
       " 'a picture of a group of one girl',\n",
       " 'a pink dress',\n",
       " '10 boys',\n",
       " 'suits',\n",
       " 'hats',\n",
       " 'A man',\n",
       " 'a woman',\n",
       " 'a pink dress',\n",
       " 'a throng of men',\n",
       " 'suits',\n",
       " 'Man',\n",
       " 'A group of 11 people',\n",
       " 'winter wear',\n",
       " 'beanies',\n",
       " 'skiing jackets',\n",
       " 'gloves',\n",
       " 'backpacks',\n",
       " 'snow paddles',\n",
       " 'a house',\n",
       " 'ice blocks',\n",
       " 'a person',\n",
       " 'the door',\n",
       " 'A group of people',\n",
       " 'snowshoes',\n",
       " 'a building',\n",
       " 'blocks of ice',\n",
       " 'The people',\n",
       " 'A group of people',\n",
       " 'an igloo',\n",
       " 'Several students',\n",
       " 'an igloo',\n",
       " 'A baseball player',\n",
       " 'red',\n",
       " 'a player',\n",
       " 'blue',\n",
       " 'other blue team members',\n",
       " 'A boy',\n",
       " 'a red uniform',\n",
       " 'home plate',\n",
       " 'the catcher',\n",
       " 'the blue uniform',\n",
       " 'A baseball player',\n",
       " 'home plate',\n",
       " 'knee held high',\n",
       " 'the catcher right',\n",
       " 'A baseball player',\n",
       " 'the catcher',\n",
       " 'the player',\n",
       " 'A baseball catcher',\n",
       " 'a base runner',\n",
       " 'A man',\n",
       " 'a hat',\n",
       " 'a white shirt',\n",
       " 'windows',\n",
       " 'A man',\n",
       " 'a white shirt',\n",
       " 'scaffolding',\n",
       " 'A man',\n",
       " 'boards',\n",
       " 'a huge ladder',\n",
       " 'Man',\n",
       " 'scaffolding',\n",
       " 'A guy',\n",
       " 'a building',\n",
       " 'A man',\n",
       " 'a reflective vest',\n",
       " 'the sidewalk',\n",
       " 'pamphlets',\n",
       " 'bicycles',\n",
       " 'the cover',\n",
       " 'Man',\n",
       " 'bright yellow vest displays bicycle safety information',\n",
       " 'street',\n",
       " 'A man',\n",
       " 'woman',\n",
       " 'a man',\n",
       " 'his face',\n",
       " 'A man',\n",
       " 'a vest',\n",
       " 'a chair',\n",
       " 'magazines',\n",
       " 'A construction worker',\n",
       " 'a sign',\n",
       " 'bicycling',\n",
       " 'A mother',\n",
       " 'her child',\n",
       " 'a piggyback ride',\n",
       " 'their apartment complex',\n",
       " 'A baby boy',\n",
       " 'a blue and white striped shirt',\n",
       " 'A mother',\n",
       " 'her young song',\n",
       " 'a young woman',\n",
       " 'a baby',\n",
       " 'a ride',\n",
       " 'A woman',\n",
       " 'a small child',\n",
       " 'a piggyback ride',\n",
       " 'A male volleyball player',\n",
       " 'red trunks',\n",
       " 'the shot of the opposing player',\n",
       " 'Men',\n",
       " 'one player',\n",
       " 'the ball',\n",
       " 'hands',\n",
       " 'A group of spectators',\n",
       " 'Volleyball players',\n",
       " 'the beach',\n",
       " 'Men',\n",
       " 'the sand',\n",
       " 'A woman',\n",
       " 'a pink shirt',\n",
       " 'red apron',\n",
       " 'food',\n",
       " 'bagged breads',\n",
       " 'a microwave',\n",
       " 'the chalkboard menu',\n",
       " 'the wall',\n",
       " 'Woman',\n",
       " 'a yellow hat',\n",
       " 'pink shirt',\n",
       " 'red apron',\n",
       " 'food',\n",
       " 'Employee',\n",
       " 'pink shirt',\n",
       " 'A woman',\n",
       " 'a bowl of food',\n",
       " 'Women',\n",
       " 'some food',\n",
       " 'An Asian man',\n",
       " 'spectacles',\n",
       " 'a t-shirt',\n",
       " 'some food',\n",
       " 'A man',\n",
       " 'a table',\n",
       " 'man',\n",
       " 'tool',\n",
       " 'a table',\n",
       " 'Indian man whittles',\n",
       " 'A man',\n",
       " 'a knife',\n",
       " 'Spelunkers',\n",
       " 'sunlight',\n",
       " 'Shaft of light',\n",
       " 'three spelunkers',\n",
       " 'Three rock climbers',\n",
       " 'People',\n",
       " 'three people',\n",
       " 'A girl',\n",
       " 'a polka',\n",
       " 'blue jean dress',\n",
       " 'a balance beam',\n",
       " 'A girl',\n",
       " 'a jean dress',\n",
       " 'a raised balance beam',\n",
       " 'The little girl',\n",
       " 'a beam',\n",
       " 'gymnastics class',\n",
       " 'A little girl',\n",
       " 'a gymnastics beam',\n",
       " 'A little girl',\n",
       " 'a balance beam',\n",
       " 'A couple',\n",
       " 'the sand',\n",
       " 'their feet',\n",
       " 'the water',\n",
       " 'hands',\n",
       " 'A man',\n",
       " 'woman',\n",
       " 'sunglasses',\n",
       " 'the water',\n",
       " 'A boy',\n",
       " 'a girl',\n",
       " 'hands',\n",
       " 'a shore',\n",
       " 'A couple',\n",
       " 'sunglasses',\n",
       " 'the beach',\n",
       " 'A blond',\n",
       " 'hands',\n",
       " 'a guy',\n",
       " 'the sand',\n",
       " 'A woman',\n",
       " '3 other people',\n",
       " 'two tables',\n",
       " 'some shelves',\n",
       " 'coffee',\n",
       " 'tea',\n",
       " 'a refrigerated drink case',\n",
       " 'A woman',\n",
       " 'a gray sweater',\n",
       " 'black baseball cap',\n",
       " 'A woman',\n",
       " 'a hat',\n",
       " 'Young people',\n",
       " 'A woman',\n",
       " 'a cap',\n",
       " 'The person',\n",
       " 'a striped shirt',\n",
       " 'a rope',\n",
       " 'a mountain',\n",
       " 'A kid',\n",
       " 'the backdrop of a green valley',\n",
       " 'The person',\n",
       " 'the striped shirt',\n",
       " 'A woman',\n",
       " 'a striped shirt',\n",
       " 'a mountain',\n",
       " 'A young man',\n",
       " 'a rocky hill',\n",
       " 'Two young attractive women',\n",
       " 'street performers',\n",
       " 'Two women',\n",
       " 'the entertainment of street performers',\n",
       " 'Two men',\n",
       " 'statutes',\n",
       " 'women',\n",
       " 'Two young women',\n",
       " 'street performers',\n",
       " 'Pedestrians',\n",
       " 'street artists',\n",
       " 'A group of people',\n",
       " 'the lawn',\n",
       " 'a building',\n",
       " 'Many people',\n",
       " 'blue jeans',\n",
       " 'a white church',\n",
       " 'A large group of people',\n",
       " 'a church',\n",
       " 'Family members',\n",
       " 'a home',\n",
       " 'People',\n",
       " 'a building',\n",
       " 'a young girl',\n",
       " 'a blue shirt',\n",
       " 'a band',\n",
       " 'a trumpet',\n",
       " 'Girl',\n",
       " 'blue shirt',\n",
       " 'black shorts',\n",
       " 'A teenager',\n",
       " 'her trumpet',\n",
       " 'the field',\n",
       " 'A girl',\n",
       " 'trumpet',\n",
       " 'a marching band',\n",
       " 'Girl',\n",
       " 'the trumpet',\n",
       " 'a marching band',\n",
       " 'Person',\n",
       " 'a brown sweatshirt',\n",
       " 'a flip',\n",
       " 'a trampoline',\n",
       " 'a river',\n",
       " 'electrical lines',\n",
       " 'A young adult',\n",
       " 'a back flip',\n",
       " 'a trampoline',\n",
       " 'a lake',\n",
       " 'A woman',\n",
       " 'a trampoline',\n",
       " 'a lake',\n",
       " 'A woman',\n",
       " 'a somersault',\n",
       " 'a trampoline',\n",
       " 'Trampolines',\n",
       " 'a man',\n",
       " 'a neon beer sign',\n",
       " 'the wall',\n",
       " 'A man',\n",
       " 'three video game machines',\n",
       " 'a beer sign',\n",
       " 'A man',\n",
       " 'a bank of computer',\n",
       " 'machines',\n",
       " 'A man',\n",
       " 'a group of video games',\n",
       " 'A man',\n",
       " 'three video machines',\n",
       " 'A woman',\n",
       " 'a green tank top',\n",
       " 'a drill',\n",
       " 'a crowd',\n",
       " 'a woman',\n",
       " 'a power drill',\n",
       " 'a group of people',\n",
       " 'A woman',\n",
       " 'a drill',\n",
       " 'another man',\n",
       " 'A woman',\n",
       " 'a teal tank top',\n",
       " 'a power drill',\n",
       " 'Spectators',\n",
       " 'a woman',\n",
       " 'a drill',\n",
       " 'A woman',\n",
       " 'a pink sweater',\n",
       " 'eyeglasses',\n",
       " 'a wooden table',\n",
       " 'a pink sponge',\n",
       " 'A woman',\n",
       " 'a pink sweater',\n",
       " 'an apron',\n",
       " 'a table',\n",
       " 'a sponge',\n",
       " 'A lady',\n",
       " 'blond-hair and glasses',\n",
       " 'her table',\n",
       " 'A woman',\n",
       " 'a pink sweater',\n",
       " 'a dining table',\n",
       " 'A woman',\n",
       " 'a pink shirt',\n",
       " 'a wooden table',\n",
       " 'A man',\n",
       " 'a utility lift',\n",
       " 'the tree branches',\n",
       " 'This man',\n",
       " 'trees',\n",
       " 'A man',\n",
       " 'black pants',\n",
       " 'bushes',\n",
       " 'Man',\n",
       " 'crane',\n",
       " 'tree branches',\n",
       " 'A man',\n",
       " 'branches of trees',\n",
       " 'Four young Asian boys',\n",
       " 'bowls',\n",
       " 'chopsticks',\n",
       " 'a barbecue',\n",
       " 'Group of Asian boys',\n",
       " 'meat',\n",
       " 'barbecue',\n",
       " 'Four young boys',\n",
       " 'a grill',\n",
       " 'Four young teens',\n",
       " 'A group of asians',\n",
       " 'Native Americans',\n",
       " 'native clothing',\n",
       " 'Three people',\n",
       " 'costumes',\n",
       " 'musical instruments',\n",
       " 'Women',\n",
       " 'traditional clothing',\n",
       " \"The indian 's\",\n",
       " 'A man',\n",
       " 'another man',\n",
       " 'the back of the head',\n",
       " 'A man',\n",
       " 'red shirt',\n",
       " 'another man',\n",
       " 'gray shirt',\n",
       " 'One man',\n",
       " \"another man 's head\",\n",
       " 'A man',\n",
       " \"his opponent 's head\",\n",
       " 'A strong man',\n",
       " 'a person',\n",
       " 'Six people',\n",
       " 'mountain bikes',\n",
       " 'a jungle environment',\n",
       " 'Men',\n",
       " 'mountain bikes',\n",
       " 'six men',\n",
       " 'a forest terrain',\n",
       " 'Six People',\n",
       " 'bikes',\n",
       " 'a trail',\n",
       " 'the forest',\n",
       " 'A group of people',\n",
       " 'Two blond women',\n",
       " 'people',\n",
       " 'casual clothing',\n",
       " 'bookbags',\n",
       " 'two females',\n",
       " '2 blond girls',\n",
       " 'a ledge',\n",
       " 'A large number of people',\n",
       " 'Two women',\n",
       " 'a seat',\n",
       " 'A small child',\n",
       " 'water',\n",
       " 'a splash',\n",
       " 'the white clouds',\n",
       " 'the mountains',\n",
       " 'A little boy',\n",
       " 'the water',\n",
       " 'mountains',\n",
       " 'A young boy',\n",
       " 'the water',\n",
       " 'the mountains',\n",
       " 'A child',\n",
       " 'the water',\n",
       " 'A boy',\n",
       " 'a lake',\n",
       " 'Three people',\n",
       " 'an outdoor table',\n",
       " 'Three people',\n",
       " 'a picnic table',\n",
       " 'Three people',\n",
       " 'an outside picnic bench',\n",
       " 'A couple of people',\n",
       " 'a table',\n",
       " 'Three people',\n",
       " 'Some young men',\n",
       " 'the edge of a bridge',\n",
       " 'a sunny day',\n",
       " 'The boys',\n",
       " 'the bridge',\n",
       " 'the water',\n",
       " '3 boys',\n",
       " 'a pier',\n",
       " 'their bathing suits',\n",
       " 'A man',\n",
       " 'a wooden guard rail',\n",
       " 'Boys',\n",
       " 'a bridge',\n",
       " 'a lake',\n",
       " 'A woman',\n",
       " 'a short-sleeved striped shirt',\n",
       " 'a green shopping bag',\n",
       " 'fish',\n",
       " 'a vendor',\n",
       " 'a white apron',\n",
       " 'a gray t-shirt',\n",
       " 'an empty plastic bag',\n",
       " 'An employee',\n",
       " 'a woman',\n",
       " 'a bag',\n",
       " 'fish',\n",
       " 'ice',\n",
       " 'A woman',\n",
       " 'the fish',\n",
       " 'The woman',\n",
       " 'fish',\n",
       " 'an Arabic person',\n",
       " 'A lady',\n",
       " 'a striped shirt',\n",
       " 'A female harp player',\n",
       " 'her instrument',\n",
       " 'A lady',\n",
       " 'dark hair',\n",
       " 'a harp',\n",
       " 'A pretty woman',\n",
       " 'a harpsichord',\n",
       " 'A smiling woman',\n",
       " 'the harp',\n",
       " 'A woman',\n",
       " 'a harp',\n",
       " 'A security officer',\n",
       " 'a tiny face',\n",
       " 'big glasses',\n",
       " 'a metal gate',\n",
       " 'a building',\n",
       " 'a uniformed security guard',\n",
       " 'a fence',\n",
       " 'A customs officer',\n",
       " 'a bike rack',\n",
       " 'an office building',\n",
       " 'An officer',\n",
       " 'a metal bar',\n",
       " 'Park Ranger',\n",
       " 'A girl',\n",
       " 'a black t-shirt',\n",
       " 'a small pizza',\n",
       " 'Woman',\n",
       " 'pizza',\n",
       " 'Latin woman',\n",
       " 'homemade pizza',\n",
       " 'A young woman',\n",
       " 'the pizza',\n",
       " 'The young lady',\n",
       " 'the pizza',\n",
       " 'A shirtless man',\n",
       " 'large rocks',\n",
       " 'a boardwalk',\n",
       " 'a tall lamp post',\n",
       " 'A shirtless man',\n",
       " 'shorts',\n",
       " 'some rocks',\n",
       " 'A shirtless man',\n",
       " 'jean shorts',\n",
       " 'the rocks',\n",
       " 'A solitary fisherman',\n",
       " 'a riverbank',\n",
       " 'A man',\n",
       " 'no shirt',\n",
       " 'A young girl',\n",
       " 'water',\n",
       " 'her life jacket',\n",
       " 'a young girl',\n",
       " 'a bulky red life jacket',\n",
       " 'a lake',\n",
       " 'The little girl',\n",
       " 'a floating device',\n",
       " 'the water',\n",
       " 'A girl',\n",
       " 'a life vest',\n",
       " 'water',\n",
       " 'A girl',\n",
       " 'a life vest',\n",
       " 'A man',\n",
       " 'a military-type uniform',\n",
       " 'another man',\n",
       " 'a piece of paper',\n",
       " 'his hands',\n",
       " 'A man',\n",
       " 'uniform',\n",
       " 'a man',\n",
       " 'a blue shirt',\n",
       " 'a truck',\n",
       " 'A man',\n",
       " 'a blue shirt',\n",
       " 'a uniformed official',\n",
       " 'A man',\n",
       " 'dressy clothes',\n",
       " 'a captain',\n",
       " 'a large truck',\n",
       " 'A man',\n",
       " 'glasses',\n",
       " 'an Asian woman',\n",
       " 'Two men',\n",
       " 'one woman',\n",
       " 'Several people',\n",
       " 'People',\n",
       " 'People',\n",
       " 'A brown-haired child',\n",
       " 'a swing',\n",
       " 'a park',\n",
       " 'the woods',\n",
       " 'the trees',\n",
       " 'a child',\n",
       " 'a swing',\n",
       " 'A child',\n",
       " 'Crocs',\n",
       " 'a swing',\n",
       " 'a wooded area',\n",
       " 'A kid',\n",
       " 'his feet',\n",
       " 'a forest',\n",
       " 'A child',\n",
       " 'A man',\n",
       " 'a red shirt',\n",
       " 'blue pants',\n",
       " 'a building',\n",
       " 'a dog',\n",
       " 'A man',\n",
       " 'a building',\n",
       " 'a dog',\n",
       " 'A man',\n",
       " 'a maroon building',\n",
       " 'a dog',\n",
       " 'A man',\n",
       " 'a red shirt',\n",
       " 'A man',\n",
       " 's foreign building',\n",
       " 'Two male friends',\n",
       " 'swimming trunks',\n",
       " 'the beach',\n",
       " 'people',\n",
       " 'Two middle-aged men',\n",
       " 'a beautiful beach',\n",
       " 'rocks',\n",
       " 'Two men',\n",
       " 'swim trunks',\n",
       " 'a moderately populated beach',\n",
       " 'Two men',\n",
       " 'swimming trunks',\n",
       " 'the beach',\n",
       " 'Two men',\n",
       " 'a rocky beach',\n",
       " 'A toddler',\n",
       " 'the handle of a tool',\n",
       " 'food',\n",
       " 'a bowl',\n",
       " 'another person',\n",
       " 'whose arms',\n",
       " 'the bowl',\n",
       " 'tool',\n",
       " 'A naked baby',\n",
       " 'a face',\n",
       " 'someone',\n",
       " 'A toddler',\n",
       " 'another person',\n",
       " 'Toddler',\n",
       " 'ingredients',\n",
       " 'A toddler',\n",
       " 'some food',\n",
       " 'a bowel',\n",
       " 'A father',\n",
       " 'daughter',\n",
       " 'a young tree',\n",
       " 'the son',\n",
       " 'a shovel',\n",
       " 'A father-figure',\n",
       " 'two children',\n",
       " 'their home',\n",
       " 'yard',\n",
       " 'a hoe',\n",
       " 'the grass',\n",
       " 'a tree',\n",
       " 'A man',\n",
       " 'a little girl',\n",
       " 'a grassy area',\n",
       " 'a tree',\n",
       " 'a little boy',\n",
       " 'a hoe',\n",
       " 'Two small children',\n",
       " 'older man',\n",
       " 'a tree',\n",
       " 'A man',\n",
       " 'two children',\n",
       " 'a tree',\n",
       " 'A man',\n",
       " 'a black sweater',\n",
       " 'food',\n",
       " 'a pan',\n",
       " 'a cluttered kitchen',\n",
       " 'A man',\n",
       " 'a stove',\n",
       " 'a kitchen',\n",
       " 'wooden utensil',\n",
       " 'A man',\n",
       " 'a black hoodie',\n",
       " 'food',\n",
       " 'A man',\n",
       " 'food',\n",
       " 'his kitchen',\n",
       " 'A man',\n",
       " 'food',\n",
       " 'the stove',\n",
       " 'An older gentleman',\n",
       " 'jeans',\n",
       " 'a long-sleeved shirt',\n",
       " 'a small red ball',\n",
       " 'the beach',\n",
       " 'An elderly man',\n",
       " 'a red rubber ball',\n",
       " 'the beach',\n",
       " 'A man',\n",
       " 'jeans',\n",
       " 'the beach',\n",
       " 'a red ball',\n",
       " 'Man',\n",
       " 'the beach',\n",
       " 'a red ball',\n",
       " 'A man',\n",
       " 'a ball',\n",
       " 'the beach',\n",
       " 'Many people',\n",
       " 'a sidewalk',\n",
       " 'a variety of little shops',\n",
       " 'A man',\n",
       " 'a backpack',\n",
       " 'the display',\n",
       " 'the store',\n",
       " 'Many people',\n",
       " 'the sidewalk',\n",
       " 'an Asian marketplace',\n",
       " 'People',\n",
       " 'sidewalk',\n",
       " 'a line of stores',\n",
       " 'People',\n",
       " 'stores',\n",
       " 'A wakeboarder',\n",
       " 'an upside down man',\n",
       " 'a waterski board',\n",
       " 'A person',\n",
       " 'water',\n",
       " 'A man',\n",
       " 'the water',\n",
       " 'A person',\n",
       " 'a water board',\n",
       " 'Four police officers',\n",
       " 'the large crowd of people',\n",
       " 'A large crowd of people',\n",
       " 'officers',\n",
       " 'A large crowd of people',\n",
       " 'A large group of people',\n",
       " 'A large crowd of people',\n",
       " 'A man',\n",
       " 'bathing trunks',\n",
       " 'the water',\n",
       " 'A man',\n",
       " 'a zip line',\n",
       " 'the water',\n",
       " 'a man',\n",
       " 'a harness',\n",
       " 'the water',\n",
       " 'A man',\n",
       " 'a tag line',\n",
       " 'the water',\n",
       " 'A man',\n",
       " 'a harness',\n",
       " 'the water',\n",
       " \"A woman 's lower body\",\n",
       " 'blue jeans',\n",
       " 'a large sign',\n",
       " 'another woman',\n",
       " 'a black top',\n",
       " 'sunglasses',\n",
       " 'A woman',\n",
       " 'rolled up jeans',\n",
       " 'a black shirt',\n",
       " 'a shopping bag',\n",
       " 'A woman',\n",
       " 'whose head',\n",
       " 'an advertisement',\n",
       " 'A woman',\n",
       " 'rolled up jeans',\n",
       " 'whose ad',\n",
       " 'A woman',\n",
       " 'jeans',\n",
       " 'an ad',\n",
       " 'a woman',\n",
       " 'her sunglasses',\n",
       " 'A young man',\n",
       " 'blue jeans',\n",
       " 'a t-shirt',\n",
       " 'the grass',\n",
       " 'a ball',\n",
       " 'A man',\n",
       " 'a red shirt',\n",
       " 'the grass',\n",
       " 'a ball',\n",
       " 'A man',\n",
       " 'a pink shirt',\n",
       " 'the grass',\n",
       " 'a ball',\n",
       " 'A man',\n",
       " 'the grass',\n",
       " 'a beautiful park',\n",
       " 'A man',\n",
       " 'the grass',\n",
       " 'a ball',\n",
       " 'Red white and blue SUV',\n",
       " 'the beach',\n",
       " 'shoreline',\n",
       " 'seagulls',\n",
       " 'the sand',\n",
       " 'A red , white , and blue security vehicle',\n",
       " 'a rocky beach',\n",
       " 'some birds',\n",
       " 'A truck',\n",
       " 'a beach',\n",
       " 'a flock of seagulls',\n",
       " 'Orange SUV',\n",
       " 'the shore',\n",
       " 'A car',\n",
       " 'the beach',\n",
       " 'Two young men',\n",
       " 'black',\n",
       " 'Two guys',\n",
       " 'Two men',\n",
       " 'two men',\n",
       " 'black',\n",
       " 'Two male spectators',\n",
       " 'A crowd',\n",
       " '2 shirtless men',\n",
       " 'one',\n",
       " 'yellow pants',\n",
       " 'one',\n",
       " 'black shorts',\n",
       " 'A man',\n",
       " 'yellow pants',\n",
       " 'no shirt',\n",
       " 'many people',\n",
       " 'a man',\n",
       " 'yellow pants',\n",
       " 'a man',\n",
       " 'black pants',\n",
       " 'The man',\n",
       " 'the yellow pants',\n",
       " 'his arms',\n",
       " 'A muscular man',\n",
       " 'yellow pants',\n",
       " 'Two men',\n",
       " 'hats',\n",
       " 'canes',\n",
       " 'a large body of water',\n",
       " 'sunlight',\n",
       " 'the water',\n",
       " 'a tree',\n",
       " 'Two men',\n",
       " 'hats',\n",
       " 'walking sticks',\n",
       " 'a body of water',\n",
       " 'Two men',\n",
       " 'a tree',\n",
       " 'the ocean',\n",
       " 'Two mature hikers',\n",
       " 'the lake',\n",
       " 'Two men',\n",
       " 'water',\n",
       " 'Three people',\n",
       " 'blue , white and black leotards',\n",
       " 'each',\n",
       " 'the same outfit',\n",
       " 'people',\n",
       " 'A group of male and female cheerleaders',\n",
       " 'three formations',\n",
       " 'Nine cheerleaders',\n",
       " 'acrobatics',\n",
       " 'a row of chairs',\n",
       " 'A cheerleading team',\n",
       " 'a routine',\n",
       " 'chairs',\n",
       " 'Male cheerleading squad',\n",
       " 'a park',\n",
       " 'A young boy',\n",
       " 'a checkers board',\n",
       " 'one fist',\n",
       " 'his head',\n",
       " 'a partially visible adult',\n",
       " 'the table',\n",
       " 'a room full of people',\n",
       " 'chairs',\n",
       " 'tables',\n",
       " 'A boy',\n",
       " 'checkers',\n",
       " 'an adult',\n",
       " 'a girl',\n",
       " 'Children',\n",
       " 'a game of checkers',\n",
       " 'The children',\n",
       " 'a game of checkers',\n",
       " 'Children',\n",
       " 'checkers',\n",
       " 'a woman',\n",
       " 'pink jeans',\n",
       " 'a child',\n",
       " 'a heart t-shirt',\n",
       " 'cyclists',\n",
       " 'others',\n",
       " 'palm trees',\n",
       " 'palm trees',\n",
       " 'figures',\n",
       " 'bicycles',\n",
       " 'a couple',\n",
       " 'a child',\n",
       " 'rollerskates',\n",
       " 'an older person',\n",
       " 'People',\n",
       " 'a street',\n",
       " 'palm trees',\n",
       " 'Small child',\n",
       " 'bicyclists',\n",
       " 'a track',\n",
       " 'A crowd of people',\n",
       " 'A man',\n",
       " 'a bench',\n",
       " 'his dog',\n",
       " 'the water',\n",
       " 'A man',\n",
       " 'a dog',\n",
       " 'a bench',\n",
       " 'a lake',\n",
       " 'A man',\n",
       " 'a dog',\n",
       " 'a bench',\n",
       " 'a body of water',\n",
       " 'A man',\n",
       " 'his dog',\n",
       " 'the sunset',\n",
       " 'a bench',\n",
       " 'a man',\n",
       " 'his dog',\n",
       " 'a pond',\n",
       " 'Two boys',\n",
       " 'red jackets',\n",
       " 'shovels',\n",
       " 'the dirt',\n",
       " 'the smaller boy',\n",
       " 'the yellow boots',\n",
       " 'a mohawk',\n",
       " 'A man',\n",
       " 'a red jacket',\n",
       " 'a child',\n",
       " 'a mohawk dig',\n",
       " 'shovels',\n",
       " 'a park',\n",
       " 'the beach',\n",
       " 'A boy',\n",
       " 'his younger brother',\n",
       " 'the playground',\n",
       " 'Two people',\n",
       " 'shovels',\n",
       " 'a playground',\n",
       " 'the ocean',\n",
       " 'Two children',\n",
       " 'Woman',\n",
       " 'blue',\n",
       " 'a bench',\n",
       " 'a cane',\n",
       " 'her purse',\n",
       " 'a stretch limo',\n",
       " 'a man',\n",
       " 'a woman',\n",
       " 'A woman',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For English\n",
    "general_df = pd.read_csv(test_triple_filepath)\n",
    "corpus_list_en = general_df[\"entity_content\"].values.tolist() \n",
    "corpus_list_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_en = [[w.lower() for w in word_tokenize(q)] for q in corpus_list_en]\n",
    "general_corpus_dct_en = gensim.corpora.Dictionary(corpus_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14476"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2758"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(general_corpus_dct_en.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1026)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(general_corpus_dct_en.dfs.values())\n",
    "torch.sum(torch.tensor(freq) >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = torchtext.vocab.GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noted that in GloVe, there is no unknown word token, nor empty word token. \n",
    "Here we use index=1, which is '.' as empty word token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/wenjian/Internship/data/flickr30kentities/queries_extracted/train_queries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = train_df[\"entity_content\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.STEMMING:\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    corpus = [[stemmer.stem(w) for w in word_tokenize(q)] for q in corpus_list]\n",
    "else: \n",
    "    corpus = [[w.lower() for w in word_tokenize(q)] for q in corpus_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['two', 'young', 'guys'],\n",
       " ['shaggy', 'hair'],\n",
       " ['their', 'hands'],\n",
       " ['two', 'young', ',', 'white', 'males'],\n",
       " ['many', 'bushes'],\n",
       " ['two', 'men'],\n",
       " ['green', 'shirts'],\n",
       " ['a', 'man'],\n",
       " ['a', 'blue', 'shirt'],\n",
       " ['two', 'friends'],\n",
       " ['several', 'men'],\n",
       " ['hard', 'hats'],\n",
       " ['a', 'giant', 'pulley', 'system'],\n",
       " ['workers'],\n",
       " ['a', 'piece', 'of', 'equipment'],\n",
       " ['two', 'men'],\n",
       " ['a', 'machine'],\n",
       " ['hard', 'hats'],\n",
       " ['four', 'men'],\n",
       " ['a', 'tall', 'structure'],\n",
       " ['three', 'men'],\n",
       " ['a', 'large', 'rig'],\n",
       " ['a', 'child'],\n",
       " ['a', 'pink', 'dress'],\n",
       " ['a', 'set', 'of', 'stairs'],\n",
       " ['an', 'entry', 'way'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['a', 'pink', 'dress'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['the', 'stairs'],\n",
       " ['her', 'playhouse'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['a', 'wooden', 'playhouse'],\n",
       " ['a', 'girl'],\n",
       " ['someone'],\n",
       " ['a', 'blue', 'shirt'],\n",
       " ['hat'],\n",
       " ['stair'],\n",
       " ['a', 'window'],\n",
       " ['a', 'man'],\n",
       " ['a', 'blue', 'shirt'],\n",
       " ['a', 'ladder'],\n",
       " ['a', 'window'],\n",
       " ['a', 'man'],\n",
       " ['a', 'ladder'],\n",
       " ['the', 'window', 'of', 'a', 'tall', 'building'],\n",
       " ['man'],\n",
       " ['blue', 'shirt'],\n",
       " ['jeans'],\n",
       " ['ladder'],\n",
       " ['windows'],\n",
       " ['a', 'man'],\n",
       " ['a', 'ladder'],\n",
       " ['a', 'window'],\n",
       " ['two', 'men'],\n",
       " ['one'],\n",
       " ['a', 'gray', 'shirt'],\n",
       " ['one'],\n",
       " ['a', 'black', 'shirt'],\n",
       " ['a', 'stove'],\n",
       " ['two', 'guy'],\n",
       " ['two', 'men'],\n",
       " ['food'],\n",
       " ['a', 'stove'],\n",
       " ['two', 'men'],\n",
       " ['the', 'stove'],\n",
       " ['food'],\n",
       " ['two', 'men'],\n",
       " ['a', 'meal'],\n",
       " ['two', 'people'],\n",
       " ['the', 'guitar'],\n",
       " ['the', 'other'],\n",
       " ['a', 'man'],\n",
       " ['green'],\n",
       " ['a', 'guitar'],\n",
       " ['the', 'other', 'man'],\n",
       " ['his', 'shirt'],\n",
       " ['a', 'man'],\n",
       " ['the', 'guitar', 'players', 'costume'],\n",
       " ['a', 'guy'],\n",
       " ['another', 'man', \"'s\", 'coat'],\n",
       " ['the', 'two', 'boys'],\n",
       " ['guitar'],\n",
       " ['a', 'man'],\n",
       " ['a', 'chair'],\n",
       " ['a', 'large', 'stuffed', 'animal', 'of', 'a', 'lion'],\n",
       " ['a', 'man'],\n",
       " ['a', 'chair'],\n",
       " ['a', 'large', 'stuffed', 'animal'],\n",
       " ['a', 'man'],\n",
       " ['the', 'finishing', 'touches'],\n",
       " ['a', 'stuffed', 'lion'],\n",
       " ['a', 'man'],\n",
       " ['a', 'large', 'stuffed', 'lion', 'toy'],\n",
       " ['a', 'man'],\n",
       " ['a', 'stuffed', 'lion'],\n",
       " ['a', 'girl'],\n",
       " ['rollerskates'],\n",
       " ['her', 'cellphone'],\n",
       " ['a', 'parking', 'lot'],\n",
       " ['a', 'trendy', 'girl'],\n",
       " ['her', 'cellphone'],\n",
       " ['the', 'street'],\n",
       " ['a', 'young', 'adult'],\n",
       " ['rollerblades'],\n",
       " ['a', 'cellular', 'phone'],\n",
       " ['a', 'young', 'girl'],\n",
       " ['her', 'cellphone'],\n",
       " ['skating'],\n",
       " ['woman'],\n",
       " ['cellphone'],\n",
       " ['rollerskates'],\n",
       " ['an', 'asian', 'man'],\n",
       " ['a', 'black', 'suit'],\n",
       " ['a', 'dark-haired', 'woman'],\n",
       " ['a', 'brown-haired', 'woman'],\n",
       " ['three', 'people'],\n",
       " ['large', 'pipes'],\n",
       " ['a', 'metal', 'railing'],\n",
       " ['a', 'young', 'woman'],\n",
       " ['two', 'young', 'people'],\n",
       " ['hip', 'black', 'outfits'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'large', 'purse'],\n",
       " ['a', 'gate'],\n",
       " ['several', 'people'],\n",
       " ['a', 'building'],\n",
       " ['two', 'men'],\n",
       " ['a', 'rail'],\n",
       " ['shirts'],\n",
       " ['two', 'youths'],\n",
       " ['a', 'roadside', 'railing'],\n",
       " ['boys'],\n",
       " ['poles'],\n",
       " ['two', 'men'],\n",
       " ['no', 'shirts'],\n",
       " ['a', 'rail'],\n",
       " ['two', 'guys'],\n",
       " ['a', 'gate'],\n",
       " ['five', 'ballet', 'dancers'],\n",
       " ['a', 'window'],\n",
       " ['ballet', 'dancers'],\n",
       " ['five', 'girls'],\n",
       " ['five', 'girls'],\n",
       " ['feet'],\n",
       " ['a', 'ballet', 'class', 'of', 'five', 'girls'],\n",
       " ['three', 'young', 'men'],\n",
       " ['a', 'young', 'woman'],\n",
       " ['sneakers'],\n",
       " ['the', 'top', 'of', 'a', 'flight'],\n",
       " ['four', 'casually', 'dressed', 'guys'],\n",
       " ['a', 'stone', 'wall'],\n",
       " ['four', 'guys'],\n",
       " ['hats'],\n",
       " ['one'],\n",
       " ['the', 'top', 'of', 'a', 'staircase'],\n",
       " ['four', 'men'],\n",
       " ['excited', 'faces'],\n",
       " ['the', 'top', 'of', 'stairs'],\n",
       " ['four', 'people'],\n",
       " ['a', 'black', 'dog'],\n",
       " ['a', 'white', 'dog'],\n",
       " ['brown', 'spots'],\n",
       " ['the', 'street'],\n",
       " ['a', 'black', 'dog'],\n",
       " ['a', 'tri-colored', 'dog'],\n",
       " ['the', 'road'],\n",
       " ['two', 'dogs', 'of', 'different', 'breeds'],\n",
       " ['the', 'road'],\n",
       " ['two', 'dogs'],\n",
       " ['pavement'],\n",
       " ['a', 'black', 'dog'],\n",
       " ['a', 'spotted', 'dog'],\n",
       " ['a', 'man'],\n",
       " ['reflective', 'safety', 'clothes'],\n",
       " ['ear', 'protection'],\n",
       " ['a', 'john', 'deere', 'tractor'],\n",
       " ['a', 'road'],\n",
       " ['john', 'deere'],\n",
       " ['a', 'street'],\n",
       " ['the', 'driver'],\n",
       " ['easy', 'to', 'see', 'clothing'],\n",
       " ['a', 'man'],\n",
       " ['orange', 'uniform'],\n",
       " ['a', 'green', 'tractor'],\n",
       " ['a', 'man'],\n",
       " ['headphones'],\n",
       " ['a', 'paved', 'street'],\n",
       " ['a', 'man'],\n",
       " ['a', 'john', 'deere', 'tractor'],\n",
       " ['a', 'main', 'road'],\n",
       " ['some', 'women'],\n",
       " ['buildings'],\n",
       " ['several', 'women'],\n",
       " ['tall', 'buildings'],\n",
       " ['a', 'group', 'of', 'women'],\n",
       " ['several', 'women'],\n",
       " ['women'],\n",
       " ['a', 'young', 'woman'],\n",
       " ['dark', 'hair'],\n",
       " ['glasses'],\n",
       " ['white', 'powder'],\n",
       " ['a', 'cake'],\n",
       " ['a', 'sifter'],\n",
       " ['a', 'lady'],\n",
       " ['a', 'black', 'top'],\n",
       " ['glasses'],\n",
       " ['powdered', 'sugar'],\n",
       " ['a', 'bundt', 'cake'],\n",
       " ['a', 'woman'],\n",
       " ['glasses', 'sprinkles'],\n",
       " ['sugar'],\n",
       " ['her', 'bundt', 'cake'],\n",
       " ['girl'],\n",
       " ['black', 'jacket'],\n",
       " ['powdered', 'sugar'],\n",
       " ['a', 'chocolate', 'cake'],\n",
       " ['a', 'standing', 'woman'],\n",
       " ['a', 'pan'],\n",
       " ['a', 'cake'],\n",
       " ['a', 'small', 'girl'],\n",
       " ['the', 'grass'],\n",
       " ['fingerpaints'],\n",
       " ['a', 'white', 'canvas'],\n",
       " ['a', 'rainbow'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['paint'],\n",
       " ['a', 'painted', 'rainbow'],\n",
       " ['her', 'hands'],\n",
       " ['a', 'bowl'],\n",
       " ['a', 'girl'],\n",
       " ['pigtails'],\n",
       " ['a', 'rainbow', 'painting'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['a', 'large', 'painted', 'rainbow'],\n",
       " ['young', 'girl'],\n",
       " ['pigtails'],\n",
       " ['the', 'grass'],\n",
       " ['a', 'man'],\n",
       " ['a', 'bench'],\n",
       " ['a', 'white', 'and', 'black', 'dog'],\n",
       " ['a', 'man'],\n",
       " ['the', 'bench'],\n",
       " ['a', 'white', 'dog'],\n",
       " ['man'],\n",
       " ['bench'],\n",
       " ['leash', 'of', 'dog'],\n",
       " ['a', 'shirtless', 'man'],\n",
       " ['a', 'park', 'bench'],\n",
       " ['his', 'dog'],\n",
       " ['a', 'man'],\n",
       " ['a', 'bench'],\n",
       " ['his', 'dog'],\n",
       " ['a', 'group', 'of', 'adults'],\n",
       " ['chairs'],\n",
       " ['a', 'circle'],\n",
       " ['a', 'type', 'of', 'musical', 'instruments'],\n",
       " ['five', 'musicians'],\n",
       " ['a', 'man'],\n",
       " ['four', 'women'],\n",
       " ['sheet', 'music'],\n",
       " ['flutes'],\n",
       " ['people'],\n",
       " ['a', 'circle'],\n",
       " ['some'],\n",
       " ['musical', 'instruments'],\n",
       " ['people'],\n",
       " ['five', 'people'],\n",
       " ['a', 'circle'],\n",
       " ['instruments'],\n",
       " ['two', 'women'],\n",
       " ['glasses'],\n",
       " ['clarinets'],\n",
       " ['an', 'elderly', 'woman'],\n",
       " ['a', 'stringed', 'instrument'],\n",
       " ['at', 'least', 'four', 'instrumentalists'],\n",
       " ['clarinets'],\n",
       " ['other', 'instruments'],\n",
       " ['four', 'women'],\n",
       " ['a', 'musical', 'instrument'],\n",
       " ['a', 'bunch', 'of', 'elderly', 'women'],\n",
       " ['their', 'clarinets'],\n",
       " ['sheet', 'music'],\n",
       " ['a', 'group', 'of', 'four', 'women'],\n",
       " ['their', 'instruments'],\n",
       " ['a', 'person'],\n",
       " ['gray'],\n",
       " ['a', 'structure'],\n",
       " ['a', 'large', 'structure'],\n",
       " ['a', 'roadway'],\n",
       " ['a', 'man'],\n",
       " ['a', 'gray', 'coat'],\n",
       " ['a', 'washed', 'out', 'bridge'],\n",
       " ['a', 'man'],\n",
       " ['wooden', 'supports'],\n",
       " ['a', 'man'],\n",
       " ['a', 'jacket'],\n",
       " ['jeans'],\n",
       " ['a', 'bridge'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 't-shirt'],\n",
       " ['a', 'crowd'],\n",
       " ['a', 'large', 'crowd', 'of', 'people'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['a', 'crowd'],\n",
       " ['crowd'],\n",
       " ['a', 'man'],\n",
       " ['a', 'goatee'],\n",
       " ['a', 'black', 'shirt'],\n",
       " ['white', 'latex', 'gloves'],\n",
       " ['a', 'tattoo', 'gun'],\n",
       " ['a', 'tattoo'],\n",
       " ['someone', \"'s\", 'back'],\n",
       " ['a', 'man'],\n",
       " ['a', 'tattoo'],\n",
       " ['a', 'another', \"'s\", 'man'],\n",
       " ['a', 'man'],\n",
       " ['a', 'black', 'shirt'],\n",
       " ['another', 'man'],\n",
       " ['a', 'tattoo'],\n",
       " ['a', 'man'],\n",
       " ['tattoo'],\n",
       " ['his', 'back'],\n",
       " ['a', 'man'],\n",
       " ['a', 'tattoo'],\n",
       " ['his', 'back'],\n",
       " ['two', 'children'],\n",
       " ['a', 'girl'],\n",
       " ['a', 'boy'],\n",
       " ['two', 'children'],\n",
       " ['a', 'small', 'seesaw'],\n",
       " ['the', 'sand'],\n",
       " ['two', 'children'],\n",
       " ['a', 'teeter', 'totter'],\n",
       " ['2', 'kids'],\n",
       " ['a', 'seesaw'],\n",
       " ['two', 'kids'],\n",
       " ['a', 'seesaw'],\n",
       " ['a', 'man'],\n",
       " ['a', 'blue', 'hard', 'hat'],\n",
       " ['orange', 'safety', 'vest'],\n",
       " ['an', 'intersection'],\n",
       " ['a', 'flag'],\n",
       " ['a', 'man'],\n",
       " ['a', 'hard', 'hat'],\n",
       " ['a', 'caution', 'vest'],\n",
       " ['the', 'street'],\n",
       " ['an', 'orange', 'flag'],\n",
       " ['a', 'man'],\n",
       " ['bright', 'vest'],\n",
       " ['hard', 'hat'],\n",
       " ['a', 'flag'],\n",
       " ['a', 'street', 'corner'],\n",
       " ['spray', 'paint'],\n",
       " ['a', 'construction', 'worker'],\n",
       " ['the', 'street'],\n",
       " ['a', 'red', 'flag'],\n",
       " ['a', 'man'],\n",
       " ['a', 'reflective', 'vest'],\n",
       " ['a', 'hard', 'hat'],\n",
       " ['a', 'flag'],\n",
       " ['the', 'road'],\n",
       " ['a', 'person'],\n",
       " ['long', 'gray', 'hair'],\n",
       " ['a', 'beret'],\n",
       " ['beige', 'and', 'white'],\n",
       " ['a', 'blue', 'raincoat'],\n",
       " ['other', 'artists'],\n",
       " ['paintings'],\n",
       " ['a', 'person'],\n",
       " ['a', 'blue', 'coat'],\n",
       " ['a', 'busy', 'sidewalk'],\n",
       " ['painting', 'of', 'a', 'street', 'scene'],\n",
       " ['a', 'person'],\n",
       " ['gray', 'hair'],\n",
       " ['a', 'public', 'place'],\n",
       " ['others'],\n",
       " ['lady'],\n",
       " ['blue', 'coat'],\n",
       " ['white', 'and', 'brown', 'hat'],\n",
       " ['a', 'painting'],\n",
       " ['passerby'],\n",
       " ['painting'],\n",
       " ['an', 'outdoor', 'art', 'fair'],\n",
       " ['a', 'man'],\n",
       " ['one', 'foot'],\n",
       " ['a', 'waste', 'basket'],\n",
       " ['a', 'man'],\n",
       " ['green', 'pants'],\n",
       " ['blue', 'shirt'],\n",
       " ['a', 'cart'],\n",
       " ['janitor'],\n",
       " ['dolly'],\n",
       " ['janitor', 'tools'],\n",
       " ['a', 'man'],\n",
       " ['green', 'pants'],\n",
       " ['the', 'road'],\n",
       " ['a', 'man'],\n",
       " ['bright', 'pants'],\n",
       " ['a', 'cart'],\n",
       " ['a', 'small', 'child'],\n",
       " ['the', 'red', 'ropes'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['pink'],\n",
       " ['a', 'rope', 'bridge'],\n",
       " ['the', 'small', 'child'],\n",
       " ['a', 'red'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['red', 'roping'],\n",
       " ['a', 'child'],\n",
       " ['a', 'rope', 'net'],\n",
       " ['young', 'man'],\n",
       " ['jacket'],\n",
       " ['a', 'toothpick'],\n",
       " ['something'],\n",
       " ['a', 'young', 'man'],\n",
       " ['a', 'piece', 'of', 'flower'],\n",
       " ['his', 'hands'],\n",
       " ['a', 'teen'],\n",
       " ['an', 'unknown', 'object'],\n",
       " ['a', 'young', 'man'],\n",
       " ['an', 'origami', 'crane'],\n",
       " ['young', 'blond', 'man'],\n",
       " ['a', 'blue', 'and', 'yellow', 'jacket'],\n",
       " ['a', 'net'],\n",
       " ['a', 'young', 'man'],\n",
       " ['a', 'black', 'and', 'yellow', 'jacket'],\n",
       " ['a', 'young', 'man'],\n",
       " ['a', 'pole', 'vault'],\n",
       " ['a', 'man'],\n",
       " ['a', 'pole'],\n",
       " ['a', 'smiling', 'man'],\n",
       " ['the', 'sky'],\n",
       " ['a', 'man'],\n",
       " ['a', 'baseball', 'cap'],\n",
       " ['black', 'jacket'],\n",
       " ['a', 'coffee', 'mug'],\n",
       " ['a', 'man'],\n",
       " ['a', 'ball', 'cap'],\n",
       " ['a', 'coffee', 'cup'],\n",
       " ['urinals'],\n",
       " ['a', 'man'],\n",
       " ['a', 'urinal'],\n",
       " ['a', 'cup', 'of', 'coffee'],\n",
       " ['a', 'man'],\n",
       " ['a', 'coffee', 'cup'],\n",
       " ['a', 'man'],\n",
       " ['a', 'urinal'],\n",
       " ['a', 'coffee', 'cup'],\n",
       " ['five', 'people'],\n",
       " ['four', 'people'],\n",
       " ['clear', 'blue', 'skies'],\n",
       " ['four', 'people'],\n",
       " ['the', 'sun'],\n",
       " ['four', 'silhouettes'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['the', 'sun'],\n",
       " ['a', 'man'],\n",
       " ['black', 'hair'],\n",
       " ['a', 'glass', 'of', 'beer'],\n",
       " ['a', 'man'],\n",
       " ['a', 'table'],\n",
       " ['a', 'drink'],\n",
       " ['a', 'man'],\n",
       " ['a', 'table'],\n",
       " ['a', 'beer'],\n",
       " ['a', 'dark-haired', 'man'],\n",
       " ['a', 'old', 'man'],\n",
       " ['a', 'beer'],\n",
       " ['an', 'officer'],\n",
       " ['a', 'reflective', 'vest'],\n",
       " ['the', 'front', 'of', 'his', 'van'],\n",
       " ['his', 'dog'],\n",
       " ['a', 'trained', 'police', 'dog'],\n",
       " ['his', 'handler'],\n",
       " ['the', 'police', 'van'],\n",
       " ['a', 'security', 'man'],\n",
       " ['his', 'watch', 'dog'],\n",
       " ['a', 'policeman'],\n",
       " ['a', 'german', 'shepherd', 'dog'],\n",
       " ['a', 'policeman'],\n",
       " ['a', 'street'],\n",
       " ['a', 'search', 'dog'],\n",
       " ['the', '``', 'white', 'out', '``', 'conditions', 'of', 'snow'],\n",
       " ['the', 'details', 'of', 'a', 'man'],\n",
       " ['a', 'heavy', 'jacket'],\n",
       " ['red', 'hat'],\n",
       " ['a', 'bicycle'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['a', 'bike'],\n",
       " ['a', 'snow'],\n",
       " ['a', 'boy'],\n",
       " ['the', 'snow'],\n",
       " ['his', 'bike'],\n",
       " ['a', 'person'],\n",
       " ['a', 'bike'],\n",
       " ['a', 'snowy', 'road'],\n",
       " ['a', 'person'],\n",
       " ['a', 'bike'],\n",
       " ['snow'],\n",
       " ['five', 'men'],\n",
       " ['white', 'shirts'],\n",
       " ['tie'],\n",
       " ['black', 'slacks'],\n",
       " ['the', 'back', 'of', 'an', 'open', 'van'],\n",
       " ['small', 'group', 'of', '5', 'white', 'males'],\n",
       " ['white', 'suits'],\n",
       " ['the', 'back', 'of', 'a', 'van'],\n",
       " ['a', 'parking', 'lot'],\n",
       " ['five', 'men'],\n",
       " ['white', 'short-sleeved', 'shirts'],\n",
       " ['ties'],\n",
       " ['a', 'parking', 'lot'],\n",
       " ['a', 'group', 'of', 'men'],\n",
       " ['ties'],\n",
       " ['the', 'street'],\n",
       " ['colleges', 'stop'],\n",
       " ['a', 'tan', 'man'],\n",
       " ['hat'],\n",
       " ['older', 'man'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 'shirt'],\n",
       " ['black', 'camp'],\n",
       " ['many', 'machines'],\n",
       " ['a', 'man'],\n",
       " ['hat'],\n",
       " ['machinery'],\n",
       " ['a', 'man'],\n",
       " ['a', 'backwards', 'cap'],\n",
       " ['a', 'caucasian', 'man'],\n",
       " ['a', 'short-sleeved', 'black', 'shirt'],\n",
       " ['a', 'dark-skinned', 'woman'],\n",
       " ['a', 'sleeveless', 'dress'],\n",
       " ['a', 'conveyor'],\n",
       " ['a', 'black', 'woman'],\n",
       " ['a', 'white', 'man'],\n",
       " ['packing', 'jars'],\n",
       " ['candles'],\n",
       " ['boxes'],\n",
       " ['a', 'woman'],\n",
       " ['white', 'tall', 'candles'],\n",
       " ['a', 'man'],\n",
       " ['a', 'green', 'shirt'],\n",
       " ['a', 'warehouse', 'manager'],\n",
       " ['an', 'employee'],\n",
       " ['two', 'people'],\n",
       " ['an', 'assembly', 'line'],\n",
       " ['man'],\n",
       " ['a', 'blue', 'and', 'white', 'outfit'],\n",
       " ['a', 'broom'],\n",
       " ['a', 'traditional', 'asian', 'architecture'],\n",
       " ['a', 'asian', 'man'],\n",
       " ['a', 'white', 'top'],\n",
       " ['baby', 'blue', 'bottoms'],\n",
       " ['a', 'broom'],\n",
       " ['the', 'dirt', 'of', 'the', 'pavement'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 'and', 'blue', 'kimono'],\n",
       " ['a', 'broom'],\n",
       " ['pavement'],\n",
       " ['man'],\n",
       " ['the', 'street'],\n",
       " ['asian', 'man'],\n",
       " ['the', 'walkway'],\n",
       " ['two', 'men'],\n",
       " ['florescent', 'vests'],\n",
       " ['parked', 'cars'],\n",
       " ['a', 'small', 'building'],\n",
       " ['a', 'driver'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'bike'],\n",
       " ['a', 'man'],\n",
       " ['a', 'car'],\n",
       " ['the', 'driver'],\n",
       " ['a', 'man'],\n",
       " ['a', 'bicycle'],\n",
       " ['a', 'man'],\n",
       " ['a', 'bicycle'],\n",
       " ['a', 'row', 'of', 'cars'],\n",
       " ['a', 'checkpoint'],\n",
       " ['a', 'park', 'ranger'],\n",
       " ['a', 'tourist'],\n",
       " ['two', 'cars'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['a', 'pink', 'shirt'],\n",
       " ['a', 'little', 'girl'],\n",
       " ['an', 'orange', 'shirt'],\n",
       " ['two', 'young', 'children'],\n",
       " ['a', 'snack'],\n",
       " ['two', 'young', 'toddlers'],\n",
       " ['two', 'infants'],\n",
       " ['2', 'female', 'babies'],\n",
       " ['chips'],\n",
       " ['a', 'person'],\n",
       " ['tan', 'pants'],\n",
       " ['a', 'silver', 'mobile', 'object'],\n",
       " ['people'],\n",
       " ['people'],\n",
       " ['a', 'person'],\n",
       " ['a', 'weird', 'vehicle'],\n",
       " ['a', 'man'],\n",
       " ['a', 'blue', 'shirt'],\n",
       " ['a', 'segway', 'type', 'vehicle'],\n",
       " ['a', 'showing', 'of', 'product'],\n",
       " ['a', 'crowd'],\n",
       " ['modern', 'art'],\n",
       " ['a', 'man'],\n",
       " ['a', 'strange', 'silver', 'object'],\n",
       " ['a', 'person'],\n",
       " ['many', 'onlookers'],\n",
       " ['a', 'roped', 'off', 'barrier'],\n",
       " ['a', 'person'],\n",
       " ['a', 'futuristic', 'looking', 'vehicle'],\n",
       " ['a', 'man'],\n",
       " ['a', 'crowd'],\n",
       " ['a', 'person'],\n",
       " ['a', 'futuristic', 'single-person', 'vehicle'],\n",
       " ['man'],\n",
       " ['silver', '4-wheeled', 'chair'],\n",
       " ['a', 'man'],\n",
       " ['a', 'silver', 'vehicle'],\n",
       " ['bride'],\n",
       " ['groom'],\n",
       " ['pathway'],\n",
       " ['brick', 'building'],\n",
       " ['a', 'beautiful', 'bride'],\n",
       " ['a', 'sidewalk'],\n",
       " ['her', 'new', 'husband'],\n",
       " ['a', 'recently', 'married', 'couple'],\n",
       " ['a', 'groom'],\n",
       " ['bride'],\n",
       " ['a', 'couple'],\n",
       " ['a', 'little', 'boy'],\n",
       " ['a', 'nintendo', 'gamecube', 'controller'],\n",
       " ['a', 'mcdonald'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['a', 'video', 'game'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['a', 'gamecube', 'kiosk'],\n",
       " ['mcdonald'],\n",
       " ['a', 'little', 'boy'],\n",
       " ['gamecube'],\n",
       " ['a', 'mcdonald'],\n",
       " ['a', 'little', 'kid'],\n",
       " ['gamecube'],\n",
       " ['mcdonald'],\n",
       " ['white', 'dog'],\n",
       " ['brown', 'ears'],\n",
       " ['water'],\n",
       " ['head'],\n",
       " ['dog'],\n",
       " ['orange', 'ball'],\n",
       " ['feet'],\n",
       " ['shore'],\n",
       " ['water'],\n",
       " ['a', 'white', 'dog'],\n",
       " ['the', 'edge', 'of', 'a', 'beach'],\n",
       " ['an', 'orange', 'ball'],\n",
       " ['white', 'dog'],\n",
       " ['a', 'red', 'ball'],\n",
       " ['the', 'shore'],\n",
       " ['the', 'water'],\n",
       " ['a', 'dog'],\n",
       " ['its', 'head'],\n",
       " ['the', 'shore'],\n",
       " ['a', 'red', 'ball'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['picnic', 'tables'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['the', 'reunion'],\n",
       " ['a', 'moon', 'bounce'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['two', 'asian', 'or', 'spanish', 'people'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'man'],\n",
       " ['a', 'glass', 'window'],\n",
       " ['cars'],\n",
       " ['a', 'man'],\n",
       " ['sunglasses'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'black', 'and', 'white', 'blouse'],\n",
       " ['a', 'man'],\n",
       " ['sunglasses'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'man'],\n",
       " ['woman'],\n",
       " ['an', 'asian', 'couple'],\n",
       " ['the', 'bench'],\n",
       " ['women'],\n",
       " ['a', 'picnic', 'table'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 't-shirt'],\n",
       " ['a', 'yellow', 'and', 'orange', 'balloon', 'design'],\n",
       " ['his', 'head'],\n",
       " ['an', 'elderly', 'woman'],\n",
       " ['a', 'burger'],\n",
       " ['the', 'man'],\n",
       " ['his', 'hat'],\n",
       " ['a', 'man'],\n",
       " ['a', 'balloon', 'hat'],\n",
       " ['people'],\n",
       " ['picnic', 'tables'],\n",
       " ['two', 'older', 'women'],\n",
       " ['a', 'table'],\n",
       " ['two', 'coolers'],\n",
       " ['a', 'gray-haired', 'person'],\n",
       " ['glasses'],\n",
       " ['a', 'sandwich'],\n",
       " ['two', 'people'],\n",
       " ['a', 'crowd'],\n",
       " ['three', 'youngsters'],\n",
       " ['the', 'mat'],\n",
       " ['a', 'boy'],\n",
       " ['three', 'kids'],\n",
       " ['wood'],\n",
       " ['a', 'boy'],\n",
       " ['three', 'other', 'students'],\n",
       " ['a', 'crowd'],\n",
       " ['a', 'group', 'of', 'five', 'martial', 'artists'],\n",
       " ['a', 'crowd', 'of', 'people'],\n",
       " ['people'],\n",
       " ['two', 'balconies'],\n",
       " ['a', 'man'],\n",
       " ['a', 'pipe'],\n",
       " ['the', 'lower', 'balcony'],\n",
       " ['liquid'],\n",
       " ['a', 'kid'],\n",
       " ['a', 'red', 'sweatshirt'],\n",
       " ['something'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 'shirt'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['a', 'bottle'],\n",
       " ['the', 'railing', 'of', 'a', 'balcony'],\n",
       " ['the', 'man'],\n",
       " ['a', 'boy'],\n",
       " ['a', 'red', 'jacket'],\n",
       " ['water'],\n",
       " ['a', 'man'],\n",
       " ['a', 'white', 'shirt'],\n",
       " ['a', 'young', 'man'],\n",
       " ['the', 'contents', 'of', 'a', 'bottle'],\n",
       " ['a', 'man'],\n",
       " ['a', 'red', 'jacket'],\n",
       " ['a', 'piece', 'of', 'paper'],\n",
       " ['a', 'man'],\n",
       " ['a', 'red', 'coat'],\n",
       " ['his', 'hand'],\n",
       " ['his', 'head'],\n",
       " ['a', 'man'],\n",
       " ['a', 'red', 'jacket'],\n",
       " ['his', 'eyes'],\n",
       " ['a', 'busy', 'street'],\n",
       " ['an', 'elderly', 'man'],\n",
       " ['a', 'red', 'jacket'],\n",
       " ['his', 'face'],\n",
       " ['man'],\n",
       " ['red', 'jacket'],\n",
       " ['face'],\n",
       " ['two', 'men'],\n",
       " ['children'],\n",
       " ['the', 'street'],\n",
       " ['two', 'men'],\n",
       " ['each'],\n",
       " ['a', 'small', 'child'],\n",
       " ['a', 'paved', 'road'],\n",
       " ['two', 'men'],\n",
       " ['their', 'two', 'young', 'children'],\n",
       " ['men'],\n",
       " ['a', 'street'],\n",
       " ['children'],\n",
       " ['two', 'men'],\n",
       " ['children'],\n",
       " ['smiling', 'boy'],\n",
       " ['white', 'shirt'],\n",
       " ['blue', 'jeans'],\n",
       " ['rock', 'wall'],\n",
       " ['man'],\n",
       " ['overalls'],\n",
       " ['a', 'little', 'boy'],\n",
       " ['the', 'street'],\n",
       " ['a', 'man'],\n",
       " ['overalls'],\n",
       " ['a', 'stone', 'wall'],\n",
       " ['a', 'young', 'child'],\n",
       " ['a', 'stone', 'paved', 'street'],\n",
       " ['a', 'metal', 'pole'],\n",
       " ['a', 'man'],\n",
       " ['a', 'boy'],\n",
       " ['a', 'stony', 'wall'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['the', 'street'],\n",
       " ['a', 'mottled', 'black', 'and', 'gray', 'dog'],\n",
       " ['a', 'blue', 'collar'],\n",
       " ['a', 'fallen', 'tree'],\n",
       " ['a', 'gray', 'dog'],\n",
       " ['a', 'fallen', 'tree'],\n",
       " ['a', 'large', 'black', 'dog'],\n",
       " ['a', 'fallen', 'log'],\n",
       " ['the', 'black', 'dog'],\n",
       " ['the', 'tree', 'stump'],\n",
       " ['a', 'black', 'dog'],\n",
       " ['a', 'log'],\n",
       " ['men'],\n",
       " ['the', 'business', 'suits'],\n",
       " ['the', 'street'],\n",
       " ['people'],\n",
       " ['placards'],\n",
       " ['the', 'street'],\n",
       " ['a', 'man'],\n",
       " ['a', 'suit'],\n",
       " ['an', 'intersection'],\n",
       " ['a', 'large', 'group', 'of', 'people', 'assembles'],\n",
       " ['a', 'man'],\n",
       " ['a', 'suit'],\n",
       " ['two', 'other', 'gentleman'],\n",
       " ['a', 'suit'],\n",
       " ['a', 'man'],\n",
       " ['a', 'suit'],\n",
       " ['the', 'street'],\n",
       " ['a', 'man'],\n",
       " ['a', 'suit'],\n",
       " ['the', 'street'],\n",
       " ['a', 'man'],\n",
       " ['a', 'red', 'long-sleeved', 'shirt'],\n",
       " ['a', 'body', 'of', 'water'],\n",
       " ['a', 'bridge'],\n",
       " ['a', 'man'],\n",
       " ['his', 'bike'],\n",
       " ['the', 'bridge'],\n",
       " ['the', 'river'],\n",
       " ['a', 'man'],\n",
       " ['red'],\n",
       " ['a', 'bicycle'],\n",
       " ['a', 'glass', 'structure'],\n",
       " ['man'],\n",
       " ['a', 'red', 'shirt'],\n",
       " ['his', 'bicycle'],\n",
       " ['water'],\n",
       " ['a', 'man'],\n",
       " ['a', 'red', 'shirt'],\n",
       " ['his', 'bicycle'],\n",
       " ['a', 'barefooted', 'man'],\n",
       " ['olive', 'green', 'shorts'],\n",
       " ['hotdogs'],\n",
       " ['a', 'small', 'propane', 'grill'],\n",
       " ['a', 'blue', 'plastic', 'cup'],\n",
       " ['a', 'guy'],\n",
       " ['shorts'],\n",
       " ['a', 'white', 't-shirt'],\n",
       " ['a', 'grill'],\n",
       " ['hotdogs'],\n",
       " ['a', 'young', 'man'],\n",
       " ['sunglasses'],\n",
       " ['a', 'blue', 'cup'],\n",
       " ['a', 'grill'],\n",
       " ['sausages'],\n",
       " ['a', 'young', 'man'],\n",
       " ['a', 'white', 'shirt'],\n",
       " ['hotdogs'],\n",
       " ['a', 'small', 'grill'],\n",
       " ['a', 'man'],\n",
       " ['his', 'cup'],\n",
       " ['hotdogs'],\n",
       " ['the', 'white', 'and', 'brown', 'dog'],\n",
       " ['the', 'surface', 'of', 'the', 'snow'],\n",
       " ['a', 'white', 'and', 'brown', 'dog'],\n",
       " ['a', 'snow', 'covered', 'field'],\n",
       " ['a', 'brown', 'and', 'white', 'dog'],\n",
       " ['the', 'snow'],\n",
       " ['a', 'dog'],\n",
       " ['snow'],\n",
       " ['a', 'dog'],\n",
       " ['the', 'snow'],\n",
       " ['man'],\n",
       " ['scooter'],\n",
       " ['some', 'of', 'those'],\n",
       " ['large', 'crowd'],\n",
       " ['a', 'crowd'],\n",
       " ['people'],\n",
       " ['an', 'older', 'woman'],\n",
       " ['a', 'crowd', 'of', 'people'],\n",
       " ['a', 'crowd', 'of', 'people'],\n",
       " ['a', 'person'],\n",
       " ['skis'],\n",
       " ['framed', 'pictures'],\n",
       " ['the', 'snow'],\n",
       " ['a', 'man'],\n",
       " ['a', 'hat'],\n",
       " ['pictures'],\n",
       " ['a', 'skier'],\n",
       " ['a', 'blue', 'hat'],\n",
       " ['a', 'man'],\n",
       " ['another', 'man'],\n",
       " ['paintings'],\n",
       " ['the', 'snow'],\n",
       " ['a', 'skier'],\n",
       " ['framed', 'pictures'],\n",
       " ['the', 'snow'],\n",
       " ['trees'],\n",
       " ['man'],\n",
       " ['skis'],\n",
       " ['artwork'],\n",
       " ['the', 'snow'],\n",
       " ['several', 'climbers'],\n",
       " ['the', 'rock'],\n",
       " ['the', 'man'],\n",
       " ['red'],\n",
       " ['the', 'line'],\n",
       " ['seven', 'climbers'],\n",
       " ['a', 'rock', 'face'],\n",
       " ['another', 'man'],\n",
       " ['the', 'rope'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['a', 'rock', 'climbing', 'wall'],\n",
       " ['a', 'group', 'of', 'people'],\n",
       " ['a', 'rock'],\n",
       " ['one', 'man'],\n",
       " ['a', 'collage', 'of', 'one', 'person'],\n",
       " ['a', 'cliff'],\n",
       " ['a', 'young', 'gymnast'],\n",
       " ['a', 'balance', 'beam'],\n",
       " ['a', 'woman'],\n",
       " ['an', 'orange', 'leotard'],\n",
       " ['gymnastics'],\n",
       " ['an', 'audience'],\n",
       " ['a', 'gymnast'],\n",
       " ['the', 'balance', 'beam'],\n",
       " ['an', 'audience'],\n",
       " ['the', 'young', 'gymnast', \"'s\", 'supple', 'body'],\n",
       " ['the', 'balance', 'beam'],\n",
       " ['a', 'gymnast'],\n",
       " ['the', 'balance', 'beam'],\n",
       " ['a', 'boy'],\n",
       " ['a', 'black', 't-shirt'],\n",
       " ['blue', 'jeans'],\n",
       " ['a', 'toy'],\n",
       " ['three', 'wheeler'],\n",
       " ['a', 'small', 'pool'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['a', 'toy', 'atv'],\n",
       " ['a', 'rubber', 'pool'],\n",
       " ['a', 'boy'],\n",
       " ['a', 'red', 'toy'],\n",
       " ['a', 'pool'],\n",
       " ['a', 'boy'],\n",
       " ['a', 'miniature', 'car'],\n",
       " ['a', 'lawn'],\n",
       " ['a', 'young', 'boy'],\n",
       " ['his', 'toy', 'quad'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'red', 'jacket'],\n",
       " ['headscarf'],\n",
       " ['over', 'a', 'scenic', 'view', 'of', 'a', 'bay'],\n",
       " ['a', 'set', 'of', 'pay', 'binoculars'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'headscarf'],\n",
       " ['a', 'window'],\n",
       " ['a', 'mounted', 'telescope'],\n",
       " ['woman'],\n",
       " ['red', 'windbreaker'],\n",
       " ['a', 'rooftop'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'headscarf'],\n",
       " ['a', 'telescope'],\n",
       " ['bay'],\n",
       " ['a', 'woman'],\n",
       " ['a', 'telescope'],\n",
       " ['a', 'red', 'coat'],\n",
       " ['a', 'man'],\n",
       " ['a', 'black', 'coat'],\n",
       " ['a', 'red', 'spaceship'],\n",
       " ['a', 'parking', 'ticket'],\n",
       " ['its', 'window'],\n",
       " ['a', 'man'],\n",
       " ['a', 'small', 'red', 'object'],\n",
       " ['a', 'plane'],\n",
       " ['a', 'man'],\n",
       " ['a', 'black', 'jacket'],\n",
       " ['the', 'street'],\n",
       " ['a', 'man'],\n",
       " ['a', 'black', 'jacket'],\n",
       " ['a', 'street'],\n",
       " ['man'],\n",
       " ['black', 'coat'],\n",
       " ['airplane', 'nose'],\n",
       " ['large', 'brown', 'dog'],\n",
       " ['the', 'sprinkler'],\n",
       " ['the', 'grass'],\n",
       " ['a', 'brown', 'dog'],\n",
       " ['the', 'water'],\n",
       " ['a', 'sprinkler'],\n",
       " ['a', 'lawn'],\n",
       " ['a', 'brown', 'dog'],\n",
       " ['a', 'lawn'],\n",
       " ['a', 'garden', 'hose'],\n",
       " ['a', 'brown', 'dog'],\n",
       " ['the', 'hose'],\n",
       " ['a', 'dog'],\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "# https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
    "class DDPNDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, cfg, phase):\n",
    "        'Initialization'\n",
    "        #self.labels = labels\n",
    "        #self.list_IDs = list_IDs\n",
    "        self.cfg = cfg\n",
    "        self.phase = phase\n",
    "        self.df_triple = pd.read_csv(self.cfg.triple_filepaths[self.phase])  # Triple means (image, ground_truth_bounding_box, query)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.df_triple.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        imageID = str(self.df_triple.iloc[index][\"imgId\"])\n",
    "        entityID = str(self.df_triple.iloc[index][\"entityId\"])\n",
    "        \n",
    "        # Load data and get label\n",
    "        # X = torch.load('data/' + ID + '.pt')\n",
    "        # X should be all the inputs, include visual features and text query\n",
    "        zf = np.load(features_dir+imageID+'.jpg.npz')\n",
    "        num_bbox = zf['num_bbox']\n",
    "        visual_feat = zf['x']  # visual_feat's shape here is supposed to be (2048, num_bbox) for resnet, (4096, num_bbox) for vgg16\n",
    "        visual_feat = np.transpose(visual_feat) # now (num_bbox, 2048) for resnet, (num_bbox, 4096) for vgg16\n",
    "        spatial_feat = zf['bbox'] # spatial_feat's shape here is supposed to be (num_bbox, 4)\n",
    "        x1 = spatial_feat[:,0]\n",
    "        y1 = spatial_feat[:,1]\n",
    "        x2 = spatial_feat[:,2]\n",
    "        y2 = spatial_feat[:,3]\n",
    "        image_w = zf['image_w']\n",
    "        image_h = zf['image_h']\n",
    "        spatial_feat = np.column_stack((x1/image_w, y1/image_h, x2/image_w, y2/image_h, (x2-x1)*(y2-y1)/(image_w*image_h)))\n",
    "        \n",
    "        # Concatenate visual features and spatial features\n",
    "        X = np.column_stack((visual_feat, spatial_feat))\n",
    "        \n",
    "        # If there are fewer than self.cfg.RPN_TOPN=100 proposals, add 0 rows below\n",
    "        for i in range(X.shape[0], self.cfg.RPN_TOPN):\n",
    "            zero_row = np.zeros((1,X.shape[1]))\n",
    "            X = np.vstack((X, zero_row))\n",
    "        # Convert numpy array to torch tensor \n",
    "        X = torch.from_numpy(X)\n",
    "        X = X.float()\n",
    "        \n",
    "        query = self.df_triple.iloc[index][\"entity_content\"]\n",
    "        \n",
    "        # Get ground truth bounding box\n",
    "        gt_bbox = self._get_bounding_box(imageID, entityID) # gt_bbox is a triple in format (x1, y1, x2, y2)\n",
    "        # Get the bounding box boundary regard as image size\n",
    "        gt_bbox[0] /= float(image_w)\n",
    "        gt_bbox[2] /= float(image_w)\n",
    "        gt_bbox[1] /= float(image_h)\n",
    "        gt_bbox[3] /= float(image_h)\n",
    "        # Convert list to torch tensor\n",
    "        gt_bbox = torch.tensor(gt_bbox) \n",
    "        \n",
    "        additional_info = (imageID, entityID, image_w, image_h) # those info are not directly used in training, but used in visualization\n",
    "\n",
    "        return (X, query), gt_bbox, additional_info  \n",
    "    \n",
    "    def _get_bounding_box(self, image_id, object_id): # image_id and object_id are expected to be string\n",
    "         \n",
    "        xml_tree = ET.parse(self.cfg.xml_dirpath + image_id + '.xml')\n",
    "        root = xml_tree.getroot()\n",
    "        boxes = []  # To deal with one object, multiple bounding boxes\n",
    "        for obj in root.findall('object'):\n",
    "            for name in obj.findall('name'):\n",
    "                if name.text == object_id:\n",
    "                    bndbox = obj.find(\"bndbox\")\n",
    "                    x1 = int(bndbox.find(\"xmin\").text)\n",
    "                    y1 = int(bndbox.find(\"ymin\").text)\n",
    "                    x2 = int(bndbox.find(\"xmax\").text)\n",
    "                    y2 = int(bndbox.find(\"ymax\").text)\n",
    "                    \n",
    "                    boxes.append([x1, y1, x2, y2])\n",
    "        if len(boxes)==0:\n",
    "            raise Exception(\"Entity not found. Image id: \"+image_id+\", Entity id: \"+object_id)\n",
    "        boxes_array = np.array(boxes)\n",
    "        # When there are multiple bounding boxes, draw the minimum box which contains all these invidual boxes\n",
    "        x1 = np.min(boxes_array[:,0])\n",
    "        y1 = np.min(boxes_array[:,1])\n",
    "        x2 = np.max(boxes_array[:,2])\n",
    "        y2 = np.max(boxes_array[:,3])\n",
    "                    \n",
    "        return [x1, y1, x2, y2]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-801709dedfb8>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-801709dedfb8>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    print(_get_bounding_box(str(1000092795), str(1))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# For testing \n",
    "def _get_bounding_box(image_id, object_id): # image_id and object_id are expected to be string\n",
    "    xml_dirpath = \"/home/wenjian/Internship/data/flickr30kentities/annotations/Annotations/\"\n",
    "\n",
    "    xml_tree = ET.parse(xml_dirpath + image_id + '.xml')\n",
    "    root = xml_tree.getroot()\n",
    "    boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        #for name in obj:\n",
    "        for name in obj.findall('name'):\n",
    "            print(name)\n",
    "            if name.text == object_id:\n",
    "                bndbox = obj.find(\"bndbox\")\n",
    "                x1 = int(bndbox.find(\"xmin\").text)\n",
    "                y1 = int(bndbox.find(\"ymin\").text)\n",
    "                x2 = int(bndbox.find(\"xmax\").text)\n",
    "                y2 = int(bndbox.find(\"ymax\").text)\n",
    "\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "    if len(boxes)==0:\n",
    "        raise Exception(\"Entity not found. Image id: \"+image_id+\", Entity id: \"+object_id)\n",
    "    boxes_array = np.array(boxes)\n",
    "\n",
    "    x1 = np.min(boxes_array[:,0])\n",
    "    y1 = np.min(boxes_array[:,1])\n",
    "    x2 = np.max(boxes_array[:,2])\n",
    "    y2 = np.max(boxes_array[:,3])\n",
    "\n",
    "    return [x1, y1, x2, y2] \n",
    "\n",
    "print(_get_bounding_box(str(36979), str(137644)))  # Expected result: [2, 40, 500, 373]\n",
    "print(_get_bounding_box(str(1000092795), str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = DDPNDataset(cfg, 'train')\n",
    "validation_set = DDPNDataset(cfg, 'val')\n",
    "test_set = DDPNDataset(cfg, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413627"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[2.9460, 0.0000, 0.0000,  ..., 0.9983, 0.9990, 0.1519],\n",
       "          [0.0000, 0.0000, 0.3983,  ..., 0.4634, 0.7727, 0.1531],\n",
       "          [2.3487, 0.0337, 0.0208,  ..., 0.7677, 0.4751, 0.0328],\n",
       "          ...,\n",
       "          [0.7473, 0.0938, 0.4703,  ..., 0.8276, 0.7052, 0.0970],\n",
       "          [0.0000, 0.0000, 0.1383,  ..., 0.5049, 0.5820, 0.2939],\n",
       "          [0.0274, 1.5578, 0.0000,  ..., 0.6135, 0.9990, 0.2173]]),\n",
       "  'Two young guys'),\n",
       " tensor([0.4775, 0.2200, 0.7838, 0.7460]),\n",
       " ('1000092795', '1', array(333), array(500)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 413627 triples in the training set\n",
    "\n",
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.9460, 0.0000, 0.0000,  ..., 0.9983, 0.9990, 0.1519],\n",
       "         [0.0000, 0.0000, 0.3983,  ..., 0.4634, 0.7727, 0.1531],\n",
       "         [2.3487, 0.0337, 0.0208,  ..., 0.7677, 0.4751, 0.0328],\n",
       "         ...,\n",
       "         [0.7473, 0.0938, 0.4703,  ..., 0.8276, 0.7052, 0.0970],\n",
       "         [0.0000, 0.0000, 0.1383,  ..., 0.5049, 0.5820, 0.2939],\n",
       "         [0.0274, 1.5578, 0.0000,  ..., 0.6135, 0.9990, 0.2173]]),\n",
       " 'Two young guys')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = training_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9460, 0.0000, 0.0000,  ..., 0.9983, 0.9990, 0.1519],\n",
       "        [0.0000, 0.0000, 0.3983,  ..., 0.4634, 0.7727, 0.1531],\n",
       "        [2.3487, 0.0337, 0.0208,  ..., 0.7677, 0.4751, 0.0328],\n",
       "        ...,\n",
       "        [0.7473, 0.0938, 0.4703,  ..., 0.8276, 0.7052, 0.0970],\n",
       "        [0.0000, 0.0000, 0.1383,  ..., 0.5049, 0.5820, 0.2939],\n",
       "        [0.0274, 1.5578, 0.0000,  ..., 0.6135, 0.9990, 0.2173]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2053])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1519)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A[0][-3] - A[0][-5])*(A[0][-2] - A[0][-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two young guys'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2053])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14526"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[1.1333e-01, 2.3880e+00, 8.1123e-01,  ..., 9.9900e-01, 5.7636e-01,\n",
       "           5.1638e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.3661e-01, 9.9833e-01,\n",
       "           9.5590e-03],\n",
       "          [9.6640e-04, 3.0147e-01, 1.2200e+00,  ..., 8.3006e-01, 8.5222e-01,\n",
       "           1.6638e-01],\n",
       "          ...,\n",
       "          [2.0308e-01, 1.5471e-03, 0.0000e+00,  ..., 7.2942e-01, 4.9238e-01,\n",
       "           2.1457e-02],\n",
       "          [0.0000e+00, 1.6355e-01, 8.3413e-02,  ..., 9.9900e-01, 9.9833e-01,\n",
       "           1.1927e-01],\n",
       "          [0.0000e+00, 4.9662e-02, 2.4938e-02,  ..., 2.7541e-01, 1.6554e-01,\n",
       "           1.7283e-03]]), 'A group of people'),\n",
       " tensor([0.1720, 0.1081, 0.4280, 0.3213]),\n",
       " ('1018148011', '568', array(500), array(333)))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 14527 triples in the validation set\n",
    "\n",
    "validation_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2053])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-2dca2111cf56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_generator' is not defined"
     ]
    }
   ],
   "source": [
    "len(training_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6462.921875"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "413627/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14476"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0.0000, 0.0000, 0.2207,  ..., 0.8460, 0.4874, 0.2967],\n",
       "          [0.0000, 0.0532, 0.0260,  ..., 0.4820, 0.5275, 0.0117],\n",
       "          [0.0020, 0.0000, 0.0000,  ..., 0.7766, 0.9983, 0.4192],\n",
       "          ...,\n",
       "          [0.0022, 0.0000, 0.0347,  ..., 0.7141, 0.9983, 0.1812],\n",
       "          [0.0439, 0.0399, 0.0406,  ..., 0.8497, 0.7945, 0.6751],\n",
       "          [0.0152, 0.7325, 0.0020,  ..., 0.3951, 0.9826, 0.1539]]), 'The man'),\n",
       " tensor([0.1100, 0.0911, 0.7980, 1.0000]),\n",
       " ('1007129816', '203', array(500), array(461)))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Under the test for: French test set translated into English by word2word manner, then run with English model\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0.4419, 0.0000, 0.1148,  ..., 0.5628, 0.2294, 0.0109],\n",
       "          [0.3927, 0.0000, 0.5165,  ..., 0.3359, 0.3034, 0.0075],\n",
       "          [0.0070, 0.0000, 0.0393,  ..., 0.1289, 0.2388, 0.0059],\n",
       "          ...,\n",
       "          [0.0231, 0.0000, 0.3389,  ..., 0.9987, 0.8358, 0.2231],\n",
       "          [0.2098, 0.0000, 0.0756,  ..., 0.9114, 0.9983, 0.3332],\n",
       "          [0.0000, 0.0854, 0.0000,  ..., 0.9987, 0.9983, 0.3263]]),\n",
       "  \"the jackets d' hiver\"),\n",
       " tensor([0.0140, 0.2027, 1.0000, 0.6987]),\n",
       " ('102617084', '749', array(500), array(375)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate IoU score between two boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(box_a, box_b):  # Tackle with N (like 100) box pairs at the same time\n",
    "    #print(box_a.type())\n",
    "    #print(box_b.type())\n",
    "    inter_xmin=torch.max(box_a[:,:,0], box_b[:,:,0])\n",
    "    inter_xmax=torch.min(box_a[:,:,2], box_b[:,:,2])\n",
    "    inter_ymin=torch.max(box_a[:,:,1], box_b[:,:,1])\n",
    "    inter_ymax=torch.min(box_a[:,:,3], box_b[:,:,3])\n",
    "    inter = torch.max((inter_xmax-inter_xmin).float(), torch.tensor(0).float().to(box_a.device)) * torch.max((inter_ymax-inter_ymin).float(), torch.tensor(0).float().to(box_a.device))\n",
    "    return inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 6., 0.]])\n"
     ]
    }
   ],
   "source": [
    "b1 = torch.tensor([[1,5,4,8],[1,1,3,3],[3,6,6,9],[2,3,5,5],[1,2,3,4]]).to(device)\n",
    "b2 = torch.tensor([[3,2,7,6],[5,5,8,8],[1,3,4,7],[1,2,6,6],[4,1,6,3]]).to(device)\n",
    "b1 = b1.unsqueeze(0)\n",
    "b2 = b2.unsqueeze(0)\n",
    "print(intersect(b1,b2)) # intersection expected: 1, 0, 1, 6, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/amdegroot/ssd.pytorch/blob/master/layers/box_utils.py#L48\n",
    "def IoU(box_a, box_b):  # Tackle with N (like 100) box pairs at the same time\n",
    "    # The shape of each input: (batch_size, box_number_in_each_image, 4)\n",
    "    box_a = box_a.float() \n",
    "    box_b = box_b.float()\n",
    "    #print(\"box_a shape\", box_a.size())\n",
    "    #print(\"box_b shape\", box_b.size())\n",
    "    inter = intersect(box_a, box_b)\n",
    "    area_a = (box_a[:,:,2] - box_a[:,:,0]) * (box_a[:,:,3] - box_a[:,:,1])\n",
    "    area_b = (box_b[:,:,2] - box_b[:,:,0]) * (box_b[:,:,3] - box_b[:,:,1])\n",
    "    union = area_a + area_b - inter\n",
    "    return inter.float() / union.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0417, 0.0000, 0.0500, 0.3000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(IoU(b1,b2))  # Expected answer: tensor([[0.0417, 0.0000, 0.0500, 0.3000, 0.0000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate softlable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.1969e-04, 4.4159e-02, 7.1317e-01, 9.4961e-01],\n",
       "        [0.0000e+00, 6.2040e-02, 4.7278e-01, 9.3002e-01],\n",
       "        [0.0000e+00, 5.4799e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [0.0000e+00, 1.2673e-01, 3.8553e-01, 5.9441e-01],\n",
       "        [2.3631e-01, 4.3101e-02, 7.0622e-01, 7.7726e-01],\n",
       "        [1.2156e-01, 2.3790e-01, 7.8092e-01, 8.9407e-01],\n",
       "        [2.0145e-01, 6.4568e-02, 6.4798e-01, 4.8737e-01],\n",
       "        [2.2413e-01, 7.5099e-02, 9.8721e-01, 5.4597e-01],\n",
       "        [9.2835e-02, 5.8494e-01, 6.3375e-01, 9.1759e-01],\n",
       "        [0.0000e+00, 1.5378e-01, 5.7126e-01, 5.7386e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 3.2736e-01, 2.6507e-01],\n",
       "        [7.6301e-01, 5.2890e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [0.0000e+00, 2.8935e-01, 6.5871e-01, 7.9631e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 9.8721e-01, 5.5247e-01],\n",
       "        [0.0000e+00, 3.1430e-02, 5.3487e-01, 4.0054e-01],\n",
       "        [1.0286e-01, 7.0030e-01, 6.0901e-01, 9.4653e-01],\n",
       "        [0.0000e+00, 3.1606e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [2.8571e-01, 3.0191e-01, 9.2748e-01, 8.2741e-01],\n",
       "        [1.8692e-01, 2.1457e-02, 6.2255e-01, 3.2091e-01],\n",
       "        [1.8927e-01, 5.9635e-01, 7.1666e-01, 9.3147e-01],\n",
       "        [0.0000e+00, 4.3508e-01, 4.1748e-01, 8.9088e-01],\n",
       "        [2.4769e-01, 2.8113e-02, 7.0878e-01, 4.1865e-01],\n",
       "        [2.3829e-01, 5.3514e-01, 7.1191e-01, 9.9219e-01],\n",
       "        [5.7845e-01, 8.1643e-02, 9.6448e-01, 4.9791e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 9.8721e-01, 9.9219e-01],\n",
       "        [5.5306e-01, 5.0825e-01, 9.8689e-01, 8.6039e-01],\n",
       "        [2.4730e-01, 2.0546e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [6.4011e-02, 7.7240e-01, 8.7594e-01, 9.8459e-01],\n",
       "        [0.0000e+00, 4.2569e-01, 7.7512e-01, 8.9017e-01],\n",
       "        [0.0000e+00, 2.4889e-01, 4.3156e-01, 8.2636e-01],\n",
       "        [7.5640e-01, 6.7741e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [1.8134e-01, 0.0000e+00, 9.1528e-01, 9.2247e-01],\n",
       "        [4.5635e-01, 4.2226e-01, 9.1520e-01, 8.2980e-01],\n",
       "        [2.3263e-01, 7.0514e-01, 7.2496e-01, 9.4018e-01],\n",
       "        [0.0000e+00, 6.3679e-01, 3.7500e-01, 9.5324e-01],\n",
       "        [0.0000e+00, 5.0653e-01, 6.3688e-01, 9.0755e-01],\n",
       "        [3.8588e-01, 7.2146e-01, 8.2199e-01, 9.4836e-01],\n",
       "        [3.5674e-01, 2.3547e-02, 9.0210e-01, 4.3336e-01],\n",
       "        [5.2044e-01, 0.0000e+00, 9.8721e-01, 2.8523e-01],\n",
       "        [0.0000e+00, 1.4431e-01, 5.4513e-01, 7.6854e-01],\n",
       "        [1.3114e-01, 0.0000e+00, 6.8220e-01, 8.5043e-01],\n",
       "        [6.7596e-01, 2.9110e-01, 9.8721e-01, 6.1554e-01],\n",
       "        [4.9492e-01, 2.2061e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [3.5400e-01, 0.0000e+00, 9.8721e-01, 6.7541e-01],\n",
       "        [1.2276e-01, 5.4238e-01, 6.1982e-01, 9.9219e-01],\n",
       "        [3.5196e-01, 5.7573e-01, 8.1557e-01, 9.9219e-01],\n",
       "        [6.3958e-02, 3.2747e-01, 7.0388e-01, 9.2481e-01],\n",
       "        [1.4900e-01, 3.4526e-01, 9.8040e-01, 8.0226e-01],\n",
       "        [2.0029e-01, 2.2022e-01, 9.8721e-01, 6.7394e-01],\n",
       "        [1.4822e-01, 4.6208e-01, 8.1937e-01, 9.4934e-01],\n",
       "        [0.0000e+00, 3.6772e-01, 5.6276e-01, 8.9484e-01],\n",
       "        [3.3409e-01, 1.6261e-01, 9.3600e-01, 7.1989e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 5.9332e-01, 2.0722e-01],\n",
       "        [5.7535e-01, 1.3839e-01, 9.3351e-01, 5.6518e-01],\n",
       "        [5.3224e-01, 0.0000e+00, 9.7960e-01, 4.4478e-01],\n",
       "        [0.0000e+00, 7.2192e-01, 3.4358e-01, 9.9219e-01],\n",
       "        [4.4696e-03, 6.1001e-01, 5.1093e-01, 9.4482e-01],\n",
       "        [4.4643e-01, 2.1135e-01, 9.7103e-01, 6.2006e-01],\n",
       "        [4.9696e-01, 5.9199e-01, 9.0680e-01, 9.9219e-01],\n",
       "        [3.5569e-01, 7.7980e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [1.2720e-01, 1.4510e-01, 6.9124e-01, 9.9219e-01],\n",
       "        [1.2856e-01, 6.6631e-01, 9.5309e-01, 9.7798e-01],\n",
       "        [4.4829e-01, 1.0288e-01, 9.8721e-01, 5.4615e-01],\n",
       "        [3.5697e-02, 0.0000e+00, 7.3871e-01, 2.4398e-01],\n",
       "        [2.9026e-01, 4.3782e-01, 8.7896e-01, 9.1976e-01],\n",
       "        [1.2975e-01, 1.0383e-01, 6.6438e-01, 6.8246e-01],\n",
       "        [4.0085e-01, 5.8874e-02, 9.0423e-01, 5.6509e-01],\n",
       "        [6.4148e-02, 1.2967e-01, 7.2236e-01, 5.8078e-01],\n",
       "        [3.2651e-01, 4.3326e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [7.0356e-01, 3.7553e-01, 9.8721e-01, 6.8219e-01],\n",
       "        [2.0979e-01, 8.0762e-02, 7.2516e-01, 5.9902e-01],\n",
       "        [3.6509e-01, 4.9976e-01, 9.8721e-01, 9.0808e-01],\n",
       "        [6.9799e-01, 6.2035e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [2.1758e-01, 0.0000e+00, 9.8721e-01, 2.6993e-01],\n",
       "        [5.7332e-01, 6.6664e-01, 9.5603e-01, 9.6725e-01],\n",
       "        [4.2628e-01, 2.6929e-01, 9.7533e-01, 7.2622e-01],\n",
       "        [6.5415e-01, 1.5063e-01, 9.8721e-01, 5.4922e-01],\n",
       "        [3.3032e-01, 3.9002e-01, 9.8721e-01, 7.3455e-01],\n",
       "        [0.0000e+00, 7.1810e-02, 9.8721e-01, 7.4424e-01],\n",
       "        [0.0000e+00, 2.0707e-02, 4.5095e-01, 3.0905e-01],\n",
       "        [6.6964e-01, 0.0000e+00, 9.8721e-01, 2.7266e-01],\n",
       "        [3.4030e-01, 6.5340e-01, 8.3316e-01, 9.4057e-01],\n",
       "        [0.0000e+00, 6.0929e-02, 4.4758e-01, 5.1297e-01],\n",
       "        [0.0000e+00, 6.5308e-01, 7.2621e-01, 9.4296e-01],\n",
       "        [1.0009e-01, 1.1553e-01, 8.5618e-01, 5.3433e-01],\n",
       "        [3.7055e-01, 5.4748e-02, 7.8511e-01, 6.6733e-01],\n",
       "        [3.8355e-01, 6.5255e-01, 9.8721e-01, 9.7966e-01],\n",
       "        [6.9475e-01, 4.9185e-01, 9.8721e-01, 8.6091e-01],\n",
       "        [6.1298e-01, 2.9687e-01, 9.8721e-01, 7.2223e-01],\n",
       "        [5.6698e-01, 3.7723e-01, 9.8721e-01, 6.6512e-01],\n",
       "        [3.9297e-01, 0.0000e+00, 9.0628e-01, 3.1733e-01],\n",
       "        [0.0000e+00, 6.9906e-01, 4.9604e-01, 9.8193e-01],\n",
       "        [5.4105e-01, 2.8813e-01, 9.8721e-01, 5.8926e-01],\n",
       "        [3.7176e-02, 6.0062e-02, 4.2541e-01, 3.9426e-01],\n",
       "        [6.6256e-01, 3.9180e-02, 9.8721e-01, 4.3597e-01],\n",
       "        [6.9949e-01, 7.4227e-01, 9.8721e-01, 9.9219e-01],\n",
       "        [6.7554e-01, 3.9544e-01, 9.8721e-01, 7.9000e-01],\n",
       "        [4.0546e-01, 5.2122e-01, 8.8524e-01, 9.7012e-01],\n",
       "        [4.3293e-02, 1.4038e-01, 5.6647e-01, 9.9219e-01],\n",
       "        [5.4658e-01, 0.0000e+00, 9.8721e-01, 7.4209e-01]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[374573][0][0][:,-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-f89a061b16e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m374573\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mIoU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRPN_TOPN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-80-034d686bec1a>\u001b[0m in \u001b[0;36mIoU\u001b[0;34m(box_a, box_b)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(\"box_a shape\", box_a.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#print(\"box_b shape\", box_b.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0marea_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0marea_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-1ad12fe02001>\u001b[0m in \u001b[0;36mintersect\u001b[0;34m(box_a, box_b)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minter_ymin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minter_ymax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_xmax\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minter_xmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_ymax\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minter_ymin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "i = 374573\n",
    "IoU(training_set[i][0][0][:,-5:-1].unsqueeze(0), training_set[i][1].repeat((1,cfg.RPN_TOPN,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softlabel_wrapper(threshold, epsilon):\n",
    "    def get_softlable(X, gt_bbox): # gt_bbox is expected as a triple in format (x1, y1, x2, y2). All the four boundaries are between 0 and 1. Batch is not considered here\n",
    "        # X is expected in shape (batch_size, N, 2053). We use the 4 columns with indexes 2047-2051. It should be noted that the last column in X is the area so we should not use it. \n",
    "        # gt_bbox is expected in format tensor with shape (batch_size, 4)\n",
    "        #print(\"gt_bbox\", gt_bbox.size())\n",
    "        gt_bbox = gt_bbox.unsqueeze(1)\n",
    "        #print(\"gt_bbox after repeat\", gt_bbox.repeat((1,cfg.RPN_TOPN,1)).size())\n",
    "        iou = IoU(X[:,:,-5:-1], gt_bbox.repeat((1,cfg.RPN_TOPN,1)))   #.double()\n",
    "        iou_with_threshold = iou*(iou>threshold).float()\n",
    "        #print(\"iou_with_threshold\", iou_with_threshold.size())  # size is (64, 100)\n",
    "        #return F.softmax(iou_with_threshold, dim=1)\n",
    "        denominator = iou_with_threshold.sum(dim=1).unsqueeze(1) + epsilon\n",
    "        #print(\"iou_with_threshold denominator\", denominator.size())  # size is (64, 1)\n",
    "        iou_with_threshold_l1_norm = iou_with_threshold / denominator\n",
    "        #assert not torch.isinf(iou_with_threshold_l1_norm).any()\n",
    "        #assert not torch.isnan(iou_with_threshold_l1_norm).any()\n",
    "        return iou_with_threshold_l1_norm\n",
    "    return get_softlable\n",
    "get_softlable = get_softlabel_wrapper(cfg.SOFTLABEL_THRESHOLD, torch.tensor(cfg.epsilon).to(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_pass_threshold(X, gt_bbox, threshold): # For statistical use only\n",
    "    iou = IoU(X[:,:,-5:-1], gt_bbox.repeat((1,cfg.RPN_TOPN,1)))   \n",
    "    return iou>threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 , counter= 1\n",
      "i= 100 , counter= 95\n",
      "i= 200 , counter= 186\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-080bf2440821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mthre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou_pass_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-34f2c18de2fa>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Convert numpy array to torch tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_triple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"entity_content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# count how many images in training set has at least one proposal with IoU > 0.5 against the ground truth bounding box\n",
    "if True:   # Modify here to do the statistics below\n",
    "    device = torch.device('cpu')\n",
    "    counter = 0\n",
    "    thre = 0.5\n",
    "    for i in range(len(training_set)):\n",
    "        iou = iou_pass_threshold(training_set[i][0][0].unsqueeze(0),training_set[i][1], thre)\n",
    "        if iou.sum() > 0:\n",
    "            counter += 1\n",
    "        if i%100 == 0:\n",
    "            print(\"i=\", i, \", counter=\", counter)\n",
    "    print(\"Finally,\", counter, \"examples pass the threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9374734042553191"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Otani's features\n",
    "387739/413600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6110275889644142"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My features\n",
    "152818.0/250100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-f0e2b4350ccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m374573\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_softlable_0_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_softlabel_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_softlable_0_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-0baf1f6b1cbf>\u001b[0m in \u001b[0;36mget_softlable\u001b[0;34m(X, gt_bbox)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mgt_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_bbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print(\"gt_bbox after repeat\", gt_bbox.repeat((1,cfg.RPN_TOPN,1)).size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIoU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_bbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRPN_TOPN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#.double()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# print(iou)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0miou_with_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-662fb35eddc4>\u001b[0m in \u001b[0;36mIoU\u001b[0;34m(box_a, box_b)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(\"box_a shape\", box_a.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(\"box_b shape\", box_b.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0marea_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0marea_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-1ad12fe02001>\u001b[0m in \u001b[0;36mintersect\u001b[0;34m(box_a, box_b)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minter_ymin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minter_ymax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_xmax\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minter_xmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_ymax\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minter_ymin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "i = 374573\n",
    "get_softlable_0_5 = get_softlabel_wrapper(0.5)\n",
    "get_softlable_0_5(training_set[i][0][0].unsqueeze(0),training_set[i][1].unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_wrapper(cfg):\n",
    "    def my_loss(predict, target):  # predict is expected to be (s,t), target their ground truth value\n",
    "        s, t = predict\n",
    "        gt_s, gt_t = target\n",
    "        #print(\"s\", s.size())   # --> s torch.Size([64, 100])\n",
    "        #print(\"gt_s\", gt_s.size())   # --> gt_s torch.Size([64, 100])\n",
    "        #print(\"t\", t.size())   # --> t torch.Size([64, 100, 4])\n",
    "        #print(\"gt_t\", gt_t.size())   # --> gt_t torch.Size([64, 4])\n",
    "        s = torch.add(s, torch.tensor(cfg.epsilon))  # In order to avoid 0 in the denominator\n",
    "        try:\n",
    "#             assert not torch.isnan(s).any()\n",
    "#             assert not torch.isinf(s).any()\n",
    "#             assert not torch.isnan(t).any()\n",
    "#             assert not torch.isinf(t).any()\n",
    "#             assert not torch.isnan(gt_s).any()\n",
    "#             assert not torch.isinf(gt_s).any()\n",
    "#             assert not torch.isnan(gt_t).any()\n",
    "#             assert not torch.isinf(gt_t).any()\n",
    "            loss_ranking = F.kl_div(torch.log(s), gt_s, reduction='batchmean') \n",
    "            assert not torch.isnan(loss_ranking).any()\n",
    "            assert not torch.isinf(loss_ranking).any()\n",
    "            logger.add_scalar(\"ranking_loss\", loss_ranking, my_loss.counter)\n",
    "            if cfg.regression_loss:\n",
    "                N = t.size()[1]\n",
    "                #print('gt_t after repeat', gt_t.unsqueeze(1).repeat(1,N,1).size())\n",
    "\n",
    "    #             proposal_chosen = torch.argmax(s, dim=1)\n",
    "    #             batch_size = s.size()[0]\n",
    "    #             t_chosen = t[torch.arange(batch_size),proposal_chosen,:]  # t_chosen shape is expected to be (batch_size, 4)\n",
    "    #             #print(\"t_chosen\", t_chosen.size())\n",
    "    #             loss_regression = F.smooth_l1_loss(t_chosen, gt_t, reduction='mean')\n",
    "\n",
    "                loss_regression = F.smooth_l1_loss(t, gt_t.unsqueeze(1).repeat(1,N,1), reduction='mean')\n",
    "\n",
    "                #print(\"loss_regression\", loss_regression)\n",
    "#                 assert not torch.isnan(loss_regression).any()\n",
    "#                 assert not torch.isinf(loss_regression).any()\n",
    "                logger.add_scalar(\"regression_loss\", cfg.GAMMA*loss_regression, my_loss.counter)\n",
    "            my_loss.counter += 1 \n",
    "            \n",
    "        except AssertionError as e:\n",
    "            torch.set_printoptions(profile='full')\n",
    "            print('s\\n', s)\n",
    "            print('t\\n', t)\n",
    "            print('gt_s\\n', gt_s)\n",
    "            print('gt_t\\n', gt_t)\n",
    "            with open(\"debug.log\", 'w') as log:\n",
    "                log.write('s\\n')\n",
    "                log.write(str(s))\n",
    "                log.write('gt_s\\n')\n",
    "                log.write(str(gt_s))\n",
    "            torch.set_printoptions(profile='default')\n",
    "            raise e\n",
    "        \n",
    "        if cfg.regression_loss:\n",
    "            #return delta*loss_ranking + loss_regression\n",
    "            return loss_ranking + cfg.GAMMA*loss_regression\n",
    "        else:\n",
    "            return loss_ranking \n",
    "    my_loss.counter = 0\n",
    "    return my_loss\n",
    "loss_func = loss_wrapper(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two young guys\n",
      "['two', 'young', 'guy']\n",
      "[3, 4, 65]\n",
      "[tensor([ 3,  4, 65]), tensor([-1,  5]), tensor([  8, 442]), tensor([  3,   4,   9,  11, 558]), tensor([5030,  979])]\n",
      "tensor([[   3,    4,   65,    0,    0],\n",
      "        [  -1,    5,    0,    0,    0],\n",
      "        [   8,  442,    0,    0,    0],\n",
      "        [   3,    4,    9,   11,  558],\n",
      "        [5030,  979,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "# For testing\n",
    "print(training_set[0][0][1])\n",
    "print([stemmer.stem(w) for w in word_tokenize(training_set[0][0][1])])\n",
    "print(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(training_set[0][0][1])]))\n",
    "qs = [training_set[i][0][1] for i in range(5)]\n",
    "print([torch.tensor(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)])) for q in qs])\n",
    "print(nn.utils.rnn.pad_sequence([torch.tensor(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)])) for q in qs], batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence_right_alignment(sequences, batch_first=False, padding_value=0):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        sequences (list[Tensor]): list of variable length sequences.\n",
    "        batch_first (bool, optional): output will be in ``B x T x *`` if True, or in\n",
    "            ``T x B x *`` otherwise\n",
    "        padding_value (float, optional): value for padded elements. Default: 0.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # assuming trailing dimensions and type of all the Tensors\n",
    "    # in sequences are same and fetching those from sequences[0]\n",
    "    max_size = sequences[0].size()\n",
    "    trailing_dims = max_size[1:]\n",
    "    max_len = max([s.size(0) for s in sequences])\n",
    "    if batch_first:\n",
    "        out_dims = (len(sequences), max_len) + trailing_dims\n",
    "    else:\n",
    "        out_dims = (max_len, len(sequences)) + trailing_dims\n",
    "\n",
    "    out_tensor = sequences[0].data.new(*out_dims).fill_(padding_value)\n",
    "    for i, tensor in enumerate(sequences):\n",
    "        length = tensor.size(0)\n",
    "        # use index notation to prevent duplicate references to the tensor\n",
    "        if batch_first:\n",
    "            out_tensor[i, -length:, ...] = tensor  # Modification 1/2\n",
    "        else:\n",
    "            out_tensor[-length:, i, ...] = tensor  # Modification 2/2\n",
    "\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two young guys\n",
      "['two', 'young', 'guy']\n",
      "[3, 4, 65]\n",
      "[tensor([ 3,  4, 65]), tensor([-1,  5]), tensor([  8, 442]), tensor([  3,   4,   9,  11, 558]), tensor([5030,  979])]\n"
     ]
    }
   ],
   "source": [
    "# For testing\n",
    "print(training_set[0][0][1])\n",
    "print([stemmer.stem(w) for w in word_tokenize(training_set[0][0][1])])\n",
    "print(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(training_set[0][0][1])]))\n",
    "qs = [training_set[i][0][1] for i in range(5)]\n",
    "print([torch.tensor(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)])) for q in qs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    3,    4,   65],\n",
      "        [   0,    0,    0,   -1,    5],\n",
      "        [   0,    0,    0,    8,  442],\n",
      "        [   3,    4,    9,   11,  558],\n",
      "        [   0,    0,    0, 5030,  979]])\n"
     ]
    }
   ],
   "source": [
    "print(pad_sequence_right_alignment([torch.tensor(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)])) for q in qs], batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,    3,    0],\n",
      "        [   0,    0,    0,    4,    0],\n",
      "        [   3,    0,    0,    9,    0],\n",
      "        [   4,   -1,    8,   11, 5030],\n",
      "        [  65,    5,  442,  558,  979]])\n"
     ]
    }
   ],
   "source": [
    "print(pad_sequence_right_alignment([torch.tensor(training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)])) for q in qs], batch_first=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is -1 above because we don't do stemming anymore when building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_sentence_to_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-b214437dbf06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqs_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentence_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-b214437dbf06>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqs_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentence_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_sentence_to_indices' is not defined"
     ]
    }
   ],
   "source": [
    "qs = [training_set[i][0][1] for i in range(5)]\n",
    "qs_tensor = [torch.tensor(tokenized_sentence_to_indices([w.lower() for w in word_tokenize(q)])) for q in qs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qs_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-d112860a5d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqs_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'qs_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pad_packed_sequence(qs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.0071e-01, -4.6867e-01, -2.0617e-01, -8.0978e-01, -2.3889e-01,\n",
       "         2.4329e-01,  1.6538e-02, -3.5687e-02, -2.2306e-01,  9.5189e-01,\n",
       "        -3.2273e-01,  2.1980e-01, -6.7524e-02, -3.7220e-01, -3.9718e-01,\n",
       "        -4.3861e-01,  1.1967e-01, -2.9964e-01,  2.8437e-02, -8.7544e-02,\n",
       "         1.6569e-01, -4.9451e-01, -6.2011e-01, -1.6574e-01, -9.7218e-02,\n",
       "        -9.9474e-02, -8.0307e-02, -3.9338e-01, -2.4195e-01,  3.2023e-01,\n",
       "        -5.3320e-01, -4.0184e-01, -6.7135e-01, -7.8561e-02,  5.5546e-01,\n",
       "         2.9997e-01, -9.9650e-02, -6.7035e-01,  1.2669e-01, -1.8618e-01,\n",
       "        -6.2621e-02,  4.5290e-01,  3.9265e-01,  2.4121e-01, -4.1474e-01,\n",
       "        -6.1890e-01, -1.0412e-01, -3.1043e-01, -6.6788e-03, -8.3248e-01,\n",
       "         6.5150e-01,  9.0181e-01,  2.4146e-02, -7.0766e-02, -3.9580e-01,\n",
       "        -3.6487e-01, -2.3929e-01, -1.5145e-01,  2.0777e-01,  5.4671e-01,\n",
       "        -2.5042e-01, -6.0142e-01, -5.4820e-01,  7.7249e-03, -5.3288e-01,\n",
       "         5.0325e-01, -1.2712e-01,  1.1989e-01, -6.4584e-01,  3.5576e-01,\n",
       "         1.7496e-01,  1.1838e-01, -3.2181e-01,  7.4814e-02, -9.0381e-02,\n",
       "        -2.9843e-01,  1.6798e-02, -1.2735e-01,  7.3567e-01, -1.7335e-01,\n",
       "         3.7123e-01,  3.7979e-01, -5.1801e-01,  2.7621e-01,  2.1512e-01,\n",
       "        -8.2588e-02,  2.1638e-01,  1.2595e-01,  3.8436e-01, -1.3332e-01,\n",
       "         5.7185e-02, -2.8127e-01, -4.4310e-01,  1.3498e-01,  1.3306e-01,\n",
       "        -3.2050e-02,  1.9719e-01,  2.5455e-01,  6.3475e-01, -2.3474e-01,\n",
       "        -3.6038e-01,  4.1148e-02, -2.4422e-01,  8.3731e-01, -2.2504e-01,\n",
       "        -2.9683e-01,  6.3898e-01, -3.9774e-01, -1.0322e-01, -1.7446e-01,\n",
       "        -7.8059e-02,  2.6479e-01, -4.2250e-01, -1.0671e-01, -9.6468e-02,\n",
       "        -1.7027e-01,  2.7497e-01, -1.2813e-01,  2.4751e-01,  2.5999e-01,\n",
       "         1.8327e-01,  1.0988e-01,  3.5486e-04, -4.9029e-01,  1.9582e-01,\n",
       "        -4.5226e-01, -1.3617e-02,  1.0765e-01, -1.6161e-02, -2.7242e-01,\n",
       "         7.7877e-02, -1.1860e-01,  9.2792e-02, -4.3774e-01, -2.6539e-01,\n",
       "        -2.6590e-01,  8.0585e-02,  1.8626e-01,  1.7362e-01, -2.0242e-01,\n",
       "         3.5327e-01, -6.4335e-02,  1.3764e-01, -4.4417e-01,  8.7521e-01,\n",
       "        -2.3260e-01, -6.7657e-01,  2.3891e-01, -8.0176e-02,  4.9526e-01,\n",
       "        -2.8579e-01,  2.5041e-01,  1.5853e-01, -1.2960e-01, -5.1529e-01,\n",
       "        -3.3175e-01,  4.1826e-01,  3.3211e-01, -1.1793e+00,  2.2818e-01,\n",
       "        -5.7755e-01,  7.7314e-01,  1.6093e-01,  2.3360e-01, -1.8764e-01,\n",
       "        -2.4516e-01, -5.4803e-01,  2.3110e-01, -3.2975e-01, -1.2646e-01,\n",
       "         3.7984e-01,  3.6006e-01,  6.0382e-01, -1.5882e-01, -4.3682e-01,\n",
       "        -6.3444e-01, -2.8830e-01, -1.3609e-01, -2.5821e-02, -4.0767e-01,\n",
       "         1.8636e-01, -4.5857e-01, -2.4611e-01, -4.5890e-02,  8.7613e-02,\n",
       "        -1.5685e-01,  3.0129e-01, -8.0176e-01,  1.2363e-01,  7.1458e-03,\n",
       "         1.4751e-01,  3.5471e-01,  1.5120e-01,  8.1938e-02, -3.6711e-01,\n",
       "        -2.7208e-01, -3.5597e-01,  1.7207e-01, -4.1850e-02,  4.9547e-01,\n",
       "        -3.1630e-01,  3.4915e-01, -3.7295e-02,  2.0996e-01, -3.0103e-01,\n",
       "        -1.0875e-01,  3.0354e-01,  2.8157e-01, -7.9880e-02, -5.0611e-01,\n",
       "        -2.9416e-01, -3.0861e-01, -8.2462e-01, -1.0019e-01,  9.0473e-02,\n",
       "        -1.8238e-01, -5.9223e-03,  6.3833e-02,  1.5210e-01, -2.5385e-01,\n",
       "        -6.8831e-01, -3.4549e-02,  4.5180e-01,  6.2293e-02, -4.6343e-01,\n",
       "         4.0400e-01,  4.5106e-02,  1.7375e-01, -2.7745e-02,  3.6361e-01,\n",
       "         7.8235e-02,  1.9538e-01, -1.6506e-01,  3.9627e-02, -3.0113e-01,\n",
       "         2.2257e-01,  2.6773e-02,  1.9151e-01,  4.9987e-01, -3.5491e-01,\n",
       "        -1.9928e-02,  9.0701e-01, -8.5490e-01, -3.9361e-01,  4.1030e-01,\n",
       "         1.4631e-01, -1.5664e-01,  5.3971e-01,  1.4869e-01, -5.5193e-02,\n",
       "        -4.7718e-01, -3.7498e-01, -5.3233e-01,  1.2320e-01, -1.2227e-01,\n",
       "        -5.8157e-02,  2.4245e-02,  1.2577e-01, -1.8558e-01,  7.5054e-02,\n",
       "        -7.2822e-01, -3.5878e-02,  1.5989e-01, -2.5743e-01,  2.1856e-01,\n",
       "        -2.2810e-01,  4.8356e-02,  5.6023e-02,  1.5111e-01,  2.2945e-01,\n",
       "         4.5846e-01, -8.7056e-02, -2.9662e-01,  1.5054e-02,  2.1102e-01,\n",
       "        -3.7446e-02,  7.8902e-01, -3.4193e-01, -8.2430e-01, -7.1748e-01,\n",
       "        -1.9649e-01,  8.7570e-02, -2.0552e-01,  1.4610e-02, -3.8088e-01,\n",
       "         6.5309e-01, -2.0561e-01, -2.8427e-02,  1.0577e-02,  8.8410e-03,\n",
       "         1.1992e-01,  1.4611e-01,  1.6034e-01,  7.2431e-02, -4.3760e-01,\n",
       "        -2.5979e-01,  5.8158e-01,  4.9267e-01, -1.1276e-01, -2.7775e-01])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove[\"unk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-40262981612b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglove_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdoc2idx_glove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdoc2idx_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc2idx_glove_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'glove' is not defined"
     ]
    }
   ],
   "source": [
    "# To convert a tokenized document to a list of list of index of each word\n",
    "def doc2idx_glove_wrapper(glove_object):\n",
    "    def doc2idx_glove(doc): # doc is a list of list of word(string)\n",
    "        return [[glove_object.stoi[word] for word in line] for line in doc]\n",
    "    return doc2idx_glove\n",
    "doc2idx_glove = doc2idx_glove_wrapper(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 2926, 2995, 13, 3827], [7, 5450, 4525, 2120]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [[\"a\", \"dog\", \"sitting\", \"on\", \"bed\"],\n",
    "        [\"a\", \"cat\", \"eating\", \"fish\"]]\n",
    "doc2idx_glove(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert a tokenized sentence to a list of index of each word\n",
    "def snt2idx_glove_wrapper(glove_object):\n",
    "    def snt2idx_glove(snt): # snt is a list of list of word(string)\n",
    "        return [glove_object.stoi[word] for word in snt]\n",
    "        #due to torchtext.\n",
    "    return snt2idx_glove\n",
    "snt2idx_glove = snt2idx_glove_wrapper(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2926, 2995, 13, 3827]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [\"a\", \"dog\", \"sitting\", \"on\", \"bed\"]\n",
    "snt2idx_glove(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.use_pretrained_word_embedding == None:\n",
    "    tokenized_sentence_to_indices = training_corpus_dct.doc2idx\n",
    "elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "    tokenized_sentence_to_indices = snt2idx_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html\n",
    "class DDPN(torch.nn.Module):\n",
    "    def __init__(self, cfg, vocab_size=None, embedding_weights=None):\n",
    "        super(DDPN, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        if type(embedding_weights) == type(None):\n",
    "            #print(\"type(embedding_weights) equals to type(None)\")\n",
    "            assert isinstance(vocab_size, int), \"Error: you are using non-pretraind embedding, and vocab_size is not an integer, but {}.\".format(vocab_size)\n",
    "            self.embedding = nn.Embedding(vocab_size, self.cfg.WORD_EMB_SIZE)  \n",
    "            self.embedding.requires_grad = True\n",
    "        else:\n",
    "            #print(\"type(embedding_weights) doesn't equal to type(None)\")\n",
    "            self.embedding = nn.Embedding(embedding_weights.size()[0], embedding_weights.size()[1])\n",
    "            self.embedding.load_state_dict({'weight': embedding_weights})\n",
    "            self.embedding.requires_grad = False\n",
    "        self.lstm = nn.LSTM(self.cfg.WORD_EMB_SIZE, self.cfg.RNN_DIM)  # This lstm is batch_first=false\n",
    "        self.fc1 = nn.Linear(self.cfg.VISUAL_FEATURES+self.cfg.SPATIAL_FEATURES+self.cfg.RNN_DIM, 512)\n",
    "        # Pytorch's Linear layer automatically exerts on the last dimension of the tensor, so we don't need to take care of N=100 manually. \n",
    "        self.fc_rank = nn.Linear(512,1)\n",
    "        if cfg.regression_loss:\n",
    "            self.fc_regression = nn.Linear(512,4)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(cfg.dropout_rate)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        #self.frozen_layers = [self.embedding, self.lstm, self.fc1, self.fc_rank]\n",
    "#         for param in networkB.conv1.parameters():\n",
    "#             param.requires_grad = False\n",
    "        \n",
    "        \n",
    "    def forward(self, Xs, queries, seq_lengths):\n",
    "        \n",
    "        # one piece of query here should be a 1d tensor of indices (index of each word in the corpus dictionary) \n",
    "        # queries is a batch of query\n",
    "        # seq_lengths is the length of each query\n",
    "        \n",
    "        batch_size = Xs.size()[0]\n",
    "        \n",
    "        emb = self.embedding(queries) # emb size is (time_sequence, batch_size, 300)\n",
    "        # self.tanh = ...\n",
    "        emb_packed = torch.nn.utils.rnn.pack_padded_sequence(emb, lengths=seq_lengths, batch_first=False, enforce_sorted=False)\n",
    "        qs = self.lstm(emb_packed)[0] # [0] is to choose the output h_t sequence\n",
    "        # qs.size() is (time_sequence, batch_size, 1024)\n",
    "        qs_unpacked, qs_len = torch.nn.utils.rnn.pad_packed_sequence(qs, batch_first=False)\n",
    "        qs_unpacked_batch_first = qs_unpacked.permute(1,0,2)\n",
    "        q = qs_unpacked_batch_first[torch.arange(batch_size),qs_len-1] # to choose the output feature of last word\n",
    "        # self.slice = ...\n",
    "        #print(\"q0\", q0.type(), q0.size())  # The shape is (64, 1024)\n",
    "        \n",
    "        q_tiled = q.unsqueeze(1).repeat((1,self.cfg.RPN_TOPN,1)) #.double()\n",
    "        #print('q_tiled', q_tiled.type(), q_tiled.size())\n",
    "        #print('Xs', Xs.type(), Xs.size())\n",
    "        x_concat = torch.cat((Xs, q_tiled), dim=2)  # x_concat's shape is expected as (batch_size, 100, 2053+1024)\n",
    "        x1_linear = self.fc1(x_concat) \n",
    "        x1 = F.relu(x1_linear)\n",
    "        x1 = x1.permute(0,2,1)\n",
    "        x1 = self.batchnorm(x1)\n",
    "        x1 = x1.permute(0,2,1)\n",
    "        x1_dropped = self.dropout(x1)\n",
    "        # x1's shape is expected as (batch_size, 100, 512)\n",
    "        s0 = self.fc_rank(x1_dropped).squeeze()  # s's shape is expected to be (batch_size, 100)\n",
    "        s = self.softmax(s0)\n",
    "        if cfg.regression_loss:\n",
    "            t = self.fc_regression(x1_dropped)\n",
    "            return (s, t)\n",
    "        else:\n",
    "            return (s, None)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tutorial on working with non-equal-length sequence when use LSTM in Pytorch\n",
    "https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=7)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cfg.use_pretrained_word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(queries):  \n",
    "    # queries is a tuple of strings. The length of queries is the batch size. \n",
    "    if cfg.STEMMING:\n",
    "        indices = [tokenized_sentence_to_indices([stemmer.stem(w) for w in word_tokenize(q)]) for q in queries]\n",
    "    else:\n",
    "        indices = [tokenized_sentence_to_indices([w.lower() for w in word_tokenize(q)]) for q in queries]\n",
    "\n",
    "    if cfg.use_pretrained_word_embedding == None:\n",
    "        # Gensim assign -1 to unknown word in the dictionary. \n",
    "        # Pytorch embedding, however, don't support negative index. \n",
    "        # So we kept 1 for unknown word when building Gensim dictionary, and convert -1 to 1 now\n",
    "        indices = [[idx if idx!=-1 else 1 for idx in row] for row in indices]\n",
    "    elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "        # Torchtext's GloVe raise KeyError when encountering a token not found\n",
    "        raise Exception(\"Part not implemented.\")  # Need modification somewhere else\n",
    "    else:\n",
    "        raise Exception(\"Illegal value for the parameter cfg.use_pretrained_word_embedding.\")\n",
    "    \n",
    "    seq_lengths = [len(row) for row in indices]\n",
    "    \n",
    "    Qs_before_padding = [torch.tensor(row) for row in indices]\n",
    "    \n",
    "    if cfg.use_pretrained_word_embedding == None:\n",
    "        padding_value = 0\n",
    "    elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "        padding_value = 1  # 1 is '.', since in GloVe there is no empty word token\n",
    "    \n",
    "    Qs = nn.utils.rnn.pad_sequence(Qs_before_padding, batch_first=False, padding_value=padding_value)\n",
    "    # Qs = pad_sequence_right_alignment(Qs_before_padding, batch_first=False, padding_value=padding_value)\n",
    "    \n",
    "    return Qs, seq_lengths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IoU_scores_wrapper(cfg):\n",
    "    def calculate_IoU_scores(Xs, pred, gt_bboxes):\n",
    "        s, t = pred\n",
    "        proposal_chosen = torch.argmax(s, dim=1)\n",
    "        batch_size = Xs.size()[0]\n",
    "        gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "        bboxes_chosen_original = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "        ious_original = IoU(bboxes_chosen_original, gt_bboxes).squeeze()\n",
    "        if cfg.regression_loss:\n",
    "            bboxes_chosen_refined = t[torch.arange(batch_size),proposal_chosen,:].unsqueeze(1)\n",
    "            ious_refined = IoU(bboxes_chosen_refined, gt_bboxes).squeeze()\n",
    "            return ious_original, ious_refined\n",
    "        return ious_original\n",
    "    return calculate_IoU_scores\n",
    "calculate_IoU_scores = calculate_IoU_scores_wrapper(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/dongwenjian/SSDBACKUP/newly_added/new_experiments/word2word_test_set/experiments/2019-10-20_21-45-46_L1-gt-softlabel_drop0.5_for-word2word-test\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "run_comment = \"_L1-gt-softlabel_drop0.5_for-word2word-test\"\n",
    "moment = datetime.datetime.now()\n",
    "run_name = str(moment.date()) + f\"_{moment.hour}-{moment.minute}-{moment.second}\" + run_comment\n",
    "\n",
    "\n",
    "output_root = os.path.join(project_root, \"experiments/\")\n",
    "output_dir_name = run_name  \n",
    "output_dir = os.path.join(output_root, output_dir_name)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "pytorch_model_save_path = output_dir\n",
    "pytorch_result_save_path = output_dir\n",
    "pytorch_checkpoint_save_path = output_dir\n",
    "\n",
    "\n",
    "#log_dir = os.path.join(\"runs/\", run_name)\n",
    "log_dir = os.path.join(output_dir, \"log\")\n",
    "os.mkdir(log_dir)\n",
    "print(output_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "train_logger = SummaryWriter(os.path.join(log_dir, \"training\"))\n",
    "val_logger = SummaryWriter(os.path.join(log_dir, \"validation\"))\n",
    "train_iou_before_refinement_logger = SummaryWriter(os.path.join(log_dir, \"train_iou_before_refinement\"))\n",
    "val_iou_before_refinement_logger = SummaryWriter(os.path.join(log_dir, \"val_iou_before_refinement\"))\n",
    "if cfg.regression_loss:\n",
    "    train_iou_after_refinement_logger = SummaryWriter(os.path.join(log_dir, \"train_iou_after_refinement\"))\n",
    "    val_iou_after_refinement_logger = SummaryWriter(os.path.join(log_dir, \"val_iou_after_refinement\"))\n",
    "\n",
    "pth_filename = \"ddpn.pth\"\n",
    "checkpoint_filename_base = \"checkpoint_\"  # eg. checkpoint_3.tar means the chechpoint after epoch=3\n",
    "process_filename = \"process.dct\" # .dct here simply means saving a dictionary in binary mode by pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=5)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-pretrained embedding is used.\n",
      "training on device: cuda:5\n",
      "log in directory: /home/wenjian/code/experiments/2019-08-17_22-21-48_L1-gt-softlabel_drop0.5/log\n",
      "gamma: 1\n",
      "epoch 0, training phase, batch 6301/6463, loss=1.2308163642883305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 , training phase finished, average loss: 1.2949965332582423\n",
      "\tTraining: accuracy based on original bounding box: 0.6276403665542603\n",
      "epoch 0 , validation phase finished, average loss: 1.1619859750189105\n",
      "\tValidation: accuracy based on original bounding box: 0.6760980486869812\n",
      "epoch 0 finished. Time used: 633.3197927474976\n",
      "epoch 1 , training phase finished, average loss: 1.0972052304834359\n",
      "\tTraining: accuracy based on original bounding box: 0.6843557357788086\n",
      "epoch 1 , validation phase finished, average loss: 1.1181843651238839\n",
      "\tValidation: accuracy based on original bounding box: 0.6889026761054993\n",
      "epoch 1 finished. Time used: 626.4466533660889\n",
      "epoch 2, training phase, batch 6342/6463, loss=1.0871148109436035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, training phase, batch 6450/6463, loss=1.0791507959365845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 , training phase finished, average loss: 1.0110066927613686\n",
      "\tTraining: accuracy based on original bounding box: 0.7100092768669128\n",
      "epoch 2 , validation phase finished, average loss: 1.1107429951392438\n",
      "\tValidation: accuracy based on original bounding box: 0.6914498209953308\n",
      "epoch 2 finished. Time used: 606.3965103626251\n",
      "epoch 3, training phase, batch 6385/6463, loss=0.8303738832473755"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 , training phase finished, average loss: 0.9460378243752645\n",
      "\tTraining: accuracy based on original bounding box: 0.7302956581115723\n",
      "epoch 3 , validation phase finished, average loss: 1.1126183174734157\n",
      "\tValidation: accuracy based on original bounding box: 0.6920005679130554\n",
      "epoch 3 finished. Time used: 605.7523183822632\n",
      "epoch 4, training phase, batch 6450/6463, loss=1.0026450157165527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 , training phase finished, average loss: 0.8968972249515331\n",
      "\tTraining: accuracy based on original bounding box: 0.7458748817443848\n",
      "epoch 4 , validation phase finished, average loss: 1.1192133696335629\n",
      "\tValidation: accuracy based on original bounding box: 0.6942034959793091\n",
      "epoch 4 finished. Time used: 607.4866087436676\n",
      "epoch 5 , training phase finished, average loss: 0.8601442484972813\n",
      "\tTraining: accuracy based on original bounding box: 0.7578470706939697\n",
      "epoch 5 , validation phase finished, average loss: 1.1313259107718927\n",
      "\tValidation: accuracy based on original bounding box: 0.6905548572540283\n",
      "epoch 5 finished. Time used: 606.6595923900604\n",
      "epoch 6, training phase, batch 6351/6463, loss=0.8243777751922607"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 6, training phase, batch 6352/6463, loss=0.9373184442520142\r",
      "epoch 6, training phase, batch 6353/6463, loss=0.8107402324676514\r",
      "epoch 6, training phase, batch 6354/6463, loss=0.867627739906311\r",
      "epoch 6, training phase, batch 6355/6463, loss=1.0726268291473389"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, training phase, batch 6415/6463, loss=1.0851452350616455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 6, training phase, batch 6416/6463, loss=0.7646947503089905\r",
      "epoch 6, training phase, batch 6417/6463, loss=0.895005464553833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 6, training phase, batch 6418/6463, loss=0.8840863704681396\r",
      "epoch 6, training phase, batch 6419/6463, loss=1.0360256433486938\r",
      "epoch 6, training phase, batch 6420/6463, loss=0.8896545767784119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, training phase, batch 6431/6463, loss=0.9126161336898804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 , training phase finished, average loss: 0.8336545921277952\n",
      "\tTraining: accuracy based on original bounding box: 0.7670800089836121\n",
      "epoch 6 , validation phase finished, average loss: 1.1357090066783473\n",
      "\tValidation: accuracy based on original bounding box: 0.6928954720497131\n",
      "epoch 6 finished. Time used: 796.5458860397339\n",
      "epoch 7, training phase, batch 6301/6463, loss=0.66352200508117684"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 7, training phase, batch 6302/6463, loss=0.974519670009613\r",
      "epoch 7, training phase, batch 6303/6463, loss=1.0102627277374268\r",
      "epoch 7, training phase, batch 6304/6463, loss=0.9645240902900696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 , training phase finished, average loss: 0.8146288396827248\n",
      "\tTraining: accuracy based on original bounding box: 0.7731651663780212\n",
      "epoch 7 , validation phase finished, average loss: 1.1437001323036857\n",
      "\tValidation: accuracy based on original bounding box: 0.6898664236068726\n",
      "epoch 7 finished. Time used: 911.1470191478729\n",
      "epoch 8, training phase, batch 6397/6463, loss=0.81043118238449195"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 , training phase finished, average loss: 0.7997023094361464\n",
      "\tTraining: accuracy based on original bounding box: 0.7786532044410706\n",
      "epoch 8 , validation phase finished, average loss: 1.1484689189106517\n",
      "\tValidation: accuracy based on original bounding box: 0.6895222067832947\n",
      "epoch 8 finished. Time used: 947.7378530502319\n",
      "epoch 9, training phase, batch 6411/6463, loss=0.99510163068771366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 9, training phase, batch 6412/6463, loss=0.7722653150558472\r",
      "epoch 9, training phase, batch 6413/6463, loss=0.8491913080215454\r",
      "epoch 9, training phase, batch 6414/6463, loss=1.0296521186828613"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 9, training phase, batch 6415/6463, loss=0.6701897382736206\r",
      "epoch 9, training phase, batch 6416/6463, loss=0.9740041494369507\r",
      "epoch 9, training phase, batch 6417/6463, loss=0.7956098318099976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 , training phase finished, average loss: 0.7888780126194638\n",
      "\tTraining: accuracy based on original bounding box: 0.7816656231880188\n",
      "epoch 9 , validation phase finished, average loss: 1.1516234384790427\n",
      "\tValidation: accuracy based on original bounding box: 0.6900041103363037\n",
      "epoch 9 finished. Time used: 974.6201646327972\n",
      "epoch 10, training phase, batch 6416/6463, loss=0.7293312549591064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 10, training phase, batch 6417/6463, loss=0.9294547438621521\r",
      "epoch 10, training phase, batch 6418/6463, loss=0.5871263742446899\r",
      "epoch 10, training phase, batch 6419/6463, loss=0.7483685612678528"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 , training phase finished, average loss: 0.7821726732193828\n",
      "\tTraining: accuracy based on original bounding box: 0.7839550971984863\n",
      "epoch 10 , validation phase finished, average loss: 1.1591910465548523\n",
      "\tValidation: accuracy based on original bounding box: 0.68780118227005\n",
      "epoch 10 finished. Time used: 965.8476724624634\n",
      "epoch 11, training phase, batch 6454/6463, loss=0.7862837910652161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 , training phase finished, average loss: 0.7770570005191372\n",
      "\tTraining: accuracy based on original bounding box: 0.785973846912384\n",
      "epoch 11 , validation phase finished, average loss: 1.1636466196577056\n",
      "\tValidation: accuracy based on original bounding box: 0.6888338327407837\n",
      "epoch 11 finished. Time used: 963.6893475055695\n",
      "epoch 12, training phase, batch 6273/6463, loss=0.80762839317321786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 12, training phase, batch 6274/6463, loss=0.8885301351547241\r",
      "epoch 12, training phase, batch 6275/6463, loss=0.787328839302063\r",
      "epoch 12, training phase, batch 6276/6463, loss=0.9615356922149658"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 12, training phase, batch 6277/6463, loss=0.7718523740768433\r",
      "epoch 12, training phase, batch 6278/6463, loss=0.6881765127182007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 , training phase finished, average loss: 0.7735399372380645\n",
      "\tTraining: accuracy based on original bounding box: 0.7866386771202087\n",
      "epoch 12 , validation phase finished, average loss: 1.1640684380440054\n",
      "\tValidation: accuracy based on original bounding box: 0.6888338327407837\n",
      "epoch 12 finished. Time used: 957.1785235404968\n",
      "epoch 13, training phase, batch 6333/6463, loss=0.71509456634521485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 13, training phase, batch 6334/6463, loss=0.8420640230178833\r",
      "epoch 13, training phase, batch 6335/6463, loss=0.6290799975395203\r",
      "epoch 13, training phase, batch 6336/6463, loss=0.8868862986564636"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, training phase, batch 6440/6463, loss=0.6882580518722534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 13, training phase, batch 6441/6463, loss=0.8681285381317139\r",
      "epoch 13, training phase, batch 6442/6463, loss=0.759001612663269\r",
      "epoch 13, training phase, batch 6443/6463, loss=0.7069380283355713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 13, training phase, batch 6444/6463, loss=0.8443927764892578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 , training phase finished, average loss: 0.7703700793276612\n",
      "\tTraining: accuracy based on original bounding box: 0.7877653241157532\n",
      "epoch 13 , validation phase finished, average loss: 1.1650471083310033\n",
      "\tValidation: accuracy based on original bounding box: 0.6886961460113525\n",
      "epoch 13 finished. Time used: 964.032737493515\n",
      "epoch 14, training phase, batch 6331/6463, loss=0.94580727815628057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, training phase, batch 6376/6463, loss=0.7607520818710327"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 14, training phase, batch 6377/6463, loss=0.819080650806427\r",
      "epoch 14, training phase, batch 6378/6463, loss=0.767373263835907"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 14, training phase, batch 6379/6463, loss=0.6913491487503052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 , training phase finished, average loss: 0.7686756344162463\n",
      "\tTraining: accuracy based on original bounding box: 0.7880868315696716\n",
      "epoch 14 , validation phase finished, average loss: 1.1606044187930502\n",
      "\tValidation: accuracy based on original bounding box: 0.6880077123641968\n",
      "epoch 14 finished. Time used: 965.7721228599548\n",
      "epoch 15, training phase, batch 6333/6463, loss=0.6420906782150269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 , training phase finished, average loss: 0.7673995758513902\n",
      "\tTraining: accuracy based on original bounding box: 0.7894648909568787\n",
      "epoch 15 , validation phase finished, average loss: 1.1670760546573575\n",
      "\tValidation: accuracy based on original bounding box: 0.6877323389053345\n",
      "epoch 15 finished. Time used: 952.2182602882385\n",
      "epoch 16, training phase, batch 6374/6463, loss=0.86973893642425545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 16, training phase, batch 6375/6463, loss=0.8425480127334595\r",
      "epoch 16, training phase, batch 6376/6463, loss=0.7437129020690918\r",
      "epoch 16, training phase, batch 6377/6463, loss=0.9987585544586182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 16, training phase, batch 6378/6463, loss=0.6624324321746826\r",
      "epoch 16, training phase, batch 6379/6463, loss=0.6223170757293701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 , training phase finished, average loss: 0.7667174859636684\n",
      "\tTraining: accuracy based on original bounding box: 0.7892497181892395\n",
      "epoch 16 , validation phase finished, average loss: 1.1633009198577577\n",
      "\tValidation: accuracy based on original bounding box: 0.6875946521759033\n",
      "epoch 16 finished. Time used: 962.3058865070343\n",
      "epoch 17, training phase, batch 6339/6463, loss=0.72322207689285284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, training phase, batch 6394/6463, loss=0.7383949160575867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 17, training phase, batch 6395/6463, loss=0.7536826133728027\r",
      "epoch 17, training phase, batch 6396/6463, loss=0.853839635848999\r",
      "epoch 17, training phase, batch 6397/6463, loss=0.7710673213005066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 17, training phase, batch 6398/6463, loss=0.591452419757843\r",
      "epoch 17, training phase, batch 6399/6463, loss=0.8720067739486694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 , training phase finished, average loss: 0.7651718580484204\n",
      "\tTraining: accuracy based on original bounding box: 0.7896655797958374\n",
      "epoch 17 , validation phase finished, average loss: 1.1676459582108334\n",
      "\tValidation: accuracy based on original bounding box: 0.6880765557289124\n",
      "epoch 17 finished. Time used: 960.4734506607056\n",
      "epoch 18, training phase, batch 6349/6463, loss=0.67491459846496584"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 18, training phase, batch 6350/6463, loss=0.7040833830833435\r",
      "epoch 18, training phase, batch 6351/6463, loss=0.8039274215698242\r",
      "epoch 18, training phase, batch 6352/6463, loss=0.637112021446228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, training phase, batch 6437/6463, loss=0.8674641847610474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 , training phase finished, average loss: 0.7652879389789813\n",
      "\tTraining: accuracy based on original bounding box: 0.7901200652122498\n",
      "epoch 18 , validation phase finished, average loss: 1.1630985775007683\n",
      "\tValidation: accuracy based on original bounding box: 0.6873881220817566\n",
      "epoch 18 finished. Time used: 957.9534723758698\n",
      "epoch 19, training phase, batch 6398/6463, loss=0.89683926105499277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 19, training phase, batch 6399/6463, loss=0.8224533796310425\r",
      "epoch 19, training phase, batch 6400/6463, loss=0.7336442470550537\r",
      "epoch 19, training phase, batch 6401/6463, loss=1.0258309841156006\r",
      "epoch 19, training phase, batch 6402/6463, loss=0.7074160575866699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, training phase, batch 6422/6463, loss=0.7974635958671577"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 19, training phase, batch 6423/6463, loss=0.7350144386291504\r",
      "epoch 19, training phase, batch 6424/6463, loss=0.7659174799919128\r",
      "epoch 19, training phase, batch 6425/6463, loss=0.6797548532485962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, training phase, batch 6436/6463, loss=0.7245078086853027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 19, training phase, batch 6437/6463, loss=0.8892806172370911\r",
      "epoch 19, training phase, batch 6438/6463, loss=0.8050147294998169\r",
      "epoch 19, training phase, batch 6439/6463, loss=0.8317879438400269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f0f17185378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/wenjian/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 , training phase finished, average loss: 0.764523020100948\n",
      "\tTraining: accuracy based on original bounding box: 0.7902506589889526\n",
      "epoch 19 , validation phase finished, average loss: 1.1659120119226942\n",
      "\tValidation: accuracy based on original bounding box: 0.6875258088111877\n",
      "epoch 19 finished. Time used: 959.2180409431458\n",
      "total time: 16931.125435829163\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'num_workers': 2}\n",
    "\n",
    "training_generator = data.DataLoader(training_set, shuffle=True, **params)\n",
    "validation_generator = data.DataLoader(validation_set, shuffle=True, **params)\n",
    "test_generator = data.DataLoader(test_set, shuffle=True, **params)\n",
    "\n",
    "\n",
    "\n",
    "if cfg.use_pretrained_word_embedding == None:\n",
    "    print(\"Non-pretrained embedding is used.\")\n",
    "    model = DDPN(cfg, vocab_size=len(training_corpus_dct.token2id))\n",
    "elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "    print(\"Glove embedding is used.\")\n",
    "    model = DDPN(cfg, embedding_weights=glove.vectors)\n",
    "else:\n",
    "    raise Exception(\"Embedding configuration not recognized\")\n",
    "    \n",
    "\n",
    "if cfg.use_pretrained_model:    \n",
    "    print(\"loading pre-trained model from \", pretrained_model_path)\n",
    "    model.load_state_dict(torch.load(pretrained_model_path, map_location=device))\n",
    "    \n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.999), lr=cfg.initial_lr) \n",
    "LR_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=cfg.lr_decay_rate)\n",
    "# Warning: Pytorch's Adam does not have the learning rate decay feature. \n",
    "#          Possibly learning rate scheduler may achieve the same effect. \n",
    "# Warning: beta2 is recommended as 0.999 in the original paper and by the community. \n",
    "\n",
    "\n",
    "print(\"training on device:\", device)\n",
    "print(\"log in directory:\", logger.logdir)\n",
    "print(\"gamma:\", cfg.GAMMA)\n",
    "\n",
    "process = {}\n",
    "process['time'] = []\n",
    "process['train_average_losses_by_epoch'] = []\n",
    "process['val_average_losses_by_epoch'] = []\n",
    "process['train_IoU_acc_before_refinement'] = []\n",
    "process['val_IoU_acc_before_refinement'] = []\n",
    "if cfg.regression_loss:\n",
    "    process['train_IoU_acc_after_refinement'] = []\n",
    "    process['val_IoU_acc_after_refinement'] = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "process['configure'] = cfg\n",
    "\n",
    "# output_root = os.path.join(project_root, \"outputs/\")\n",
    "# output_dir_name = run_name  \n",
    "# output_dir = os.path.join(output_root, output_dir_name)\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.mkdir(output_dir)\n",
    "# pytorch_model_save_path = output_dir\n",
    "# pytorch_result_save_path = output_dir\n",
    "# pytorch_checkpoint_save_path = output_dir\n",
    "\n",
    "\n",
    "# Loop over epochs\n",
    "max_epochs = 20\n",
    "time_start_all = time.time()\n",
    "loss = None\n",
    "train_batch_counter_total = 0\n",
    "val_batch_counter_total = 0\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    time_start = time.time()\n",
    "    # Training\n",
    "    #train_batch_counter = 0\n",
    "    train_losses_by_epoch = []\n",
    "    train_loss_average_by_epoch = 0.0\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    train_all_ious_original = []\n",
    "    if cfg.regression_loss:\n",
    "        train_all_ious_refined = []\n",
    "    \n",
    "    #for inputs, gt_bboxes in training_generator:\n",
    "    for train_batch_counter, (inputs, gt_bboxes, _) in enumerate(training_generator):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        Xs, queries = inputs\n",
    "        #print(\"train_batch_counter\", train_batch_counter)\n",
    "        #print(\"Xs\", Xs.size())\n",
    "        #print(\"queries\", len(queries))\n",
    "        #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "        \n",
    "        # print('Xs shape:', Xs.size())\n",
    "        #print('queries:\\n', len(queries))  # queries is a tuple of strings. The length of queries is the batch size. \n",
    "        \n",
    "        Qs, seq_lengths = preprocess_query(queries)\n",
    "        #print(Qs)\n",
    "        #print(len(seq_lengths))  # len(seq_lengths) equals to batch_size\n",
    "        #print(seq_lengths)\n",
    "        \n",
    "        \n",
    "        Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "        \n",
    "        pred = model(Xs, Qs, seq_lengths)\n",
    "        targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "        try:\n",
    "            loss = loss_func(pred, targ)\n",
    "        except AssertionError as e:\n",
    "            print(f\"epoch {epoch}, train, batch: {train_batch_counter}\")\n",
    "            with open(\"debug.log\", 'a') as log:\n",
    "                log.write(f\"epoch {epoch}, train, batch: {train_batch_counter}\\n\")\n",
    "            raise e\n",
    "        train_losses_by_epoch.append(loss.item())\n",
    "        train_loss_average_by_epoch += loss.item()*Xs.size(0)\n",
    "        #logger.add_scalar('train_losses_all_batches', train_losses, train_batch_counter)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        print(f\"\\repoch {epoch}, training phase, batch {train_batch_counter}/{len(training_generator)}, loss={loss.item()}\", end='')\n",
    "        logger.add_scalar(\"train_loss_by_batch\", loss.item(), train_batch_counter_total)\n",
    "        \n",
    "        # statistics of IoU score\n",
    "        if cfg.regression_loss:\n",
    "            ious_original, ious_refined = calculate_IoU_scores(Xs, pred, gt_bboxes)\n",
    "        else:\n",
    "            ious_original = calculate_IoU_scores(Xs, pred, gt_bboxes)\n",
    "        #print(ious.size())\n",
    "        train_all_ious_original = train_all_ious_original + ious_original.tolist()\n",
    "        if cfg.regression_loss:\n",
    "            train_all_ious_refined = train_all_ious_refined + ious_refined.tolist()\n",
    "        \n",
    "        #train_batch_counter += 1\n",
    "        train_batch_counter_total += 1\n",
    "        \n",
    "        #print(\"fc_regression 0\", list(model.fc_regression.parameters())[0].size())\n",
    "        #print(\"fc_regression 1\", list(model.fc_regression.parameters())[1].size())\n",
    "        \n",
    "        #if train_batch_counter == 20: break  # For debugging the codes after training phase\n",
    "        \n",
    "    train_losses.append(train_losses_by_epoch)\n",
    "    train_loss_average_by_epoch /= len(training_generator.dataset)\n",
    "    print(\"\\repoch\", epoch, \", training phase finished, average loss:\",train_loss_average_by_epoch)\n",
    "    #logger.add_scalar(\"train_loss_average_by_epoch\", train_loss_average_by_epoch, epoch)\n",
    "    train_logger.add_scalar(\"average_loss_by_epoch\", train_loss_average_by_epoch, epoch)\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    train_good_original = torch.tensor(train_all_ious_original) > 0.5     \n",
    "    #print(\"\\tTraining: good bounding box based on original bounding box:\", train_good_original.sum().item())\n",
    "    train_acc_original = train_good_original.sum().float()/len(training_set)\n",
    "    print(\"\\tTraining: accuracy based on original bounding box:\", train_acc_original.item())\n",
    "    train_iou_before_refinement_logger.add_scalar(\"IoU_accuracy\", train_acc_original, epoch)\n",
    "\n",
    "    if cfg.regression_loss:\n",
    "        train_good_refined = torch.tensor(train_all_ious_refined) > 0.5\n",
    "        #print(\"\\tTraining: good bounding box refined:\", train_good_refined.sum().item())\n",
    "        train_acc_refined = train_good_refined.sum().float()/len(training_set)\n",
    "        print(\"\\tTraining: accuracy of refined bounding box:\", train_acc_refined.item())\n",
    "        train_iou_after_refinement_logger.add_scalar(\"IoU_accuracy\", train_acc_refined, epoch)\n",
    "\n",
    "    # Validation\n",
    "    #val_batch_counter = 0\n",
    "    val_losses_by_epoch = []\n",
    "    val_loss_average_by_epoch = 0.0\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    val_all_ious_original = []\n",
    "    if cfg.regression_loss:\n",
    "        val_all_ious_refined = []\n",
    "    \n",
    "    with torch.no_grad():      \n",
    "        #for inputs, gt_bboxes in validation_generator:\n",
    "        for val_batch_counter, (inputs, gt_bboxes, _) in enumerate(validation_generator):\n",
    "            Xs, queries = inputs\n",
    "            #print(\"val_batch_counter\", val_batch_counter)\n",
    "            #print(\"Xs\", Xs.size())\n",
    "            #print(\"queries\", len(queries))\n",
    "            #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "           \n",
    "            Qs, seq_lengths = preprocess_query(queries)\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "            \n",
    "            val_pred = model(Xs, Qs, seq_lengths)\n",
    "            val_targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "            try:\n",
    "                val_loss = loss_func(val_pred, val_targ)\n",
    "            except AssertionError as e:\n",
    "                print(f\"epoch {epoch}, val, batch: {val_batch_counter}\")\n",
    "                with open(\"debug.log\", 'a') as log:\n",
    "                    log.write(f\"epoch {epoch}, val, batch: {val_batch_counter}\\n\")\n",
    "                raise e\n",
    "            val_losses_by_epoch.append(val_loss.item())\n",
    "            val_loss_average_by_epoch += val_loss.item()*Xs.size(0)\n",
    "            #logger.add_scalar('val_losses_all_batches', val_losses, val_batch_counter)\n",
    "        \n",
    "            print(f\"\\repoch {epoch}, validation phase, batch {val_batch_counter}/{len(validation_generator)}, val_loss={val_loss.item()}\", end='')\n",
    "            logger.add_scalar(\"val_loss_by_batch\", val_loss.item(), val_batch_counter_total)\n",
    "            \n",
    "            # Statistics of IoU score\n",
    "            if cfg.regression_loss:\n",
    "                ious_original, ious_refined = calculate_IoU_scores(Xs, val_pred, gt_bboxes)\n",
    "            else:\n",
    "                ious_original = calculate_IoU_scores(Xs, val_pred, gt_bboxes)\n",
    "            val_all_ious_original = val_all_ious_original + ious_original.tolist()\n",
    "            if cfg.regression_loss:\n",
    "                val_all_ious_refined = val_all_ious_refined + ious_refined.tolist()\n",
    "            \n",
    "\n",
    "            #val_batch_counter += 1\n",
    "            val_batch_counter_total += 1\n",
    "            \n",
    "    LR_scheduler.step() # Decay the learning rate every epoch\n",
    "    \n",
    "    val_losses.append(val_losses_by_epoch)\n",
    "    val_loss_average_by_epoch /= len(validation_generator.dataset)\n",
    "    print(\"\\repoch\", epoch, \", validation phase finished, average loss:\",val_loss_average_by_epoch)\n",
    "    #logger.add_scalar(\"val_loss_average_by_epoch\", val_loss_average_by_epoch, epoch)\n",
    "    val_logger.add_scalar(\"average_loss_by_epoch\", val_loss_average_by_epoch, epoch)\n",
    "    \n",
    "    # For statistics of IoU score\n",
    "    val_good_original = torch.tensor(val_all_ious_original) > 0.5     \n",
    "    #print(\"\\tValidation: good bounding box based on original bounding box:\", val_good_original.sum().item())\n",
    "    val_acc_original = val_good_original.sum().float()/len(validation_set)\n",
    "    print(\"\\tValidation: accuracy based on original bounding box:\", val_acc_original.item())\n",
    "    val_iou_before_refinement_logger.add_scalar(\"IoU_accuracy\", val_acc_original, epoch)\n",
    "\n",
    "    if cfg.regression_loss:\n",
    "        val_good_refined = torch.tensor(val_all_ious_refined) > 0.5\n",
    "        #print(\"\\tValidation: good bounding box refined:\", val_good_refined.sum().item())\n",
    "        val_acc_refined = val_good_refined.sum().float()/len(validation_set)\n",
    "        print(\"\\tValidation: accuracy of refined bounding box:\", val_acc_refined.item())\n",
    "        val_iou_after_refinement_logger.add_scalar(\"IoU_accuracy\", val_acc_refined, epoch)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_epoch = time_end - time_start\n",
    "    print(f\"epoch {epoch} finished. Time used: {time_epoch}\")\n",
    "    \n",
    "    model.eval() # Do this before saving the model when dropout or batch normalization is involved. https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "    # Save model's learnable parameters\n",
    "    torch.save(model.state_dict(), os.path.join(pytorch_model_save_path,pth_filename))\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                \n",
    "                }, os.path.join(pytorch_checkpoint_save_path, (checkpoint_filename_base+str(epoch)+'.tar')))\n",
    "    \n",
    "    # Save loss (value) evolution\n",
    "    process['train_losses'] = train_losses\n",
    "    process['val_losses'] = val_losses\n",
    "    process['train_average_losses_by_epoch'].append(train_loss_average_by_epoch)\n",
    "    process['val_average_losses_by_epoch'].append(val_loss_average_by_epoch)\n",
    "    process['train_IoU_acc_before_refinement'].append(train_acc_original)\n",
    "    process['val_IoU_acc_before_refinement'].append(val_acc_original)\n",
    "    if cfg.regression_loss:\n",
    "        process['train_IoU_acc_after_refinement'].append(train_acc_refined)\n",
    "        process['val_IoU_acc_after_refinement'].append(val_acc_refined)\n",
    "    process['time'].append(time_epoch)\n",
    "    with open(os.path.join(pytorch_result_save_path, process_filename), 'wb') as fp:\n",
    "        pickle.dump(process, fp)\n",
    "        \n",
    "    # the vocabulary dictionary also needs saving in the future\n",
    "\n",
    "time_end_all = time.time()\n",
    "time_total = time_end_all - time_start_all\n",
    "print(f\"total time: {time_total}\")\n",
    "process[\"total_time\"] = time_total\n",
    "\n",
    "with open(os.path.join(pytorch_result_save_path, process_filename), 'wb') as fp:\n",
    "    pickle.dump(process, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"645pt\" height=\"1285pt\"\n",
       " viewBox=\"0.00 0.00 644.95 1285.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.69951 0.69951) rotate(0) translate(4 1833)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1833 918,-1833 918,4 -4,4\"/>\n",
       "<!-- 139856939104128 -->\n",
       "<g id=\"node1\" class=\"node\"><title>139856939104128</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"885.5,-21 780.5,-21 780.5,-0 885.5,-0 885.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"833\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">SoftmaxBackward</text>\n",
       "</g>\n",
       "<!-- 139856939102336 -->\n",
       "<g id=\"node2\" class=\"node\"><title>139856939102336</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"888.5,-78 777.5,-78 777.5,-57 888.5,-57 888.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"833\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">SqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 139856939102336&#45;&gt;139856939104128 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>139856939102336&#45;&gt;139856939104128</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M833,-56.9197C833,-49.9083 833,-40.1442 833,-31.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"836.5,-31.3408 833,-21.3408 829.5,-31.3409 836.5,-31.3408\"/>\n",
       "</g>\n",
       "<!-- 139856939130496 -->\n",
       "<g id=\"node3\" class=\"node\"><title>139856939130496</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"879,-135 787,-135 787,-114 879,-114 879,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"833\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 139856939130496&#45;&gt;139856939102336 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>139856939130496&#45;&gt;139856939102336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M833,-113.92C833,-106.908 833,-97.1442 833,-88.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"836.5,-88.3408 833,-78.3408 829.5,-88.3409 836.5,-88.3408\"/>\n",
       "</g>\n",
       "<!-- 139859098636240 -->\n",
       "<g id=\"node4\" class=\"node\"><title>139859098636240</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"841.5,-199 716.5,-199 716.5,-178 841.5,-178 841.5,-199\"/>\n",
       "<text text-anchor=\"middle\" x=\"779\" y=\"-185.4\" font-family=\"Times,serif\" font-size=\"12.00\">UnsafeViewBackward</text>\n",
       "</g>\n",
       "<!-- 139859098636240&#45;&gt;139856939130496 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>139859098636240&#45;&gt;139856939130496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M787.438,-177.812C795.553,-168.495 808.005,-154.197 817.842,-142.903\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"820.515,-145.164 824.444,-135.324 815.236,-140.566 820.515,-145.164\"/>\n",
       "</g>\n",
       "<!-- 139857005870608 -->\n",
       "<g id=\"node5\" class=\"node\"><title>139857005870608</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"821.5,-263 736.5,-263 736.5,-242 821.5,-242 821.5,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"779\" y=\"-249.4\" font-family=\"Times,serif\" font-size=\"12.00\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139857005870608&#45;&gt;139859098636240 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>139857005870608&#45;&gt;139859098636240</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M779,-241.812C779,-233.218 779,-220.388 779,-209.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"782.5,-209.324 779,-199.324 775.5,-209.324 782.5,-209.324\"/>\n",
       "</g>\n",
       "<!-- 139857005870720 -->\n",
       "<g id=\"node6\" class=\"node\"><title>139857005870720</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"775,-320 683,-320 683,-299 775,-299 775,-320\"/>\n",
       "<text text-anchor=\"middle\" x=\"729\" y=\"-306.4\" font-family=\"Times,serif\" font-size=\"12.00\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 139857005870720&#45;&gt;139857005870608 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>139857005870720&#45;&gt;139857005870608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M737.709,-298.92C744.721,-291.207 754.76,-280.164 763.184,-270.898\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"765.917,-273.095 770.054,-263.341 760.737,-268.386 765.917,-273.095\"/>\n",
       "</g>\n",
       "<!-- 139856998460944 -->\n",
       "<g id=\"node7\" class=\"node\"><title>139856998460944</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"721,-384 627,-384 627,-363 721,-363 721,-384\"/>\n",
       "<text text-anchor=\"middle\" x=\"674\" y=\"-370.4\" font-family=\"Times,serif\" font-size=\"12.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 139856998460944&#45;&gt;139857005870720 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>139856998460944&#45;&gt;139857005870720</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M682.594,-362.812C690.86,-353.495 703.543,-339.197 713.562,-327.903\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"716.267,-330.128 720.285,-320.324 711.031,-325.482 716.267,-330.128\"/>\n",
       "</g>\n",
       "<!-- 139856998461112 -->\n",
       "<g id=\"node55\" class=\"node\"><title>139856998461112</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"665,-320 573,-320 573,-299 665,-299 665,-320\"/>\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-306.4\" font-family=\"Times,serif\" font-size=\"12.00\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 139856998460944&#45;&gt;139856998461112 -->\n",
       "<g id=\"edge58\" class=\"edge\"><title>139856998460944&#45;&gt;139856998461112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M665.406,-362.812C657.14,-353.495 644.457,-339.197 634.438,-327.903\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"636.969,-325.482 627.715,-320.324 631.733,-330.128 636.969,-325.482\"/>\n",
       "</g>\n",
       "<!-- 139856998461000 -->\n",
       "<g id=\"node8\" class=\"node\"><title>139856998461000</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"720,-448 628,-448 628,-427 720,-427 720,-448\"/>\n",
       "<text text-anchor=\"middle\" x=\"674\" y=\"-434.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 139856998461000&#45;&gt;139856998460944 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>139856998461000&#45;&gt;139856998460944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M674,-426.812C674,-418.218 674,-405.388 674,-394.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"677.5,-394.324 674,-384.324 670.5,-394.324 677.5,-394.324\"/>\n",
       "</g>\n",
       "<!-- 139856908676344 -->\n",
       "<g id=\"node9\" class=\"node\"><title>139856908676344</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"682.5,-512 557.5,-512 557.5,-491 682.5,-491 682.5,-512\"/>\n",
       "<text text-anchor=\"middle\" x=\"620\" y=\"-498.4\" font-family=\"Times,serif\" font-size=\"12.00\">UnsafeViewBackward</text>\n",
       "</g>\n",
       "<!-- 139856908676344&#45;&gt;139856998461000 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>139856908676344&#45;&gt;139856998461000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M628.438,-490.812C636.553,-481.495 649.005,-467.197 658.842,-455.903\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"661.515,-458.164 665.444,-448.324 656.236,-453.566 661.515,-458.164\"/>\n",
       "</g>\n",
       "<!-- 139856869299424 -->\n",
       "<g id=\"node10\" class=\"node\"><title>139856869299424</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"662.5,-576 577.5,-576 577.5,-555 662.5,-555 662.5,-576\"/>\n",
       "<text text-anchor=\"middle\" x=\"620\" y=\"-562.4\" font-family=\"Times,serif\" font-size=\"12.00\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139856869299424&#45;&gt;139856908676344 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>139856869299424&#45;&gt;139856908676344</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M620,-554.812C620,-546.218 620,-533.388 620,-522.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"623.5,-522.324 620,-512.324 616.5,-522.324 623.5,-522.324\"/>\n",
       "</g>\n",
       "<!-- 139856869301832 -->\n",
       "<g id=\"node11\" class=\"node\"><title>139856869301832</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"616,-633 524,-633 524,-612 616,-612 616,-633\"/>\n",
       "<text text-anchor=\"middle\" x=\"570\" y=\"-619.4\" font-family=\"Times,serif\" font-size=\"12.00\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 139856869301832&#45;&gt;139856869299424 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>139856869301832&#45;&gt;139856869299424</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M578.709,-611.92C585.721,-604.207 595.76,-593.164 604.184,-583.898\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"606.917,-586.095 611.054,-576.341 601.737,-581.386 606.917,-586.095\"/>\n",
       "</g>\n",
       "<!-- 139856869298528 -->\n",
       "<g id=\"node12\" class=\"node\"><title>139856869298528</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"611,-697 529,-697 529,-676 611,-676 611,-697\"/>\n",
       "<text text-anchor=\"middle\" x=\"570\" y=\"-683.4\" font-family=\"Times,serif\" font-size=\"12.00\">CatBackward</text>\n",
       "</g>\n",
       "<!-- 139856869298528&#45;&gt;139856869301832 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>139856869298528&#45;&gt;139856869301832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M570,-675.812C570,-667.218 570,-654.388 570,-643.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"573.5,-643.324 570,-633.324 566.5,-643.324 573.5,-643.324\"/>\n",
       "</g>\n",
       "<!-- 139856869300432 -->\n",
       "<g id=\"node13\" class=\"node\"><title>139856869300432</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"619,-761 521,-761 521,-740 619,-740 619,-761\"/>\n",
       "<text text-anchor=\"middle\" x=\"570\" y=\"-747.4\" font-family=\"Times,serif\" font-size=\"12.00\">RepeatBackward</text>\n",
       "</g>\n",
       "<!-- 139856869300432&#45;&gt;139856869298528 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>139856869300432&#45;&gt;139856869298528</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M570,-739.812C570,-731.218 570,-718.388 570,-707.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"573.5,-707.324 570,-697.324 566.5,-707.324 573.5,-707.324\"/>\n",
       "</g>\n",
       "<!-- 139856869300712 -->\n",
       "<g id=\"node14\" class=\"node\"><title>139856869300712</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"632,-818 508,-818 508,-797 632,-797 632,-818\"/>\n",
       "<text text-anchor=\"middle\" x=\"570\" y=\"-804.4\" font-family=\"Times,serif\" font-size=\"12.00\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 139856869300712&#45;&gt;139856869300432 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>139856869300712&#45;&gt;139856869300432</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M570,-796.92C570,-789.908 570,-780.144 570,-771.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"573.5,-771.341 570,-761.341 566.5,-771.341 573.5,-771.341\"/>\n",
       "</g>\n",
       "<!-- 139856869301944 -->\n",
       "<g id=\"node15\" class=\"node\"><title>139856869301944</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"637,-875 503,-875 503,-854 637,-854 637,-875\"/>\n",
       "<text text-anchor=\"middle\" x=\"570\" y=\"-861.4\" font-family=\"Times,serif\" font-size=\"12.00\">FusedDropoutBackward</text>\n",
       "</g>\n",
       "<!-- 139856869301944&#45;&gt;139856869300712 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>139856869301944&#45;&gt;139856869300712</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M570,-853.92C570,-846.908 570,-837.144 570,-828.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"573.5,-828.341 570,-818.341 566.5,-828.341 573.5,-828.341\"/>\n",
       "</g>\n",
       "<!-- 139856869299648 -->\n",
       "<g id=\"node16\" class=\"node\"><title>139856869299648</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"646.5,-932 493.5,-932 493.5,-911 646.5,-911 646.5,-932\"/>\n",
       "<text text-anchor=\"middle\" x=\"570\" y=\"-918.4\" font-family=\"Times,serif\" font-size=\"12.00\">CudnnBatchNormBackward</text>\n",
       "</g>\n",
       "<!-- 139856869299648&#45;&gt;139856869301944 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>139856869299648&#45;&gt;139856869301944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M570,-910.92C570,-903.908 570,-894.144 570,-885.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"573.5,-885.341 570,-875.341 566.5,-885.341 573.5,-885.341\"/>\n",
       "</g>\n",
       "<!-- 139856869300768 -->\n",
       "<g id=\"node17\" class=\"node\"><title>139856869300768</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"525,-996 433,-996 433,-975 525,-975 525,-996\"/>\n",
       "<text text-anchor=\"middle\" x=\"479\" y=\"-982.4\" font-family=\"Times,serif\" font-size=\"12.00\">IndexBackward</text>\n",
       "</g>\n",
       "<!-- 139856869300768&#45;&gt;139856869299648 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>139856869300768&#45;&gt;139856869299648</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M493.219,-974.812C507.777,-964.894 530.616,-949.333 547.605,-937.758\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"549.588,-940.643 555.881,-932.119 545.646,-934.858 549.588,-940.643\"/>\n",
       "</g>\n",
       "<!-- 139856869302000 -->\n",
       "<g id=\"node18\" class=\"node\"><title>139856869302000</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"531,-1060 427,-1060 427,-1039 531,-1039 531,-1060\"/>\n",
       "<text text-anchor=\"middle\" x=\"479\" y=\"-1046.4\" font-family=\"Times,serif\" font-size=\"12.00\">PermuteBackward</text>\n",
       "</g>\n",
       "<!-- 139856869302000&#45;&gt;139856869300768 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>139856869302000&#45;&gt;139856869300768</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M479,-1038.81C479,-1030.22 479,-1017.39 479,-1006.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"482.5,-1006.32 479,-996.324 475.5,-1006.32 482.5,-1006.32\"/>\n",
       "</g>\n",
       "<!-- 139856869301440 -->\n",
       "<g id=\"node19\" class=\"node\"><title>139856869301440</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"539.5,-1117 418.5,-1117 418.5,-1096 539.5,-1096 539.5,-1117\"/>\n",
       "<text text-anchor=\"middle\" x=\"479\" y=\"-1103.4\" font-family=\"Times,serif\" font-size=\"12.00\">IndexSelectBackward</text>\n",
       "</g>\n",
       "<!-- 139856869301440&#45;&gt;139856869302000 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>139856869301440&#45;&gt;139856869302000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M479,-1095.92C479,-1088.91 479,-1079.14 479,-1070.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"482.5,-1070.34 479,-1060.34 475.5,-1070.34 482.5,-1070.34\"/>\n",
       "</g>\n",
       "<!-- 139856869298360 -->\n",
       "<g id=\"node20\" class=\"node\"><title>139856869298360</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"514.5,-1174 443.5,-1174 443.5,-1153 514.5,-1153 514.5,-1174\"/>\n",
       "<text text-anchor=\"middle\" x=\"479\" y=\"-1160.4\" font-family=\"Times,serif\" font-size=\"12.00\">CopySlices</text>\n",
       "</g>\n",
       "<!-- 139856869298360&#45;&gt;139856869301440 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>139856869298360&#45;&gt;139856869301440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M479,-1152.92C479,-1145.91 479,-1136.14 479,-1127.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"482.5,-1127.34 479,-1117.34 475.5,-1127.34 482.5,-1127.34\"/>\n",
       "</g>\n",
       "<!-- 139856869301552 -->\n",
       "<g id=\"node21\" class=\"node\"><title>139856869301552</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"464.5,-1231 393.5,-1231 393.5,-1210 464.5,-1210 464.5,-1231\"/>\n",
       "<text text-anchor=\"middle\" x=\"429\" y=\"-1217.4\" font-family=\"Times,serif\" font-size=\"12.00\">CopySlices</text>\n",
       "</g>\n",
       "<!-- 139856869301552&#45;&gt;139856869298360 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>139856869301552&#45;&gt;139856869298360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M437.709,-1209.92C444.721,-1202.21 454.76,-1191.16 463.184,-1181.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"465.917,-1184.09 470.054,-1174.34 460.737,-1179.39 465.917,-1184.09\"/>\n",
       "</g>\n",
       "<!-- 139856869301384 -->\n",
       "<g id=\"node22\" class=\"node\"><title>139856869301384</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"357.5,-1288 286.5,-1288 286.5,-1267 357.5,-1267 357.5,-1288\"/>\n",
       "<text text-anchor=\"middle\" x=\"322\" y=\"-1274.4\" font-family=\"Times,serif\" font-size=\"12.00\">CopySlices</text>\n",
       "</g>\n",
       "<!-- 139856869301384&#45;&gt;139856869301552 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>139856869301384&#45;&gt;139856869301552</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M340.638,-1266.92C357.336,-1258.34 382.06,-1245.63 401.112,-1235.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"402.923,-1238.84 410.217,-1231.16 399.723,-1232.61 402.923,-1238.84\"/>\n",
       "</g>\n",
       "<!-- 139856869300936 -->\n",
       "<g id=\"node23\" class=\"node\"><title>139856869300936</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"250.5,-1345 179.5,-1345 179.5,-1324 250.5,-1324 250.5,-1345\"/>\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-1331.4\" font-family=\"Times,serif\" font-size=\"12.00\">CopySlices</text>\n",
       "</g>\n",
       "<!-- 139856869300936&#45;&gt;139856869301384 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>139856869300936&#45;&gt;139856869301384</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.638,-1323.92C250.336,-1315.34 275.06,-1302.63 294.112,-1292.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"295.923,-1295.84 303.217,-1288.16 292.723,-1289.61 295.923,-1295.84\"/>\n",
       "</g>\n",
       "<!-- 139856869298976 -->\n",
       "<g id=\"node24\" class=\"node\"><title>139856869298976</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148.5,-1402 77.5,-1402 77.5,-1381 148.5,-1381 148.5,-1402\"/>\n",
       "<text text-anchor=\"middle\" x=\"113\" y=\"-1388.4\" font-family=\"Times,serif\" font-size=\"12.00\">CopySlices</text>\n",
       "</g>\n",
       "<!-- 139856869298976&#45;&gt;139856869300936 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>139856869298976&#45;&gt;139856869300936</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.767,-1380.92C146.612,-1372.38 170.038,-1359.74 188.166,-1349.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"189.954,-1352.98 197.094,-1345.16 186.631,-1346.82 189.954,-1352.98\"/>\n",
       "</g>\n",
       "<!-- 139856908687176 -->\n",
       "<g id=\"node25\" class=\"node\"><title>139856908687176</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"156,-1459 64,-1459 64,-1438 156,-1438 156,-1459\"/>\n",
       "<text text-anchor=\"middle\" x=\"110\" y=\"-1445.4\" font-family=\"Times,serif\" font-size=\"12.00\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 139856908687176&#45;&gt;139856869298976 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>139856908687176&#45;&gt;139856869298976</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110.523,-1437.92C110.905,-1430.91 111.438,-1421.14 111.911,-1412.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.413,-1412.52 112.463,-1402.34 108.424,-1412.14 115.413,-1412.52\"/>\n",
       "</g>\n",
       "<!-- 139856908685944 -->\n",
       "<g id=\"node26\" class=\"node\"><title>139856908685944</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"152.5,-1516 63.5,-1516 63.5,-1495 152.5,-1495 152.5,-1516\"/>\n",
       "<text text-anchor=\"middle\" x=\"108\" y=\"-1502.4\" font-family=\"Times,serif\" font-size=\"12.00\">SliceBackward</text>\n",
       "</g>\n",
       "<!-- 139856908685944&#45;&gt;139856908687176 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>139856908685944&#45;&gt;139856908687176</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.348,-1494.92C108.603,-1487.91 108.958,-1478.14 109.274,-1469.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.776,-1469.46 109.642,-1459.34 105.781,-1469.21 112.776,-1469.46\"/>\n",
       "</g>\n",
       "<!-- 139856921714816 -->\n",
       "<g id=\"node27\" class=\"node\"><title>139856921714816</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"381,-1573 263,-1573 263,-1552 381,-1552 381,-1573\"/>\n",
       "<text text-anchor=\"middle\" x=\"322\" y=\"-1559.4\" font-family=\"Times,serif\" font-size=\"12.00\">CudnnRnnBackward</text>\n",
       "</g>\n",
       "<!-- 139856921714816&#45;&gt;139856908685944 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>139856921714816&#45;&gt;139856908685944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M284.724,-1551.92C248.778,-1542.68 194.236,-1528.66 155.259,-1518.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.764,-1515.16 145.207,-1516.06 154.021,-1521.94 155.764,-1515.16\"/>\n",
       "</g>\n",
       "<!-- 139856908685496 -->\n",
       "<g id=\"node37\" class=\"node\"><title>139856908685496</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"259.5,-1516 170.5,-1516 170.5,-1495 259.5,-1495 259.5,-1516\"/>\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-1502.4\" font-family=\"Times,serif\" font-size=\"12.00\">SliceBackward</text>\n",
       "</g>\n",
       "<!-- 139856921714816&#45;&gt;139856908685496 -->\n",
       "<g id=\"edge37\" class=\"edge\"><title>139856921714816&#45;&gt;139856908685496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M303.362,-1551.92C286.664,-1543.34 261.94,-1530.63 242.888,-1520.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"244.277,-1517.61 233.783,-1516.16 241.077,-1523.84 244.277,-1517.61\"/>\n",
       "</g>\n",
       "<!-- 139856908686392 -->\n",
       "<g id=\"node39\" class=\"node\"><title>139856908686392</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"366.5,-1516 277.5,-1516 277.5,-1495 366.5,-1495 366.5,-1516\"/>\n",
       "<text text-anchor=\"middle\" x=\"322\" y=\"-1502.4\" font-family=\"Times,serif\" font-size=\"12.00\">SliceBackward</text>\n",
       "</g>\n",
       "<!-- 139856921714816&#45;&gt;139856908686392 -->\n",
       "<g id=\"edge40\" class=\"edge\"><title>139856921714816&#45;&gt;139856908686392</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M322,-1551.92C322,-1544.91 322,-1535.14 322,-1526.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"325.5,-1526.34 322,-1516.34 318.5,-1526.34 325.5,-1526.34\"/>\n",
       "</g>\n",
       "<!-- 139856869300376 -->\n",
       "<g id=\"node41\" class=\"node\"><title>139856869300376</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"473.5,-1516 384.5,-1516 384.5,-1495 473.5,-1495 473.5,-1516\"/>\n",
       "<text text-anchor=\"middle\" x=\"429\" y=\"-1502.4\" font-family=\"Times,serif\" font-size=\"12.00\">SliceBackward</text>\n",
       "</g>\n",
       "<!-- 139856921714816&#45;&gt;139856869300376 -->\n",
       "<g id=\"edge43\" class=\"edge\"><title>139856921714816&#45;&gt;139856869300376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M340.638,-1551.92C357.336,-1543.34 382.06,-1530.63 401.112,-1520.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"402.923,-1523.84 410.217,-1516.16 399.723,-1517.61 402.923,-1523.84\"/>\n",
       "</g>\n",
       "<!-- 139856869302224 -->\n",
       "<g id=\"node43\" class=\"node\"><title>139856869302224</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"580.5,-1516 491.5,-1516 491.5,-1495 580.5,-1495 580.5,-1516\"/>\n",
       "<text text-anchor=\"middle\" x=\"536\" y=\"-1502.4\" font-family=\"Times,serif\" font-size=\"12.00\">SliceBackward</text>\n",
       "</g>\n",
       "<!-- 139856921714816&#45;&gt;139856869302224 -->\n",
       "<g id=\"edge46\" class=\"edge\"><title>139856921714816&#45;&gt;139856869302224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.276,-1551.92C395.222,-1542.68 449.764,-1528.66 488.741,-1518.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"489.979,-1521.94 498.793,-1516.06 488.236,-1515.16 489.979,-1521.94\"/>\n",
       "</g>\n",
       "<!-- 139856921715320 -->\n",
       "<g id=\"node28\" class=\"node\"><title>139856921715320</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"170,-1637 0,-1637 0,-1616 170,-1616 170,-1637\"/>\n",
       "<text text-anchor=\"middle\" x=\"85\" y=\"-1623.4\" font-family=\"Times,serif\" font-size=\"12.00\">PackPaddedSequenceBackward</text>\n",
       "</g>\n",
       "<!-- 139856921715320&#45;&gt;139856921714816 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>139856921715320&#45;&gt;139856921714816</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M121.512,-1615.95C162.917,-1605.12 230.516,-1587.43 275.62,-1575.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"276.658,-1578.98 285.447,-1573.06 274.886,-1572.21 276.658,-1578.98\"/>\n",
       "</g>\n",
       "<!-- 139856921714928 -->\n",
       "<g id=\"node29\" class=\"node\"><title>139856921714928</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"145.5,-1701 24.5,-1701 24.5,-1680 145.5,-1680 145.5,-1701\"/>\n",
       "<text text-anchor=\"middle\" x=\"85\" y=\"-1687.4\" font-family=\"Times,serif\" font-size=\"12.00\">IndexSelectBackward</text>\n",
       "</g>\n",
       "<!-- 139856921714928&#45;&gt;139856921715320 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>139856921714928&#45;&gt;139856921715320</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85,-1679.81C85,-1671.22 85,-1658.39 85,-1647.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"88.5001,-1647.32 85,-1637.32 81.5001,-1647.32 88.5001,-1647.32\"/>\n",
       "</g>\n",
       "<!-- 139856921714872 -->\n",
       "<g id=\"node30\" class=\"node\"><title>139856921714872</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"145,-1758 25,-1758 25,-1737 145,-1737 145,-1758\"/>\n",
       "<text text-anchor=\"middle\" x=\"85\" y=\"-1744.4\" font-family=\"Times,serif\" font-size=\"12.00\">EmbeddingBackward</text>\n",
       "</g>\n",
       "<!-- 139856921714872&#45;&gt;139856921714928 -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>139856921714872&#45;&gt;139856921714928</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85,-1736.92C85,-1729.91 85,-1720.14 85,-1711.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"88.5001,-1711.34 85,-1701.34 81.5001,-1711.34 88.5001,-1711.34\"/>\n",
       "</g>\n",
       "<!-- 139856921715264 -->\n",
       "<g id=\"node31\" class=\"node\"><title>139856921715264</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"125.5,-1829 44.5,-1829 44.5,-1794 125.5,-1794 125.5,-1829\"/>\n",
       "<text text-anchor=\"middle\" x=\"85\" y=\"-1801.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (14384, 300)</text>\n",
       "</g>\n",
       "<!-- 139856921715264&#45;&gt;139856921714872 -->\n",
       "<g id=\"edge30\" class=\"edge\"><title>139856921715264&#45;&gt;139856921714872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85,-1793.89C85,-1785.99 85,-1776.5 85,-1768.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"88.5001,-1768.02 85,-1758.02 81.5001,-1768.02 88.5001,-1768.02\"/>\n",
       "</g>\n",
       "<!-- 139856921715152 -->\n",
       "<g id=\"node32\" class=\"node\"><title>139856921715152</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"263.5,-1644 188.5,-1644 188.5,-1609 263.5,-1609 263.5,-1644\"/>\n",
       "<text text-anchor=\"middle\" x=\"226\" y=\"-1616.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (4096, 300)</text>\n",
       "</g>\n",
       "<!-- 139856921715152&#45;&gt;139856921714816 -->\n",
       "<g id=\"edge31\" class=\"edge\"><title>139856921715152&#45;&gt;139856921714816</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.726,-1608.89C266.305,-1599.47 284.407,-1587.78 298.587,-1578.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"300.761,-1581.38 307.263,-1573.02 296.964,-1575.5 300.761,-1581.38\"/>\n",
       "</g>\n",
       "<!-- 139856921716944 -->\n",
       "<g id=\"node33\" class=\"node\"><title>139856921716944</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"362.5,-1644 281.5,-1644 281.5,-1609 362.5,-1609 362.5,-1644\"/>\n",
       "<text text-anchor=\"middle\" x=\"322\" y=\"-1616.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (4096, 1024)</text>\n",
       "</g>\n",
       "<!-- 139856921716944&#45;&gt;139856921714816 -->\n",
       "<g id=\"edge32\" class=\"edge\"><title>139856921716944&#45;&gt;139856921714816</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M322,-1608.89C322,-1600.99 322,-1591.5 322,-1583.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"325.5,-1583.02 322,-1573.02 318.5,-1583.02 325.5,-1583.02\"/>\n",
       "</g>\n",
       "<!-- 139856921716272 -->\n",
       "<g id=\"node34\" class=\"node\"><title>139856921716272</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"435,-1644 381,-1644 381,-1609 435,-1609 435,-1644\"/>\n",
       "<text text-anchor=\"middle\" x=\"408\" y=\"-1616.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (4096)</text>\n",
       "</g>\n",
       "<!-- 139856921716272&#45;&gt;139856921714816 -->\n",
       "<g id=\"edge33\" class=\"edge\"><title>139856921716272&#45;&gt;139856921714816</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M384.954,-1608.89C372.017,-1599.56 355.986,-1588 343.338,-1578.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"345.361,-1576.03 335.202,-1573.02 341.267,-1581.7 345.361,-1576.03\"/>\n",
       "</g>\n",
       "<!-- 139856921714760 -->\n",
       "<g id=\"node35\" class=\"node\"><title>139856921714760</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"507,-1644 453,-1644 453,-1609 507,-1609 507,-1644\"/>\n",
       "<text text-anchor=\"middle\" x=\"480\" y=\"-1616.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (4096)</text>\n",
       "</g>\n",
       "<!-- 139856921714760&#45;&gt;139856921714816 -->\n",
       "<g id=\"edge34\" class=\"edge\"><title>139856921714760&#45;&gt;139856921714816</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M452.966,-1612.85C449.955,-1611.52 446.921,-1610.21 444,-1609 415.74,-1597.27 383.259,-1585.23 358.92,-1576.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"359.951,-1573.13 349.356,-1573.06 357.594,-1579.72 359.951,-1573.13\"/>\n",
       "</g>\n",
       "<!-- 139856869300880 -->\n",
       "<g id=\"node36\" class=\"node\"><title>139856869300880</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"261,-1402 169,-1402 169,-1381 261,-1381 261,-1402\"/>\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-1388.4\" font-family=\"Times,serif\" font-size=\"12.00\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 139856869300880&#45;&gt;139856869300936 -->\n",
       "<g id=\"edge35\" class=\"edge\"><title>139856869300880&#45;&gt;139856869300936</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M215,-1380.92C215,-1373.91 215,-1364.14 215,-1355.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"218.5,-1355.34 215,-1345.34 211.5,-1355.34 218.5,-1355.34\"/>\n",
       "</g>\n",
       "<!-- 139856908685496&#45;&gt;139856869300880 -->\n",
       "<g id=\"edge36\" class=\"edge\"><title>139856908685496&#45;&gt;139856869300880</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M215,-1494.95C215,-1476.68 215,-1436.46 215,-1412.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"218.5,-1412.02 215,-1402.02 211.5,-1412.02 218.5,-1412.02\"/>\n",
       "</g>\n",
       "<!-- 139856869298416 -->\n",
       "<g id=\"node38\" class=\"node\"><title>139856869298416</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"368,-1345 276,-1345 276,-1324 368,-1324 368,-1345\"/>\n",
       "<text text-anchor=\"middle\" x=\"322\" y=\"-1331.4\" font-family=\"Times,serif\" font-size=\"12.00\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 139856869298416&#45;&gt;139856869301384 -->\n",
       "<g id=\"edge38\" class=\"edge\"><title>139856869298416&#45;&gt;139856869301384</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M322,-1323.92C322,-1316.91 322,-1307.14 322,-1298.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"325.5,-1298.34 322,-1288.34 318.5,-1298.34 325.5,-1298.34\"/>\n",
       "</g>\n",
       "<!-- 139856908686392&#45;&gt;139856869298416 -->\n",
       "<g id=\"edge39\" class=\"edge\"><title>139856908686392&#45;&gt;139856869298416</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M322,-1494.93C322,-1468.21 322,-1392.4 322,-1355.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"325.5,-1355.39 322,-1345.39 318.5,-1355.39 325.5,-1355.39\"/>\n",
       "</g>\n",
       "<!-- 139856869300208 -->\n",
       "<g id=\"node40\" class=\"node\"><title>139856869300208</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"475,-1288 383,-1288 383,-1267 475,-1267 475,-1288\"/>\n",
       "<text text-anchor=\"middle\" x=\"429\" y=\"-1274.4\" font-family=\"Times,serif\" font-size=\"12.00\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 139856869300208&#45;&gt;139856869301552 -->\n",
       "<g id=\"edge41\" class=\"edge\"><title>139856869300208&#45;&gt;139856869301552</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M429,-1266.92C429,-1259.91 429,-1250.14 429,-1241.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.5,-1241.34 429,-1231.34 425.5,-1241.34 432.5,-1241.34\"/>\n",
       "</g>\n",
       "<!-- 139856869300376&#45;&gt;139856869300208 -->\n",
       "<g id=\"edge42\" class=\"edge\"><title>139856869300376&#45;&gt;139856869300208</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M429,-1494.79C429,-1460.52 429,-1344.83 429,-1298.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.5,-1298.17 429,-1288.17 425.5,-1298.17 432.5,-1298.17\"/>\n",
       "</g>\n",
       "<!-- 139856869299088 -->\n",
       "<g id=\"node42\" class=\"node\"><title>139856869299088</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"578,-1231 486,-1231 486,-1210 578,-1210 578,-1231\"/>\n",
       "<text text-anchor=\"middle\" x=\"532\" y=\"-1217.4\" font-family=\"Times,serif\" font-size=\"12.00\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 139856869299088&#45;&gt;139856869298360 -->\n",
       "<g id=\"edge44\" class=\"edge\"><title>139856869299088&#45;&gt;139856869298360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M522.768,-1209.92C515.261,-1202.13 504.479,-1190.94 495.495,-1181.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"497.942,-1179.11 488.483,-1174.34 492.902,-1183.97 497.942,-1179.11\"/>\n",
       "</g>\n",
       "<!-- 139856869302224&#45;&gt;139856869299088 -->\n",
       "<g id=\"edge45\" class=\"edge\"><title>139856869302224&#45;&gt;139856869299088</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535.713,-1494.91C535.16,-1475.56 534,-1430.42 534,-1392.5 534,-1392.5 534,-1392.5 534,-1333.5 534,-1301.21 533.159,-1263.68 532.567,-1241.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"536.06,-1240.99 532.287,-1231.09 529.063,-1241.18 536.06,-1240.99\"/>\n",
       "</g>\n",
       "<!-- 139856869298752 -->\n",
       "<g id=\"node44\" class=\"node\"><title>139856869298752</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"597,-1003 543,-1003 543,-968 597,-968 597,-1003\"/>\n",
       "<text text-anchor=\"middle\" x=\"570\" y=\"-975.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 139856869298752&#45;&gt;139856869299648 -->\n",
       "<g id=\"edge47\" class=\"edge\"><title>139856869298752&#45;&gt;139856869299648</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M570,-967.885C570,-959.994 570,-950.505 570,-942.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"573.5,-942.018 570,-932.018 566.5,-942.018 573.5,-942.018\"/>\n",
       "</g>\n",
       "<!-- 139856869301104 -->\n",
       "<g id=\"node45\" class=\"node\"><title>139856869301104</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"669,-1003 615,-1003 615,-968 669,-968 669,-1003\"/>\n",
       "<text text-anchor=\"middle\" x=\"642\" y=\"-975.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 139856869301104&#45;&gt;139856869299648 -->\n",
       "<g id=\"edge48\" class=\"edge\"><title>139856869301104&#45;&gt;139856869299648</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M622.705,-967.885C612.187,-958.828 599.225,-947.666 588.788,-938.678\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"590.914,-935.891 581.053,-932.018 586.347,-941.195 590.914,-935.891\"/>\n",
       "</g>\n",
       "<!-- 139856869299312 -->\n",
       "<g id=\"node46\" class=\"node\"><title>139856869299312</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"707.5,-633 634.5,-633 634.5,-612 707.5,-612 707.5,-633\"/>\n",
       "<text text-anchor=\"middle\" x=\"671\" y=\"-619.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139856869299312&#45;&gt;139856869299424 -->\n",
       "<g id=\"edge49\" class=\"edge\"><title>139856869299312&#45;&gt;139856869299424</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M662.116,-611.92C654.965,-604.207 644.725,-593.164 636.133,-583.898\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"638.491,-581.294 629.125,-576.341 633.358,-586.053 638.491,-581.294\"/>\n",
       "</g>\n",
       "<!-- 139856869300992 -->\n",
       "<g id=\"node47\" class=\"node\"><title>139856869300992</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"708.5,-704 633.5,-704 633.5,-669 708.5,-669 708.5,-704\"/>\n",
       "<text text-anchor=\"middle\" x=\"671\" y=\"-676.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (512, 3077)</text>\n",
       "</g>\n",
       "<!-- 139856869300992&#45;&gt;139856869299312 -->\n",
       "<g id=\"edge50\" class=\"edge\"><title>139856869300992&#45;&gt;139856869299312</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M671,-668.885C671,-660.994 671,-651.505 671,-643.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"674.5,-643.018 671,-633.018 667.5,-643.018 674.5,-643.018\"/>\n",
       "</g>\n",
       "<!-- 139856869299144 -->\n",
       "<g id=\"node48\" class=\"node\"><title>139856869299144</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"755,-519 701,-519 701,-484 755,-484 755,-519\"/>\n",
       "<text text-anchor=\"middle\" x=\"728\" y=\"-491.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (512)</text>\n",
       "</g>\n",
       "<!-- 139856869299144&#45;&gt;139856998461000 -->\n",
       "<g id=\"edge51\" class=\"edge\"><title>139856869299144&#45;&gt;139856998461000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M713.529,-483.885C705.953,-475.187 696.686,-464.547 689.029,-455.756\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"691.497,-453.26 682.29,-448.018 686.218,-457.857 691.497,-453.26\"/>\n",
       "</g>\n",
       "<!-- 139857005892944 -->\n",
       "<g id=\"node49\" class=\"node\"><title>139857005892944</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"866.5,-320 793.5,-320 793.5,-299 866.5,-299 866.5,-320\"/>\n",
       "<text text-anchor=\"middle\" x=\"830\" y=\"-306.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139857005892944&#45;&gt;139857005870608 -->\n",
       "<g id=\"edge52\" class=\"edge\"><title>139857005892944&#45;&gt;139857005870608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M821.116,-298.92C813.965,-291.207 803.725,-280.164 795.133,-270.898\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"797.491,-268.294 788.125,-263.341 792.358,-273.053 797.491,-268.294\"/>\n",
       "</g>\n",
       "<!-- 139856998461392 -->\n",
       "<g id=\"node50\" class=\"node\"><title>139856998461392</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"858.5,-391 801.5,-391 801.5,-356 858.5,-356 858.5,-391\"/>\n",
       "<text text-anchor=\"middle\" x=\"830\" y=\"-363.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1, 512)</text>\n",
       "</g>\n",
       "<!-- 139856998461392&#45;&gt;139857005892944 -->\n",
       "<g id=\"edge53\" class=\"edge\"><title>139856998461392&#45;&gt;139857005892944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M830,-355.885C830,-347.994 830,-338.505 830,-330.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"833.5,-330.018 830,-320.018 826.5,-330.018 833.5,-330.018\"/>\n",
       "</g>\n",
       "<!-- 139859099098472 -->\n",
       "<g id=\"node51\" class=\"node\"><title>139859099098472</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"914,-206 860,-206 860,-171 914,-171 914,-206\"/>\n",
       "<text text-anchor=\"middle\" x=\"887\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 139859099098472&#45;&gt;139856939130496 -->\n",
       "<g id=\"edge54\" class=\"edge\"><title>139859099098472&#45;&gt;139856939130496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M872.529,-170.885C864.953,-162.187 855.686,-151.547 848.029,-142.756\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"850.497,-140.26 841.29,-135.018 845.218,-144.857 850.497,-140.26\"/>\n",
       "</g>\n",
       "<!-- 139856939102840 -->\n",
       "<g id=\"node52\" class=\"node\"><title>139856939102840</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"560,-135 468,-135 468,-114 560,-114 560,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"514\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 139856939102280 -->\n",
       "<g id=\"node53\" class=\"node\"><title>139856939102280</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"630.5,-199 505.5,-199 505.5,-178 630.5,-178 630.5,-199\"/>\n",
       "<text text-anchor=\"middle\" x=\"568\" y=\"-185.4\" font-family=\"Times,serif\" font-size=\"12.00\">UnsafeViewBackward</text>\n",
       "</g>\n",
       "<!-- 139856939102280&#45;&gt;139856939102840 -->\n",
       "<g id=\"edge55\" class=\"edge\"><title>139856939102280&#45;&gt;139856939102840</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M559.562,-177.812C551.447,-168.495 538.995,-154.197 529.158,-142.903\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"531.764,-140.566 522.556,-135.324 526.485,-145.164 531.764,-140.566\"/>\n",
       "</g>\n",
       "<!-- 139857005870104 -->\n",
       "<g id=\"node54\" class=\"node\"><title>139857005870104</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"610.5,-263 525.5,-263 525.5,-242 610.5,-242 610.5,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"568\" y=\"-249.4\" font-family=\"Times,serif\" font-size=\"12.00\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139857005870104&#45;&gt;139856939102280 -->\n",
       "<g id=\"edge56\" class=\"edge\"><title>139857005870104&#45;&gt;139856939102280</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M568,-241.812C568,-233.218 568,-220.388 568,-209.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"571.5,-209.324 568,-199.324 564.5,-209.324 571.5,-209.324\"/>\n",
       "</g>\n",
       "<!-- 139856998461112&#45;&gt;139857005870104 -->\n",
       "<g id=\"edge57\" class=\"edge\"><title>139856998461112&#45;&gt;139857005870104</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M610.116,-298.92C602.965,-291.207 592.725,-280.164 584.133,-270.898\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"586.491,-268.294 577.125,-263.341 581.358,-273.053 586.491,-268.294\"/>\n",
       "</g>\n",
       "<!-- 139856869300544 -->\n",
       "<g id=\"node56\" class=\"node\"><title>139856869300544</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"554.5,-320 481.5,-320 481.5,-299 554.5,-299 554.5,-320\"/>\n",
       "<text text-anchor=\"middle\" x=\"518\" y=\"-306.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139856869300544&#45;&gt;139857005870104 -->\n",
       "<g id=\"edge59\" class=\"edge\"><title>139856869300544&#45;&gt;139857005870104</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M526.709,-298.92C533.721,-291.207 543.76,-280.164 552.184,-270.898\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"554.917,-273.095 559.054,-263.341 549.737,-268.386 554.917,-273.095\"/>\n",
       "</g>\n",
       "<!-- 139856869301664 -->\n",
       "<g id=\"node57\" class=\"node\"><title>139856869301664</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"546.5,-391 489.5,-391 489.5,-356 546.5,-356 546.5,-391\"/>\n",
       "<text text-anchor=\"middle\" x=\"518\" y=\"-363.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (4, 512)</text>\n",
       "</g>\n",
       "<!-- 139856869301664&#45;&gt;139856869300544 -->\n",
       "<g id=\"edge60\" class=\"edge\"><title>139856869301664&#45;&gt;139856869300544</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M518,-355.885C518,-347.994 518,-338.505 518,-330.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"521.5,-330.018 518,-320.018 514.5,-330.018 521.5,-330.018\"/>\n",
       "</g>\n",
       "<!-- 139859099017288 -->\n",
       "<g id=\"node58\" class=\"node\"><title>139859099017288</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"487,-206 433,-206 433,-171 487,-171 487,-206\"/>\n",
       "<text text-anchor=\"middle\" x=\"460\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (4)</text>\n",
       "</g>\n",
       "<!-- 139859099017288&#45;&gt;139856939102840 -->\n",
       "<g id=\"edge61\" class=\"edge\"><title>139859099017288&#45;&gt;139856939102840</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M474.471,-170.885C482.047,-162.187 491.314,-151.547 498.971,-142.756\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"501.782,-144.857 505.71,-135.018 496.503,-140.26 501.782,-144.857\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f32fb2cb6d8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "make_dot(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f95e74eb978>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VOXZ+PHvnT1kYUsQZAsgO4GkhqVYF0RxBaxiwe0Ft1atC1p/VV+rItXXWq1bi7XWulSpglgVfau4vCjuEhRRdhCUsIZAErJv9++Pc2YyCUlmEjKZgdyf65pr5uz3nJk595znec5zRFUxxhhjmhIR6gCMMcaEP0sWxhhj/LJkYYwxxi9LFsYYY/yyZGGMMcYvSxbGGGP8smRhABCRD0TkilDH0RgRSRMRFZGoUMcSSk19Ts3ZR6Han63xPQv37+qRypKFMWFKROaIyAuHsPwvRORTESkRkQ9aMTRTj4jcKCK7RKRARJ4WkdhG5osRkUUistVN1ie1cagtZsmilbX3f74mrOwDHgH+EOpAAnG4/nZE5DTgVmAikAb0B+5uYpGPgYuBXUEPrhVZsmgF7r+EW0RkFVAsIn1E5BURyRWRLSJyvc+88SLynIjsF5G1IvJbEclpYt2xIvKIiOxwH494/rWIyEkikiMivxGRPSKyU0Qu9RPrVBFZKSKFIrJZRE73mdxXRD4RkQMi8o6IpPgsN0VEVotIvlsMMNRn2i0ist1dbr2ITHTHR4jIre528kRkoYh0cad5ikFmisiPIrJXRG4PYHdf5u6HnSLymwD30y0i8rnnYCQiV7vvJa6J/RQnIi+4ceeLyHIROcqd9oGI3OP+ay8SkTdEpKuIzHf363IRSfNZ13h3XIH7PN5n2tEislhE9onIJhG50h1/OvDfwHR3G98E8jn5UtX3VHUhsMPfTm0sDnfaGBHJdt/bbhF5yN8+CoSIzHLfx8Misg+Y08h8p4rIOnf//QWQetMvc39L+0VkiYj09Zk2XETedd/XbhH5b5/39Jkb904R+YuIxLjT5onIn+pt4w0Rmd3IW5kJ/ENVV6vqfuD3wKyGZlTVClV9RFU/BqoD2E3hQ1XtcYgPYCuwEugNJAArgDuBGJx/Gd8Dp7nz/gH4EOgM9AJWATlNrHsu8DnQDUgFPgV+7047Cahy54kGzgRKgM6NrGsMUACcivNHoScwxJ32AbAZGATEu8N/cKcNAord5aKB3wKb3Pc3GNgGHO3OmwYMcF/PdmPvBcQCfwNe9JlPgb+72xsFlANDG4ndM/+L7j5OB3KBUwLYTxHAMpyD0UBgP5Dp5zP9FfAG0AGIBI4Fkn321SZgANARWANsAE4BooB/As+483Zxt3eJO+0Cd7irO/1D4HEgDshw39NEd9oc4IV6cTX1OXn2UVS9Za4APmhkf0YFEMdnwCXu60RgnL991MR+/QC4wn09C+f7e527b+IbmD8FKASm4Xz3bnSX8azjHPezGOqu43fAp+60JGAn8Bv3fSUBY91pxwLj3GXSgLXAbJ/fyQ4gwieGEuCoRt7TN8D0ejGr5zNuYl/kACeF+vgV8HEu1AEcCQ+cZHGZ+3os8GO96bdRe/DwJg53+AqaThabgTN9hk8DtrqvTwJKfQ8OwB7Pj7mBdf0NeLiRaR8Av/MZvgZ42319B7DQZ1oEsN3d/jHuNk8Bouutc63ngOMO9wAqfX6gCvTymf4lMKOR+DzzD/EZ90ecf3RN7ief5fe5Md0WwGd6GU7CGdnIvrrdZ/hPwFs+w5OBle7rS4Av6y3/Gc6BsjfOv8skn2n3Ac+6r+fQcLJo7HPy7KNmJYsA4liGU6ySEug+amK/fkDdZPGjn/n/C/jcZ1hwDrKedbwFXF7vu1kC9MVJzF8HGNds4NV6391T3dfXAv/x8xs93Wc42t23aX62eVglCyuGaj3b3Oe+wNHu6W2+iOTjFCd4Ts+P9pnXdzlE5CK3yKFIRN7ymf8Hn/l/cMd55Klqlc9wCZAoTlGYZ11F7rTeOF/sxviWoZbg/Is8KAZVrXHj7qmqm3B+aHOAPSLykoh44usLvOqzH9biHJR8iyoa3KZv7CLSx2ce333nuy+a3E+quhVYinOQnNf4LvB6HlgCvOQWa/1RRKJ9pu/2eV3awHCD+84ntp7utH2qeqCBaU1p7HNqKX9xXI5zJrPOLWo62x3vbx8FwvfzxC0e9Hzux1Pv96LOUdZ3mb7Aoz7fsX04CaUnTXzfRWSQiLwpTqV0IfA/OGcEHs/h1CvgPj/vLtfQb7QISPZZ1vPad38e9ixZtB5P973bgC2q2snnkaSqZ7rTd+IUy3j09q5Adb6qJrqPM9zRO3B+EB59CKAMWlV/9FmX52CyDafopLnqxCAi4sa93d3Wv1T1Z+48Ctzvs70z6u2LOFXdHkD8iT6PH30m9fZ57bsvmtxPInIm8FPgfeCBALZfqap3q+owYDxwNs6/3OaqH5cntu3utC4iktTANKj9TgVbk3Go6kZVvQCniO9+YJGIJLTSPqrzHlV1uM/n/hHO78X7mft89zy2Ab+q9x2LV9VPafr7/ldgHTBQVZNx/tD51oW8AEwVkVE4RVyvufE19BtdjVOM6jEK2K2qec3ZEeHOkkXr+xIoFKdSNV5EIkVkhIiMdqcvBG4Tkc4i0hPnFLcpLwK/E5FUtyLzTpwvckv8A7hURCaKU/ncU0SGBLDcQuAsd7lonDLgcuBTERksIieLU5lchvOv2lNx9wRwr6fC0X0PU1sYu8cdItJBRIYDlwIL3PGN7id3+B84xTEzgclu8miUiEwQkXQRicQpM6+kZRWS/wEGiciFIhIlItOBYcCbqroNpxjnPreyeCTOv/j57rK7gTQRadHv1P3uxeEUNUW42zjon7+/OETkYhFJdc8o893FqltxHzXlf4HhInKuOA0Urge6+0x/Auf3NNyNtaOInO9OexPoLiKzxWkAkSQiY91pSW7MRe5v4GrfjapqDrAc54ziFVUtbSLGfwKXi8gwEemMU2/ybGMzu7F4GlfEuPtcGps/XFiyaGWqWo1TZp0BbAH2Ak/hVISCUxGb4057D1iEc+BtzD1ANk5F+LfAV+64lsT2Jc4B9mGciu4POfhfb0PLrcc5Ff8zzvuZDExW1Qqcius/uON34fz7/G930UeBxcA7InIApwJ6LIfmQ5wKzfeBB1X1HXd8U/vpSeB1Vf2P+2/vcuApEenaxHa643w2hTjFZx/SgiTtbu9snASbh9M44GxV3evOcgFO0dgO4FXgLlV91532svucJyJfNXfbOPUlpTj/oo93X/+9kXmbiuN0YLVbnPkoTr1SGa20j5ri7qfzcb5jeTgNFD7xmf4qztnOS25x0nfAGe60AziNMibjfDc3AhPcRW8GLsQpKvo7tX86fD2H05DieT8xvo1Tf7YUp/juB+Auz3S3aO0in0XW43wWPXGK8UoJ4HcYauJWtJgQEZGrcX58J4Y6FmNMLRE5ASf5pblnVe2anVm0MRHpISLHucVAg3H+cb4a6riMMbXc4robgKcsUTgsWbS9GJwmrAeA/wNex2nfbtpYvZYtvo/VoY7tcNbIPvW0bgp74lxwmo/T1PuREIcTNqwYyhhjjF92ZmGMMcavw7LjroakpKRoWlpaqMMwxpjDyooVK/aqaqq/+YKaLMTpDO1RnH5jnlLVg3q/FJFf4Fz9q8A3qnqhO34mTntlgHtU9bmmtpWWlkZ2dnYrRm+MMUc+Eanfw0CDgpYs3At15uG0c84BlovIYlVd4zPPQJx+k45T1f0i0s0d3wWnnXIWThJZ4S67P1jxGmOMaVww6yzGAJtU9Xv34q2XgPpX714JzPMkAVXd444/DXhXVfe5097FuTDIGGNMCAQzWfSkbodfORzcQdognK4QPhHnfgOnN2NZROSX4vSzn52bm9uKoRtjjPEVzGTRUF8n9dvpRuFcvn8STncDT4lIpwCXRVWfVNUsVc1KTfVbP2OMMaaFgpkscqjbO2QvDu4tNQenz55KVd2C02fKwACXNcYY00aCmSyWAwNFpJ84tyucgdOpnK/XcDv2cnsGHYRzc6AlwCS3Z9bOwCR3nDHGmBAIWmsoVa0SkWtxDvKRwNOqulpE5gLZqrqY2qSwBqdr4//n6QNeRH6Pk3AA5qrqvmDFaowxpmlHTHcfWVlZatdZGGMCVVOjVFTXUF5ZQ3lVNeVVNe7DeV3hGa6sN+wzHaBzQgxdE2Lo3CGGronOc+cO0URFHh4dZIjIClXN8jffEXMFtzHm8FdVXUNxRTUlFVUUl1dRXF5NcUUVJe5zcbkzraSi2jloV9YewGsP5vWGKxueXlkd3D/KHeOj6ZIQQxdPIkmIoXNCDF0SoumSEFv73CGGLokxJMREEs73QLJkYYxpkarqGkoqqykpr6aovMo9wLsH+opq92DvHNiL3YO/56BfUuEuU2/Y8289ENGRQkxkBLHRkcRGRRATFUFsVASxUbXDibFRxEZF1k6LjiAmMpLY6Np5a5fzrMOdHhnhzhdZd5rPtmoU8ksqyCuuYH+x+1xSQV6R87yv2Hnk7C9hVU4++0sqGk1SMZERdD4okdQOd3YTj28Cim7DsxdLFsYchqqqa7xFIRXVniKSusUlFT7TPf+sff9de6dV1lBRXXd67XK+63LWX+oe2MubcWCPjYogITaKDjGRJPo8H5UUR4fYSBJiougQG0liTBQdYqNIiImkQ2wUibGRdIiJqp3uLtshJorIiPD4F94tOY5uyXH+ZwRUlaLyKm8SqfMocRKOZ/jb/fnsK66gsKyq0fUlx0XRJSGGn/TpzEPTM1rrLTXIkoUxIVBdoxSWVrK/pIL9JZXk13muYF9x7ev8kkrySyopqajyJoaaVipBiY4U77/rmMjaf8wxnkdkBB3jo51/8O642gN+FAmeg7nvAb/+tJjIw6b8PthEhKS4aJLiounbNSGgZSqra5zvSXElecXl7C+uZF9xOfuKne9PXnEFKUmxQY7ckoUxh6ysspr8Es+Bv6L2dbGTAHzHeZ4LSitprG1JZITQuUM0ndyK0t5dOjCyVzQdYqJqD+aRtQd078HeHe8pQmlqekyk84gIk3/npnHRkRF0S4qjW1IckBSyOCxZmHatpkYpraxbiVpSUe08yp2y94LS2n/53n//xbVnA6WV1Y2uv0NMJJ07xNCpQzSdO8TQs1O801omwUkEvtM6d4ihU0I0SbFRYV3RadonSxbmsKCqlFfVOJWlPpWmJT6tYw4+4Ncd9ixX4m1tU93kgd5XhDitWzwH9x4d4xjaI9k54CfUNpfs1CGGzgm188VGRQZ5zxjTNixZmLBQUVXDpj1FrN1ZyLpdhazdeYAd+aV1EkBzyunjoiO8ZegJMVHExzjPKYmx3opWT0Wpb7l7fHTd4Q7RUSTHR5EcF21FNqZds2Rh2tzeonLW7ix0HwdYu7OQzblF3iaFMVERDD4qiWFHJ5MYW3ug97aaiYkkwXe8O5wQE0l8mLWUMeZIYcnCBE1ldQ3f5xZ7E8OanYWs23WA3APl3nm6J8cxpEcSE4Z0Y2iPZIb1SCKta4K1njEmzFiyMK1iX3HFQWcLm/YUUVHttMWPiYxg4FGJnDgolSHdkxjWI5khPZLpkhAT4siNMYGwZGGapaq6hi17i1njJgWnfqGQ3YW1ZwvdkmIZ0iOZ4welOEmhezL9UxPa9GpTY0zrsmRhGpVfUuE9S1jrFiFt2H3Ae+VudKRwTLckjjsmhaHdkxnaI5khPZJISQz+BULGmLZlycIATqXzqpx8vtlWwLfbC1i7s5CdBWXe6SmJMQztkczM8WkM7ZHEkO7JDEhNJCbKzhaMaQ8sWbRDxeVVfLu9gG+25bMqp4CV2/LZnl8KONcTHNMtkbH9ujC0R7L3kdoG3QkYY8KXJYsjXEVVDet3HWBlTj6rtuXzTU4+G/cUebua6N0lnsw+nZg1Po1RvTsxomcyHWLsa2GMqcuOCkeQmhrl+73FbnFSPt/kFLBmZ6G32+euCTGM6t2Js9KPZmTvjozq1claIxljAmLJ4jClquwqLOObbQV8k5PPqpx8Vm0r4EC5051xQkwkI3p25NLxaYzs1YlRvTvSs1O89TlkjGkRSxaHiYKSSm9SWLmtgFU5+exxL26LjhSGdE9maubRjOzViYzenRiQmmhXMRtjWo0lizBUVlnN6h0FPmcNBWzZW+yd3j81gZ8dk8LIXh0Z1bsTQ3skExdtHdYZY4LHkkUYyC+p4ONNe/l0cx4rf8xn/e4DVLu95vXoGMfIXh05P6sXo3p1YkTPjnSMjw5xxMaY9saSRQhUVtewcls+yzbksmzjXlbl5KMKSXFRZPTuxNVDBnjPGo4K8HaNxhgTTJYs2sgPecUs27iXZRty+WxzHkXlVUQIZPbpzA0TB3L8wFRG9epoHegZY8KSJYsgOVBWyaeb8/hoYy7LNuzlx30lAPTqHM+UjKM5YWAKPx2QYkVKxpjDgiWLVlJdo3y7vYBlG3L5aGMuX/2YT3WNkhATyU8HdOWK4/tx/MBU0rp2sOarxpjDjiWLQ7Ajv9R75vDxpr0UlFYiAuk9O3LVif05YWAqmX06W/9JxpjDniWLZiipqOKL7/exbGMuyzbksjnXac56VHIsk4YdxfGDUvnZMSl2VbQx5ohjyaIJNTXK2l2FLNuwl4825pK9dT8V1TXERkUwtn9XLhjThxMGpTKwW6IVLRljjmiWLOrZc6CMj91WSx9v2sveogoAhnRPYtZxaZwwMJWstM52EZwxpl1p98mioqqGL7fs46ONuXy4IZd1uw4ATqd7xw9M4fiBqRw/MIVudr2DMaYda/fJIq+4nIv/8QXRkUJW3y7ccvoQjh/o3A40wvpWMsYYwJIFPTrG868rx5LRu5Pdx8EYYxphR0dg/ICUUIdgjDFhzS4AMMYY41dQk4WInC4i60Vkk4jc2sD0WSKSKyIr3ccVPtOqfcYvDmacxhhjmha0YigRiQTmAacCOcByEVmsqmvqzbpAVa9tYBWlqpoRrPiMMcYELphnFmOATar6vapWAC8BU4O4PWOMMUESzGTRE9jmM5zjjqvvPBFZJSKLRKS3z/g4EckWkc9F5JyGNiAiv3Tnyc7NzW3F0I0xxvgKZrJo6CIFrTf8BpCmqiOB94DnfKb1UdUs4ELgEREZcNDKVJ9U1SxVzUpNTW2tuI0xxtQTzGSRA/ieKfQCdvjOoKp5qlruDv4dONZn2g73+XvgAyAziLEaY4xpQjCTxXJgoIj0E5EYYAZQp1WTiPTwGZwCrHXHdxaRWPd1CnAcUL9i3BhjTBsJWmsoVa0SkWuBJUAk8LSqrhaRuUC2qi4GrheRKUAVsA+Y5S4+FPibiNTgJLQ/NNCKyhhjTBsR1frVCIenrKwszc7ODnUYxhhzWBGRFW79cJPsCm5jjDF+WbIwxhjjlyULY4wxflmyMMYY45clC2OMMX5ZsjDGGOOXJQtjjDF+WbIwxhjjlyULY4wxflmyMMYY45clC2OMMX5ZsjDGGOOXJQtjjDF+WbIwxhjjlyULY4wxflmyMMYY45clC2OMMX5ZsjDGGOOXJQtjjDF+WbIwxhjjlyULY4wxflmyMMYY45clC2OMMX5ZsjDGGOOXJQtjjDF++U0WItKlLQIxxhgTvgI5s/hCRF4WkTNFRIIekTHGmLATSLIYBDwJXAJsEpH/EZFBwQ3LGGNMOPGbLNTxrqpeAFwBzAS+FJEPReSnQY/QGGNMyEX5m0FEugIX45xZ7AauAxYDGcDLQL9gBmiMMSb0/CYL4DPgeeAcVc3xGZ8tIk8EJyxjjDHhJJBkMVhVtaEJqnp/K8djjDEmDAVSwf2OiHTyDIhIZxFZEsSYjDHGhJlAkkWqquZ7BlR1P9AteCEZY4wJN4Eki2oR6eMZEJG+QIPFUsYYY45MgSSL24GPReR5EXkeWAbcFsjKReR0EVkvIptE5NYGps8SkVwRWek+rvCZNlNENrqPmYG+IWOMMa3PbwW3qr4tIj8BxgEC3Kiqe/0tJyKRwDzgVCAHWC4ii1V1Tb1ZF6jqtfWW7QLcBWThnMWscJfdH8ibMsYY07oC7UiwGtgDFADDROSEAJYZA2xS1e9VtQJ4CZga4PZOA95V1X1ugngXOD3AZY0xxrSyQDoSvAKn6GkJcLf7PCeAdfcEtvkM57jj6jtPRFaJyCIR6d2cZUXklyKSLSLZubm5AYRkjDGmJQI5s7gBGA38oKoTgEwgkCNzQ50O1q8YfwNIU9WRwHvAc81YFlV9UlWzVDUrNTU1gJCMMca0RCDJokxVywBEJFZV1wGDA1guB+jtM9wL2OE7g6rmqWq5O/h34NhAlzXGGNN2AkkWOe5Fea8B74rI6wR24F4ODBSRfiISA8zA6VPKS0R6+AxOAda6r5cAk9wLADsDk9xxxhhjQiCQ1lA/d1/OEZGlQEfg7QCWqxKRa3EO8pHA06q6WkTmAtmquhi4XkSmAFXAPmCWu+w+Efk9TsIBmKuq+5r31owxxrQWaaTbJ2eiSASwSlVHtF1ILZOVlaXZ2dmhDsMYYw4rIrJCVbP8zddkMZSq1gDf+F7BbYwxpv0JpNfZHsBqEfkSKPaMVNUpQYvKGGNMWAkkWdwd9CiMMcaEtUAquD9si0CMMcaEr0Buq3qA2gviYoBooFhVk4MZmDHGmPARyJlFku+wiJyD0++TMcaYdiLQjgS9VPU14OQgxGKMMSZMBVIMda7PYAS13YYbY4xpJwJpDTXZ53UVsJXAuxo3xhhzBAikzuLStgjEGGNM+ArkfhbPuR0JeoY7i8jTwQ3LGGNMOAmkgnukquZ7Btw712UGLyRjjDHhJpBkEeF2Ew54748dSF2HMcaYI0QgB/0/AZ+KyCKcVlC/AO4NalTGGGPCSiAV3P8UkWycaysEOFdV1wQ9MmOMMWEjkOssxgGrVfUv7nCSiIxV1S+CHp0xxpiwEEidxV+BIp/hYnecMcaYdiKQZCHqczs994ZIVsFtjDHtSCDJ4nsRuV5Eot3HDcD3wQ7MGGNM+AgkWVwFjAe2AznAWOCXwQzKGGNMeAmkNdQeYEYbxGKMMSZMBdIaKg64HBgOxHnGq+plQYzLGGNMGAmkGOp5oDtwGvAh0As4EMygjDHGhJdAksUxqnoHzq1UnwPOAtKDG5YxxphwEkiyqHSf80VkBNARSAtaRMYYY8JOINdLPOl2JPg7YDGQCNwR1KiMMcaElUBaQz3lvlwG9A9uOMYYY8JRIMVQxhhj2jlLFsYYY/yyZGGMMcavRussROTceqMU2AusVFW7zsIYY9qRpiq4JzcwrgswUkQuV9X/C1JMxhhjwkyjyUJVL21ovIj0BRbidChojDGmHWh2nYWq/gBEByEWY4wxYarZyUJEBgPlAc57uoisF5FNInJrE/NNExEVkSx3OE1ESkVkpft4orlxGmOMaT1NVXC/gVOp7asL0AO42N+KRSQSmAecinMfjOUislhV19SbLwm4Hqh/T+/Nqprh9x0YY4wJuqYquB+sN6xAHrBRVSsCWPcYYJOqfg8gIi8BU4E19eb7PfBH4OaAIjbGGNPmGi2GUtUPPQ9gHZAM9AM6BbjunsA2n+Ecd5yXiGQCvVX1zQaW7yciX4vIhyJyfEMbEJFfiki2iGTn5uYGGJYxxpjm8ltnISK/AL4Ezgd+AXwhItMCWLc0MM5brCUiEcDDwG8amG8n0EdVM4GbgH+JSPJBK1N9UlWzVDUrNTU1gJCMMca0RCC9zt4OjHZvr4qIpALvAYv8LJcD9PYZ7gXs8BlOAkYAH4gIODdYWiwiU1Q1G7cSXVVXiMhmYBCQHUC8xhhjWlkgraEiPInClRfgcsuBgSLST0RicO7jvdgzUVULVDVFVdNUNQ34HJiiqtkikupWkCMi/YGBwPeBvSVjjDGtLZAzi7dFZAnwojs8HfiPv4VUtUpErgWWAJHA06q6WkTmAtmquriJxU8A5opIFVANXKWq+wKI1RhjTBCIav3WsQ3MJHIecBxOPcQyVX012IE1V1ZWlmZnWymVMcY0h4isUNUsf/MFcmaBqr4CvHLIURljjDksNXVR3gEOvigPnLMLVdWDWicZY4w5MjXVkWBSWwZijDEmfNnNj4wxxvhlycIYY4xfliyMMcb4ZcnCGGOMX5YsjDHG+GXJwhhjjF+WLIwxxvhlycIYY4xfliyMMcb4ZcnCGGOMXwF1JGiMMcZVXQnffwhrXoVd30FULETFOY/oOIiKd8ZFu89R8e54zzw+473z+S7vM19kDEhDNx1te5YsjDHGH98Ese5/oXQ/xCZDryyoqYaqMijLh8oy53VVWe3r6vJD2LAcnEQaSkqpg+GUOa30ZhtmycIYYxrSWIIYfAYMOwcGnOwctP2pqalNIHUSSSlUlUNl6cEJpqrMHV/uzFfZ0PJlUFEExXudhBFkliyMMcajtRKEr4gIiOngPA5jliyMMe1bMBLEEciShTGm/bEE0WyWLIwx7YMliENiycKYw4G6dzgOk2aUhw1LEK3GkoUx4aqmBn74GFYthDWLnZYvMQkQ3cFp/eJ5HdMBohPc5w7u+Hif1x0amTe+7nIRkaF+x63DEkRQWLIwJtzsXg2rFsC3i6BwO8QkwpCzoWNPqCiBymKnWaXndUWJ03yyohgqS2rHa03zthsVVzexNJaQYpMhLhniOrqvO9UbTnaWacuzIEsQQWfJwphwUJDjJIdVC2HPaoiIgmNOgUm/h0FnNL/Zparbhr+kbgKp8AwX13suaXze4lzI9xlfVgha3fT2I6LcxNGxXiLpWO91/WnJEOs+R0Y3vQ1LEG3KkoUxoVKaD2sXOwli68eAQq8xcOaDMPxcSOja8nWLOAfK6DigS2tF7FB1kkhZIZQVQLn77Hl4hwvrvi7aXDtcUeR/O9EdGkgk7uuqMtjwtiWINmTJwpi2VFUOG991ipk2LHG6guh6DJx0G4w8H7r0D3WE/ok4xVMxCZDco2XrqK5yEkd5YQNJp4EkVF4IJXmwb4szjMLASZYg2pAlC2OCraYGtn3unEGsftXpQyghFbIuhZG/gKN/0v5aOUVGQYcuzsMcFixZGBMse9bVVlQX/OgUqwzNdxZTAAAYz0lEQVQ5G0ZOh/4nOQdMYw4T9m01pjUV7oTvXnGSxK5VIBFOMcnEO2DwmRCbGOoIjWkRSxbGHKqyQlj3ppMgtixzmqwe/RM4/X4YcS4kdgt1hMYcMksWxrREdSVset9JEOv/47TO6ZwGx9/s1EOkDAx1hMa0KksWxgRKFXKWOwniu39D6T6I7wKZFzv1EL1Gt7+KatNuWLIw4au60n0h7kHYfW7rA/LejU5Lpm8Xwv6tzpXOg890EsSAkyEqpm3jMSYELFmY8FN+AP79S6d4p0n1kkiD45p4xvPU1DzqXMGMQP8T4cRbnBZNccmt/KaNCW+WLEx4KdgO/5oOe9bAuF9DfCe3x1WtfYaDx/mdp7FlaHo9qk79w4jzIPnoNtkFxoSjoCYLETkdeBSIBJ5S1T80Mt804GVgtKpmu+NuAy4HqoHrVXVJMGM1YWDnKvjXL6C8CC5cCANPCXVExhhX0JKFiEQC84BTgRxguYgsVtU19eZLAq4HvvAZNwyYAQwHjgbeE5FBqv56LzOHrQ3vwKJLnX5/Lnsbuo8IdUTGGB8RQVz3GGCTqn6vqhXAS8DUBub7PfBHoMxn3FTgJVUtV9UtwCZ3feZItPwpeHG60y/SFe9ZojAmDAWzGKonsM1nOAcY6zuDiGQCvVX1TRG5ud6yn9dbtmf9DYjIL4FfAvTp06eVwjZtpqYG3rsTPv0zDDwNpj3dJlc4V1ZWkpOTQ1lZmf+ZjTlCxMXF0atXL6Kj/XT93ohgJouG2jeqd6JIBPAwMKu5y3pHqD4JPAmQlZV10HQTxipLnRZPaxfD6Cvh9D+0WV9JOTk5JCUlkZaWhth1EaYdUFXy8vLIycmhX79+LVpHMH+dOUBvn+FewA6f4SRgBPCB+4PtDiwWkSkBLGsOZ0W58OIM2L4CTvsfGHdNm147UVZWZonCtCsiQteuXcnNzW3xOoKZLJYDA0WkH7Adp8L6Qs9EVS0AUjzDIvIBcLOqZotIKfAvEXkIp4J7IPBlEGM1bSV3Pcw/H4r2wPTnYejkkIRhicK0N4f6nQ9aslDVKhG5FliC03T2aVVdLSJzgWxVXdzEsqtFZCGwBqgCfm0toY4AWz6CBRdBZAzM+l/odWyoIzLGBCiohcSq+h/gP/XG3dnIvCfVG74XuDdowZm29c1L8Pq1TounixY6ne4ZYw4bwWw6a4xzBfTS++DVX0GfcXD5EksUzZSY2HgLsa1btzJiRNNNjZ999lmuvfbaOuNOOukksrOzWyW+5khLS2Pv3r0Bz19eXs4pp5xCRkYGCxYsCGJkgbngggsYOXIkDz/8MHfeeSfvvfdeqEOqY+vWrfzrX/8Kyrqtuw8TPFUVsPg6WPUSjLoQJj8adp3u3f3GatbsKGzVdQ47Opm7Jg9v1XW2V19//TWVlZWsXLky4GWqq6uJjIxs0faqqqqIimr4sLhr1y4+/fRTfvjhhxatuy14ksWFF17of+ZmsjMLExyl++GFc51EMeF2OOfxsEsUoXLLLbfw+OOPe4fnzJnD3XffzcSJE/nJT35Ceno6r7/+erPXW1ZWxqWXXkp6ejqZmZksXbq0xTFeffXVZGVlMXz4cO666y7v+OXLlzN+/HhGjRrFmDFjOHDgANXV1dx8882kp6czcuRI/vznPze57gceeIAxY8YwZswYNm3aBEBubi7nnXceo0ePZvTo0XzyySfs2bOHiy++mJUrV5KRkcHmzZt5//33yczMJD09ncsuu4zy8nLAOWOZO3cuP/vZz3j55ZfZvHkzp59+OsceeyzHH38869atazSeWbNmcdNNNzFhwgRuueUWiouLueyyyxg9ejSZmZnez2LSpEns2bOHjIwMPvroI2bNmsWiRYu827/rrru8n59ne42t69lnn+Wcc85h8uTJ9OvXj7/85S889NBDZGZmMm7cOPbt2wfQ6PuYNWsW119/PePHj6d///7eOG699VY++ugjMjIyePjhh5v3ofujqkfE49hjj1UTJvK+V33sWNW5KarfLAh1NAdZs2ZNSLf/1Vdf6QknnOAdHjp0qP7www9aUFCgqqq5ubk6YMAArampUVXVhISERte1ZcsWHT58uKqqPvjggzpr1ixVVV27dq327t1bS0tL9ZlnntFf//rXdZY78cQTdfny5Y2uNy8vT1VVq6qq9MQTT9RvvvlGy8vLtV+/fvrll1+qqmpBQYFWVlbq448/rueee65WVlbWWbYhffv21XvuuUdVVZ977jk966yzVFX1ggsu0I8++khVVX/44QcdMmSIqqouXbrUO09paan26tVL169fr6qql1xyiT788MPe9d5///3e7Zx88sm6YcMGVVX9/PPPdcKECY3GNHPmTD3rrLO0qqpKVVVvu+02ff7551VVdf/+/Tpw4EAtKiqqs689y7388sve7T/22GOqqjpv3jy9/PLLm1zXM888owMGDNDCwkLds2ePJicn61//+ldVVZ09e7b3fTX2PmbOnKnTpk3T6upqXb16tQ4YMOCg/dWQhr77OA2O/B5jrRjKtK5ty51rKGqq4JLXIO24UEcUdjIzM9mzZw87duwgNzeXzp0706NHD2688UaWLVtGREQE27dvZ/fu3XTv3j3g9X788cdcd911AAwZMoS+ffuyYcOGRptMNtWUcuHChTz55JNUVVWxc+dO1qxZg4jQo0cPRo8eDUBystNN+3vvvcdVV13lLb7p0qVLk3FecMEF3ucbb7zRu441a2q7jSssLOTAgQN1llu/fj39+vVj0KBBAMycOZN58+Yxe/ZsAKZPnw5AUVERn376Keeff753Wc8ZSGPOP/98b9HVO++8w+LFi3nwwQcB54ztxx9/JD4+vsl1nHvuuQAce+yx/Pvf/25yXQATJkwgKSmJpKQkOnbsyOTJTjPy9PR0Vq1a5fd9nHPOOURERDBs2DB2797dZGytwZKFaT1rXneuyk7qDhctsluLNmHatGksWrSIXbt2MWPGDObPn09ubi4rVqwgOjqatLS0ZndHotpwJwZdu3Zl//79dcbt27ePlJSUBuffsmULDz74IMuXL6dz587MmjWLsrIyVLXBBNPY+Mb4zut5XVNTw2effdbkAbmx9+eRkJDgXVenTp2aVc/hWdaznVdeeYXBgwfXmWfr1q1NriM2NhaAyMhIqqqqmlzXF1984Z0fICIiwjscERFBVVWV3/fhu7y/fdMarM7CHDpV+OQxWDgTuo+EK963ROHHjBkzeOmll1i0aBHTpk2joKCAbt26ER0dzdKlS1tUiXrCCScwf/58ADZs2MCPP/7I4MGDvXUAu3btAiA7O5vy8nJ69+7d4HoKCwtJSEigY8eO7N69m7feegtwzlZ27NjB8uXLAThw4ABVVVVMmjSJJ554wnuA9JS3N8bTqmnBggX89Kc/BZz6gL/85S/eeRo6QA4ZMoStW7d66zmef/55TjzxxIPmS05Opl+/frz88suAcyD95ptvmozJ12mnncaf//xn7wH466+/DnjZ1lxXS95HUlLSQWdkrcWShTk01VXwvzfBu3fAsKkwczEkNPyP1dQaPnw4Bw4coGfPnvTo0YOLLrqI7OxssrKymD9/PkOGDGn2Oq+55hqqq6tJT09n+vTpPPvss8TGxnLUUUfx6KOPcuaZZ5KRkcHs2bN58cUXiYho+Oc/atQoMjMzGT58OJdddhnHHecUJcbExLBgwQKuu+46Ro0axamnnkpZWRlXXHEFffr0YeTIkYwaNcpv083y8nLGjh3Lo48+6q2Efeyxx8jOzmbkyJEMGzaMJ5544qDl4uLieOaZZzj//PNJT08nIiKCq666qsFtzJ8/n3/84x+MGjWK4cOHN6vBwB133EFlZSUjR45kxIgR3HHHHQEv29rrau77GDlyJFFRUYwaNarVK7ilLU5f2kJWVpaGot14u1Z+AF6+FDa9C8fNhol3QSMHoHCydu1ahg4dGuowjGlzDX33RWSFqmb5W9bqLEzL+N7+9OxHIOvSUEdkjAkiSxam+Xxvf3rRQjjGbn8abN9++y2XXHJJnXGxsbF88cUXjSwRmLFjxx7UUuj5558nPT39kNb785//nC1bttQZd//993Paaacd0noPxb333ust//c4//zzuf3220MU0eHFiqFM8/je/vTChYflXe2sGMq0V4dSDBX+BcwmfNS5/en7h2WiMMa0jBVDGf9CdPtTY0z4sGRhmhbC258aY8KH/epN40J8+1NjTPiwOgvTsNz18NRE2L3auf3pT39tiSJEjqT7WTRm3bp1ZGRkkJmZyYoVK+r0yhuKGDZv3sz48ePbPAZ/XnvttTp9aLUlO7MIB9VVkP8D7N8CCkREuo8o5yGRDYyLqH3tHR/pzuszTiKaf5BvT7c/fetW2PVt666zezqc8YfWXecR7rXXXmPq1KncfffdbN26lccff5xrrrkm4OU9PaM2dlW6R1P3uvCNAeDTTz8N/A20kddee42zzz6bYcOGtfm2LVm0papyyNsEuesgdwPsXe/8g8/bBNUVwduuRNZLLJE+SSjKueraNzHlbXJvf/oydO4bvLjaqVtuuYW+fft6D4Zz5sxBRFi2bBn79++nsrKSe+65h6lTpzZrvWVlZVx99dVkZ2cTFRXFQw89xIQJE1oU49VXX83y5cspLS1l2rRp3gPo8uXLueGGGyguLiY2Npb333+fDh06cMstt7BkyRJEhCuvvNLb+219c+fO5Y033qC0tJTx48fzt7/9jbfeeotHHnmEyMhIli1bxlFHHcXmzZvJyMjg1FNP5YEHHuCBBx5g4cKFlJeX8/Of/9ybVM444wwmTJjAZ599xmuvvUbfvgd/XxMTE7nppptYsmQJf/rTn4iPj+emm26iqKiIlJQUnn32Wb7++us6MSxdupTExESKior44IMPmDNnDikpKXz33Xcce+yxvPDCC4gIK1asOGhdPXr04KSTTvKeJeXm5vLPf/6T++67j2+//Zbp06dzzz33APDCCy/w2GOPUVFRwdixY3n88ceJjIwkMTGRG264gTfffJP4+Hhef/11Nm/ezOLFi/nwww+55557eOWVVxgwYECLPt+WsGQRDOUHYO8GJxHkrndfr4P9W0Fr3JnEORCnDHYuaksd7BygI6Kc7r1rqmuftbqJcZ7xzRhXU+UzvqZ2umdc3/Ew8U6I7xTKvdg2QnAGMGPGDGbPnu1NFgsXLuTtt9/mxhtvJDk5mb179zJu3DimTJnSrN5c582bBzgX8K1bt45JkyaxYcOGFsV477330qVLF6qrq5k4cSKrVq1iyJAhTJ8+nQULFjB69GgKCwuJj4/nySefZMuWLXz99ddERUU12ZHgtddey5133gnAJZdcwptvvsnkyZO56qqrSExM5Oabb2br1q1899133s4E33nnHTZu3MiXX36JqjJlyhSWLVtGnz59WL9+Pc8880yTxVbFxcWMGDGCuXPnUllZyYknnsjrr79OamoqCxYs4Pbbb+fpp5+uE0N9X3/9NatXr+boo4/muOOO45NPPmHs2LFcd911Da4LnL60li1bxqOPPsrUqVNZsWIFXbp0YcCAAdx4443s2bOHBQsW8MknnxAdHc0111zD/Pnz+a//+i+Ki4sZN24c9957L7/97W/5+9//zu9+9zumTJnC2WefzbRp01r0uR4KSxaHojjPPTuod6ZQuL12noho6DrAKZoYMc1JCqmDoesxEN10//jmyNSe72exdOlS/vjHP1JSUsK+ffsYPny49z4OjXnnnXd45513yMzMBJz7VWzcuJE+ffrQt29fxo0b1+TykZGRnHfeeYBzT4zvvvuOU089FXCKpXr06NHk8gBjxoyhV69eAGRkZLB161Y6derU5LqmTJkCOPenGD58uHda//792bZtGx9//DErVqzw7s/S0lK6desGOInm7LPPBpz7Y7z77rt+Yww2Sxb+qELhjtpE4HumUJJXO190B6db7rSfQcogNykMgc5pEBkdsvBNeGqP97MoKyvjmmuuITs7m969ezNnzpyA3qOqctttt/GrX/2qzvitW7fWuQ9FY+Li4rz1FKrK8OHD+eyzz/wu58v33hGe+1X4W5fv/Snq37vCs/zMmTO57777Dlo2Ojrau099748RStYayqOmGvI2w7r/wMcPw6tXw99Phvt6w8PD4Pmfw9u3wupXnXmHnAWT7oWLXoHZ38Jt2+FXy+DcJ+GEm2HoZCd5WKIwDWiP97PwJIaUlBSKioq8942ur/49GU477TSefvppioqKANi+fTt79uxp1r7xGDx4MLm5ud4DfGVlJatXrw7JuiZOnMiiRYu872Xfvn1+P/dg3q/CHzuzKNwJ86fB3o1Q7dOhWmJ35+wg4wL3TGGIM5yQak1IzSFr6H4WkydPJisri4yMjBbfz+Kqq64iPT2dqKioBu9nUVNTQ2JiYsD3s+jfv3+D97MoLS0lPj6e9957jyuuuIINGzYwcuRIoqOjufLKKw9qqgvQqVMnrrzyStLT00lLS/MWv9TXtWtXjjvuOEaMGMEZZ5zBAw88wNq1a703SkpMTOSFF15otFVTU2JiYli0aBHXX389BQUFVFVVMXv2bIYPH97m6xo2bBj33HMPkyZNoqamhujoaObNm9dgJb3HjBkzuPLKK3nsscdYtGhRm1ZwW0eCVRWw8BLnLCB1iFPhnDKwfVTutlPWkaBpr+x+FociKgYuXBDqKIwxJqxZsjDmMGD3s/AvWO/FOCxZmHYp0BY84SI9Pd173UFrOtRk05hXX301KOttSrDey5HiUKscrDWUaXfi4uLIy8s75B+PMYcLVSUvL4+4uLgWr8POLEy706tXL3JycsjNzQ11KMa0mbi4OO+FhS1hycK0O9HR0fTr1y/UYRhzWLFiKGOMMX5ZsjDGGOOXJQtjjDF+HTFXcItILtD8DnVqpQB7Wymcw53ti7psf9Rl+6PWkbAv+qpqqr+ZjphkcahEJDuQS97bA9sXddn+qMv2R632tC+sGMoYY4xfliyMMcb4Zcmi1pOhDiCM2L6oy/ZHXbY/arWbfWF1FsYYY/yyMwtjjDF+WbIwxhjjV7tPFiJyuoisF5FNInJrqOMJJRHpLSJLRWStiKwWkRtCHVOoiUikiHwtIm+GOpZQE5FOIrJIRNa535GfhjqmUBKRG93fyXci8qKItLxL18NAu04WIhIJzAPOAIYBF4jIsNBGFVJVwG9UdSgwDvh1O98fADcAa0MdRJh4FHhbVYcAo2jH+0VEegLXA1mqOgKIBGaENqrgatfJAhgDbFLV71W1AngJmBrimEJGVXeq6lfu6wM4B4OeoY0qdESkF3AW8FSoYwk1EUkGTgD+AaCqFaqaH9qoQi4KiBeRKKADsCPE8QRVe08WPYFtPsM5tOODoy8RSQMygfZ8+7FHgN8CNaEOJAz0B3KBZ9xiuadEJCHUQYWKqm4HHgR+BHYCBar6TmijCq72niwauq9mu29LLCKJwCvAbFUtDHU8oSAiZwN7VHVFqGMJE1HAT4C/qmomUAy02zo+EemMUwrRDzgaSBCRi0MbVXC192SRA/T2Ge7FEX4q6Y+IROMkivmq+u9QxxNCxwFTRGQrTvHkySLyQmhDCqkcIEdVPWeai3CSR3t1CrBFVXNVtRL4NzA+xDEFVXtPFsuBgSLST0RicCqoFoc4ppAREcEpk16rqg+FOp5QUtXbVLWXqqbhfC/+T1WP6H+OTVHVXcA2ERnsjpoIrAlhSKH2IzBORDq4v5uJHOEV/u36tqqqWiUi1wJLcFozPK2qq0McVigdB1wCfCsiK91x/62q/wlhTCZ8XAfMd/9YfQ9cGuJ4QkZVvxCRRcBXOK0Iv+YI7/rDuvswxhjjV3svhjLGGBMASxbGGGP8smRhjDHGL0sWxhhj/LJkYYwxxi9LFsaEARE5yXq2NeHMkoUxxhi/LFkY0wwicrGIfCkiK0Xkb+79LopE5E8i8pWIvC8iqe68GSLyuYisEpFX3f6EEJFjROQ9EfnGXWaAu/pEn/tFzHevDDYmLFiyMCZAIjIUmA4cp6oZQDVwEZAAfKWqPwE+BO5yF/kncIuqjgS+9Rk/H5inqqNw+hPa6Y7PBGbj3FulP84V9caEhXbd3YcxzTQROBZY7v7pjwf24HRhvsCd5wXg3yLSEeikqh+6458DXhaRJKCnqr4KoKplAO76vlTVHHd4JZAGfBz8t2WMf5YsjAmcAM+p6m11RorcUW++pvrQaapoqdzndTX2+zRhxIqhjAnc+8A0EekGICJdRKQvzu9omjvPhcDHqloA7BeR493xlwAfuvcHyRGRc9x1xIpIhzZ9F8a0gP1zMSZAqrpGRH4HvCMiEUAl8GucGwENF5EVQAFOvQbATOAJNxn49tJ6CfA3EZnrruP8NnwbxrSI9TprzCESkSJVTQx1HMYEkxVDGWOM8cvOLIwxxvhlZxbGGGP8smRhjDHGL0sWxhhj/LJkYYwxxi9LFsYYY/z6/4m0wrgq2400AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('IoU accuracy')\n",
    "plt.title('reg-on-chosen-box_smoothl1loss_lr-decay-0.1')\n",
    "plt.plot(process['val_IoU_acc_before_refinement'], label='val_IoU_acc_before_refinement')\n",
    "plt.plot(process['val_IoU_acc_after_refinement'], label='val_IoU_acc_after_refinement')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/wenjian/Internship/DDPN_transfer/outputs/2019-08-06_19-53-21_gereral-dictionary-mapping_ranking-loss-only/process.dct\", \"rb\") as f:\n",
    "    loaded_process = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDPN(\n",
       "  (embedding): Embedding(14384, 300)\n",
       "  (lstm): LSTM(300, 1024)\n",
       "  (fc1): Linear(in_features=3077, out_features=512, bias=True)\n",
       "  (fc_rank): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab = len(training_corpus_dct.token2id)\n",
    "\n",
    "model_test = DDPN(cfg, vocab_size=en_vocab)\n",
    "\n",
    "#model_en.load_state_dict(torch.load(english_pretrained_model_path, map_location=device))\n",
    "model_to_test_path = pretrained_model_path\n",
    "checkpoint = torch.load(model_to_test_path, map_location=device)\n",
    "\n",
    "if not cfg.regression_loss:  # In case of the pretrained model has regression loss while now not\n",
    "    try:\n",
    "        checkpoint['model_state_dict'].pop(\"fc_regression.weight\")\n",
    "        checkpoint['model_state_dict'].pop(\"fc_regression.bias\")\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "model_test.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'num_workers': 2}\n",
    "test_generator = data.DataLoader(test_set, shuffle=False, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set: 2789 samples\n",
      "Test set: good bounding box based on original bounding box: 1737\n",
      "Test set: accuracy based on original bounding box: 0.6228038668632507\n"
     ]
    }
   ],
   "source": [
    "# For statistics of IoU score\n",
    "test_all_ious_original = []\n",
    "if cfg.regression_loss:\n",
    "    test_all_ious_refined = []\n",
    "    \n",
    "print(f\"Evaluating on test set: {len(test_set)} samples\" )\n",
    "with torch.no_grad():      \n",
    "    for test_batch_counter, (inputs, gt_bboxes, _) in enumerate(test_generator):\n",
    "        Xs, queries = inputs\n",
    "        #print(\"val_batch_counter\", val_batch_counter)\n",
    "        #print(\"Xs\", Xs.size())\n",
    "        #print(\"queries\", len(queries))\n",
    "        #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "\n",
    "        Qs, seq_lengths = preprocess_query(queries)\n",
    "\n",
    "        model_test.eval()\n",
    "\n",
    "        Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "        test_pred = model_test(Xs, Qs, seq_lengths)\n",
    "        test_targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "#         try:\n",
    "#             val_loss = loss_func(val_pred, val_targ)\n",
    "#         except AssertionError as e:\n",
    "#             print(f\"epoch {epoch}, val, batch: {val_batch_counter}\")\n",
    "#             with open(\"debug.log\", 'a') as log:\n",
    "#                 log.write(f\"epoch {epoch}, val, batch: {val_batch_counter}\\n\")\n",
    "#             raise e\n",
    "#         test_losses_by_epoch.append(val_loss.item())\n",
    "#         val_loss_average_by_epoch += val_loss.item()*Xs.size(0)\n",
    "        #logger.add_scalar('val_losses_all_batches', val_losses, val_batch_counter)\n",
    "\n",
    "#         print(f\"\\repoch {epoch}, validation phase, batch {val_batch_counter}/{len(validation_generator)}, val_loss={val_loss.item()}\", end='')\n",
    "#         logger.add_scalar(\"val_loss_by_batch\", val_loss.item(), val_batch_counter_total)\n",
    "\n",
    "        # Statistics of IoU score\n",
    "        if cfg.regression_loss:\n",
    "            ious_original, ious_refined = calculate_IoU_scores(Xs, test_pred, gt_bboxes)\n",
    "        else:\n",
    "            ious_original = calculate_IoU_scores(Xs, test_pred, gt_bboxes)\n",
    "        test_all_ious_original = test_all_ious_original + ious_original.tolist()\n",
    "        if cfg.regression_loss:\n",
    "            test_all_ious_refined = test_all_ious_refined + ious_refined.tolist()\n",
    "    \n",
    "    good_original = torch.tensor(test_all_ious_original) > 0.5     \n",
    "    print(\"Test set: good bounding box based on original bounding box:\", good_original.sum().item())\n",
    "    acc_original = good_original.sum().float()/len(test_set)\n",
    "    print(\"Test set: accuracy based on original bounding box:\", acc_original.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2word translate: 62.28%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "\n",
    "def draw_bounding_box(filepath_sourceimage, bbox, color, output_dir=\"\", output_name=\"\"):\n",
    "    \"\"\"\n",
    "    Arguemnts:\n",
    "        filepath: the path to the image file.\n",
    "        bbox: a 4-element list to describe a bounding box; format: [x1,y1,x2,y2]\n",
    "        color: a 3-element tuple or a string to describe a color. Example(pure red): (255,0,0) or \"#ff0000\" or \"red\"\n",
    "    \"\"\"\n",
    "    img_name = os.path.basename(filepath_sourceimage)\n",
    "\n",
    "    if isinstance(color, str):\n",
    "        color = PIL.ImageColor.getrgb(color)\n",
    "\n",
    "    img = Image.open(filepath_sourceimage).convert(\"RGBA\")\n",
    "    tmp = Image.new('RGBA', img.size, (0,0,0,0))\n",
    "    draw = ImageDraw.Draw(tmp)\n",
    "    draw.rectangle(bbox, fill=color+(32,), outline=color, width=2)\n",
    "    img = Image.alpha_composite(img, tmp)\n",
    "    img = img.convert(\"RGB\") # Remove alpha for saving\n",
    "    if output_name == \"\":\n",
    "        out_img_name = 'bbox_' + img_name\n",
    "    else:\n",
    "        out_img_name = output_name\n",
    "    output_path = os.path.join(output_dir, out_img_name)\n",
    "    img.save(output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_multiple_bounding_boxes(filepath_sourceimage, bbox_color_tuple_list, output_dir=\"\", output_name=\"\"):\n",
    "    \"\"\"\n",
    "    Arguemnts:\n",
    "        filepath: the path to the image file.\n",
    "        bbox_color_tuple_list: a list of (bbox, color) tuple, where\n",
    "            bbox: a 4-element list to describe a bounding box; format: [x1,y1,x2,y2]\n",
    "            color: a 3-element tuple or a string to describe a color. Example(pure red): (255,0,0) or \"#ff0000\" or \"red\"\n",
    "    \"\"\"\n",
    "    img_name = os.path.basename(filepath_sourceimage)\n",
    "    \n",
    "    img = Image.open(filepath_sourceimage).convert(\"RGBA\")\n",
    "    \n",
    "    \n",
    "    for bbox, color in bbox_color_tuple_list:\n",
    "        if isinstance(color, str):\n",
    "            color = PIL.ImageColor.getrgb(color)\n",
    "        tmp = Image.new('RGBA', img.size, (0,0,0,0))\n",
    "        draw = ImageDraw.Draw(tmp)\n",
    "        draw.rectangle(bbox, fill=color+(32,), outline=color, width=2)\n",
    "        img = Image.alpha_composite(img, tmp)\n",
    "        \n",
    "    img = img.convert(\"RGB\") # Remove alpha for saving\n",
    "    if output_name == \"\":\n",
    "        out_img_name = 'bbox_' + img_name\n",
    "    else:\n",
    "        out_img_name = output_name     \n",
    "    output_path = os.path.join(output_dir, out_img_name)\n",
    "    img.save(output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate this function from loss_wrapper to print two losses separately \n",
    "# Don't forget to synchronize this function when the loss_wrapper is modified\n",
    "# Noted that no matter regularization loss is trained on chosen proposal or on all proposals, the loss in this function should always work on the chosen proposal. \n",
    "def loss_wrapper_testing(delta, epsilon):\n",
    "    def my_loss(predict, target):  # predict is expected to be (s,t), target their ground truth value\n",
    "        s, t = predict\n",
    "        gt_s, gt_t = target\n",
    "        #print(\"s\", s.size())   # --> s torch.Size([64, 100])\n",
    "        #print(\"gt_s\", gt_s.size())   # --> gt_s torch.Size([64, 100])\n",
    "        #print(\"t\", t.size())   # --> t torch.Size([64, 100, 4])\n",
    "        #print(\"gt_t\", gt_t.size())   # --> gt_t torch.Size([64, 4])\n",
    "        s = torch.add(s, torch.tensor(epsilon))  # In order to avoid 0 in the denominator\n",
    "        try:\n",
    "            assert not torch.isnan(s).any()\n",
    "            assert not torch.isinf(s).any()\n",
    "            assert not torch.isnan(t).any()\n",
    "            assert not torch.isinf(t).any()\n",
    "            assert not torch.isnan(gt_s).any()\n",
    "            assert not torch.isinf(gt_s).any()\n",
    "            assert not torch.isnan(gt_t).any()\n",
    "            assert not torch.isinf(gt_t).any()\n",
    "            loss_ranking = F.kl_div(torch.log(s), gt_s, reduction='batchmean') \n",
    "            assert not torch.isnan(loss_ranking).any()\n",
    "            assert not torch.isinf(loss_ranking).any()\n",
    "            N = t.size()[1]\n",
    "            #print('gt_t after repeat', gt_t.unsqueeze(1).repeat(1,N,1).size())\n",
    "            \n",
    "            \n",
    "            proposal_chosen = torch.argmax(s, dim=1)\n",
    "            batch_size = s.size()[0]\n",
    "            t_chosen = t[torch.arange(batch_size),proposal_chosen,:]  # t_chosen shape is expected to be (batch_size, 4)\n",
    "            #print(\"t_chosen\", t_chosen.size())\n",
    "            loss_regression = F.smooth_l1_loss(t_chosen, gt_t, reduction='none')\n",
    "            \n",
    "            #loss_regression = F.smooth_l1_loss(t, gt_t.unsqueeze(1).repeat(1,N,1), reduction='mean')\n",
    "            \n",
    "            \n",
    "            #print(\"loss_regression\", loss_regression)\n",
    "            assert not torch.isnan(loss_regression).any()\n",
    "            assert not torch.isinf(loss_regression).any()\n",
    "            \n",
    "            print(\"ranking_loss\", loss_ranking)\n",
    "            print(\"regression_loss\", loss_regression)\n",
    "            #my_loss.counter += 1 \n",
    "            \n",
    "        except AssertionError as e:\n",
    "            torch.set_printoptions(profile='full')\n",
    "            print('s\\n', s)\n",
    "            print('t\\n', t)\n",
    "            print('gt_s\\n', gt_s)\n",
    "            print('gt_t\\n', gt_t)\n",
    "            with open(\"debug.log\", 'w') as log:\n",
    "                log.write('s\\n')\n",
    "                log.write(str(s))\n",
    "                log.write('gt_s\\n')\n",
    "                log.write(str(gt_s))\n",
    "            torch.set_printoptions(profile='default')\n",
    "            raise e\n",
    "           \n",
    "        return delta*loss_ranking + torch.mean(loss_regression)  # Manual reduction\n",
    "        #return loss_ranking + gamma*loss_regression\n",
    "        #return loss_ranking \n",
    "    #my_loss.counter = 0\n",
    "    return my_loss\n",
    "loss_func_testing = loss_wrapper_testing(cfg.DELTA, cfg.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking_loss tensor(0.0051, device='cuda:3')\n",
      "regression_loss tensor([[3.5208e-04, 8.3301e-03, 1.4395e-07, 1.8458e-04],\n",
      "        [1.0197e-04, 9.0384e-03, 1.7739e-03, 1.9695e-02],\n",
      "        [1.8238e-03, 1.3999e-02, 1.1021e-02, 5.7377e-03],\n",
      "        [5.4663e-03, 1.0063e-03, 2.3000e-05, 2.8862e-04],\n",
      "        [4.4660e-05, 7.2171e-03, 5.9437e-05, 1.2161e-05],\n",
      "        [3.9638e-03, 1.1866e-02, 8.0416e-05, 1.4272e-03],\n",
      "        [1.0353e-05, 7.8609e-03, 1.2517e-06, 4.1720e-04],\n",
      "        [7.5158e-03, 1.2149e-02, 1.0817e-05, 5.9755e-04],\n",
      "        [9.5321e-03, 3.4907e-02, 1.0334e-02, 5.2831e-03],\n",
      "        [9.3181e-04, 9.4682e-05, 2.0898e-03, 2.3649e-05],\n",
      "        [8.8877e-05, 2.0509e-02, 4.2518e-06, 3.3216e-03],\n",
      "        [3.1346e-03, 1.3755e-07, 2.9779e-04, 2.1452e-04],\n",
      "        [3.4714e-02, 5.5310e-04, 1.7211e-02, 1.7143e-02],\n",
      "        [1.1393e-02, 1.4931e-02, 9.1838e-03, 5.4214e-03],\n",
      "        [4.1188e-03, 2.1181e-03, 8.4488e-05, 4.4536e-07],\n",
      "        [3.2111e-04, 2.1581e-04, 6.4923e-03, 9.9500e-05],\n",
      "        [1.4035e-04, 4.7364e-04, 4.4173e-04, 2.2273e-04],\n",
      "        [2.7837e-02, 2.3235e-02, 4.6991e-03, 2.7050e-02],\n",
      "        [6.4864e-04, 6.5890e-05, 1.1978e-03, 3.3703e-03],\n",
      "        [2.1324e-04, 2.1317e-04, 3.7455e-03, 6.9287e-05],\n",
      "        [1.3691e-04, 2.7932e-04, 2.7924e-05, 9.7651e-05],\n",
      "        [2.9408e-02, 8.6771e-03, 5.5310e-03, 1.4482e-02],\n",
      "        [3.5230e-03, 5.6352e-04, 5.6723e-05, 3.4843e-04],\n",
      "        [2.8966e-04, 4.2482e-05, 4.2794e-03, 6.3761e-04],\n",
      "        [1.0359e-03, 2.9980e-04, 1.5308e-03, 2.8446e-04],\n",
      "        [5.4546e-04, 1.5178e-04, 4.1907e-03, 2.7677e-04],\n",
      "        [1.9164e-05, 1.6018e-03, 3.1095e-06, 7.2429e-03],\n",
      "        [2.4297e-05, 2.6459e-03, 1.0537e-02, 4.9885e-03],\n",
      "        [8.2250e-04, 5.2056e-03, 9.7369e-04, 1.1270e-02],\n",
      "        [6.3495e-03, 8.4807e-03, 1.3436e-02, 1.9656e-01],\n",
      "        [2.9611e-05, 1.2214e-04, 4.1780e-04, 4.6509e-07],\n",
      "        [5.5223e-03, 9.1086e-04, 5.1290e-03, 1.0733e-02],\n",
      "        [1.0008e-03, 3.1328e-04, 2.9909e-03, 1.5484e-02],\n",
      "        [9.8746e-05, 2.2288e-03, 1.3288e-02, 4.1415e-03],\n",
      "        [1.9467e-02, 1.3287e-02, 8.4443e-03, 1.8670e-02],\n",
      "        [1.1971e-03, 5.9539e-03, 4.2921e-03, 1.8236e-01],\n",
      "        [3.1021e-05, 8.3277e-05, 5.1551e-04, 1.5067e-05],\n",
      "        [4.3518e-03, 9.8412e-05, 4.5627e-03, 8.3362e-03],\n",
      "        [2.4840e-05, 3.5242e-03, 1.3413e-02, 5.3393e-03],\n",
      "        [4.8160e-03, 1.4792e-03, 1.6316e-03, 1.1398e-02],\n",
      "        [1.0690e-03, 3.1551e-03, 4.8690e-04, 1.1947e-03],\n",
      "        [9.0178e-03, 2.0023e-03, 1.5254e-03, 1.1604e-02],\n",
      "        [1.8995e-01, 8.5548e-03, 5.3617e-02, 8.3388e-03],\n",
      "        [1.3515e-03, 3.1920e-03, 1.2126e-05, 8.0993e-03],\n",
      "        [4.6950e-04, 6.2657e-04, 1.4376e-05, 1.0066e-03],\n",
      "        [4.0184e-04, 2.0620e-03, 1.0425e-03, 3.5387e-02],\n",
      "        [6.4834e-02, 1.1542e-04, 1.0985e-02, 1.6912e-02],\n",
      "        [1.4213e-01, 2.0195e-03, 2.4691e-03, 1.0098e-01],\n",
      "        [1.9843e-03, 6.0524e-04, 1.8852e-04, 1.6428e-03],\n",
      "        [9.0538e-03, 3.6292e-03, 1.9882e-03, 6.9045e-03],\n",
      "        [2.8362e-04, 4.8765e-05, 1.2736e-06, 2.0571e-04],\n",
      "        [5.0004e-02, 3.9757e-04, 1.7832e-02, 2.3431e-02],\n",
      "        [1.7640e-02, 3.4859e-03, 5.5917e-03, 4.6475e-03],\n",
      "        [2.1215e-03, 9.7901e-04, 1.4567e-04, 2.8618e-03],\n",
      "        [8.9565e-03, 2.5194e-03, 1.5170e-03, 7.4701e-03],\n",
      "        [1.1075e-02, 6.3038e-05, 8.9396e-05, 1.7207e-04],\n",
      "        [4.4488e-03, 1.9557e-03, 6.7221e-02, 2.4080e-02],\n",
      "        [1.3391e-04, 1.6451e-06, 1.8097e-03, 4.7416e-03],\n",
      "        [1.3965e-02, 3.0727e-02, 2.0614e-02, 2.8555e-02],\n",
      "        [8.2002e-03, 4.6078e-05, 2.9960e-04, 7.0009e-04],\n",
      "        [2.8716e-04, 1.3663e-03, 1.8235e-03, 1.0431e-02],\n",
      "        [2.2924e-02, 4.0400e-02, 2.2921e-02, 4.7113e-02],\n",
      "        [4.2956e-04, 1.3978e-03, 1.4664e-06, 3.4662e-05],\n",
      "        [8.8041e-03, 1.6150e-09, 4.6298e-05, 2.7851e-04]], device='cuda:3')\n",
      "0.014490429311990738\n",
      "64 10350842 988 A man 0.7322602868080139 0.7008048892021179\n",
      "65 10350842 991 a red life-vest 0.6554079651832581 0.1692930907011032\n",
      "66 10350842 990 a canoe 0.8025606870651245 0.2305883914232254\n",
      "67 10350842 989 a body of water 0.7029799818992615 0.7808376550674438\n",
      "68 10350842 988 A balding man 0.7322602868080139 0.7469741702079773\n",
      "69 10350842 991 a red life jacket 0.6554079651832581 0.34362316131591797\n",
      "70 10350842 988 A man 0.7322602868080139 0.7499653100967407\n",
      "71 10350842 991 a red life vest 0.6554079651832581 0.33252453804016113\n",
      "72 10350842 990 a canoe 0.6643998622894287 0.16518886387348175\n",
      "73 1054620089 1389 A woman 0.7174680233001709 0.8632680773735046\n",
      "74 1054620089 1395 jeans 0.47478652000427246 0.5056222677230835\n",
      "75 1054620089 1392 a red coat 0.5740190148353577 0.8396521210670471\n",
      "76 1054620089 1390 a multicolored handbag 0.6178174018859863 0.06508664786815643\n",
      "77 1054620089 1397 her arms 0.32364481687545776 0.32971829175949097\n",
      "78 1054620089 1391 a cobblestone street 0.7124428749084473 0.7352026104927063\n",
      "79 1054620089 1389 A lady 0.7174680233001709 0.8165894746780396\n",
      "80 1054620089 1392 a red coat 0.5740190148353577 0.8624181747436523\n",
      "81 1054620089 1390 a bluish hand bag 0.6178174018859863 0.0\n",
      "82 1054620089 1389 asian descent 0.7174680233001709 0.7951408624649048\n",
      "83 1054620089 1389 A woman 0.7174680233001709 0.8532681465148926\n",
      "84 1054620089 1392 a red jacket 0.5740190148353577 0.9055782556533813\n",
      "85 1054620089 1390 a blue and gold handbag 0.6178174018859863 0.04873591661453247\n",
      "86 1054620089 1391 a cobblestone street 0.7124428749084473 0.7351527810096741\n",
      "87 1054620089 1389 A woman 0.7174680233001709 0.8304508924484253\n",
      "88 1054620089 1392 a red coat 0.5740190148353577 0.812138557434082\n",
      "89 1054620089 1389 Girl 0.7174680233001709 0.8248057961463928\n",
      "90 1054620089 1392 red 0.5740190148353577 0.7260295152664185\n",
      "91 1056873310 1475 Two dogs 0.471582293510437 0.43536505103111267\n",
      "92 1056873310 1476 a rocky area 0.6922076344490051 0.6721076965332031\n",
      "93 1056873310 1478 water 0.0 0.016569392755627632\n",
      "94 1056873310 1474 A brown dog 0.6035997867584229 0.822023868560791\n",
      "95 1056873310 1477 a black dog 0.17064569890499115 0.2360924929380417\n",
      "96 1056873310 1476 a rocky shore 0.6922076344490051 0.6598660349845886\n",
      "97 1056873310 1475 Two dogs 0.471582293510437 0.4327831268310547\n",
      "98 1056873310 1476 stones 0.6922076344490051 0.37635332345962524\n",
      "99 1056873310 1478 a body of water 0.0 0.04509937763214111\n",
      "100 1056873310 1474 A brown dog 0.6035997867584229 0.807309091091156\n",
      "101 1056873310 1477 the black dog 0.17064569890499115 0.3039288818836212\n",
      "102 1056873310 1475 Two dogs 0.471582293510437 0.4055650234222412\n",
      "103 1056873310 1476 a beach 0.6922076344490051 0.6500818729400635\n",
      "104 1072439304 1742 A young helmeted man 0.7510720491409302 0.732742428779602\n",
      "105 1072439304 1743 his team uniform 0.4475885033607483 0.4497281610965729\n",
      "106 1072439304 1745 his bat 0.0 0.0\n",
      "107 1072439304 1744 an incoming baseball 0.7397023439407349 0.1401638239622116\n",
      "108 1072439304 1742 A young boy 0.7510720491409302 0.8385670185089111\n",
      "109 1072439304 1743 a Giants jersey 0.46402549743652344 0.36390939354896545\n",
      "110 1072439304 1745 a baseball bat 0.6442427039146423 0.08786408603191376\n",
      "111 1072439304 1744 an incoming pitch 0.008835605345666409 0.0042420667596161366\n",
      "112 1072439304 1742 A boy 0.7510720491409302 0.758181095123291\n",
      "113 1072439304 1744 a baseball 0.7397023439407349 0.03832104802131653\n",
      "114 1072439304 1742 A child 0.7510720491409302 0.9121809005737305\n",
      "115 1072439304 1745 a baseball bat 0.6442427039146423 0.07181879132986069\n",
      "116 1072439304 1744 the ball 0.7397023439407349 0.0\n",
      "117 1072439304 1742 This little boy 0.7510720491409302 0.7330185174942017\n",
      "118 1072439304 1744 a ball 0.7397023439407349 0.048711277544498444\n",
      "119 1073444492 1759 A guy 0.7595064043998718 0.5348851680755615\n",
      "120 1073444492 1760 a desk 0.1849280297756195 0.21842220425605774\n",
      "121 1073444492 1761 a phone 0.0 0.18835145235061646\n",
      "122 1073444492 1762 books 0.7835381031036377 0.3062276840209961\n",
      "123 1073444492 1759 Man 0.7595064043998718 0.5453752279281616\n",
      "124 1073444492 1761 a phone 0.0 0.06271602213382721\n",
      "125 1073444492 1762 books 0.7835381031036377 0.21766352653503418\n",
      "126 1073444492 1763 an office 0.7284999489784241 0.9135473370552063\n",
      "127 1073444492 1759 A man 0.7595064043998718 0.5812724828720093\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(\"./visualization/\"):\n",
    "    os.mkdir(\"./visualization/\")\n",
    "\n",
    "validation_generator_for_visualization = data.DataLoader(validation_set, shuffle=False, batch_size=64)\n",
    "\n",
    "with torch.no_grad():\n",
    "        \n",
    "    batch_number = 1 # batch_number begins by 0, until last batch in validation set\n",
    "\n",
    "    #for inputs, gt_bboxes in validation_generator:\n",
    "    it = iter(validation_generator_for_visualization)\n",
    "    for i in range(batch_number+1):\n",
    "        inputs, gt_bboxes, IDs = next(it)\n",
    "    Xs, queries = inputs\n",
    "    img_ids, obj_ids, img_ws, img_hs = IDs\n",
    "    #print(\"val_batch_counter\", val_batch_counter)\n",
    "    #print(\"Xs\", Xs.size())\n",
    "    #print(\"queries\", len(queries))\n",
    "    #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "\n",
    "    Qs, seq_lengths = preprocess_query(queries)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "    val_pred = model(Xs, Qs, seq_lengths)\n",
    "    val_targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "    try:\n",
    "        val_loss = loss_func_testing(val_pred, val_targ)\n",
    "    except AssertionError as e:\n",
    "        print(f\"epoch {epoch}, val, batch: {val_batch_counter}\")\n",
    "        with open(\"debug.log\", 'a') as log:\n",
    "            log.write(f\"epoch {epoch}, val, batch: {val_batch_counter}\\n\")\n",
    "        raise e\n",
    "    print(val_loss.item())\n",
    "\n",
    "\n",
    "    # Statistics of IoU score\n",
    "\n",
    "    s, t = val_pred\n",
    "    proposal_chosen = torch.argmax(s, dim=1)\n",
    "    batch_size = Xs.size()[0]\n",
    "    gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "    bboxes_chosen_original = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "    bboxes_chosen_refined = t[torch.arange(batch_size),proposal_chosen,:].unsqueeze(1)\n",
    "    #print(bboxes_chosen.size())\n",
    "    ious_original = IoU(bboxes_chosen_original, gt_bboxes).squeeze()  \n",
    "    ious_refined = IoU(bboxes_chosen_refined, gt_bboxes).squeeze() \n",
    "    \n",
    "    \n",
    "    def get_bbox_in_original_scale(boxes, img_ws, img_hs, sample_in_batch):\n",
    "        box = boxes[sample_in_batch].tolist()[0]  # [0] is to remove a pair of []\n",
    "        #print(box)\n",
    "        #print(img_ws[sample_in_batch])\n",
    "        #print(img_hs[sample_in_batch])\n",
    "        #print(img_ws[sample_in_batch].data.cpu().numpy())\n",
    "        box[0] *= img_ws[sample_in_batch].item()\n",
    "        box[1] *= img_hs[sample_in_batch].item()\n",
    "        box[2] *= img_ws[sample_in_batch].item()\n",
    "        box[3] *= img_hs[sample_in_batch].item()\n",
    "        #print(\"box[0]\", box[0])\n",
    "        return box\n",
    "    \n",
    "    for sample_in_batch in range(0,64): # Change here to see a different sample\n",
    "\n",
    "        gt_box = get_bbox_in_original_scale(gt_bboxes, img_ws, img_hs, sample_in_batch)\n",
    "        first_box = get_bbox_in_original_scale(bboxes_chosen_original, img_ws, img_hs, sample_in_batch)\n",
    "        refined_first_box = get_bbox_in_original_scale(bboxes_chosen_refined, img_ws, img_hs, sample_in_batch)\n",
    "\n",
    "        boxes_colors = [(gt_box, \"green\"),\n",
    "                        (first_box, \"yellow\"),\n",
    "                        (refined_first_box, \"red\")\n",
    "                        ]\n",
    "\n",
    "        img_path_source = os.path.join(img_dir, img_ids[sample_in_batch]+'.jpg')  \n",
    "        query_number = batch_number*batch_size+sample_in_batch\n",
    "        output_path = draw_multiple_bounding_boxes(img_path_source, boxes_colors, output_dir = \"./visualization/\",\n",
    "                output_name=str(query_number) + \"_\" + img_ids[sample_in_batch]+'_'+obj_ids[sample_in_batch]+'_'+queries[sample_in_batch]+'.jpg')\n",
    "        print(query_number, img_ids[sample_in_batch], obj_ids[sample_in_batch], queries[sample_in_batch], ious_original[sample_in_batch].item(), ious_refined[sample_in_batch].item())\n",
    "\n",
    "#os.system(\"xdg-open \"+output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDPN(\n",
       "  (embedding): Embedding(14384, 300)\n",
       "  (lstm): LSTM(300, 1024)\n",
       "  (fc1): Linear(in_features=3077, out_features=512, bias=True)\n",
       "  (fc_rank): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase = \"test\"\n",
    "\n",
    "folder = \"./test-visualization_google-translation/\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "if phase == 'val':\n",
    "    generator_for_visualization = data.DataLoader(validation_set, shuffle=False, batch_size=64)\n",
    "elif phase == 'test':\n",
    "    generator_for_visualization = data.DataLoader(test_set, shuffle=False, batch_size=64)\n",
    "\n",
    "    \n",
    "model_test = DDPN(cfg, vocab_size=en_vocab)\n",
    "\n",
    "#model_en.load_state_dict(torch.load(english_pretrained_model_path, map_location=device))\n",
    "# model_to_test_path = os.path.join(output_dir, \"checkpoint_1.tar\")\n",
    "# checkpoint = torch.load(model_to_test_path, map_location=device)\n",
    "# model_test.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# model_test.to(device)\n",
    "\n",
    "\n",
    "model_to_test_path = \"/home/wenjian/code/experiments/2019-08-17_19-26-48_L1-gt-softlabel_drop0.5_checkpoint_4_69.30.tar\"\n",
    "checkpoint = torch.load(model_to_test_path, map_location=device)\n",
    "\n",
    "if not cfg.regression_loss:  # In case of the pretrained model has regression loss while now not\n",
    "    try:\n",
    "        checkpoint['model_state_dict'].pop(\"fc_regression.weight\")\n",
    "        checkpoint['model_state_dict'].pop(\"fc_regression.bias\")\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "model_test.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint: /home/wenjian/code/experiments/2019-08-17_19-26-48_L1-gt-softlabel_drop0.5_checkpoint_4_69.30.tar\n",
      "1.4053672552108765\n",
      "192 151970521 15557 blue 0.5710521340370178\n",
      "193 151970521 15561 a black leather bag 0.41171401739120483\n",
      "194 151970521 15555 bench 0.5994035601615906\n",
      "195 151970521 15559 people 0.4411853849887848\n",
      "196 151970521 15554 a limousine 0.21216724812984467\n",
      "197 1526325728 15644 the brown dog 0.8459575176239014\n",
      "198 155210731 16150 a woman 0.6949360966682434\n",
      "199 155210731 16154 a laundry basket 0.7720130085945129\n",
      "200 155210731 16155 tissues 0.2899075746536255\n",
      "201 157910841 16868 a man 0.8442575931549072\n",
      "202 1579198375 16883 a woman 0.7630705237388611\n",
      "203 1579198375 16885 a guitarist 0.7273948788642883\n",
      "204 1579206585 16891 a guitarist 0.5605291128158569\n",
      "205 1579206585 16893 a nightclub 0.4734116792678833\n",
      "206 157955034 16921 a child 0.6101589202880859\n",
      "207 157955034 16922 a garden chair 0.5897736549377441\n",
      "208 160792599 17430 two women 0.33142876625061035\n",
      "209 160792599 17429 three men 0.5713517069816589\n",
      "210 160792599 17431 the ocean 0.7247169613838196\n",
      "211 16151663 17527 an artist 0.0\n",
      "212 16151663 17531 a violin 0.0\n",
      "213 16151663 17530 a street 0.5147570371627808\n",
      "214 16151663 17532 a woman 0.37557944655418396\n",
      "215 16151663 17529 a blue guitar 0.7432575225830078\n",
      "216 16437914 18024 a young girl 0.3674068748950958\n",
      "217 16437914 18025 swimming pool 0.6977897882461548\n",
      "218 16495609 18098 several children 0.827208399772644\n",
      "219 164969525 18104 three teenagers 0.6976901292800903\n",
      "220 1659358141 18195 a brown dog 0.9360426664352417\n",
      "221 1659358141 18196 the grass 0.7421738505363464\n",
      "222 1659358141 18197 his language 0.0\n",
      "223 16626851 18235 people 0.7192690968513489\n",
      "224 16626851 18238 the grass 0.8121597766876221\n",
      "225 16626851 18237 a building 0.5621132850646973\n",
      "226 166283675 18242 a shirtless guy 0.6628512144088745\n",
      "227 166283675 18248 three women 0.7080618143081665\n",
      "228 166283675 18246 a crowd 0.7552569508552551\n",
      "229 166283675 18244 A coffee 0.0\n",
      "230 1664475761 18328 two young boys 0.6552189588546753\n",
      "231 1664475761 18329 fruits 0.0\n",
      "232 1664475761 18330 the bike 0.6735206246376038\n",
      "233 1675332284 18518 a man 0.4659477770328522\n",
      "234 1675332284 18520 black t-shirt 0.7522011995315552\n",
      "235 1675332284 18519 cap 0.7203779220581055\n",
      "236 1675332284 18526 jeans 0.6360646486282349\n",
      "237 1675332284 18521 percussion 0.5186004042625427\n",
      "238 1675332284 18523 a yellow bucket returned 0.08004961907863617\n",
      "239 1681253990 18686 a young artist 0.8773117065429688\n",
      "240 1681253990 18687 a portrait of a woman 0.17855432629585266\n",
      "241 1681253990 18688 a wall 0.28926995396614075\n",
      "242 1690926854 18846 two women members of the American team [ 0.44062167406082153\n",
      "243 1690926854 18851 two other teammates 0.8304269313812256\n",
      "244 17186135 19374 a man 0.7827800512313843\n",
      "245 17186135 19378 a pot of liquid 0.44581809639930725\n",
      "246 172092464 19419 the boy 0.5172264575958252\n",
      "247 172092464 19420 Lake 0.8061633706092834\n",
      "248 1749702972 19908 a man 0.0\n",
      "249 1749702972 19909 a hot dog stand 0.25202783942222595\n",
      "250 175556963 19982 a big number of people 0.8229801654815674\n",
      "251 1798209205 20727 a blonde woman 0.6570433378219604\n",
      "252 1798209205 20731 drinks 0.0\n",
      "253 179828434 20745 a small child 0.7189093232154846\n",
      "254 179828434 20747 a blue and white t-shirt 0.7236438393592834\n",
      "255 179828434 20746 a yellow plastic alligator 0.583636999130249\n"
     ]
    }
   ],
   "source": [
    "# Test set or val set\n",
    "\n",
    "print(\"loaded checkpoint:\", model_to_test_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        \n",
    "    batch_number = 3 # batch_number begins by 0, until last batch in the data set\n",
    "\n",
    "    #for inputs, gt_bboxes in generator:\n",
    "    it = iter(generator_for_visualization)\n",
    "    for i in range(batch_number+1):\n",
    "        inputs, gt_bboxes, IDs = next(it)\n",
    "    Xs, queries = inputs\n",
    "    img_ids, obj_ids, img_ws, img_hs = IDs\n",
    "    #print(\"val_batch_counter\", val_batch_counter)\n",
    "    #print(\"Xs\", Xs.size())\n",
    "    #print(\"queries\", len(queries))\n",
    "    #print(\"gt_bboxes\", gt_bboxes.size())\n",
    "\n",
    "    Qs, seq_lengths = preprocess_query(queries)\n",
    "\n",
    "    model_test.eval()\n",
    "\n",
    "    Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "    pred = model_test(Xs, Qs, seq_lengths)\n",
    "    targ = (get_softlable(Xs, gt_bboxes), gt_bboxes)\n",
    "    #loss = loss_func_testing(pred, targ)\n",
    "    loss = loss_func(pred, targ)\n",
    "    print(loss.item())\n",
    "\n",
    "\n",
    "    # Statistics of IoU score\n",
    "\n",
    "    s, t = pred\n",
    "    proposal_chosen = torch.argmax(s, dim=1)\n",
    "    batch_size = Xs.size()[0]\n",
    "    gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "    bboxes_chosen_original = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "    #bboxes_chosen_refined = t[torch.arange(batch_size),proposal_chosen,:].unsqueeze(1)\n",
    "    #print(bboxes_chosen.size())\n",
    "    ious_original = IoU(bboxes_chosen_original, gt_bboxes).squeeze()  \n",
    "    #ious_refined = IoU(bboxes_chosen_refined, gt_bboxes).squeeze() \n",
    "    \n",
    "    \n",
    "    def get_bbox_in_original_scale(boxes, img_ws, img_hs, sample_in_batch):\n",
    "        box = boxes[sample_in_batch].tolist()[0]  # [0] is to remove a pair of []\n",
    "        #print(box)\n",
    "        #print(img_ws[sample_in_batch])\n",
    "        #print(img_hs[sample_in_batch])\n",
    "        #print(img_ws[sample_in_batch].data.cpu().numpy())\n",
    "        box[0] *= img_ws[sample_in_batch].item()\n",
    "        box[1] *= img_hs[sample_in_batch].item()\n",
    "        box[2] *= img_ws[sample_in_batch].item()\n",
    "        box[3] *= img_hs[sample_in_batch].item()\n",
    "        #print(\"box[0]\", box[0])\n",
    "        return box\n",
    "    \n",
    "    for sample_in_batch in range(0,64): # Change here to see different samples\n",
    "\n",
    "        gt_box = get_bbox_in_original_scale(gt_bboxes, img_ws, img_hs, sample_in_batch)\n",
    "        top_rank_box = get_bbox_in_original_scale(bboxes_chosen_original, img_ws, img_hs, sample_in_batch)\n",
    "        #refined_top_rank_box = get_bbox_in_original_scale(bboxes_chosen_refined, img_ws, img_hs, sample_in_batch)\n",
    "\n",
    "#         boxes_colors = [(gt_box, \"green\"),\n",
    "#                         (top_rank_box, \"yellow\"),\n",
    "#                         (refined_top_rank_box, \"red\")\n",
    "#                         ]\n",
    "\n",
    "        boxes_colors = [(gt_box, \"green\"),\n",
    "                        (top_rank_box, \"yellow\"),\n",
    "                        ]\n",
    "\n",
    "        img_path_source = os.path.join(img_dir, img_ids[sample_in_batch]+'.jpg')  \n",
    "        query_number = batch_number*batch_size+sample_in_batch\n",
    "        output_path = draw_multiple_bounding_boxes(img_path_source, boxes_colors, output_dir = folder,\n",
    "                output_name=str(query_number) + \"_\" + img_ids[sample_in_batch]+'_'+obj_ids[sample_in_batch]+'_'+queries[sample_in_batch]+'.jpg')\n",
    "        print(query_number, img_ids[sample_in_batch], obj_ids[sample_in_batch], queries[sample_in_batch], ious_original[sample_in_batch].item())\n",
    "\n",
    "#os.system(\"xdg-open \"+output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is to draw all bounding box proposals on one image.  \n",
    "\n",
    "visualization_dir = \"./visualization_gt2/\"\n",
    "\n",
    "\n",
    "if not os.path.exists(visualization_dir):\n",
    "    os.mkdir(visualization_dir)\n",
    "\n",
    "validation_generator_for_visualization = data.DataLoader(validation_set, shuffle=False, batch_size=64)\n",
    "\n",
    "\n",
    "batch_number = 1 # batch_number begins by 0, until last batch in validation set\n",
    "\n",
    "#for inputs, gt_bboxes in validation_generator:\n",
    "it = iter(validation_generator_for_visualization)\n",
    "for i in range(batch_number+1):\n",
    "    inputs, gt_bboxes, IDs = next(it)\n",
    "Xs, queries = inputs\n",
    "img_ids, obj_ids, img_ws, img_hs = IDs\n",
    "#print(\"val_batch_counter\", val_batch_counter)\n",
    "#print(\"Xs\", Xs.size())\n",
    "#print(\"queries\", len(queries))\n",
    "\n",
    "\n",
    "\n",
    "def get_bbox_in_original_scale_all_proposals(boxes, img_ws, img_hs, sample_in_batch):\n",
    "    #print(boxes)\n",
    "    box = boxes.clone()\n",
    "    #print(box[0])\n",
    "    #print(img_ws[sample_in_batch])\n",
    "    #print(img_hs[sample_in_batch])\n",
    "    #print(img_ws[sample_in_batch].data.cpu().numpy())\n",
    "    box[:,0] *= img_ws[sample_in_batch]\n",
    "    box[:,1] *= img_hs[sample_in_batch]\n",
    "    box[:,2] *= img_ws[sample_in_batch]\n",
    "    box[:,3] *= img_hs[sample_in_batch]\n",
    "    print(\"box\", box)\n",
    "    return box.tolist()\n",
    "\n",
    "for sample_in_batch in range(0,64): # Change here to see a different sample\n",
    "\n",
    "    sample_in_batch = 0\n",
    "\n",
    "    proposals = Xs[sample_in_batch,:,-5:-1]\n",
    "    proposal_list = get_bbox_in_original_scale_all_proposals(proposals, img_ws, img_hs, sample_in_batch)\n",
    "    \n",
    "     \n",
    "    #print(proposal_list[0])\n",
    "    \n",
    "    img_path_source = os.path.join(img_dir, img_ids[sample_in_batch]+'.jpg')  \n",
    "    im = Image.open(img_path_source)\n",
    "    \n",
    "    print(len(proposal_list[i]))\n",
    "    \n",
    "    for i in range(len(proposal_list)):\n",
    "        ImageDraw.ImageDraw(im).rectangle(proposal_list[i], outline=\"yellow\", width=0)\n",
    "        \n",
    "    query_number = batch_number*batch_size+sample_in_batch\n",
    "#     output_path = draw_multiple_bounding_boxes(img_path_source, boxes_colors, output_dir = visualization_dir,\n",
    "#             output_name=str(query_number) + \"_\" + img_ids[sample_in_batch]+'_'+obj_ids[sample_in_batch]+'_'+queries[sample_in_batch]+'.jpg')\n",
    "    im.save(os.path.join(visualization_dir, str(query_number) + \"_\" + img_ids[sample_in_batch]+'_'+obj_ids[sample_in_batch]+'_'+queries[sample_in_batch]+'.jpg'))\n",
    "    print(query_number, img_ids[sample_in_batch], obj_ids[sample_in_batch], queries[sample_in_batch])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(torch.tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,    0,    0,    0,    0,    0,   17,    0,    0,    0,\n",
       "            0,    0,    0,   17,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,  130,  239,    0,    0,\n",
       "            0,  239,    0,   31,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,   17,    0,    0,    0,    0,   71,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,   17,    0,    0,    0,\n",
       "           17,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,  186,  186,   17,    0,\n",
       "            0,  186,    0,   30,   44,    0,    0,    0,    3,    0,    0,    0,\n",
       "            0,   17,    0,    0,    0,   17,   87,    0,   17,    0,    0,   70,\n",
       "            3,    0,    0,   17,    0,    0,    0,    0,  943,    0,   17,    0,\n",
       "         8687,    0,    0,    0,   17,    0,   49,    0,   17,    0,    0,    0,\n",
       "           17,    0,    0,    0],\n",
       "        [   0,   71,   19,   17,   66,    0,   17,   17,   11,   11,  369,    0,\n",
       "           17,  277,   17, 5848,  298,   71,   17, 4364,    4,   17, 5537, 2607,\n",
       "           71,   48,   17,   17,    0,   63,   30,   17,    4,   17,    3,    3,\n",
       "           37,    0,    0,  237,   49,   17,   17,   17,  186,   17, 2553,   97,\n",
       "          446,   17,   49,    0,  446,   71,  240,    3, 2052,   17,   50,    0,\n",
       "          276,   17,    0,    0],\n",
       "        [ 971,  317,   59,   18,  547, 3571,   18,  452,  129, 8458,   39,   68,\n",
       "          223,   84, 1038,   29,   18,   69,  369,  139,  158,  297, 5538, 1321,\n",
       "          442,  223,   96,  444,  239,  129,   68,   96,  223,  247,  116, 1335,\n",
       "         1296,  702,   18,  624, 8449,  247,  369, 2331,  472,   96, 1574, 9564,\n",
       "          444,   90, 1448, 1391,  125,  221, 7594,   14, 1145,   54,  823,   68,\n",
       "           96,  166,  323,  222]], device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A blog on tips of deep learning debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pytorch_result_save_path+loss_filename, 'wb') as fp:\n",
    "    pickle.dump(process, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # Do this before saving the model when dropout or batch normalization is involved. https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "# Save model's learnable parameters\n",
    "torch.save(model.state_dict(), pytorch_model_save_path+pth_filename)\n",
    "# Save checkpoint\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "\n",
    "            }, pytorch_checkpoint_save_path+checkpoint_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Error: you are using non-pretraind embedding, and vocab_size is not an integer, but <__main__.CFG object at 0x7fb52806ee80>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e1617743e348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pretrained_word_embedding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_corpus_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pretrained_word_embedding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GloVe\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_corpus_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-1dc839866046>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, vocab_size, embedding_weights)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m#print(\"type(embedding_weights) equals to type(None)\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Error: you are using non-pretraind embedding, and vocab_size is not an integer, but {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORD_EMB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Error: you are using non-pretraind embedding, and vocab_size is not an integer, but <__main__.CFG object at 0x7fb52806ee80>."
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "if False:\n",
    "    if cfg.use_pretrained_word_embedding == None:\n",
    "        model = DDPN(len(training_corpus_dct.token2id), cfg)\n",
    "    elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "        model = DDPN(len(training_corpus_dct.token2id), cfg, glove.vectors)\n",
    "    model.load_state_dict(torch.load('/home/wenjian/Internship/DDPN_draft/model/ddpn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the validation set (14526 samples)...\n",
      "good bounding box based on original bounding box: tensor(9112)\n",
      "accuracy based on original bounding box: tensor(0.6273)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(f\"Evaluating the model on the validation set ({len(validation_set)} samples)...\")\n",
    "    all_ious_original = []\n",
    "    all_ious_refined = []\n",
    "    counter = 0\n",
    "    for inputs, gt_bboxes in validation_generator:\n",
    "        Xs, queries = inputs\n",
    "        batch_size = Xs.size()[0]\n",
    "        \"\"\"\n",
    "        indices = [training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)]) for q in queries]\n",
    "        #print(\"---aaa---\\n\", indices)\n",
    "        # Gensim assign -1 to unknown word in the dictionary. \n",
    "        # Pytorch embedding, however, don't support negative index. \n",
    "        # So we kept 1 for unknown word when building Gensim dictionary, and convert -1 to 1 now\n",
    "        indices = [[idx if idx!=-1 else 1 for idx in row] for row in indices]\n",
    "        #print(\"---bbb---\\n\", indices)\n",
    "\n",
    "        Qs_before_padding = [torch.tensor(row) for row in indices]\n",
    "        if cfg.use_pretrained_word_embedding == None:\n",
    "            padding_value = 0\n",
    "        elif cfg.use_pretrained_word_embedding == \"GloVe\":\n",
    "            padding_value = 1  # 1 is '.', since in GloVe there is no empty word token\n",
    "        #Qs = nn.utils.rnn.pad_sequence(Qs_before_padding, batch_first=False)\n",
    "        Qs = pad_sequence_right_alignment(Qs_before_padding, batch_first=False, padding_value=padding_value)\n",
    "        \"\"\"\n",
    "        Qs, seq_lengths = preprocess_query(queries)\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "        val_pred = model(Xs, Qs, seq_lengths)\n",
    "        \n",
    "        s, t = val_pred\n",
    "        \n",
    "        proposal_chosen = torch.argmax(s, dim=1)\n",
    "        \n",
    "        gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "        bboxes_chosen_original = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "#         bboxes_chosen_refined = t[torch.arange(batch_size),proposal_chosen,:].unsqueeze(1)\n",
    "        #print(bboxes_chosen.size())\n",
    "        ious_original = IoU(bboxes_chosen_original, gt_bboxes)  \n",
    "#         ious_refined = IoU(bboxes_chosen_refined, gt_bboxes) \n",
    "        \n",
    "        #print(ious.size())\n",
    "        all_ious_original = all_ious_original + ious_original.squeeze().tolist()\n",
    "#         all_ious_refined = all_ious_refined + ious_refined.squeeze().tolist()\n",
    "        \n",
    "        counter += 1\n",
    "        #if counter%10 == 0:\n",
    "        #    print(counter)\n",
    "\n",
    "good_original = torch.tensor(all_ious_original) > 0.5     \n",
    "print(\"good bounding box based on original bounding box:\", good_original.sum())\n",
    "acc_original = good_original.sum().float()/len(validation_set)\n",
    "print(\"accuracy based on original bounding box:\", acc_original)\n",
    "\n",
    "# good_refined = torch.tensor(all_ious_refined) > 0.5\n",
    "# print(\"good bounding box refined:\", good_refined.sum())\n",
    "# acc_refined = good_refined.sum().float()/len(validation_set)\n",
    "# print(\"accuracy of refined bounding box:\", acc_refined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without pretrained embedding:\n",
    "With Wenjian's feature:\n",
    "Epochs --> accuracy based on original bounding box --> accuracy of refined bounding box\n",
    "3 epochs --> 20.30% --> 21.56% <br>\n",
    "10 epochs --> 20.16% --> 21.70% <br>\n",
    "20 epochs --> 18.88% --> 23.67%\n",
    "\n",
    "With Otani's feature:\n",
    "3 epochs --> 24.15% --> 19.12% <br>\n",
    "\n",
    "Only consider ranking loss: <br>\n",
    "3 epochs --> 57.83% (before considering multiple bounding boxes) <br>\n",
    "3 epochs --> 62.73% (after considering multiple bounding boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Random selection test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2028)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(f\"Evaluating the model on the validation set ({len(validation_set)} samples)...\")\n",
    "all_ious_original = []\n",
    "all_ious_refined = []\n",
    "counter = 0\n",
    "random.seed()\n",
    "for inputs, gt_bboxes in validation_generator:\n",
    "    Xs, queries = inputs\n",
    "    batch_size = Xs.size()[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    proposal_chosen = [random.randint(0,99) for i in range(100)]\n",
    "\n",
    "    gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "    bboxes_chosen_original = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "    #print(bboxes_chosen.size())\n",
    "    ious_original = IoU(bboxes_chosen_original, gt_bboxes)  \n",
    "\n",
    "    #print(ious.size())\n",
    "    all_ious_original = all_ious_original + ious_original.squeeze().tolist()\n",
    "\n",
    "    counter += 1\n",
    "    #if counter%10 == 0:\n",
    "    #    print(counter)\n",
    "\n",
    "good_original = torch.tensor(all_ious_original) > 0.5     \n",
    "print(\"good bounding box based on original bounding box:\", good_original.sum())\n",
    "acc_original = good_original.sum().float()/len(validation_set)\n",
    "print(\"accuracy based on original bounding box:\", acc_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the test set (14476 samples)...\n",
      "good bounding box based on original bounding box: tensor(678)\n",
      "accuracy based on original bounding box: tensor(0.0467)\n"
     ]
    }
   ],
   "source": [
    "# On test set\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'num_workers': 8}\n",
    "test_generator = data.DataLoader(test_set, shuffle=True, **params)\n",
    "\n",
    "import random\n",
    "print(f\"Evaluating the model on the test set ({len(test_set)} samples)...\")\n",
    "all_ious_original = []\n",
    "\n",
    "counter = 0\n",
    "#random.seed()\n",
    "for test_batch_counter, (inputs, gt_bboxes, _) in enumerate(test_generator):\n",
    "    Xs, queries = inputs\n",
    "    batch_size = Xs.size()[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    proposal_chosen = [random.randint(0,99) for i in range(batch_size)]\n",
    "\n",
    "    gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "    bboxes_chosen_original = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "    #print(bboxes_chosen.size())\n",
    "    ious_original = IoU(bboxes_chosen_original, gt_bboxes)  \n",
    "\n",
    "    #print(ious.size())\n",
    "    all_ious_original = all_ious_original + ious_original.squeeze().tolist()\n",
    "\n",
    "    counter += 1\n",
    "    #if counter%10 == 0:\n",
    "    #    print(counter)\n",
    "\n",
    "good_original = torch.tensor(all_ious_original) > 0.5     \n",
    "print(\"good bounding box based on original bounding box:\", good_original.sum())\n",
    "acc_original = good_original.sum().float()/len(validation_set)\n",
    "print(\"accuracy based on original bounding box:\", acc_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refined bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    all_ious = []\n",
    "    counter = 0\n",
    "    for inputs, gt_bboxes in validation_generator:\n",
    "        Xs, queries = inputs\n",
    "        batch_size = Xs.size()[0]\n",
    "        indices = [training_corpus_dct.doc2idx([stemmer.stem(w) for w in word_tokenize(q)]) for q in queries]\n",
    "        #print(\"---aaa---\\n\", indices)\n",
    "        # Gensim assign -1 to unknown word in the dictionary. \n",
    "        # Pytorch embedding, however, don't support negative index. \n",
    "        # So we kept 1 for unknown word when building Gensim dictionary, and convert -1 to 1 now\n",
    "        indices = [[idx if idx!=-1 else 1 for idx in row] for row in indices]\n",
    "        #print(\"---bbb---\\n\", indices)\n",
    "\n",
    "        Qs_before_padding = [torch.tensor(row) for row in indices]\n",
    "        Qs = nn.utils.rnn.pad_sequence(Qs_before_padding, batch_first=False)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        Xs, Qs, gt_bboxes = Xs.to(device), Qs.to(device), gt_bboxes.to(device)\n",
    "\n",
    "        val_pred = model(Xs, Qs)\n",
    "        \n",
    "        s, t = val_pred\n",
    "        #print(\"t\", t.size())\n",
    "        \n",
    "        proposal_chosen = torch.argmax(s, dim=1)\n",
    "        \n",
    "        gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "        bboxes_chosen_refined = t[torch.arange(batch_size),proposal_chosen,:].unsqueeze(1)\n",
    "        #print(bboxes_chosen.size())\n",
    "        ious = IoU(bboxes_chosen_refined, gt_bboxes)  \n",
    "        \n",
    "        #print(ious.size())\n",
    "        all_ious = all_ious + ious.squeeze().tolist()\n",
    "        \n",
    "        counter += 1\n",
    "        print(counter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3132)\n"
     ]
    }
   ],
   "source": [
    "good_refined = torch.tensor(all_ious) > 0.5\n",
    "print(good_refined.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2156)\n"
     ]
    }
   ],
   "source": [
    "print(good_refined.sum().float()/len(validation_set))\n",
    "# First try (3 epochs) --> 21.56%\n",
    "# Second try (20 epochs) --> 23.67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 , average= 1.0\n",
      "i= 100 , average= 4.554455445544554\n",
      "i= 200 , average= 4.3283582089552235\n",
      "i= 300 , average= 4.212624584717608\n",
      "i= 400 , average= 4.082294264339152\n",
      "i= 500 , average= 4.06187624750499\n",
      "i= 600 , average= 4.2579034941763725\n",
      "i= 700 , average= 4.272467902995721\n",
      "i= 800 , average= 4.253433208489389\n",
      "i= 900 , average= 4.314095449500555\n",
      "i= 1000 , average= 4.393606393606394\n",
      "i= 1100 , average= 4.464123524069028\n",
      "i= 1200 , average= 4.385512073272273\n",
      "i= 1300 , average= 4.467332820906995\n",
      "i= 1400 , average= 4.599571734475375\n",
      "i= 1500 , average= 4.574950033311126\n",
      "i= 1600 , average= 4.553404122423485\n",
      "i= 1700 , average= 4.577895355673133\n",
      "i= 1800 , average= 4.520821765685731\n",
      "i= 1900 , average= 4.52656496580747\n",
      "i= 2000 , average= 4.491754122938531\n",
      "i= 2100 , average= 4.488338886244645\n",
      "i= 2200 , average= 4.534756928668787\n",
      "i= 2300 , average= 4.515428074750108\n",
      "i= 2400 , average= 4.555601832569763\n",
      "i= 2500 , average= 4.591363454618152\n",
      "i= 2600 , average= 4.549404075355633\n",
      "i= 2700 , average= 4.611625323954091\n",
      "i= 2800 , average= 4.578364869689397\n",
      "i= 2900 , average= 4.566011720096518\n",
      "i= 3000 , average= 4.555814728423859\n",
      "i= 3100 , average= 4.547887778136085\n",
      "i= 3200 , average= 4.564511090284286\n",
      "i= 3300 , average= 4.60224174492578\n",
      "i= 3400 , average= 4.602763892972655\n",
      "i= 3500 , average= 4.592116538131962\n",
      "i= 3600 , average= 4.591502360455429\n",
      "i= 3700 , average= 4.593353147797893\n",
      "i= 3800 , average= 4.588529334385688\n",
      "i= 3900 , average= 4.589336067674955\n",
      "i= 4000 , average= 4.596600849787553\n",
      "i= 4100 , average= 4.574250182882224\n",
      "i= 4200 , average= 4.572482742204237\n",
      "i= 4300 , average= 4.564054870960242\n",
      "i= 4400 , average= 4.561463303794592\n",
      "i= 4500 , average= 4.584758942457232\n",
      "i= 4600 , average= 4.601173657900456\n",
      "i= 4700 , average= 4.610933843863008\n",
      "i= 4800 , average= 4.619870860237451\n",
      "i= 4900 , average= 4.640073454397061\n",
      "i= 5000 , average= 4.6374725054989\n",
      "i= 5100 , average= 4.627916094883356\n",
      "i= 5200 , average= 4.667179388579119\n",
      "i= 5300 , average= 4.680249009620827\n",
      "i= 5400 , average= 4.690798000370302\n",
      "i= 5500 , average= 4.710779858207599\n",
      "i= 5600 , average= 4.702731655061596\n",
      "i= 5700 , average= 4.696895281529557\n",
      "i= 5800 , average= 4.697810722289261\n",
      "i= 5900 , average= 4.687680054228097\n",
      "i= 6000 , average= 4.704715880686552\n",
      "i= 6100 , average= 4.710703163415833\n",
      "i= 6200 , average= 4.699564586357039\n",
      "i= 6300 , average= 4.701475956197429\n",
      "i= 6400 , average= 4.709889079831276\n",
      "i= 6500 , average= 4.7260421473619445\n",
      "i= 6600 , average= 4.732616270262081\n",
      "i= 6700 , average= 4.7361587822713025\n",
      "i= 6800 , average= 4.7368034112630495\n",
      "i= 6900 , average= 4.720475293435734\n",
      "i= 7000 , average= 4.72146836166262\n",
      "i= 7100 , average= 4.739332488381918\n",
      "i= 7200 , average= 4.751006804610471\n",
      "i= 7300 , average= 4.742227092179154\n",
      "i= 7400 , average= 4.734360221591677\n",
      "i= 7500 , average= 4.726169844020797\n",
      "i= 7600 , average= 4.714116563610052\n",
      "i= 7700 , average= 4.727827554863005\n",
      "i= 7800 , average= 4.717600307652865\n",
      "i= 7900 , average= 4.725730920136692\n",
      "i= 8000 , average= 4.7390326209223845\n",
      "i= 8100 , average= 4.745586964572275\n",
      "i= 8200 , average= 4.737836849164736\n",
      "i= 8300 , average= 4.738344777737622\n",
      "i= 8400 , average= 4.729317938340674\n",
      "i= 8500 , average= 4.73120809316551\n",
      "i= 8600 , average= 4.730380188350192\n",
      "i= 8700 , average= 4.7309504654637395\n",
      "i= 8800 , average= 4.723667765026701\n",
      "i= 8900 , average= 4.7346365576901475\n",
      "i= 9000 , average= 4.735473836240418\n",
      "i= 9100 , average= 4.7368421052631575\n",
      "i= 9200 , average= 4.72513857189436\n",
      "i= 9300 , average= 4.724438232448124\n",
      "i= 9400 , average= 4.725880225507924\n",
      "i= 9500 , average= 4.7276076202505\n",
      "i= 9600 , average= 4.719404228726174\n",
      "i= 9700 , average= 4.72270899907226\n",
      "i= 9800 , average= 4.723191511070299\n",
      "i= 9900 , average= 4.714877285122715\n",
      "i= 10000 , average= 4.714728527147285\n",
      "i= 10100 , average= 4.7076527076527075\n",
      "i= 10200 , average= 4.703166356239584\n",
      "i= 10300 , average= 4.696437239103\n",
      "i= 10400 , average= 4.697721372944909\n",
      "i= 10500 , average= 4.6917436434625275\n",
      "i= 10600 , average= 4.688142628053957\n",
      "i= 10700 , average= 4.678815064012709\n",
      "i= 10800 , average= 4.665586519766689\n",
      "i= 10900 , average= 4.659847720392625\n",
      "i= 11000 , average= 4.654667757476593\n",
      "i= 11100 , average= 4.654355463471759\n",
      "i= 11200 , average= 4.659048299258995\n",
      "i= 11300 , average= 4.6603840368109015\n",
      "i= 11400 , average= 4.652574335584598\n",
      "i= 11500 , average= 4.653595339535692\n",
      "i= 11600 , average= 4.641324023791053\n",
      "i= 11700 , average= 4.637808734296214\n",
      "i= 11800 , average= 4.64181001610033\n",
      "i= 11900 , average= 4.632972019158054\n",
      "i= 12000 , average= 4.634863761353221\n",
      "i= 12100 , average= 4.641434592182464\n",
      "i= 12200 , average= 4.653716908450127\n",
      "i= 12300 , average= 4.6503536297861965\n",
      "i= 12400 , average= 4.650189500846706\n",
      "i= 12500 , average= 4.649308055355571\n",
      "i= 12600 , average= 4.652567256566939\n",
      "i= 12700 , average= 4.653334383119439\n",
      "i= 12800 , average= 4.64963674712913\n",
      "i= 12900 , average= 4.656305712735447\n",
      "i= 13000 , average= 4.6581801399892315\n",
      "i= 13100 , average= 4.65346156781925\n",
      "i= 13200 , average= 4.644648132717219\n",
      "i= 13300 , average= 4.647470115028945\n",
      "i= 13400 , average= 4.64204163868368\n",
      "i= 13500 , average= 4.634249314865565\n",
      "i= 13600 , average= 4.6351738842732155\n",
      "i= 13700 , average= 4.6328005255090865\n",
      "i= 13800 , average= 4.633287442938918\n",
      "i= 13900 , average= 4.630098554060859\n",
      "i= 14000 , average= 4.6258124419684306\n",
      "i= 14100 , average= 4.628324232323949\n",
      "i= 14200 , average= 4.630237307231885\n",
      "i= 14300 , average= 4.626669463673869\n",
      "i= 14400 , average= 4.625026039858343\n",
      "i= 14500 , average= 4.626301634370043\n"
     ]
    }
   ],
   "source": [
    "# Attention! this function only work on CPU. Relaod the oringal version after using this version\n",
    "def intersect(box_a, box_b):  # Tackle with N (like 100) box pairs at the same time\n",
    "    #print(box_a.type())\n",
    "    #print(box_b.type())\n",
    "    inter_xmin=torch.max(box_a[:,:,0], box_b[:,:,0])\n",
    "    inter_xmax=torch.min(box_a[:,:,2], box_b[:,:,2])\n",
    "    inter_ymin=torch.max(box_a[:,:,1], box_b[:,:,1])\n",
    "    inter_ymax=torch.min(box_a[:,:,3], box_b[:,:,3])\n",
    "    inter = torch.max((inter_xmax-inter_xmin).float(), torch.tensor(0).float().to('cpu')) * torch.max((inter_ymax-inter_ymin).float(), torch.tensor(0).float().to('cpu'))\n",
    "    return inter\n",
    "thre = 0.5\n",
    "good_proposal = []\n",
    "for i in range(len(validation_set)):\n",
    "    iou = iou_pass_threshold(validation_set[i][0][0].unsqueeze(0),validation_set[i][1], thre)\n",
    "    \n",
    "    good_proposal.append(iou.sum())\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(\"i=\", i, \", average=\", np.array(good_proposal).mean())\n",
    "#print(\"Finally,\", counter, \"examples pass the threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05281045751633987"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.04/76.5  # There are 76.5 proposals per image on average for the whole Flickr30k dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    all_ious = []\n",
    "    counter = 0\n",
    "    for inputs, gt_bboxes in validation_generator:\n",
    "        Xs, queries = inputs\n",
    "        batch_size = Xs.size()[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        gt_bboxes = gt_bboxes.unsqueeze(1) # add a dimension 1 at the middle is to use the function IoU\n",
    "        bboxes_chosen = Xs[torch.arange(batch_size),proposal_chosen,-5:-1].unsqueeze(1)\n",
    "        #print(bboxes_chosen.size())\n",
    "        ious = IoU(bboxes_chosen, gt_bboxes)  \n",
    "        \n",
    "        #print(ious.size())\n",
    "        all_ious = all_ious + ious.squeeze().tolist()\n",
    "        \n",
    "        counter += 1\n",
    "        print(counter)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7500, 1.2500])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3,5]).float() / torch.tensor(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a>1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*(a>1.5).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array((1,2,3))\n",
    "b = np.array((4,5,6))\n",
    "c = np.array((7,8,9))\n",
    "d = np.array((10,11,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.column_stack((a,b))\n",
    "B = np.column_stack((c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB = np.column_stack((A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABA = np.column_stack((AB,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4,  7, 10,  1,  4],\n",
       "       [ 2,  5,  8, 11,  2,  5],\n",
       "       [ 3,  6,  9, 12,  3,  6]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-e23de71598de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mABA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "ABA[[1,2,3],[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],[15,16,17]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14],\n",
       "        [15, 16, 17]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0,2,1,0,2,0])\n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5,  7,  9, 14, 15])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[torch.arange(6), y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f06cc5108d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/wenjian/.local/lib/python2.7/site-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "np.stack((AB,A), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ManglingTest:\n",
    "    def __init__(self):\n",
    "        self.__mangled = 'hello'\n",
    "\n",
    "    def get_mangled(self):\n",
    "        return self.__mangled\n",
    "\n",
    "ManglingTest().get_mangled()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ManglingTest instance has no attribute '__mangled'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-0bb3c4f8d3a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mManglingTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mangled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: ManglingTest instance has no attribute '__mangled'"
     ]
    }
   ],
   "source": [
    "ManglingTest().__mangled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.repeat((4,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(4, 2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [1, 2, 3]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(4, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(4, 2, 1).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-0ed8aeb7c585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "C.a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 2 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-e2c3e9e6a185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 2 values to unpack"
     ]
    }
   ],
   "source": [
    "def myfunc():\n",
    "    a = 1\n",
    "    b = 2\n",
    "    c = 3\n",
    "    return (a,b), c\n",
    "d,e,f = myfunc()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = a.repeat(1,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4],\n",
       "         [1, 2],\n",
       "         [3, 4]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(range(1,13)).view((3,4)).float()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor(range(1,4)).unsqueeze(1).float()\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 2.0000, 3.0000, 4.0000],\n",
       "        [2.5000, 3.0000, 3.5000, 4.0000],\n",
       "        [3.0000, 3.3333, 3.6667, 4.0000]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a/b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1000, 2.1000, 3.1000, 4.1000],\n",
       "        [2.6000, 3.1000, 3.6000, 4.1000],\n",
       "        [3.1000, 3.4333, 3.7667, 4.1000]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c + torch.tensor(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.device(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_cached(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], device='cuda:0')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard.summary.writer'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-247a8ab0a07a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     raise ImportError('TensorBoard logging requires TensorBoard with Python summary writer installed. '\n\u001b[0m\u001b[1;32m      5\u001b[0m                       'This should be available in 1.14 or above.')\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy (from torch)\n",
      "  Using cached https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Installing collected packages: numpy, torch\n",
      "Successfully installed numpy-1.16.4 torch-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -U torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "m = gensim.models.KeyedVectors.load_word2vec_format('./word2vec/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectors',\n",
       " 'vocab',\n",
       " 'vector_size',\n",
       " 'index2word',\n",
       " 'vectors_norm',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " 'save_word2vec_format',\n",
       " 'load_word2vec_format',\n",
       " 'get_keras_embedding',\n",
       " 'load',\n",
       " '__init__',\n",
       " 'wv',\n",
       " 'index2entity',\n",
       " 'syn0',\n",
       " 'syn0norm',\n",
       " '__contains__',\n",
       " 'save',\n",
       " 'word_vec',\n",
       " 'get_vector',\n",
       " 'words_closer_than',\n",
       " 'most_similar',\n",
       " 'similar_by_word',\n",
       " 'similar_by_vector',\n",
       " 'similarity_matrix',\n",
       " 'wmdistance',\n",
       " 'most_similar_cosmul',\n",
       " 'doesnt_match',\n",
       " 'cosine_similarities',\n",
       " 'distances',\n",
       " 'distance',\n",
       " 'similarity',\n",
       " 'n_similarity',\n",
       " '_log_evaluate_word_analogies',\n",
       " 'evaluate_word_analogies',\n",
       " 'log_accuracy',\n",
       " 'accuracy',\n",
       " 'log_evaluate_word_pairs',\n",
       " 'evaluate_word_pairs',\n",
       " 'init_sims',\n",
       " 'relative_cosine_similarity',\n",
       " 'add',\n",
       " '__setitem__',\n",
       " '__getitem__',\n",
       " 'most_similar_to_given',\n",
       " 'closer_than',\n",
       " 'rank',\n",
       " '_load_specials',\n",
       " '_adapt_by_suffix',\n",
       " '_smart_save',\n",
       " '_save_specials',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__new__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gen():\n",
    "    for i in range(5):\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object my_gen at 0x7efc78480150>\n"
     ]
    }
   ],
   "source": [
    "print(my_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
